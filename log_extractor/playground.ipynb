{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "files = os.listdir(\"./extracted_logs\")\n",
    "prefix = \"so_\"\n",
    "files = [f for f in files if f.startswith(prefix)]\n",
    "file_heads = []\n",
    "\n",
    "for f in files:\n",
    "    print(f\"Processing {f}\")\n",
    "    df = pd.read_parquet(f\"./extracted_logs/{f}\")\n",
    "    file_heads.extend(df.head().to_dict(orient=\"records\"))\n",
    "    \n",
    "with open(f\"extracted_logs_head_sample_{prefix}latest.json\", \"w\") as f:\n",
    "    json.dump(file_heads, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "use std::fs::{File, self};\n",
       "use std::io::Write;\n",
       "use std::os::unix::prelude::PermissionsExt;\n",
       "use std::env;\n",
       "use std::path::{Path, PathBuf};\n",
       "\n",
       "\n",
       "fn main() {\n",
       "    let out_dir = env::var_os(\"CARGO_MANIFEST_DIR\").unwrap();\n",
       "    let dest_path: PathBuf = Path::new(&out_dir).join(\"target/release/Settings.toml\");\n",
       "    println!(\"{:?}\", dest_path.as_os_str());\n",
       "    let f = File::create(dest_path);\n",
       "    f.as_ref()\n",
       "    .unwrap()\n",
       "    .write_all(\"largest_number = 7\".as_bytes())\n",
       "    .unwrap();\n",
       "    set_permissions(f);\n",
       "}\n",
       "\n",
       "fn set_permissions(f: Result<File, std::io::Error>) {\n",
       "\n",
       "    f.as_ref()\n",
       "    .unwrap()\n",
       "    .metadata()\n",
       "    .unwrap()\n",
       "    .permissions()\n",
       "    .set_mode(0x777);\n",
       "\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output, display, HTML\n",
    "\n",
    "\n",
    "issues_dataset_path = \"D:\\\\Contributing\\\\issue-analysis-eval-logs\\\\data\"\n",
    "output_path = \"./log_classification_data/\"\n",
    "classification_dataset = pd.DataFrame(columns=[\"logs\", \"class\"])\n",
    "files = os.listdir(issues_dataset_path)\n",
    "num_files = len(files)\n",
    "for fi,f in enumerate(files):\n",
    "    df = pd.read_parquet(f\"{issues_dataset_path}\\\\{f}\")\n",
    "    sampled_df = df.sample(n=2)\n",
    "    for i, sample in sampled_df.iterrows():\n",
    "        clear_output(wait=True)\n",
    "        try:\n",
    "            display(HTML(sample['logs']))\n",
    "        except:\n",
    "            display(sample['logs'])\n",
    "        # 0 is log, 1 is code block\n",
    "        sampled_df.at[i,'class'] = input(\"Enter class for this sample(0,1): \")\n",
    "    \n",
    "    classification_dataset = pd.concat([classification_dataset, sampled_df])\n",
    "    if (fi+1) % 25 == 0:\n",
    "        classification_dataset.to_parquet(f\"{output_path}classification_dataset_checkpoint_{fi+1}.parquet\")\n",
    "classification_dataset.to_parquet(f\"{output_path}classification_dataset.parquet\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
